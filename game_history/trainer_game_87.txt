 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[289.69705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    4  -30    0    0   20  -30    0    0    0   -1    0    0
    0    0] 
sum of rewards: -542 

action type: buy - action 0.0
Learning step: -26.78571891784668
desired expected reward: -33.071380615234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[263.2857 ]
 [281.17093]
 [274.11127]
 [224.71944]
 [270.73718]
 [290.9699 ]
 [275.93808]
 [274.7524 ]
 [243.27266]
 [271.12735]
 [262.0809 ]
 [294.42987]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.606949806213379
desired expected reward: 284.7744445800781



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[322.99112]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.506186008453369
desired expected reward: 286.9236145019531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[293.75928]
 [312.46182]
 [304.16208]
 [254.91843]
 [321.20197]
 [307.12585]
 [300.73474]
 [323.41278]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.463122367858887
desired expected reward: 315.6615295410156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  3.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[324.037]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.957813262939453
desired expected reward: 314.4549560546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[296.14523]
 [312.00662]
 [304.962  ]
 [262.55334]
 [302.81497]
 [320.2897 ]
 [307.79413]
 [306.69858]
 [278.7218 ]
 [302.7863 ]
 [294.61166]
 [323.09314]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.480426788330078
desired expected reward: 315.5340576171875



buy possibilites: [-1] 
expected returns: [[319.03702]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -9.228930473327637
desired expected reward: 286.91632080078125






Player: 1 
cards in hand: [ 0.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[332.87076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [11. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.547303199768066
desired expected reward: 310.4897155761719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[299.93832]
 [319.81268]
 [312.06418]
 [259.89258]
 [329.65353]
 [313.42194]
 [307.80844]
 [333.13037]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [11. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.709818840026855
desired expected reward: 323.82562255859375



buy possibilites: [-1] 
expected returns: [[335.11652]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [11. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -9.056796073913574
desired expected reward: 290.8815612792969






Player: 1 
cards in hand: [ 0.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [11. 10.  0.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [11. 10.  0.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [11. 10.  0.  0.  3.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 11  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[312.1868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 11  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.797355651855469
desired expected reward: 325.31915283203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[275.00702]
 [292.61752]
 [285.52377]
 [238.80151]
 [282.48682]
 [300.7387 ]
 [287.37512]
 [286.2172 ]
 [255.86185]
 [282.07275]
 [273.05112]
 [303.9678 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 11  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.374561309814453
desired expected reward: 304.3352355957031



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 11.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 11  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[353.26462]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.358979225158691
desired expected reward: 296.60882568359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[318.19012]
 [336.72754]
 [329.25708]
 [280.84872]
 [325.88904]
 [346.05066]
 [330.96213]
 [329.6868 ]
 [298.67197]
 [325.3831 ]
 [316.27307]
 [349.84085]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.339920997619629
desired expected reward: 342.52276611328125



buy possibilites: [-1] 
expected returns: [[325.63626]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -22.365619659423828
desired expected reward: 258.48309326171875






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  8. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[337.0864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -9.44383716583252
desired expected reward: 316.1924133300781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[301.8692 ]
 [316.45035]
 [310.56396]
 [273.50064]
 [324.1262 ]
 [311.69278]
 [307.4879 ]
 [327.31546]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -10.254690170288086
desired expected reward: 322.5442199707031



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 6. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 6. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 6. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 6. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[284.28024]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 6. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -9.55372428894043
desired expected reward: 296.5238037109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[251.97672]
 [269.5702 ]
 [263.15753]
 [216.08447]
 [259.29742]
 [278.9084 ]
 [263.7112 ]
 [262.58664]
 [233.37761]
 [259.2621 ]
 [250.46576]
 [282.8294 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 6. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -8.965660095214844
desired expected reward: 275.48553466796875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [ 8. 10.  0.  0.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [ 8. 10.  0.  0.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [ 8. 10.  0.  0.  3.  3.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[283.79535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8 15] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -8.494678497314453
desired expected reward: 274.3347473144531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[250.25792]
 [263.55356]
 [258.66382]
 [218.90953]
 [255.77827]
 [271.1324 ]
 [259.1617 ]
 [258.35208]
 [234.55464]
 [256.03336]
 [249.47047]
 [274.75897]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8 15] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -8.832695960998535
desired expected reward: 271.0247802734375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[308.43643]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  3.  8.  0. 15.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8 15] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -7.447953701019287
desired expected reward: 267.3110656738281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[275.48404]
 [291.9571 ]
 [285.90173]
 [242.75407]
 [301.0169 ]
 [286.67203]
 [282.7322 ]
 [305.12265]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  3.  8.  0. 15.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8 15] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.590217590332031
desired expected reward: 298.8541564941406



buy possibilites: [-1] 
expected returns: [[306.01382]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  3.  8.  0. 15.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8 15] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -43.0 

action type: buy - action 0.0
Learning step: -9.03889274597168
desired expected reward: 266.4451904296875






Player: 1 
cards in hand: [ 8.  3.  8.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8.  0. 15.] 
cards in discard: [ 0.  3.  0.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  8.  0. 15.] 
cards in discard: [ 0.  3.  0.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  8.  0. 15.] 
cards in discard: [ 0.  3.  0.  0. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8 15  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0] -> size -> 14 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[269.4163]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.  0.  8.  3.  8.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8 15  0] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -9.906607627868652
desired expected reward: 296.1072082519531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[236.9646 ]
 [250.8401 ]
 [245.1347 ]
 [209.4605 ]
 [242.83365]
 [259.66745]
 [246.62979]
 [245.7595 ]
 [222.82071]
 [242.69576]
 [235.74556]
 [263.65463]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.  0.  8.  3.  8.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8 15  0] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -8.543853759765625
desired expected reward: 260.0821228027344



buy possibilites: [-1] 
expected returns: [[252.17319]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 30. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.  0.  8.  3.  8.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8 15  0] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -11.0 

action type: buy - action 8.0
Learning step: -7.207592010498047
desired expected reward: 239.42218017578125






Player: 1 
cards in hand: [ 0.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [ 0.  3.  0.  0. 11.  0.  8.  3.  8.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8 15  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8] -> size -> 15 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  8  0  0  8 15  0] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8] -> size -> 15 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 3 
card supply: [24. 30. 30. 30. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8] -> size -> 15 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 30. 30. 30. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8] -> size -> 15 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[261.96735]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 0. 0. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  3. 11.  0.  8.] 
adversary cards in discard: [10. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -7.431283473968506
desired expected reward: 244.7418975830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[232.97517]
 [249.93996]
 [241.8647 ]
 [198.61446]
 [239.90797]
 [257.36414]
 [245.25633]
 [243.69495]
 [214.19739]
 [238.76715]
 [230.19751]
 [258.0558 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 0. 0. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 30. 30. 30. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  3. 11.  0.  8.] 
adversary cards in discard: [10. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -8.164390563964844
desired expected reward: 250.830078125



buy possibilites: [-1] 
expected returns: [[278.69955]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 0. 0. 0. 0. 3. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 30. 30.  8.  9. 10.  8.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  3. 11.  0.  8.] 
adversary cards in discard: [10. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -11.0 

action type: buy - action 8.0
Learning step: -6.542076110839844
desired expected reward: 238.7142333984375






Player: 1 
cards in hand: [ 8.  3. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.  0.  8.] 
cards in discard: [10. 15.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  9. 10.  8.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8] -> size -> 16 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 8.] 
cards in discard: [10. 15.  0.  0.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8] -> size -> 16 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 8.] 
cards in discard: [10. 15.  0.  0.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8] -> size -> 16 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 8.] 
cards in discard: [10. 15.  0.  0.  3. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0 11  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8] -> size -> 16 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[235.58017]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10. 15.  0.  0.  3. 11.  0. 11.  8.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0 11  0] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -9.28686237335205
desired expected reward: 269.4126892089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[209.60669]
 [218.97104]
 [181.48117]
 [219.58524]
 [235.6219 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10. 15.  0.  0.  3. 11.  0. 11.  8.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0 11  0] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.530725002288818
desired expected reward: 227.94105529785156



buy possibilites: [-1] 
expected returns: [[256.53455]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10. 15.  0.  0.  3. 11.  0. 11.  8.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0 11  0] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -43.0 

action type: buy - action 0.0
Learning step: -6.562221050262451
desired expected reward: 203.04443359375






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10. 15.  0.  0.  3. 11.  0. 11.  8.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0 11  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 6. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0] -> size -> 17 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10. 15.  0.  0.  3. 11.  0. 11.  8.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0 11  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 6. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0] -> size -> 17 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[234.79034]
 [222.0807 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 6. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10. 15.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0 11  0] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.283487319946289
desired expected reward: 248.2510528564453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[218.0225 ]
 [234.25267]
 [226.8944 ]
 [184.241  ]
 [241.29466]
 [229.43527]
 [223.6135 ]
 [243.16017]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 6. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10. 15.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0 11  0] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.314810276031494
desired expected reward: 228.86871337890625



buy possibilites: [-1] 
expected returns: [[227.96101]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 6. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10. 15.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0 11  0] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -43.0 

action type: buy - action 0.0
Learning step: -7.922003269195557
desired expected reward: 210.1005096435547






Player: 1 
cards in hand: [10. 15.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 11  8  0  0  8 15  0 11  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [0. 3. 0. 6. 0. 3. 0. 8. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0] -> size -> 18 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 10 11  8  0  0  8  0 11  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [0. 3. 0. 6. 0. 3. 0. 8. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0] -> size -> 18 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 10 11  8  0  0  8  0 11  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [0. 3. 0. 6. 0. 3. 0. 8. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0] -> size -> 18 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[253.47664]
 [237.73267]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [0. 3. 0. 6. 0. 3. 0. 8. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 10 11  8  0  0  8  0 11  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -6.5171098709106445
desired expected reward: 221.44390869140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[230.79092]
 [245.4525 ]
 [239.78804]
 [206.11061]
 [236.7688 ]
 [253.53893]
 [240.79663]
 [239.77924]
 [217.33046]
 [237.17287]
 [230.09758]
 [256.79214]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [0. 3. 0. 6. 0. 3. 0. 8. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 10 11  8  0  0  8  0 11  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.858126163482666
desired expected reward: 244.4046173095703



buy possibilites: [-1] 
expected returns: [[224.9057]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [0. 3. 0. 6. 0. 3. 0. 8. 0. 0. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0] -> size -> 19 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 10 11  8  0  0  8  0 11  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -43.0 

action type: buy - action 0.0
Learning step: -8.629167556762695
desired expected reward: 222.1617431640625






Player: 1 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 8. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10 11  8  0  0  8  0 11  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0] -> size -> 19 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0] -> size -> 19 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0] -> size -> 19 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[256.086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  3. 11.] 
adversary cards in discard: [ 8. 10.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -6.147615432739258
desired expected reward: 218.75808715820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[230.72588]
 [246.46576]
 [241.2191 ]
 [190.66013]
 [254.20244]
 [241.24948]
 [237.65216]
 [258.04022]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  3. 11.] 
adversary cards in discard: [ 8. 10.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.988108158111572
desired expected reward: 247.4638671875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3. 11.] 
cards in discard: [ 8. 10.  0.  8.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [0. 3. 0. 6. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0] -> size -> 19 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3. 11.] 
cards in discard: [ 8. 10.  0.  8.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 30. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [0. 3. 0. 6. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0] -> size -> 19 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3. 11.] 
cards in discard: [ 8. 10.  0.  8.  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 29. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [0. 3. 0. 6. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0] -> size -> 19 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[201.86829]
 [191.7006 ]
 [191.7006 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [0. 3. 0. 6. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 29. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -9.647273063659668
desired expected reward: 248.39297485351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[182.2623 ]
 [195.56375]
 [188.51216]
 [155.23659]
 [201.49533]
 [191.74599]
 [186.01654]
 [202.7368 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [0. 3. 0. 6. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 29. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -6.915809631347656
desired expected reward: 194.27597045898438



buy possibilites: [-1] 
expected returns: [[215.37509]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [0. 3. 0. 6. 0. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 29. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -5 

action type: buy - action 1.0
Learning step: -5.182248592376709
desired expected reward: 190.3815155029297






Player: 1 
cards in hand: [ 0. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 29. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 6. 0. 1. 0. 0. 8. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1] -> size -> 20 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 29. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 6. 0. 1. 0. 0. 8. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1] -> size -> 20 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 29. 30. 29. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 6. 0. 1. 0. 0. 8. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1] -> size -> 20 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 28. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 6. 0. 1. 0. 0. 8. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1] -> size -> 20 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[203.30408]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 6. 0. 1. 0. 0. 8. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 28. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  3.  3.] 
adversary cards in discard: [ 3. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3  3] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -7.843926429748535
desired expected reward: 207.53115844726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[186.47604]
 [201.31764]
 [194.62865]
 [167.16817]
 [156.90373]
 [192.52667]
 [207.79189]
 [197.28088]
 [217.10437]
 [196.00955]
 [170.53308]
 [178.67296]
 [192.57681]
 [163.62672]
 [184.99019]
 [209.03163]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 6. 0. 1. 0. 0. 8. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 29. 30. 28. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  3.  3.] 
adversary cards in discard: [ 3. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3  3] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -7.448623180389404
desired expected reward: 195.8770751953125



buy possibilites: [-1] 
expected returns: [[174.68564]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 6. 0. 1. 0. 0. 8. 8. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1 3] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 29. 30. 27. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  3.  3.] 
adversary cards in discard: [ 3. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -20.0 

action type: buy - action 3.0
Learning step: -6.801004886627197
desired expected reward: 187.82762145996094






Player: 1 
cards in hand: [ 3. 11.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.  3.] 
cards in discard: [ 3. 10.  0.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  9. 10.  7.  6. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1 3] -> size -> 21 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 3. 10.  0.  0.  3.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3  3 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1 3] -> size -> 21 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 3. 10.  0.  0.  3.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3  3 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1 3] -> size -> 21 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[186.6283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1 3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3  3 29] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -5.683591842651367
desired expected reward: 169.00204467773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[161.92415]
 [175.24881]
 [169.15378]
 [136.00664]
 [181.59798]
 [171.55879]
 [166.97594]
 [183.33942]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1 3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 29. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3  3 29] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -6.472267150878906
desired expected reward: 178.00283813476562



buy possibilites: [-1] 
expected returns: [[110.05812]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3  3 29] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -4 

action type: buy - action 1.0
Learning step: -6.11041784286499
desired expected reward: 161.6240997314453






Player: 1 
cards in hand: [ 0.  0. 11.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10 11  8  0  0  8  0 11  0  3  3 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 22 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 22 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 22 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 22 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[242.06308]
 [225.63208]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 0.  8. 11.] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -1.3182861804962158
desired expected reward: 108.73983764648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[218.06438]
 [238.4708 ]
 [229.75769]
 [172.00606]
 [226.82863]
 [247.40334]
 [233.08798]
 [231.22107]
 [193.05344]
 [225.75931]
 [214.51077]
 [249.02126]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 28. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 0.  8. 11.] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -8.01821517944336
desired expected reward: 233.07894897460938



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 0.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3. 0. 8. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 22 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 0.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3. 0. 8. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 22 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 0.  8. 11.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3. 0. 8. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 22 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [8. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[179.67207]
 [165.63295]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3. 0. 8. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  3. 29.  3.] 
adversary cards in discard: [ 0.  8. 11.  1.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -9.753825187683105
desired expected reward: 239.26739501953125



action possibilites: [-1] 
expected returns: [[237.56918]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3. 0. 8. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  3. 29.  3.] 
adversary cards in discard: [ 0.  8. 11.  1.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: trash_cards_n_from_hand - action 3
Learning step: -3.965048313140869
desired expected reward: 158.24205017089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[218.20494]
 [226.38947]
 [190.5785 ]
 [227.53413]
 [240.62001]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3. 0. 8. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 27. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  3. 29.  3.] 
adversary cards in discard: [ 0.  8. 11.  1.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -8.025805473327637
desired expected reward: 229.5433807373047






Player: 1 
cards in hand: [11.  0.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 29.  3.] 
cards in discard: [ 0.  8. 11.  1.  0.  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3. 0. 8. 0. 0. 0. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 20 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 29.  3.] 
cards in discard: [ 0.  8. 11.  1.  0.  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3. 0. 8. 0. 0. 0. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 20 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 29.  3.] 
cards in discard: [ 0.  8. 11.  1.  0.  0.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3. 0. 8. 0. 0. 0. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 20 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[219.61218]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3. 0. 8. 0. 0. 0. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1. 29.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -9.385708808898926
desired expected reward: 231.23428344726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[199.5468 ]
 [210.77966]
 [205.39171]
 [177.46672]
 [204.02933]
 [218.52902]
 [207.72778]
 [206.88779]
 [187.99138]
 [204.2257 ]
 [198.54994]
 [220.78679]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3. 0. 8. 0. 0. 0. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 0 0 6 0 8 8 0 0 0 1 3 1] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 27. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1. 29.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -8.312738418579102
desired expected reward: 207.03353881835938



buy possibilites: [-1] 
expected returns: [[202.97578]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 1.  0.  3.  0.  0.  3.  0.  8.  0.  0.  0.  8.  0.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 1. 29.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -12 

action type: buy - action 15.0
Learning step: -5.96054220199585
desired expected reward: 192.5894012451172






Player: 1 
cards in hand: [ 1. 29.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15] -> size -> 21 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 27. 30. 27. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15] -> size -> 21 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0.  3. 10.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 26. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15] -> size -> 21 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[160.96852]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  3.  0. 11.  0.] 
adversary cards in discard: [ 3.  1. 29.  0.  3. 10.] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -9.217141151428223
desired expected reward: 193.75863647460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[147.19743]
 [159.04852]
 [152.80806]
 [130.6823 ]
 [120.4256 ]
 [152.19287]
 [164.2783 ]
 [155.93222]
 [174.75232]
 [154.91779]
 [133.06868]
 [139.95143]
 [151.02019]
 [127.19885]
 [144.83702]
 [165.75188]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 27. 30. 26. 30.  8.  9. 10.  7.  6. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  3.  0. 11.  0.] 
adversary cards in discard: [ 3.  1. 29.  0.  3. 10.] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -7.31591796875
desired expected reward: 154.09068298339844



buy possibilites: [-1] 
expected returns: [[186.88771]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  9. 10.  7.  6.  9.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  3.  0. 11.  0.] 
adversary cards in discard: [ 3.  1. 29.  0.  3. 10.] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: -4 

action type: buy - action 25.0
Learning step: -4.732640266418457
desired expected reward: 170.01963806152344






Player: 1 
cards in hand: [ 3.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.  0.] 
cards in discard: [ 3.  1. 29.  0.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  9. 10.  7.  6.  9.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [25.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25] -> size -> 22 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 3.  1. 29.  0.  3. 10. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  9. 10.  7.  6.  9.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [25.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25] -> size -> 22 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 3.  1. 29.  0.  3. 10. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 26. 30.  8.  9. 10.  7.  6.  9.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [25.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25] -> size -> 22 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 3.  1. 29.  0.  3. 10. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3 29  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 27. 30. 26. 30.  8.  9. 10.  7.  6.  9.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [25.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25] -> size -> 22 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[154.7879]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [25.  0.  0.  3.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  9. 10.  7.  6.  9.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0. 11.  8.  0.] 
adversary cards in discard: [ 3.  1. 29.  0.  3. 10. 29.  0. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3 29  0] -> size -> 20 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -8.7056245803833
desired expected reward: 178.1820831298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[126.06618]
 [145.91968]
 [137.71243]
 [ 88.3932 ]
 [133.74765]
 [155.15887]
 [138.99925]
 [137.23395]
 [105.48296]
 [132.74171]
 [123.38492]
 [156.63072]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [25.  0.  0.  3.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 30. 26. 30.  8.  9. 10.  7.  6.  9.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0. 11.  8.  0.] 
adversary cards in discard: [ 3.  1. 29.  0.  3. 10. 29.  0. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3 29  0] -> size -> 20 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -7.045056343078613
desired expected reward: 141.3443145751953



buy possibilites: [-1] 
expected returns: [[163.156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [25.  0.  0.  3.  0.  1. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  9. 10.  7.  6.  9.  7. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0. 11.  8.  0.] 
adversary cards in discard: [ 3.  1. 29.  0.  3. 10. 29.  0. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3 29  0] -> size -> 20 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -22 

action type: buy - action 29.0
Learning step: -4.081231594085693
desired expected reward: 133.1527557373047






Player: 1 
cards in hand: [ 3.  0. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  8.  0.] 
cards in discard: [ 3.  1. 29.  0.  3. 10. 29.  0. 11.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3 29  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  9. 10.  7.  6.  9.  7. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  8.  0.  0.  0.] 
adversary cards in discard: [25.  0.  0.  3.  0.  1. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29] -> size -> 23 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [ 3.  1. 29.  0.  3. 10. 29.  0. 11.  3.  3.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  8.  0.  0.  0.] 
adversary cards in discard: [25.  0.  0.  3.  0.  1. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29] -> size -> 23 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [ 3.  1. 29.  0.  3. 10. 29.  0. 11.  3.  3.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 26. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  8.  0.  0.  0.] 
adversary cards in discard: [25.  0.  0.  3.  0.  1. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29] -> size -> 23 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [15.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[216.41122]
 [199.44037]
 [209.4908 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  0.  0.] 
cards in discard: [25.  0.  0.  3.  0.  1. 29.  3.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 21 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -6.1748948097229
desired expected reward: 156.98110961914062



action possibilites: [-1] 
expected returns: [[170.98074]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.] 
cards in discard: [25.  0.  0.  3.  0.  1. 29.  3.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 21 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: trash_cards_n_from_hand - action 0
Learning step: -7.712148189544678
desired expected reward: 189.47215270996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[152.3487 ]
 [161.87695]
 [124.79738]
 [161.40617]
 [173.90936]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.] 
cards in discard: [25.  0.  0.  3.  0.  1. 29.  3.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 26. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 21 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1
Learning step: -6.680844306945801
desired expected reward: 164.29989624023438



buy possibilites: [-1] 
expected returns: [[140.92786]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.] 
cards in discard: [25.  0.  0.  3.  0.  1. 29.  3.  0.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -15 

action type: buy - action 3.0
Learning step: -5.672970294952393
desired expected reward: 156.20396423339844






Player: 1 
cards in hand: [8. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 10 11  0  0  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 6. 1.] 
adversary cards in discard: [25.  0.  0.  3.  0.  1. 29.  3.  0.  0.  0.  0.  3.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3] -> size -> 23 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 6. 1.] 
adversary cards in discard: [25.  0.  0.  3.  0.  1. 29.  3.  0.  0.  0.  0.  3.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 6. 1.] 
adversary cards in discard: [25.  0.  0.  3.  0.  1. 29.  3.  0.  0.  0.  0.  3.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[170.66011]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 1.] 
cards in discard: [25.  0.  0.  3.  0.  1. 29.  3.  0.  0.  0.  0.  3.  8. 15.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 29. 11.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -4.390268325805664
desired expected reward: 136.53758239746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[156.65219]
 [165.79692]
 [162.73192]
 [145.12427]
 [139.63052]
 [160.46495]
 [171.00197]
 [162.34904]
 [179.05367]
 [161.76924]
 [147.80794]
 [153.50562]
 [160.40462]
 [143.77463]
 [156.20074]
 [174.10518]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 1.] 
cards in discard: [25.  0.  0.  3.  0.  1. 29.  3.  0.  0.  0.  0.  3.  8. 15.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 27. 30. 25. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 29. 11.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -5.946542263031006
desired expected reward: 163.21453857421875



buy possibilites: [-1] 
expected returns: [[62.840855]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 1.] 
cards in discard: [25.  0.  0.  3.  0.  1. 29.  3.  0.  0.  0.  0.  3.  8. 15.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 27. 30. 24. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 29. 11.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -10.0 

action type: buy - action 3.0
Learning step: -7.2226762771606445
desired expected reward: 155.5092315673828






Player: 1 
cards in hand: [ 0. 29.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29. 11.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3] -> size -> 24 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 29. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 11. 29.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 24. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3] -> size -> 24 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29.  1.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [17. 27. 30. 24. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 29.  1.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [17. 27. 30. 24. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[115.169205]
 [104.223724]
 [104.223724]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [ 8. 29. 29.  0.  0. 11. 29.  1.] 
adversary owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -1.2940071821212769
desired expected reward: 61.54684829711914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[101.06034 ]
 [106.73292 ]
 [ 86.369774]
 [106.2613  ]
 [118.52502 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 24. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [ 8. 29. 29.  0.  0. 11. 29.  1.] 
adversary owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -3.939915418624878
desired expected reward: 110.8587646484375



buy possibilites: [-1] 
expected returns: [[132.15312]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 8.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 27. 30. 24. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [ 8. 29. 29.  0.  0. 11. 29.  1.] 
adversary owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -42.0 

action type: buy - action 0.0
Learning step: -4.179572105407715
desired expected reward: 96.88076782226562






Player: 1 
cards in hand: [ 0.  3.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [ 8. 29. 29.  0.  0. 11. 29.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 24. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  0.  6.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 8. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [ 8. 29. 29.  0.  0. 11. 29.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 24. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  0.  6.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 8. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [ 8. 29. 29.  0.  0. 11. 29.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  0.  6.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 8. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [15.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[71.18503 ]
 [55.899677]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  6.  0.  0.] 
cards in discard: [0. 3. 0. 0. 8. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  3.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -6.256645202636719
desired expected reward: 125.89647674560547



action possibilites: [-1] 
expected returns: [[257.7399]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [0. 3. 0. 0. 8. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 27. 30. 23. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  3.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action 15.0
Learning step: 2.9104387760162354
desired expected reward: 58.68461227416992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[246.55463]
 [254.92065]
 [252.02545]
 [235.45053]
 [229.71562]
 [250.03612]
 [259.1246 ]
 [251.87918]
 [264.6402 ]
 [251.25719]
 [237.72005]
 [243.12463]
 [249.89186]
 [233.99046]
 [245.76746]
 [260.84   ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [0. 3. 0. 0. 8. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 27. 30. 23. 30.  8.  9. 10.  7.  6.  9.  6. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  3.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1
Learning step: -7.335078716278076
desired expected reward: 250.40481567382812



buy possibilites: [-1] 
expected returns: [[137.01031]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 0.  3.  0.  0.  8.  8. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 23. 30.  8.  9. 10.  7.  6.  9.  5. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  3.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -20.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: 6.0 

action type: buy - action 29.0
Learning step: -9.180127143859863
desired expected reward: 242.07704162597656






Player: 1 
cards in hand: [29.  3.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 30.  8.  9. 10.  7.  6.  9.  5. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29] -> size -> 25 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 23. 30.  8.  9. 10.  7.  6.  9.  5. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29] -> size -> 25 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  1. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3] -> size -> 18 
action values: 2 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 23. 30.  8.  9. 10.  7.  6.  9.  5. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29] -> size -> 25 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 23. 30.  8.  9. 10.  7.  6.  9.  4. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29] -> size -> 25 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 27. 30. 23. 30.  8.  9. 10.  7.  6.  9.  4. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29] -> size -> 25 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1.] 
cards in discard: [29. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 30.  8.  9.  9.  7.  6.  9.  4. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29] -> size -> 25 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[84.822426]
 [90.29975 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 25.] 
cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 30.  8.  9.  9.  7.  6.  9.  4. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29. 29.  0.  3.  0.] 
adversary cards in discard: [29. 16. 29. 10. 11.  3.  0.  3.  1.] 
adversary owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -5.987062931060791
desired expected reward: 131.02325439453125



action possibilites: [-1] 
expected returns: [[101.91716]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 30.  8.  8.  9.  7.  6.  9.  4. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29. 29.  0.  3.  0.] 
adversary cards in discard: [29. 16. 29. 10. 11.  3.  0.  3.  1.  6.] 
adversary owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: 0 

action type: take_action - action 25.0
Learning step: -1.9542573690414429
desired expected reward: 82.99361419677734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[74.810905]
 [85.42424 ]
 [81.463036]
 [60.74765 ]
 [55.197456]
 [79.17906 ]
 [90.033394]
 [81.64217 ]
 [97.47719 ]
 [80.641685]
 [63.092964]
 [69.9819  ]
 [78.48799 ]
 [59.09764 ]
 [73.17006 ]
 [90.723495]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 27. 30. 23. 30.  8.  8.  9.  7.  6.  9.  4. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29. 29.  0.  3.  0.] 
adversary cards in discard: [29. 16. 29. 10. 11.  3.  0.  3.  1.  6.] 
adversary owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1
Learning step: -3.3856353759765625
desired expected reward: 98.53152465820312



buy possibilites: [-1] 
expected returns: [[142.36539]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 27. 30. 23. 30.  8.  8.  9.  7.  5.  9.  4. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29. 29.  0.  3.  0.] 
adversary cards in discard: [29. 16. 29. 10. 11.  3.  0.  3.  1.  6.] 
adversary owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -20.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -0.8788871765136719
desired expected reward: 80.76327514648438






Player: 1 
cards in hand: [29. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  3.  0.] 
cards in discard: [29. 16. 29. 10. 11.  3.  0.  3.  1.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 30.  8.  8.  9.  7.  5.  9.  4. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  0.  3.  0.  1.] 
adversary cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.  8. 25.  0.  3.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8] -> size -> 26 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  3.] 
cards in discard: [29. 16. 29. 10. 11.  3.  0.  3.  1.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 23. 30.  8.  8.  9.  7.  5.  9.  4. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  0.  3.  0.  1.] 
adversary cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.  8. 25.  0.  3.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8] -> size -> 26 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [29. 16. 29. 10. 11.  3.  0.  3.  1.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [16. 27. 30. 23. 30.  8.  8.  9.  7.  5.  9.  4. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  0.  3.  0.  1.] 
adversary cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.  8. 25.  0.  3.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8] -> size -> 26 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [29. 16. 29. 10. 11.  3.  0.  3.  1.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 27. 30. 23. 30.  8.  8.  9.  7.  5.  9.  4. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  0.  3.  0.  1.] 
adversary cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.  8. 25.  0.  3.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8] -> size -> 26 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [29. 16. 29. 10. 11.  3.  0.  3.  1.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 27. 30. 23. 30.  8.  8.  9.  7.  5.  9.  4. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  0.  3.  0.  1.] 
adversary cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.  8. 25.  0.  3.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8] -> size -> 26 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [29. 16. 29. 10. 11.  3.  0.  3.  1.  6.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 23. 30.  8.  8.  9.  7.  5.  9.  4. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  0.  3.  0.  1.] 
adversary cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.  8. 25.  0.  3.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8] -> size -> 26 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [29.  0.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[27.913452]
 [22.197779]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  1.] 
cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.  8. 25.  0.  3.  0.  0.  0.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 30.  8.  8.  9.  7.  5.  9.  4. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  0.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -7.141961097717285
desired expected reward: 135.22341918945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.785007 ]
 [24.466677 ]
 [23.6098   ]
 [10.6152525]
 [21.204544 ]
 [27.333788 ]
 [21.61919  ]
 [21.534702 ]
 [14.360147 ]
 [22.222996 ]
 [19.77512  ]
 [28.806822 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  1.] 
cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.  8. 25.  0.  3.  0.  0.  0.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 26. 30. 23. 30.  8.  8.  9.  7.  5.  9.  4. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  0.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -1.4853466749191284
desired expected reward: 26.42808723449707



buy possibilites: [-1] 
expected returns: [[131.81166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  1.] 
cards in discard: [ 0.  3.  0.  0.  8.  8. 29. 15.  6.  0.  0.  8. 25.  0.  3.  0.  0.  0.
  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 30.  8.  8.  9.  7.  5.  9.  4.  9. 10.  9. 10.  8.] 
adversary cards in hand: [29.  0.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 20 

action type: buy - action 14.0
Learning step: 3.2477569580078125
desired expected reward: 17.607868194580078






Player: 1 
cards in hand: [29.  0.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 30.  8.  8.  9.  7.  5.  9.  4.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14] -> size -> 27 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 23. 30.  8.  8.  9.  7.  5.  9.  4.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14] -> size -> 27 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 23. 30.  8.  8.  9.  7.  5.  9.  4.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14] -> size -> 27 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 26. 30. 23. 30.  8.  8.  9.  7.  5.  9.  4.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14] -> size -> 27 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 26. 30. 23. 30.  8.  8.  9.  7.  4.  9.  4.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14] -> size -> 27 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[120.73965]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 30.  8.  8.  9.  7.  4.  9.  4.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29. 11.  3. 29.] 
adversary cards in discard: [ 8. 29.  8.  0.  0.  0.] 
adversary owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -4.035212516784668
desired expected reward: 127.77645111083984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[118.05319 ]
 [127.91469 ]
 [124.096535]
 [104.57536 ]
 [ 97.26888 ]
 [122.182045]
 [133.1246  ]
 [124.79077 ]
 [141.13293 ]
 [124.015884]
 [107.341965]
 [113.41402 ]
 [122.20607 ]
 [102.49551 ]
 [117.161674]
 [135.28761 ]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 26. 30. 23. 30.  8.  8.  9.  7.  4.  9.  4.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29. 11.  3. 29.] 
adversary cards in discard: [ 8. 29.  8.  0.  0.  0.] 
adversary owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -3.2135531902313232
desired expected reward: 114.80291748046875



buy possibilites: [-1] 
expected returns: [[161.3158]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [4.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 29.  8.  8.  9.  7.  4.  9.  4.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29. 11.  3. 29.] 
adversary cards in discard: [ 8. 29.  8.  0.  0.  0.] 
adversary owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8] -> size -> 23 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 81 

action type: buy - action 4.0
Learning step: 2.4508373737335205
desired expected reward: 107.02619171142578






Player: 1 
cards in hand: [ 0. 29. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  3. 29.] 
cards in discard: [ 8. 29.  8.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 29.  8.  8.  9.  7.  4.  9.  4.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 29.  0. 29.] 
adversary cards in discard: [4. 0. 0. 0. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4] -> size -> 28 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 29.] 
cards in discard: [ 8. 29.  8.  0.  0.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 29.  8.  8.  9.  7.  4.  9.  3.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 29.  0. 29.] 
adversary cards in discard: [4. 0. 0. 0. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4] -> size -> 28 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 29.] 
cards in discard: [ 8. 29.  8.  0.  0.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 23. 29.  8.  8.  9.  7.  4.  9.  3.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 29.  0. 29.] 
adversary cards in discard: [4. 0. 0. 0. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4] -> size -> 28 
adversary victory points: 6
player victory points: 3 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[99.83481 ]
 [86.701096]
 [86.701096]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0. 29.] 
cards in discard: [4. 0. 0. 0. 3. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 29.  8.  8.  9.  7.  4.  9.  3.  9. 10.  9. 10.  8.] 
adversary cards in hand: [11.  1.  3.  3.  3.] 
adversary cards in discard: [ 8. 29.  8.  0.  0.  0. 29. 11.  0. 29.  3. 29.] 
adversary owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: buy - action -1
Learning step: -4.46434211730957
desired expected reward: 156.85145568847656



action possibilites: [-1. 29.] 
expected returns: [[183.90291]
 [172.37859]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [4. 0. 0. 0. 3. 1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 23. 29.  8.  8.  9.  7.  4.  9.  3.  9. 10.  9. 10.  8.] 
adversary cards in hand: [11.  1.  3.  3.  3.] 
adversary cards in discard: [ 8. 29.  8.  0.  0.  0. 29. 11.  0. 29.  3. 29.] 
adversary owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action 29.0
Learning step: 2.329103469848633
desired expected reward: 87.41675567626953



action possibilites: [-1.] 
expected returns: [[149.51782]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [4. 0. 0. 0. 3. 1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [15. 26. 30. 23. 29.  8.  8.  9.  7.  4.  9.  3.  9. 10.  9. 10.  8.] 
adversary cards in hand: [11.  1.  3.  3.  3.] 
adversary cards in discard: [ 8. 29.  8.  0.  0.  0. 29. 11.  0. 29.  3. 29.] 
adversary owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action 29.0
Learning step: -1.704779863357544
desired expected reward: 170.67384338378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[144.10046]
 [149.45093]
 [147.44742]
 [137.00809]
 [133.19241]
 [146.38   ]
 [152.15752]
 [147.3975 ]
 [156.24258]
 [147.02318]
 [138.30884]
 [141.80847]
 [145.90648]
 [135.98987]
 [143.29077]
 [153.70609]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [4. 0. 0. 0. 3. 1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 26. 30. 23. 29.  8.  8.  9.  7.  4.  9.  3.  9. 10.  9. 10.  8.] 
adversary cards in hand: [11.  1.  3.  3.  3.] 
adversary cards in discard: [ 8. 29.  8.  0.  0.  0. 29. 11.  0. 29.  3. 29.] 
adversary owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1.0
Learning step: -0.6146575808525085
desired expected reward: 148.90316772460938



buy possibilites: [-1] 
expected returns: [[155.67941]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 4.  0.  0.  0.  3.  1. 23.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4 23] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 29.  8.  8.  9.  7.  4.  9.  3.  9.  9.  9. 10.  8.] 
adversary cards in hand: [11.  1.  3.  3.  3.] 
adversary cards in discard: [ 8. 29.  8.  0.  0.  0. 29. 11.  0. 29.  3. 29.] 
adversary owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0 40  0  0  0  0  0  0  0 50  0] 
sum of rewards: 121 

action type: buy - action 23.0
Learning step: 2.4623641967773438
desired expected reward: 144.27081298828125






Player: 1 
cards in hand: [11.  1.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  3.  3.] 
cards in discard: [ 8. 29.  8.  0.  0.  0. 29. 11.  0. 29.  3. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 29.  8.  8.  9.  7.  4.  9.  3.  9.  9.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 25.  8.  6.] 
adversary cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4 23] -> size -> 29 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 3.] 
cards in discard: [ 8. 29.  8.  0.  0.  0. 29. 11.  0. 29.  3. 29. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 29.  8.  8.  8.  7.  4.  9.  3.  9.  9.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 25.  8.  6.] 
adversary cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4 23] -> size -> 29 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 3.] 
cards in discard: [ 8. 29.  8.  0.  0.  0. 29. 11.  0. 29.  3. 29. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29
 16] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 23. 29.  8.  8.  8.  7.  4.  9.  3.  9.  9.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 25.  8.  6.] 
adversary cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4 23] -> size -> 29 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 3.] 
cards in discard: [ 8. 29.  8.  0.  0.  0. 29. 11.  0. 29.  3. 29. 16.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29
 16  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 23. 29.  8.  8.  8.  7.  4.  9.  3.  9.  9.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 25.  8.  6.] 
adversary cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4 23] -> size -> 29 
adversary victory points: 6
player victory points: 3 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 25.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[51.452854]
 [54.58101 ]
 [47.008553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  8.  6.] 
cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4 23] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 23. 29.  8.  8.  8.  7.  4.  9.  3.  9.  9.  9. 10.  8.] 
adversary cards in hand: [ 0. 16.  6. 29. 10.] 
adversary cards in discard: [ 8. 29.  8.  0.  0.  0. 29. 11.  0. 29.  3. 29. 16.  0. 11.  1.  3.  3.
  3.] 
adversary owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29
 16  0] -> size -> 26 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: buy - action -1
Learning step: -5.070479869842529
desired expected reward: 150.6089324951172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[42.878727]
 [33.57086 ]
 [49.798775]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  8.  6.] 
cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4 23] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 26. 30. 23. 29.  8.  8.  8.  7.  4.  9.  3.  9.  9.  9. 10.  8.] 
adversary cards in hand: [ 0. 16.  6. 29. 10.] 
adversary cards in discard: [ 8. 29.  8.  0.  0.  0. 29. 11.  0. 29.  3. 29. 16.  0. 11.  1.  3.  3.
  3.] 
adversary owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29
 16  0] -> size -> 26 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: take_action - action -1.0
Learning step: -0.041875459253787994
desired expected reward: 51.410972595214844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 16.  6. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6. 29. 10.] 
cards in discard: [ 8. 29.  8.  0.  0.  0. 29. 11.  0. 29.  3. 29. 16.  0. 11.  1.  3.  3.
  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29
 16  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 23. 29.  8.  8.  8.  7.  4.  9.  3.  9.  9.  9. 10.  8.] 
adversary cards in hand: [0. 1. 8. 0. 0.] 
adversary cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.  0.  3. 25.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4 23] -> size -> 29 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1. 16. 29.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6. 29.  0.] 
cards in discard: [ 8. 29.  8.  0.  0.  0. 29. 11.  0. 29.  3. 29. 16.  0. 11.  1.  3.  3.
  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 11  8  0 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29
 16  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 23. 29.  8.  8.  8.  7.  4.  9.  3.  9.  9.  9. 10.  8.] 
adversary cards in hand: [0. 1. 8. 0. 0.] 
adversary cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.  0.  3. 25.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4 23] -> size -> 29 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.] 
cards in discard: [ 8. 29.  8.  0.  0.  0. 29. 11.  0. 29.  3. 29. 16.  0. 11.  1.  3.  3.
  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [10 11  8 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 23. 29.  8.  7.  8.  7.  4.  9.  3.  9.  9.  9. 10.  8.] 
adversary cards in hand: [0. 1. 8. 0. 0.] 
adversary cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.  0.  3. 25.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4 23] -> size -> 29 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  0.] 
cards in discard: [ 8. 29.  8.  0.  0.  0. 29. 11.  0. 29.  3. 29. 16.  0. 11.  1.  3.  3.
  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [10 11  8 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 26. 30. 23. 29.  8.  7.  8.  7.  4.  9.  3.  9.  9.  9. 10.  8.] 
adversary cards in hand: [0. 1. 8. 0. 0.] 
adversary cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.  0.  3. 25.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4 23] -> size -> 29 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [0. 1. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[39.833443]
 [38.980297]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 0. 0.] 
cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.  0.  3. 25.  8.
  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  6  0  8  8  0  0  0  1  3  1 15 25 29  3  3  0
 29  8 14  4 23] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 23. 29.  8.  7.  8.  7.  4.  9.  3.  9.  9.  9. 10.  8.] 
adversary cards in hand: [16.  3.  6. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  8 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1.0
Learning step: 0.4383348524570465
desired expected reward: 50.44221496582031



action possibilites: [-1] 
expected returns: [[118.63402]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.  0.  3. 25.  8.
  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 23. 29.  8.  7.  8.  7.  4.  9.  3.  9.  9.  9. 10.  8.] 
adversary cards in hand: [16.  3.  6. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  8 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: trash_cards_n_from_hand - action 5
Learning step: 3.793187379837036
desired expected reward: 42.31474685668945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[100.76811 ]
 [ 84.897064]
 [119.24858 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.  0.  3. 25.  8.
  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 26. 30. 23. 29.  8.  7.  8.  7.  4.  9.  3.  9.  9.  9. 10.  8.] 
adversary cards in hand: [16.  3.  6. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  8 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1
Learning step: -0.5174660086631775
desired expected reward: 118.1165542602539






Player: 1 
cards in hand: [16.  3.  6. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  6. 11.  1.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 23. 29.  8.  7.  8.  7.  4.  9.  3.  9.  9.  9. 10.  8.] 
adversary cards in hand: [ 8.  0. 15.  0. 14.] 
adversary cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.  0.  3. 25.  8.
  6.  8.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23] -> size -> 26 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  1.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 23. 29.  8.  7.  8.  7.  4.  9.  3.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 8.  0. 15.  0. 14.] 
adversary cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.  0.  3. 25.  8.
  6.  8.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23] -> size -> 26 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  1.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 26. 30. 23. 29.  8.  7.  8.  7.  4.  9.  3.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 8.  0. 15.  0. 14.] 
adversary cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.  0.  3. 25.  8.
  6.  8.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23] -> size -> 26 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  1.] 
cards in discard: [10.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 23. 29.  8.  7.  8.  7.  3.  9.  3.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 8.  0. 15.  0. 14.] 
adversary cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.  0.  3. 25.  8.
  6.  8.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23] -> size -> 26 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 15.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 14.] 
expected returns: [[46.153793]
 [33.24878 ]
 [31.325094]
 [26.145342]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  0. 14.] 
cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.  0.  3. 25.  8.
  6.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 23. 29.  8.  7.  8.  7.  3.  9.  3.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  0. 29. 16. 11.] 
adversary cards in discard: [10.  8. 16.  6. 11.  1.] 
adversary owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8] -> size -> 27 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1.0
Learning step: -2.5900750160217285
desired expected reward: 116.65853881835938



action possibilites: [-1] 
expected returns: [[50.255814]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  0.] 
cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.  0.  3. 25.  8.
  6.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 23. 29.  8.  7.  8.  7.  3.  9.  3.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6. 29. 11.] 
adversary cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.] 
adversary owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8] -> size -> 27 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action 14.0
Learning step: 3.37349009513855
desired expected reward: 29.518808364868164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[39.018574]
 [44.92896 ]
 [42.895134]
 [31.459757]
 [41.164467]
 [48.14372 ]
 [42.435337]
 [41.935715]
 [35.150265]
 [41.3451  ]
 [38.851616]
 [49.505856]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15.  0.] 
cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.  0.  3. 25.  8.
  6.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 26. 30. 23. 29.  8.  7.  8.  7.  3.  9.  3.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6. 29. 11.] 
adversary cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.] 
adversary owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8] -> size -> 27 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1
Learning step: 2.0043785572052
desired expected reward: 52.26019287109375



buy possibilites: [-1] 
expected returns: [[20.359444]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15.  0.] 
cards in discard: [ 4.  0.  0.  0.  3.  1. 23. 29. 29.  0.  0.  0.  3.  3.  0.  3. 25.  8.
  6.  8.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6. 29. 11.] 
adversary cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.] 
adversary owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8] -> size -> 27 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5.  0.  6. 50.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 73.0 

action type: buy - action 8.0
Learning step: 1.9863204956054688
desired expected reward: 44.421661376953125






Player: 1 
cards in hand: [ 6. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 11.] 
cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29. 11.] 
cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29. 11.] 
cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 8. 29.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[46.503555]
 [38.45293 ]
 [38.073544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 10.  0.] 
adversary cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.  0.  6. 29. 11.] 
adversary owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8  0] -> size -> 28 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: 2.444828510284424
desired expected reward: 22.804271697998047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[36.673687]
 [41.97504 ]
 [41.11152 ]
 [29.257883]
 [38.508343]
 [45.40035 ]
 [39.29065 ]
 [38.936813]
 [33.115887]
 [39.047146]
 [37.11874 ]
 [47.767616]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 10.  0.] 
adversary cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.  0.  6. 29. 11.] 
adversary owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8  0] -> size -> 28 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: 1.2063864469528198
desired expected reward: 46.405303955078125



buy possibilites: [-1] 
expected returns: [[70.029976]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.  1.  0.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23  8  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 4 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 10.  0.] 
adversary cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.  0.  6. 29. 11.] 
adversary owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8  0] -> size -> 28 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6.  50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 21.0 

action type: buy - action 0.0
Learning step: 0.7919902801513672
desired expected reward: 37.465675354003906






Player: 1 
cards in hand: [ 0.  0. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 10.  0.] 
cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.  0.  6. 29. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  8.] 
adversary cards in hand: [15.  0.  0.  0.  3.] 
adversary cards in discard: [ 0.  8. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23  8  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.  0.  6. 29. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  8.] 
adversary cards in hand: [15.  0.  0.  0.  3.] 
adversary cards in discard: [ 0.  8. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23  8  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.  0.  6. 29. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  8.] 
adversary cards in hand: [15.  0.  0.  0.  3.] 
adversary cards in discard: [ 0.  8. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23  8  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.  0.  6. 29. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  8.] 
adversary cards in hand: [15.  0.  0.  0.  3.] 
adversary cards in discard: [ 0.  8. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23  8  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.  0.  6. 29. 11. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8  0 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  7.] 
adversary cards in hand: [15.  0.  0.  0.  3.] 
adversary cards in discard: [ 0.  8. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23  8  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [15.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[91.527725]
 [74.92457 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0.  3.] 
cards in discard: [ 0.  8. 29.  0.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14
  4 23  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  7.] 
adversary cards in hand: [ 1.  8.  0. 29.  0.] 
adversary cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.  0.  6. 29. 11. 15. 10. 29.  0.  0.  0.
  3.  3.] 
adversary owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8  0 15] -> size -> 29 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: 0.9575668573379517
desired expected reward: 70.98754119873047



action possibilites: [-1] 
expected returns: [[144.79117]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0.  8. 29.  0.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4
 23  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  7.] 
adversary cards in hand: [ 1.  8.  0. 29.  0.] 
adversary cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.  0.  6. 29. 11. 15. 10. 29.  0.  0.  0.
  3.  3.] 
adversary owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8  0 15] -> size -> 29 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action 15.0
Learning step: 3.0615735054016113
desired expected reward: 77.98612976074219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[128.01651 ]
 [137.27452 ]
 [134.26872 ]
 [116.76837 ]
 [111.47183 ]
 [131.80269 ]
 [142.44913 ]
 [133.6702  ]
 [148.46693 ]
 [132.94684 ]
 [118.87192 ]
 [124.402794]
 [131.5225  ]
 [115.44344 ]
 [126.98488 ]
 [145.14488 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0.  8. 29.  0.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4
 23  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  7.] 
adversary cards in hand: [ 1.  8.  0. 29.  0.] 
adversary cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.  0.  6. 29. 11. 15. 10. 29.  0.  0.  0.
  3.  3.] 
adversary owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8  0 15] -> size -> 29 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1
Learning step: -0.683972954750061
desired expected reward: 144.10719299316406



buy possibilites: [-1] 
expected returns: [[100.276184]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0.  8. 29.  0.  1.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4
 23  8  0 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [ 1.  8.  0. 29.  0.] 
adversary cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.  0.  6. 29. 11. 15. 10. 29.  0.  0.  0.
  3.  3.] 
adversary owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8  0 15] -> size -> 29 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5.  0.  6. 50.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 79.0 

action type: buy - action 15.0
Learning step: -0.14302979409694672
desired expected reward: 126.84185028076172






Player: 1 
cards in hand: [ 1.  8.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0. 29.  0.] 
cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.  0.  6. 29. 11. 15. 10. 29.  0.  0.  0.
  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3 29  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0
  6 10  8  0 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [ 0.  0.  0. 14.  3.] 
adversary cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4
 23  8  0 15] -> size -> 28 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.  0.  6. 29. 11. 15. 10. 29.  0.  0.  0.
  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [ 0.  0.  0. 14.  3.] 
adversary cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4
 23  8  0 15] -> size -> 28 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [10.  8. 16.  6. 11.  1.  0. 16.  0.  6. 29. 11. 15. 10. 29.  0.  0.  0.
  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [ 0.  0.  0. 14.  3.] 
adversary cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4
 23  8  0 15] -> size -> 28 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[23.50163 ]
 [10.867034]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.  3.] 
cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4
 23  8  0 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [11.  8. 29. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15] -> size -> 28 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: -2.049403429031372
desired expected reward: 98.2267837524414



action possibilites: [-1] 
expected returns: [[26.942371]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4
 23  8  0 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [ 8. 29.  3.] 
adversary cards in discard: [11. 29.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15] -> size -> 28 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action 14.0
Learning step: 3.6183083057403564
desired expected reward: 14.37621021270752





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[22.997225]
 [26.122946]
 [25.535051]
 [19.013073]
 [17.274933]
 [24.282215]
 [27.791702]
 [24.686455]
 [29.343422]
 [24.462284]
 [20.005894]
 [22.23371 ]
 [24.371983]
 [18.794443]
 [22.90112 ]
 [28.521566]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4
 23  8  0 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  2.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [ 8. 29.  3.] 
adversary cards in discard: [11. 29.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15] -> size -> 28 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1
Learning step: 2.759953498840332
desired expected reward: 29.70232391357422



buy possibilites: [-1] 
expected returns: [[31.231998]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4
 23  8  0 15  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  1.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [ 8. 29.  3.] 
adversary cards in discard: [11. 29.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15] -> size -> 28 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5.  0.  6. 50.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 73.0 

action type: buy - action 8.0
Learning step: 3.118396520614624
desired expected reward: 27.80486297607422






Player: 1 
cards in hand: [ 8. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3.] 
cards in discard: [11. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  1.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [3. 0. 8. 8. 4.] 
adversary cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.  8. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4
 23  8  0 15  8] -> size -> 29 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8.] 
cards in discard: [11. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  1.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [3. 0. 8. 8. 4.] 
adversary cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.  8. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4
 23  8  0 15  8] -> size -> 29 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 8.] 
cards in discard: [11. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15] -> size -> 28 
action values: 1 
buys: 1 
player value: 1 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  1.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [3. 0. 8. 8. 4.] 
adversary cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.  8. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4
 23  8  0 15  8] -> size -> 29 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [3. 0. 8. 8. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[22.559612]
 [20.064178]
 [20.064178]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 8. 4.] 
cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.  8. 14.  0.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0  6  0  8  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4
 23  8  0 15  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  1.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [16.  0.  3. 15.  0.] 
adversary cards in discard: [11. 29. 29.  8.  3.  8.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15] -> size -> 28 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: 1.4658699035644531
desired expected reward: 32.69786834716797



action possibilites: [-1] 
expected returns: [[56.44794]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 4.] 
cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.  8. 14.  0.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  1.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [16.  0.  3. 15.  0.] 
adversary cards in discard: [11. 29. 29.  8.  3.  8.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15] -> size -> 28 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: trash_cards_n_from_hand - action 9
Learning step: 3.6070010662078857
desired expected reward: 27.868549346923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[52.847324]
 [42.24399 ]
 [58.304615]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 4.] 
cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.  8. 14.  0.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 26. 30. 23. 29.  8.  7.  8.  7.  1.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [16.  0.  3. 15.  0.] 
adversary cards in discard: [11. 29. 29.  8.  3.  8.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15] -> size -> 28 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1
Learning step: 1.909589171409607
desired expected reward: 58.35752868652344



buy possibilites: [-1] 
expected returns: [[32.242203]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 4.] 
cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.  8. 14.  0.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 23. 29.  8.  7.  8.  7.  1.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [16.  0.  3. 15.  0.] 
adversary cards in discard: [11. 29. 29.  8.  3.  8.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15] -> size -> 28 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   6  50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 41 

action type: buy - action 0.0
Learning step: 0.13308314979076385
desired expected reward: 52.980411529541016






Player: 1 
cards in hand: [16.  0.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3. 15.  0.] 
cards in discard: [11. 29. 29.  8.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 23. 29.  8.  7.  8.  7.  1.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [29.  0.  8.  3.  6.] 
adversary cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.  8. 14.  0.  0.  0.  3.  0.
  8.  3.  4.] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3. 15.  0.] 
cards in discard: [11. 29. 29.  8.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 23. 29.  8.  7.  8.  7.  1.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [29.  0.  8.  3.  6.] 
adversary cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.  8. 14.  0.  0.  0.  3.  0.
  8.  3.  4.] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3. 15.  0.] 
cards in discard: [11. 29. 29.  8.  3.  8.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 23. 29.  8.  7.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [29.  0.  8.  3.  6.] 
adversary cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.  8. 14.  0.  0.  0.  3.  0.
  8.  3.  4.] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [29.  0.  8.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[7.079465 ]
 [1.7510366]
 [2.1033225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8.  3.  6.] 
cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.  8. 14.  0.  0.  0.  3.  0.
  8.  3.  4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 23. 29.  8.  7.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [ 6.  8.  0. 10. 29.] 
adversary cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8] -> size -> 29 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: 1.0349863767623901
desired expected reward: 33.27718734741211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -2.8004246]
 [-11.140613 ]
 [  6.3681602]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  8.  3.  6.] 
cards in discard: [ 0.  8. 29.  0.  1.  0. 15. 15.  0.  0.  3.  8. 14.  0.  0.  0.  3.  0.
  8.  3.  4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 23. 29.  8.  7.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [ 6.  8.  0. 10. 29.] 
adversary cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8] -> size -> 29 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: 2.1783037185668945
desired expected reward: 9.257771492004395



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  8.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0. 10. 29.] 
cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 23. 29.  8.  7.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [ 8.  8. 14. 23. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  0. 10. 29.] 
cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 23. 29.  8.  7.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [ 8.  8. 14. 23. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  0. 10. 29.] 
cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 23. 29.  8.  7.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [ 8.  8. 14. 23. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 8.  8. 14. 23. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14. 23. 25.] 
expected returns: [[ 1.1078882]
 [-3.7516649]
 [-3.7516649]
 [-2.597054 ]
 [-1.2266188]
 [-3.1218927]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 14. 23. 25.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 23. 29.  8.  7.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.  0.  6.  8.  0. 10. 29.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0] -> size -> 30 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1.0
Learning step: 2.1822612285614014
desired expected reward: 8.550427436828613



action possibilites: [-1] 
expected returns: [[39.404404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 14. 23.  0.  8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 23. 29.  8.  6.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.  0.  6.  8.  0. 10. 29.
  6.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6] -> size -> 31 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 72 

action type: take_action - action 25.0
Learning step: 4.686981678009033
desired expected reward: 0.679326057434082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.09996 ]
 [25.99185 ]
 [40.265842]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 14. 23.  0.  8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 26. 30. 23. 29.  8.  6.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.  0.  6.  8.  0. 10. 29.
  6.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6] -> size -> 31 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1
Learning step: 2.3563644886016846
desired expected reward: 41.76076889038086






Player: 1 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.  0.  6.  8.  0. 10. 29.
  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 23. 29.  8.  6.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [ 4.  3. 29.  0.  6.] 
adversary cards in discard: [25.  8.  8. 14. 23.  0.  8.] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.  0.  6.  8.  0. 10. 29.
  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 6 
card supply: [10. 26. 30. 23. 29.  8.  6.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [ 4.  3. 29.  0.  6.] 
adversary cards in discard: [25.  8.  8. 14. 23.  0.  8.] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.  0.  6.  8.  0. 10. 29.
  6.  4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 23. 28.  8.  6.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [ 4.  3. 29.  0.  6.] 
adversary cards in discard: [25.  8.  8. 14. 23.  0.  8.] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
adversary victory points: 6
player victory points: 3 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 4.  3. 29.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-11.504433]
 [-12.234148]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  3. 29.  0.  6.] 
cards in discard: [25.  8.  8. 14. 23.  0.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 23. 28.  8.  6.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [16. 29.  6. 11. 10.] 
adversary cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.  0.  6.  8.  0. 10. 29.
  6.  4.  0.  0.  0.  0.  1.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4] -> size -> 32 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: buy - action -1.0
Learning step: -0.7287471890449524
desired expected reward: 39.537078857421875



action possibilites: [-1. 15.] 
expected returns: [[ 8.198435 ]
 [-2.2176213]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  0.  6. 15.] 
cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 23. 28.  8.  6.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [16. 29.  6. 11. 10.] 
adversary cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.  0.  6.  8.  0. 10. 29.
  6.  4.  0.  0.  0.  0.  1.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4] -> size -> 32 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: discard_n_cards - action 4
Learning step: 3.736823320388794
desired expected reward: -21.01152801513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-1.4617019]
 [ 2.1290202]
 [-6.7827954]
 [ 7.7621193]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  0.  6. 15.] 
cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 23. 28.  8.  6.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [16. 29.  6. 11. 10.] 
adversary cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.  0.  6.  8.  0. 10. 29.
  6.  4.  0.  0.  0.  0.  1.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4] -> size -> 32 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: 2.181640148162842
desired expected reward: 10.380044937133789



buy possibilites: [-1] 
expected returns: [[-4.4656954]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  0.  6. 15.] 
cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 22. 28.  8.  6.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [16. 29.  6. 11. 10.] 
adversary cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.  0.  6.  8.  0. 10. 29.
  6.  4.  0.  0.  0.  0.  1.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4] -> size -> 32 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 70 

action type: buy - action 3.0
Learning step: 3.2930715084075928
desired expected reward: 5.422087669372559






Player: 1 
cards in hand: [16. 29.  6. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  6. 11. 10.] 
cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.  0.  6.  8.  0. 10. 29.
  6.  4.  0.  0.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 22. 28.  8.  6.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3] -> size -> 29 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1. 16. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  6. 11.  1.] 
cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.  0.  6.  8.  0. 10. 29.
  6.  4.  0.  0.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 22. 28.  8.  6.  8.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3] -> size -> 29 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1. 16. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  6.  1.] 
cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.  0.  6.  8.  0. 10. 29.
  6.  4.  0.  0.  0.  0.  1. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 22. 28.  8.  6.  7.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3] -> size -> 29 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29.  6.  1.] 
cards in discard: [11. 29. 29.  8.  3.  8.  8. 16.  0.  3. 15.  0.  0.  6.  8.  0. 10. 29.
  6.  4.  0.  0.  0.  0.  1. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 22. 28.  8.  6.  7.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3] -> size -> 29 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-12.287664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 22. 28.  8.  6.  7.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [29.  0. 29.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4 16] -> size -> 33 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: buy - action -1
Learning step: 2.0468122959136963
desired expected reward: -2.4188830852508545





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[-7.6938453]
 [-8.452829 ]
 [-8.078985 ]
 [-6.5077467]
 [-8.148171 ]
 [-7.4923496]
 [-7.309576 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 26. 30. 22. 28.  8.  6.  7.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [29.  0. 29.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4 16] -> size -> 33 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: take_action - action -1.0
Learning step: 2.5469319820404053
desired expected reward: -9.740732192993164



buy possibilites: [-1] 
expected returns: [[42.845795]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 26. 30. 22. 28.  8.  5.  7.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [29.  0. 29.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4 16] -> size -> 33 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[  -5.    0.    6.   30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -269.0 

action type: buy - action 6.0
Learning step: -12.160582542419434
desired expected reward: -18.66832733154297






Player: 1 
cards in hand: [29.  0. 29.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  1.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 22. 28.  8.  5.  7.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [29.  0.  0.  3. 15.] 
adversary cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.  6.  3.  0.  0.
  3.  0.] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3  6] -> size -> 30 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3.  0.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 22. 28.  8.  5.  7.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [29.  0.  0.  3. 15.] 
adversary cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.  6.  3.  0.  0.
  3.  0.] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3  6] -> size -> 30 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  3.  0.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 26. 30. 22. 28.  8.  5.  7.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [29.  0.  0.  3. 15.] 
adversary cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.  6.  3.  0.  0.
  3.  0.] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3  6] -> size -> 30 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  3.  0.] 
cards in discard: [0. 3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4 16  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 26. 30. 21. 28.  8.  5.  7.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [29.  0.  0.  3. 15.] 
adversary cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.  6.  3.  0.  0.
  3.  0.] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3  6] -> size -> 30 
adversary victory points: 6
player victory points: 4 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[ -0.2907238]
 [-15.963799 ]
 [-19.986506 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3. 15.] 
cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.  6.  3.  0.  0.
  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 28.  8.  5.  7.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [ 6. 16.  8.  0. 16.] 
adversary cards in discard: [ 0.  3. 29. 29.  1.  3.  0.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4 16  3] -> size -> 34 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: buy - action -1
Learning step: -1.3122936487197876
desired expected reward: 41.53350067138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-20.3883   ]
 [-11.688609 ]
 [-41.37509  ]
 [ -1.7094734]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3. 15.] 
cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.  6.  3.  0.  0.
  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 21. 28.  8.  5.  7.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [ 6. 16.  8.  0. 16.] 
adversary cards in discard: [ 0.  3. 29. 29.  1.  3.  0.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4 16  3] -> size -> 34 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: take_action - action -1.0
Learning step: 0.7168064117431641
desired expected reward: 0.4260892868041992



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6. 16.  8.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  8.  0. 16.] 
cards in discard: [ 0.  3. 29. 29.  1.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29 16  6  0  1  8 29 16  0  6
 10  8  0 15  8  0  6  4 16  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 28.  8.  5.  7.  7.  0.  9.  3.  9.  9.  8. 10.  6.] 
adversary cards in hand: [1. 8. 0. 0. 0.] 
adversary cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.  6.  3.  0.  0.
  3.  0. 29.  0.  0.  3. 15.] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3  6] -> size -> 30 
adversary victory points: 6
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0.] 
cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6  4 16  3 23] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 28.  8.  5.  7.  7.  0.  9.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [1. 8. 0. 0. 0.] 
adversary cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.  6.  3.  0.  0.
  3.  0. 29.  0.  0.  3. 15.] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3  6] -> size -> 30 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0.] 
cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6  4 16  3 23] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 26. 30. 21. 28.  8.  5.  7.  7.  0.  9.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [1. 8. 0. 0. 0.] 
adversary cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.  6.  3.  0.  0.
  3.  0. 29.  0.  0.  3. 15.] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3  6] -> size -> 30 
adversary victory points: 6
player victory points: 4 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [1. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[48.721992]
 [43.21237 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 0. 0.] 
cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.  6.  3.  0.  0.
  3.  0. 29.  0.  0.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 28.  8.  5.  7.  7.  0.  9.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [10. 29. 11. 29.  8.] 
adversary cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6  4 16  3 23] -> size -> 34 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: buy - action -1.0
Learning step: 2.18183970451355
desired expected reward: 0.4723721742630005





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[41.728226]
 [46.075844]
 [44.813957]
 [35.941734]
 [33.03563 ]
 [43.509483]
 [48.694077]
 [50.993088]
 [44.184975]
 [37.390953]
 [40.148598]
 [43.828003]
 [35.304657]
 [41.683968]
 [49.916237]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 0. 0.] 
cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.  6.  3.  0.  0.
  3.  0. 29.  0.  0.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 26. 30. 21. 28.  8.  5.  7.  7.  0.  9.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [10. 29. 11. 29.  8.] 
adversary cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6  4 16  3 23] -> size -> 34 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: take_action - action -1.0
Learning step: -0.3928340971469879
desired expected reward: 48.32917404174805



buy possibilites: [-1] 
expected returns: [[51.197975]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 0. 0.] 
cards in discard: [25.  8.  8. 14. 23.  0.  8.  3.  3. 29.  4.  0.  6. 15.  6.  3.  0.  0.
  3.  0. 29.  0.  0.  3. 15. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3  6 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [10. 29. 11. 29.  8.] 
adversary cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6  4 16  3 23] -> size -> 34 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 71 

action type: buy - action 25.0
Learning step: 2.152299165725708
desired expected reward: 53.145408630371094






Player: 1 
cards in hand: [10. 29. 11. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11. 29.  8.] 
cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6  4 16  3 23] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3  6 25] -> size -> 31 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 11. 29.  8.] 
cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6  4 16  3 23] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3  6 25] -> size -> 31 
adversary victory points: 6
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [3. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[30.03253 ]
 [25.066782]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8
  0 15  8  0  3  6 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 4. 10. 16. 11.  3.] 
adversary cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6  4 16  3 23] -> size -> 34 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: buy - action -1
Learning step: -0.8791217803955078
desired expected reward: 50.31885528564453



action possibilites: [-1] 
expected returns: [[50.47116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 4. 10. 16. 11.  3.] 
adversary cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6  4 16  3 23] -> size -> 34 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: trash_cards_n_from_hand - action 1
Learning step: 1.3828494548797607
desired expected reward: 26.437881469726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[42.386948]
 [46.27767 ]
 [32.767776]
 [51.457253]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 4. 10. 16. 11.  3.] 
adversary cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6  4 16  3 23] -> size -> 34 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action -1
Learning step: -0.01486968994140625
desired expected reward: 50.45629119873047



buy possibilites: [-1] 
expected returns: [[1.7511468]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 4. 10. 16. 11.  3.] 
adversary cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6  4 16  3 23] -> size -> 34 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5.  10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 0.0 

action type: buy - action 0.0
Learning step: -2.079946279525757
desired expected reward: 40.3069953918457






Player: 1 
cards in hand: [ 4. 10. 16. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 10. 16. 11.  3.] 
cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6  4 16  3 23] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [23.  0. 15.  3.  0.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0] -> size -> 31 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.] 
cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6 16  3 23  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [23.  0. 15.  3.  0.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0] -> size -> 31 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.] 
cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6 16  3 23  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [23.  0. 15.  3.  0.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0] -> size -> 31 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [23.  0. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 15.] 
expected returns: [[53.00432 ]
 [41.932297]
 [43.121124]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0. 15.  3.  0.] 
cards in discard: [0. 8. 0. 3. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.  0.
 16. 10. 11.  3.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6 16  3 23  0] -> size -> 34 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1
Learning step: 2.9785680770874023
desired expected reward: 4.729714870452881





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[41.37475 ]
 [45.520676]
 [31.535063]
 [50.89687 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0. 15.  3.  0.] 
cards in discard: [0. 8. 0. 3. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.  0.
 16. 10. 11.  3.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6 16  3 23  0] -> size -> 34 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1.0
Learning step: 0.22883263230323792
desired expected reward: 55.45420455932617



buy possibilites: [-1] 
expected returns: [[111.57542]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0. 15.  3.  0.] 
cards in discard: [0. 8. 0. 3. 0. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.  0.
 16. 10. 11.  3.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6 16  3 23  0] -> size -> 34 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5.  40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 10.0 

action type: buy - action 0.0
Learning step: 0.9417099356651306
desired expected reward: 42.31645202636719






Player: 1 
cards in hand: [1. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.  0.
 16. 10. 11.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6 16  3 23  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [15.  6.  3.  8.  4.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0] -> size -> 32 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.  0.
 16. 10. 11.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6 16  3 23  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  3.  9.  8.  8. 10.  6.] 
adversary cards in hand: [15.  6.  3.  8.  4.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0] -> size -> 32 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.  0.
 16. 10. 11.  3. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6 16  3 23  0 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [15.  6.  3.  8.  4.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0] -> size -> 32 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [15.  6.  3.  8.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[30.5221  ]
 [23.786581]
 [26.116426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  3.  8.  4.] 
cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 6. 15.  0.  8.  6.] 
adversary cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.  0.
 16. 10. 11.  3. 29.  1.  0.  0.  0.  3.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6 16  3 23  0 29] -> size -> 35 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1
Learning step: -2.9592645168304443
desired expected reward: 108.61614990234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.543434]
 [14.993584]
 [31.698172]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  3.  8.  4.] 
cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 6. 15.  0.  8.  6.] 
adversary cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.  0.
 16. 10. 11.  3. 29.  1.  0.  0.  0.  3.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6 16  3 23  0 29] -> size -> 35 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1.0
Learning step: 1.043104887008667
desired expected reward: 31.565208435058594



buy possibilites: [-1] 
expected returns: [[76.72727]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  3.  8.  4.] 
cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 6. 15.  0.  8.  6.] 
adversary cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.  0.
 16. 10. 11.  3. 29.  1.  0.  0.  0.  3.] 
adversary owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6 16  3 23  0 29] -> size -> 35 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   5  40   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 10 

action type: buy - action 0.0
Learning step: 0.9991915822029114
desired expected reward: 25.542631149291992






Player: 1 
cards in hand: [ 6. 15.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.  8.  6.] 
cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.  0.
 16. 10. 11.  3. 29.  1.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  0  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10
  8  0 15  8  0  6 16  3 23  0 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [29. 29.  0.  0.  1.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.  0. 15.  6.  3.  8.  4.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0] -> size -> 33 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6.] 
cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.  0.
 16. 10. 11.  3. 29.  1.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 11  8 11  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8
  0 15  8  0  6 16  3 23  0 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [29. 29.  0.  0.  1.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.  0. 15.  6.  3.  8.  4.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0] -> size -> 33 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6.] 
cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.  0.
 16. 10. 11.  3. 29.  1.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 11  8 11  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8
  0 15  8  0  6 16  3 23  0 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 26. 30. 21. 28.  8.  5.  7.  7.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [29. 29.  0.  0.  1.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.  0. 15.  6.  3.  8.  4.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0] -> size -> 33 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6.] 
cards in discard: [ 0.  3. 29. 29.  1.  3.  0. 23. 16.  6.  8.  0. 10. 29. 11. 29.  8.  0.
 16. 10. 11.  3. 29.  1.  0.  0.  0.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 11  8 11  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8
  0 15  8  0  6 16  3 23  0 29 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 21. 28.  8.  5.  7.  6.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [29. 29.  0.  0.  1.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.  0. 15.  6.  3.  8.  4.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0] -> size -> 33 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [29. 29.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-5.82218 ]
 [-8.747396]
 [-8.747396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0.  1.] 
cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.  0. 15.  6.  3.  8.  4.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 21. 28.  8.  5.  7.  6.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [15. 29.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  8 11  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8
  0 15  8  0  6 16  3 23  0 29 11] -> size -> 35 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1
Learning step: -2.002671957015991
desired expected reward: 74.72460174560547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[ -9.874819 ]
 [ -7.476014 ]
 [ -6.8590293]
 [-25.266668 ]
 [ -8.967819 ]
 [ -5.785667 ]
 [ -9.075631 ]
 [-17.06842  ]
 [ -8.170894 ]
 [ -9.271639 ]
 [ -6.086705 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0.  0.  1.] 
cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.  0. 15.  6.  3.  8.  4.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 26. 30. 21. 28.  8.  5.  7.  6.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [15. 29.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  8 11  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8
  0 15  8  0  6 16  3 23  0 29 11] -> size -> 35 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1.0
Learning step: 2.07820200920105
desired expected reward: -3.7439796924591064



buy possibilites: [-1] 
expected returns: [[45.74135]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0.  0.  1.] 
cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.  0. 15.  6.  3.  8.  4. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 26. 30. 21. 28.  8.  5.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [15. 29.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  8 11  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8
  0 15  8  0  6 16  3 23  0 29 11] -> size -> 35 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5.   0.   5.  40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 44.5 

action type: buy - action 11.0
Learning step: 3.5434634685516357
desired expected reward: -2.2421963214874268






Player: 1 
cards in hand: [15. 29.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  3  0  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8
  0 15  8  0  6 16  3 23  0 29 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 21. 28.  8.  5.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 6.  0. 25.  8.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.  0. 15.  6.  3.  8.  4. 11.
 29. 29.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11] -> size -> 34 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 26. 30. 21. 28.  8.  5.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 6.  0. 25.  8.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.  0. 15.  6.  3.  8.  4. 11.
 29. 29.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11] -> size -> 34 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  8.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 26. 30. 21. 28.  8.  5.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 6.  0. 25.  8.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.  0. 15.  6.  3.  8.  4. 11.
 29. 29.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11] -> size -> 34 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 25.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[84.82408 ]
 [87.95053 ]
 [77.249985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 25.  8.  0.] 
cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.  0. 15.  6.  3.  8.  4. 11.
 29. 29.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 21. 28.  8.  5.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [10. 29.  3.  6.  6.] 
adversary cards in discard: [15. 29.  0.  8.] 
adversary owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11] -> size -> 34 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1
Learning step: 1.6083691120147705
desired expected reward: 47.34971618652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[73.28431 ]
 [78.555695]
 [60.876728]
 [84.90006 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 25.  8.  0.] 
cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.  0. 15.  6.  3.  8.  4. 11.
 29. 29.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 26. 30. 21. 28.  8.  5.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [10. 29.  3.  6.  6.] 
adversary cards in discard: [15. 29.  0.  8.] 
adversary owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11] -> size -> 34 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1.0
Learning step: -0.5209888815879822
desired expected reward: 84.30306243896484



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10. 29.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  3.  6.  6.] 
cards in discard: [15. 29.  0.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 21. 28.  8.  5.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 0. 14. 25.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.  0. 15.  6.  3.  8.  4. 11.
 29. 29.  0.  0.  1.  6.  0. 25.  8.  0.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11] -> size -> 34 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  3.  6.  6.] 
cards in discard: [15. 29.  0.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 6. 26. 30. 21. 28.  8.  5.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 0. 14. 25.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.  0. 15.  6.  3.  8.  4. 11.
 29. 29.  0.  0.  1.  6.  0. 25.  8.  0.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11] -> size -> 34 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  3.  6.  6.] 
cards in discard: [15. 29.  0.  8.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 21. 28.  8.  5.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 0. 14. 25.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.  0. 15.  6.  3.  8.  4. 11.
 29. 29.  0.  0.  1.  6.  0. 25.  8.  0.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11] -> size -> 34 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 0. 14. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
expected returns: [[113.955765]
 [ 91.7111  ]
 [119.31804 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 25.  3.  0.] 
cards in discard: [ 0.  8.  0.  3.  0.  0. 23.  0. 15.  3.  0.  0. 15.  6.  3.  8.  4. 11.
 29. 29.  0.  0.  1.  6.  0. 25.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 21. 28.  8.  5.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 0. 16. 29.  3.  0.] 
adversary cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.] 
adversary owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11  0] -> size -> 35 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1.0
Learning step: 0.24067306518554688
desired expected reward: 85.14073181152344



action possibilites: [-1] 
expected returns: [[45.188564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0.  4.  8.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 21. 28.  8.  4.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 0. 16. 29.  3.  0.] 
adversary cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.] 
adversary owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11  0  6] -> size -> 36 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 60 

action type: take_action - action 25.0
Learning step: -1.9491592645645142
desired expected reward: 117.36888122558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[35.444653]
 [41.30834 ]
 [18.21137 ]
 [47.01192 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  0.  4.  8.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 26. 30. 21. 28.  8.  4.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 0. 16. 29.  3.  0.] 
adversary cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.] 
adversary owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11  0  6] -> size -> 36 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 60 

action type: take_action - action -1
Learning step: 1.5897982120513916
desired expected reward: 46.77836227416992



buy possibilites: [-1] 
expected returns: [[54.06853]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  0.  4.  8.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 26. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 0. 16. 29.  3.  0.] 
adversary cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.] 
adversary owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11  0  6] -> size -> 36 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.   30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -251.0 

action type: buy - action 6.0
Learning step: -12.244025230407715
desired expected reward: 5.967310905456543






Player: 1 
cards in hand: [ 0. 16. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 29.  3.  0.] 
cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11  0  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [15.  0.  0. 15.  3.] 
adversary cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6] -> size -> 35 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0.] 
cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11  0  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 5. 26. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [15.  0.  0. 15.  3.] 
adversary cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6] -> size -> 35 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0.] 
cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11  0  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 26. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [15.  0.  0. 15.  3.] 
adversary cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6] -> size -> 35 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0.] 
cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11  0  6  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [15.  0.  0. 15.  3.] 
adversary cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6] -> size -> 35 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [15.  0.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[28.698706]
 [21.504562]
 [21.504562]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 15.  3.] 
cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 0.  8.  0. 10.  0.] 
adversary cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.] 
adversary owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11  0  6  1] -> size -> 37 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: -0.19454364478588104
desired expected reward: 53.87398910522461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[23.037138]
 [26.060469]
 [15.59597 ]
 [29.991758]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0. 15.  3.] 
cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 0.  8.  0. 10.  0.] 
adversary cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.] 
adversary owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11  0  6  1] -> size -> 37 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: 1.075441837310791
desired expected reward: 29.774147033691406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10.  0.] 
cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  8 11  3  1  0  3 29  0 29  3 29  6  0  1  8 29 16  0  6 10  8  0
 15  8  0  6 16  3 23  0 29 11  0  6  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 0. 29. 25.  3. 29.] 
adversary cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6] -> size -> 35 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8 11  3  1  3 29 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0
  6 16  3 23  0 29 11  0  6  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 0. 29. 25.  3. 29.] 
adversary cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6] -> size -> 35 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8 11  3  1  3 29 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0
  6 16  3 23  0 29 11  0  6  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 0. 29. 25.  3. 29.] 
adversary cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6] -> size -> 35 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 25.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[-6.6456194]
 [-7.8203373]
 [-8.182056 ]
 [-7.8203373]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  3. 29.] 
cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 3.  8.  1. 11.  1.] 
adversary cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.
  8.  0.] 
adversary owned cards: [11  8 11  3  1  3 29 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0
  6 16  3 23  0 29 11  0  6  1] -> size -> 34 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: 0.20309238135814667
desired expected reward: 31.79892921447754



action possibilites: [-1. 25. 29.] 
expected returns: [[8.115225 ]
 [6.9915433]
 [3.4840345]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 29.  6.] 
cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 5. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 3.  8.  1. 11.  1.] 
adversary cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.
  8.  0.] 
adversary owned cards: [11  8 11  3  1  3 29 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0
  6 16  3 23  0 29 11  0  6  1] -> size -> 34 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: discard_n_cards - action 2
Learning step: 3.420996904373169
desired expected reward: -3.0417392253875732





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[5.3335834]
 [1.8090744]
 [9.0237465]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3. 29.  6.] 
cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6] -> size -> 35 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 5. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 3.  8.  1. 11.  1.] 
adversary cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.
  8.  0.] 
adversary owned cards: [11  8 11  3  1  3 29 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0
  6 16  3 23  0 29 11  0  6  1] -> size -> 34 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1.0
Learning step: 2.6814587116241455
desired expected reward: 10.796683311462402



buy possibilites: [-1] 
expected returns: [[20.877905]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3. 29.  6.] 
cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 3.  8.  1. 11.  1.] 
adversary cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.
  8.  0.] 
adversary owned cards: [11  8 11  3  1  3 29 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0
  6 16  3 23  0 29 11  0  6  1] -> size -> 34 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  40.   0.   0.  20. -30.   0.   0.   0.  -1.   0.   0.
   0.   0.] 
sum of rewards: 28.0 

action type: buy - action 0.0
Learning step: 1.6030737161636353
desired expected reward: 6.936656951904297






Player: 1 
cards in hand: [ 3.  8.  1. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  1. 11.  1.] 
cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.
  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [11  8 11  3  1  3 29 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0
  6 16  3 23  0 29 11  0  6  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6  0] -> size -> 36 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.
  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  3 29 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3
 23  0 29 11  0  6  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6  0] -> size -> 36 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.
  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  3 29 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3
 23  0 29 11  0  6  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.] 
adversary owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6  0] -> size -> 36 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[23.801014]
 [22.47755 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0
 15  8  0  3  6 25  0  0  0 11  6  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 8. 23. 11. 16. 29.] 
adversary cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.
  8.  0.  8.  1.] 
adversary owned cards: [ 8 11  3 29 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3
 23  0 29 11  0  6  1] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1
Learning step: 1.929646372795105
desired expected reward: 22.80755043029785



action possibilites: [-1] 
expected returns: [[33.010918]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0 15
  8  0  3  6 25  0  0  0 11  6  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 8. 23. 11. 16. 29.] 
adversary cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.
  8.  0.  8.  1.] 
adversary owned cards: [ 8 11  3 29 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3
 23  0 29 11  0  6  1] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: trash_cards_n_from_hand - action 0
Learning step: 3.20198130607605
desired expected reward: 23.01726722717285





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[26.13543 ]
 [28.442549]
 [27.947672]
 [22.516226]
 [30.204735]
 [27.262344]
 [31.678497]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0 15
  8  0  3  6 25  0  0  0 11  6  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 8. 23. 11. 16. 29.] 
adversary cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.
  8.  0.  8.  1.] 
adversary owned cards: [ 8 11  3 29 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3
 23  0 29 11  0  6  1] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action -1
Learning step: 2.4409291744232178
desired expected reward: 35.451847076416016



buy possibilites: [-1] 
expected returns: [[49.697273]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0 15
  8  0  3  6 25  0  0  0 11  6  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 8. 23. 11. 16. 29.] 
adversary cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.
  8.  0.  8.  1.] 
adversary owned cards: [ 8 11  3 29 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3
 23  0 29 11  0  6  1] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  50.   0.   0.  20. -30.   0.   0.   0.  -1.   0.   0.
   0.   0.] 
sum of rewards: 38.0 

action type: buy - action 0.0
Learning step: 1.7114170789718628
desired expected reward: 27.846847534179688






Player: 1 
cards in hand: [ 8. 23. 11. 16. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 11. 16. 29.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23. 11. 16. 29.] 
cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.
  8.  0.  8.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3 29 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3
 23  0 29 11  0  6  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [0. 1. 8. 0. 0.] 
adversary cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0 15
  8  0  3  6 25  0  0  0 11  6  0  0] -> size -> 36 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23. 11.] 
cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.
  8.  0.  8.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 11  3 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23
  0 29 11  0  6  1  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [0. 1. 8. 0. 0.] 
adversary cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0 15
  8  0  3  6 25  0  0  0 11  6  0  0] -> size -> 36 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 23. 11.] 
cards in discard: [15. 29.  0.  8.  0. 10. 29.  3.  6.  6.  6.  6.  1. 29.  0. 16.  3.  0.
  8.  0.  8.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 11  3 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23
  0 29 11  0  6  1  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [0. 1. 8. 0. 0.] 
adversary cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0 15
  8  0  3  6 25  0  0  0 11  6  0  0] -> size -> 36 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [0. 1. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[47.533524]
 [42.897476]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 0. 0.] 
cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.  0.  8.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6  0  8  0  0  0  3  1 15 25 29  3  3  0 29  8 14  4 23  8  0 15
  8  0  3  6 25  0  0  0 11  6  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 6.  0. 11. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23
  0 29 11  0  6  1  0] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1
Learning step: 0.9926708340644836
desired expected reward: 50.689945220947266



action possibilites: [-1] 
expected returns: [[43.253216]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.  0.  8.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6  0  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3
  6 25  0  0  0 11  6  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 6.  0. 11. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23
  0 29 11  0  6  1  0] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: trash_cards_n_from_hand - action 7
Learning step: 2.8680036067962646
desired expected reward: 33.97187423706055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[38.632576]
 [32.59411 ]
 [44.48335 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.  0.  8.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6  0  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3
  6 25  0  0  0 11  6  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 6.  0. 11. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23
  0 29 11  0  6  1  0] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action -1
Learning step: 2.181148052215576
desired expected reward: 45.434364318847656






Player: 1 
cards in hand: [ 6.  0. 11. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11. 29.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23
  0 29 11  0  6  1  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  6.] 
adversary cards in hand: [ 6.  3.  0. 23.  8.] 
adversary cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.  0.  8.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 6  0  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3
  6 25  0  0  0 11  6  0  0] -> size -> 33 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 29.  3.] 
cards in discard: [15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23
  0 29 11  0  6  1  0 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 6.  3.  0. 23.  8.] 
adversary cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.  0.  8.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 6  0  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3
  6 25  0  0  0 11  6  0  0] -> size -> 33 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 29.  3.] 
cards in discard: [15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23
  0 29 11  0  6  1  0 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 6.  3.  0. 23.  8.] 
adversary cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.  0.  8.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 6  0  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3
  6 25  0  0  0 11  6  0  0] -> size -> 33 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  0. 23.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
expected returns: [[24.064014]
 [12.189613]
 [19.043922]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 23.  8.] 
cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.  0.  8.  0.  0.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  0  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3
  6 25  0  0  0 11  6  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 0.  8. 29. 29.  0.] 
adversary cards in discard: [15. 11.  6.  0. 29.  3.] 
adversary owned cards: [ 8 11  3 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23
  0 29 11  0  6  1  0 15] -> size -> 32 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1.0
Learning step: 0.6653091311454773
desired expected reward: 45.148658752441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.210979 ]
 [ 4.2802773]
 [22.820713 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 23.  8.] 
cards in discard: [ 6. 25.  0. 14.  3.  0.  4.  8. 15.  0.  0. 15.  3.  0.  0. 29. 25.  3.
 29.  6.  0.  8.  0.  0.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  0  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3
  6 25  0  0  0 11  6  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 0.  8. 29. 29.  0.] 
adversary cards in discard: [15. 11.  6.  0. 29.  3.] 
adversary owned cards: [ 8 11  3 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23
  0 29 11  0  6  1  0 15] -> size -> 32 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1.0
Learning step: 1.59640634059906
desired expected reward: 25.660398483276367



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29. 29.  0.] 
cards in discard: [15. 11.  6.  0. 29.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3 29  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23
  0 29 11  0  6  1  0 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 0. 15.  8.  4. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  0  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3
  6 25  0  0  0 11  6  0  0] -> size -> 33 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [15. 11.  6.  0. 29.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  3  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0
 29 11  0  6  1  0 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 0. 15.  8.  4. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  0  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3
  6 25  0  0  0 11  6  0  0] -> size -> 33 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [15. 11.  6.  0. 29.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  3  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0
 29 11  0  6  1  0 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 0. 15.  8.  4. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  0  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3
  6 25  0  0  0 11  6  0  0] -> size -> 33 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  8.  4. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 11.] 
expected returns: [[-17.475266]
 [-18.52365 ]
 [-18.882631]
 [-18.017216]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8.  4. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  0  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3
  6 25  0  0  0 11  6  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 1.  0. 15.  6.  6.] 
adversary cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.] 
adversary owned cards: [ 8 11  3  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0
 29 11  0  6  1  0 15] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1.0
Learning step: 0.7529222369194031
desired expected reward: 26.559226989746094



action possibilites: [-1] 
expected returns: [[46.222225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  4. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 1.  0. 15.  6.  6.] 
adversary cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.] 
adversary owned cards: [ 8 11  3  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0
 29 11  0  6  1  0 15] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action 15.0
Learning step: 5.416182041168213
desired expected reward: -13.107458114624023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[31.193314]
 [37.303333]
 [39.674374]
 [25.331108]
 [42.8475  ]
 [35.716633]
 [47.72743 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  4. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 25. 30. 21. 28.  8.  3.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 1.  0. 15.  6.  6.] 
adversary cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.] 
adversary owned cards: [ 8 11  3  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0
 29 11  0  6  1  0 15] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action -1
Learning step: 2.020578145980835
desired expected reward: 48.242801666259766



buy possibilites: [-1] 
expected returns: [[15.418666]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  4. 11.] 
cards in discard: [6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 25. 30. 21. 28.  8.  2.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 1.  0. 15.  6.  6.] 
adversary cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.] 
adversary owned cards: [ 8 11  3  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0
 29 11  0  6  1  0 15] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.   40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -242.0 

action type: buy - action 6.0
Learning step: -13.019635200500488
desired expected reward: 12.311470985412598






Player: 1 
cards in hand: [ 1.  0. 15.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15.  6.  6.] 
cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  3 29  6  0  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0
 29 11  0  6  1  0 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 21. 28.  8.  2.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [ 6. 15.  8.  4. 11.] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6] -> size -> 33 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 6.] 
cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 25. 30. 21. 28.  8.  2.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [ 6. 15.  8.  4. 11.] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6] -> size -> 33 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6.] 
cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 2. 25. 30. 21. 28.  8.  2.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [ 6. 15.  8.  4. 11.] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6] -> size -> 33 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6.] 
cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 21. 27.  8.  2.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [ 6. 15.  8.  4. 11.] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6] -> size -> 33 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-10.789286]
 [-13.826817]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 6.] 
cards in discard: [ 6. 15.  8.  4. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 21. 27.  8.  2.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [16. 29.  3.  6. 10.] 
adversary cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.] 
adversary owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -0.6411909461021423
desired expected reward: 14.777475357055664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-12.220116]
 [-11.129814]
 [-10.43484 ]
 [-12.383884]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 6.] 
cards in discard: [ 6. 15.  8.  4. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 25. 30. 21. 27.  8.  2.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [16. 29.  3.  6. 10.] 
adversary cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.] 
adversary owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: 0.68463134765625
desired expected reward: -10.104657173156738



buy possibilites: [-1] 
expected returns: [[-8.930698]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 6.] 
cards in discard: [ 6. 15.  8.  4. 11.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 25. 30. 21. 27.  8.  1.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [16. 29.  3.  6. 10.] 
adversary cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.] 
adversary owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4] -> size -> 31 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -303.0 

action type: buy - action 6.0
Learning step: -14.829197883605957
desired expected reward: -25.2640380859375






Player: 1 
cards in hand: [16. 29.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  3.  6. 10.] 
cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 21. 27.  8.  1.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6] -> size -> 34 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29.  3.  6. 10.] 
cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4] -> size -> 31 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 2. 25. 30. 21. 27.  8.  1.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6] -> size -> 34 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29.  3.  6. 10.] 
cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 21. 27.  8.  1.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6] -> size -> 34 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-0.17997885]
 [-6.2346706 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 21. 27.  8.  1.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [23. 16.  8.  0.  8.] 
adversary cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.  0. 16. 29.
  3.  6. 10.] 
adversary owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0] -> size -> 32 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: 0.2376723289489746
desired expected reward: -8.693025588989258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[ -8.359317 ]
 [ -4.0432625]
 [ -3.7649038]
 [-11.163793 ]
 [ -1.4282123]
 [ -5.906229 ]
 [ -0.7184193]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 25. 30. 21. 27.  8.  1.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [23. 16.  8.  0.  8.] 
adversary cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.  0. 16. 29.
  3.  6. 10.] 
adversary owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0] -> size -> 32 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -0.23568157851696014
desired expected reward: -0.4156544804573059



buy possibilites: [-1] 
expected returns: [[-8.001229]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 21. 27.  8.  1.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [23. 16.  8.  0.  8.] 
adversary cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.  0. 16. 29.
  3.  6. 10.] 
adversary owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0] -> size -> 32 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 15 

action type: buy - action 1.0
Learning step: 0.7721353769302368
desired expected reward: -3.2711257934570312






Player: 1 
cards in hand: [23. 16.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 16.  8.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 16.  8.  0.  8.] 
cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.  0. 16. 29.
  3.  6. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 21. 27.  8.  1.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 0.  0.  0. 23.  3.] 
adversary cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1] -> size -> 35 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1. 16.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  0.  8.  0.] 
cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.  0. 16. 29.
  3.  6. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0] -> size -> 32 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 1. 24. 30. 21. 27.  8.  1.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 0.  0.  0. 23.  3.] 
adversary cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1] -> size -> 35 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  0.  8.  0.] 
cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.  0. 16. 29.
  3.  6. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0] -> size -> 32 
action values: 0 
buys: 2 
player value: 3 
card supply: [ 1. 24. 30. 21. 27.  8.  1.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 0.  0.  0. 23.  3.] 
adversary cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1] -> size -> 35 
adversary victory points: 2
player victory points: 2 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  0.  8.  0.] 
cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.  0. 16. 29.
  3.  6. 10.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 23. 30. 21. 27.  8.  1.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 0.  0.  0. 23.  3.] 
adversary cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1] -> size -> 35 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[-5.9805965]
 [-1.9050689]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 23.  3.] 
cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 21. 27.  8.  1.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 8.  3.  1. 11.  0.] 
adversary cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.  0. 16. 29.
  3.  6. 10.  1. 23. 16.  8.  0.  8.  0.] 
adversary owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0  1] -> size -> 33 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: 0.17030170559883118
desired expected reward: -7.83092737197876



action possibilites: [-1.  8.] 
expected returns: [[14.623605]
 [13.991847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1] -> size -> 35 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 1. 23. 30. 21. 27.  8.  1.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 8.  3.  1. 11.  0.] 
adversary cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.  0. 16. 29.
  3.  6. 10.  1. 23. 16.  8.  0.  8.  0.] 
adversary owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0  1] -> size -> 33 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action 23.0
Learning step: 1.26856529712677
desired expected reward: -0.6365033388137817





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[13.699433 ]
 [15.334323 ]
 [15.220372 ]
 [16.02555  ]
 [14.2719965]
 [16.020317 ]
 [14.30301  ]
 [15.291003 ]
 [14.630136 ]
 [14.142646 ]
 [16.579447 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1] -> size -> 35 
action values: 0 
buys: 2 
player value: 4 
card supply: [ 1. 23. 30. 21. 27.  8.  1.  7.  5.  0.  8.  2.  9.  8.  8. 10.  5.] 
adversary cards in hand: [ 8.  3.  1. 11.  0.] 
adversary cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.  0. 16. 29.
  3.  6. 10.  1. 23. 16.  8.  0.  8.  0.] 
adversary owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0  1] -> size -> 33 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: 0.4641127288341522
desired expected reward: 15.08772087097168



buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 6.5511065]
 [ 3.7976835]
 [10.5035715]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 23. 30. 21. 27.  8.  1.  7.  5.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [ 8.  3.  1. 11.  0.] 
adversary cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.  0. 16. 29.
  3.  6. 10.  1. 23. 16.  8.  0.  8.  0.] 
adversary owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0  1] -> size -> 33 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0 -1  0  0 16  0] 
sum of rewards: 32 

action type: buy - action 15.0
Learning step: 1.0648714303970337
desired expected reward: 15.20751953125






Player: 1 
cards in hand: [ 8.  3.  1. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  1. 11.  0.] 
cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.  0. 16. 29.
  3.  6. 10.  1. 23. 16.  8.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 21. 27.  8.  1.  7.  5.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [ 0. 25. 15. 29.  8.] 
adversary cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0. 15.
 23.  0.  0.  0.  3.  8.] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15] -> size -> 36 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  1. 11.  0.] 
cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.  0. 16. 29.
  3.  6. 10.  1. 23. 16.  8.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 23. 30. 21. 27.  8.  1.  7.  5.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [ 0. 25. 15. 29.  8.] 
adversary cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0. 15.
 23.  0.  0.  0.  3.  8.] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15] -> size -> 36 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  1. 11.  0.] 
cards in discard: [15. 11.  6.  0. 29.  3.  8.  0. 29.  0.  4. 15.  1.  6.  6.  0. 16. 29.
  3.  6. 10.  1. 23. 16.  8.  0.  8.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0  1 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 21. 27.  8.  1.  7.  4.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [ 0. 25. 15. 29.  8.] 
adversary cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0. 15.
 23.  0.  0.  0.  3.  8.] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15] -> size -> 36 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 15. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 29.  8.] 
expected returns: [[-16.163652]
 [-19.178173]
 [-27.780357]
 [-26.467857]
 [-26.245974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 15. 29.  8.] 
cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0. 15.
 23.  0.  0.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 21. 27.  8.  1.  7.  4.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [10.  6. 29.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0  1 11] -> size -> 34 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -1.165666937828064
desired expected reward: 9.337907791137695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-25.920975]
 [-36.41144 ]
 [-13.613114]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 15. 29.  8.] 
cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0. 15.
 23.  0.  0.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 23. 30. 21. 27.  8.  1.  7.  4.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [10.  6. 29.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0  1 11] -> size -> 34 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: 0.14000920951366425
desired expected reward: -16.023622512817383



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  6. 29.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 29.  6.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0  1 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 21. 27.  8.  1.  7.  4.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [ 3.  6. 25.  0.  3.] 
adversary cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0. 15.
 23.  0.  0.  0.  3.  8.  0. 25. 15. 29.  8.] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15] -> size -> 36 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 29.  6.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0  1 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 23. 30. 21. 27.  8.  1.  7.  4.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [ 3.  6. 25.  0.  3.] 
adversary cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0. 15.
 23.  0.  0.  0.  3.  8.  0. 25. 15. 29.  8.] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15] -> size -> 36 
adversary victory points: 2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 3.  6. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[41.891735]
 [44.741142]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 25.  0.  3.] 
cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0. 15.
 23.  0.  0.  0.  3.  8.  0. 25. 15. 29.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 21. 27.  8.  1.  7.  4.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [ 8.  8.  6. 16.  0.] 
adversary cards in discard: [10.  6. 29.  6.  0.] 
adversary owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0  1 11] -> size -> 34 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: 1.530534267425537
desired expected reward: -12.462547302246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.052502]
 [19.756191]
 [40.916096]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 25.  0.  3.] 
cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0. 15.
 23.  0.  0.  0.  3.  8.  0. 25. 15. 29.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 23. 30. 21. 27.  8.  1.  7.  4.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [ 8.  8.  6. 16.  0.] 
adversary cards in discard: [10.  6. 29.  6.  0.] 
adversary owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0  1 11] -> size -> 34 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -1.5112107992172241
desired expected reward: 40.38050842285156



buy possibilites: [-1] 
expected returns: [[-4.2054257]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 25.  0.  3.] 
cards in discard: [ 6. 15.  8.  4. 11.  6.  0.  6.  0.  8.  6.  1.  0. 29.  0.  3.  0. 15.
 23.  0.  0.  0.  3.  8.  0. 25. 15. 29.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 21. 27.  8.  1.  7.  4.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [ 8.  8.  6. 16.  0.] 
adversary cards in discard: [10.  6. 29.  6.  0.] 
adversary owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0  1 11] -> size -> 34 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.   0.   0.   0.   0. -30.   0.   0.   0.  -2.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: -3.3972465991973877
desired expected reward: 27.655242919921875






Player: 1 
cards in hand: [ 8.  8.  6. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  6. 16.  0.] 
cards in discard: [10.  6. 29.  6.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  3 29  6  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29
 11  0  6  1  0 15  4  0  1 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 21. 27.  8.  1.  7.  4.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [ 6.  0.  6.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15  0] -> size -> 37 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0.] 
cards in discard: [10.  6. 29.  6.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  3  3 29  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29 11
  0  6  1  0 15  4  0  1 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 21. 27.  8.  1.  7.  4.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [ 6.  0.  6.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  0.] 
cards in discard: [10.  6. 29.  6.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  3  3 29  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29 11
  0  6  1  0 15  4  0  1 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 21. 27.  8.  1.  7.  4.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [ 6.  0.  6.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  6.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-4.7344017]
 [-3.717424 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6.  0. 14.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 21. 27.  8.  1.  7.  4.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [ 0. 15. 11. 29.  3.] 
adversary cards in discard: [10.  6. 29.  6.  0.  8.  8. 16.  0.] 
adversary owned cards: [ 8 11  3  3 29  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29 11
  0  6  1  0 15  4  0  1 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -0.5325774550437927
desired expected reward: -4.738003253936768



action possibilites: [-1] 
expected returns: [[-5.510434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 23. 30. 21. 27.  8.  1.  7.  4.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [15. 11.  3.] 
adversary cards in discard: [10.  6. 29.  6.  0.  8.  8. 16.  0.  0. 29.] 
adversary owned cards: [ 8 11  3  3 29  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29 11
  0  6  1  0 15  4  0  1 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action 14.0
Learning step: 0.4118863046169281
desired expected reward: -3.305535078048706





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-7.904108 ]
 [-7.8933578]
 [-6.0983524]
 [-8.093918 ]
 [-7.397926 ]
 [-7.796265 ]
 [-6.6546774]
 [-7.8130174]
 [-7.323979 ]
 [-7.287066 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 23. 30. 21. 27.  8.  1.  7.  4.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [15. 11.  3.] 
adversary cards in discard: [10.  6. 29.  6.  0.  8.  8. 16.  0.  0. 29.] 
adversary owned cards: [ 8 11  3  3 29  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29 11
  0  6  1  0 15  4  0  1 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: 0.4642655849456787
desired expected reward: -5.046168327331543



Player 1 won the game! 



Player 0 bought cards:
Copper: 15 
Silver: 3 
Gold: 0 
Estate: 4 
Duchy: 1 
Province: 0 
Curse: 6 

Remodel: 0 
Workshop: 1 
Chapel: 5 
Witch: 2 
Poacher: 2 
Militia: 1 
Market: 1 
Village: 0 
Library: 0 
Moneylender: 3 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [6.] 
cards in deck: 32 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 6  8  0  0  0  3 15 25 29  3  3  0 29  8 14  4 23  8  0 15  8  0  3  6
 25  0  0  0 11  6  0  0  6  6  1 15  0  6] -> size -> 38 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0. 23. 30. 21. 27.  8.  0.  7.  4.  0.  8.  2.  9.  8.  8. 10.  4.] 
adversary cards in hand: [15. 11.  3.] 
adversary cards in discard: [10.  6. 29.  6.  0.  8.  8. 16.  0.  0. 29.] 
adversary owned cards: [ 8 11  3  3 29  1  8 29 16  0  6 10  8  0 15  8  0  6 16  3 23  0 29 11
  0  6  1  0 15  4  0  1 11] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5 -500    1  -20    0    0   20    0    0    0    0   -3    0 -300
    0    0] 
sum of rewards: -807 

action type: buy - action 6.0
Learning step: -40.04508590698242
desired expected reward: -46.143436431884766



