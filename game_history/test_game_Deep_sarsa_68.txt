 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[46.96114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     150       0       0      40       0       0
       0       0     -60       0       0      27       0] 
sum of rewards: 3000152 

action type: buy - action 11.0
Learning step: 300012.5
desired expected reward: 300039.53125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[42.601215]
 [67.04206 ]
 [58.649082]
 [27.949194]
 [76.5925  ]
 [57.84972 ]
 [49.906162]
 [43.96462 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 46.7154426574707



buy possibilites: [-1] 
expected returns: [[34.82809]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 76.59249877929688






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[54.381016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.82809066772461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 51.703552]
 [ 76.09859 ]
 [ 67.95161 ]
 [ 35.95558 ]
 [ 65.48567 ]
 [ 86.018074]
 [ 67.11415 ]
 [102.776634]
 [ 50.414932]
 [ 59.682583]
 [ 74.37504 ]
 [ 53.513145]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 53.11801528930664



buy possibilites: [-1] 
expected returns: [[20.35162]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 102.77664184570312






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  0.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[36.38711]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.351619720458984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[37.853107]
 [60.97318 ]
 [53.062828]
 [23.602777]
 [68.22777 ]
 [52.630093]
 [44.831066]
 [37.23976 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 35.939453125



buy possibilites: [-1] 
expected returns: [[43.3839]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 68.22776794433594






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[30.19947]
 [74.32029]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.3838996887207



action possibilites: [-1.] 
expected returns: [[95.22354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 74.35443878173828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 94.21944 ]
 [127.94931 ]
 [116.0941  ]
 [ 82.176094]
 [ 71.22766 ]
 [113.856895]
 [138.85556 ]
 [115.30817 ]
 [172.44011 ]
 [158.45312 ]
 [ 92.213745]
 [123.667046]
 [104.98238 ]
 [ 90.13461 ]
 [125.086975]
 [ 95.90153 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 95.22354125976562



buy possibilites: [-1] 
expected returns: [[37.325924]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 172.44009399414062






Player: 1 
cards in hand: [ 0.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [10.  3.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [10.  3.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10] -> size -> 13 
action values: 2 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  0.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[15.521554]
 [49.25839 ]
 [33.360737]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.325923919677734



action possibilites: [-1] 
expected returns: [[23.462526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 29.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 48.750579833984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.555578]
 [35.351234]
 [30.605816]
 [ 9.635489]
 [27.524954]
 [42.16907 ]
 [29.583504]
 [48.565887]
 [18.429245]
 [25.052553]
 [34.98976 ]
 [25.168545]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11. 29.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.462526321411133



buy possibilites: [-1] 
expected returns: [[24.021053]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11. 29.  0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8. 10.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 48.56587600708008






Player: 1 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8. 10.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 11.  0.] 
adversary cards in discard: [29. 25.  0.  0.  0. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29] -> size -> 15 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8. 10.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 11.  0.] 
adversary cards in discard: [29. 25.  0.  0.  0. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8. 10.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 11.  0.] 
adversary cards in discard: [29. 25.  0.  0.  0. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29] -> size -> 15 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6. 1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8.  9. 10.  8. 10.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 11.  0.] 
adversary cards in discard: [29. 25.  0.  0.  0. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29] -> size -> 15 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 9.560061]
 [20.300262]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.  0.] 
cards in discard: [29. 25.  0.  0.  0. 11. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10.  8. 10.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3. 14. 29.  0.] 
adversary cards in discard: [ 6.  1. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.021053314208984



action possibilites: [-1] 
expected returns: [[10.988742]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29. 25.  0.  0.  0. 11. 29.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10.  8. 10.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3. 14. 29.  0.] 
adversary cards in discard: [ 6.  1. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 23.827312469482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 8.34354  ]
 [18.629093 ]
 [-1.0563078]
 [17.845114 ]
 [12.149435 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29. 25.  0.  0.  0. 11. 29.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8.  9. 10.  8. 10.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3. 14. 29.  0.] 
adversary cards in discard: [ 6.  1. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.988741874694824



buy possibilites: [-1] 
expected returns: [[8.651319]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29. 25.  0.  0.  0. 11. 29.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  8. 10.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3. 14. 29.  0.] 
adversary cards in discard: [ 6.  1. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 18.629093170166016






Player: 1 
cards in hand: [10.  3. 14. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 14. 29.  0.] 
cards in discard: [ 6.  1. 10.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  8. 10.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3] -> size -> 17 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 14. 29.  0.] 
cards in discard: [ 6.  1. 10.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  8. 10.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3] -> size -> 17 
adversary victory points: 4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[25.335682]
 [49.375484]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  8. 10.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.651318550109863



action possibilites: [-1] 
expected returns: [[44.43619]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  8. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 55.54116439819336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[46.16817 ]
 [68.4655  ]
 [60.959126]
 [32.561573]
 [76.14366 ]
 [60.331486]
 [52.944633]
 [45.739582]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  8. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.43619155883789



buy possibilites: [-1] 
expected returns: [[53.727993]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 76.14366149902344






Player: 1 
cards in hand: [ 0. 14.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10. 25.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11] -> size -> 19 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10. 25.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11] -> size -> 19 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  0.  0.] 
cards in discard: [1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10. 25.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11] -> size -> 19 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[43.93694 ]
 [49.707447]
 [87.2357  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10. 25.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  6.  1.  0.] 
adversary cards in discard: [ 1.  0. 14.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.72799301147461



action possibilites: [-1] 
expected returns: [[56.383472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10. 29. 11.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  7. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  6.  1.  0.] 
adversary cards in discard: [ 1.  0. 14.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6] -> size -> 18 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 76.41020965576172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[58.059196]
 [71.23726 ]
 [44.144344]
 [70.638695]
 [58.726894]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10. 29. 11.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  7. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  6.  1.  0.] 
adversary cards in discard: [ 1.  0. 14.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6] -> size -> 18 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.38347244262695



buy possibilites: [-1] 
expected returns: [[38.17119]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10. 29. 11.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  7. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  6.  1.  0.] 
adversary cards in discard: [ 1.  0. 14.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6] -> size -> 18 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 71.23724365234375






Player: 1 
cards in hand: [ 3. 10.  6.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6.  1.  0.] 
cards in discard: [ 1.  0. 14.  3.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  7. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.  3. 25.  3.  0.  0. 10. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3] -> size -> 20 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  1.  0.] 
cards in discard: [ 1.  0. 14.  3.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  7. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.  3. 25.  3.  0.  0. 10. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3] -> size -> 20 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  1.  0.] 
cards in discard: [ 1.  0. 14.  3.  0.  0.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  8. 10.  7. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.  3. 25.  3.  0.  0. 10. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3] -> size -> 20 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-5.9650927]
 [24.092604 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.  3. 25.  3.  0.  0. 10. 29. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  8. 10.  7. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3. 29.] 
adversary cards in discard: [ 1.  0. 14.  3.  0.  0.  6.  1.  3. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1] -> size -> 19 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.17118835449219



action possibilites: [-1. 10.] 
expected returns: [[77.46493]
 [82.97289]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 28. 30.  8.  8. 10.  7. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3. 29.] 
adversary cards in discard: [ 1.  0. 14.  3.  0.  0.  6.  1.  3. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1] -> size -> 19 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 21.32379722595215



action possibilites: [-1. 29.] 
expected returns: [[ 79.49962]
 [108.39502]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3] -> size -> 20 
action values: 2 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 28. 30.  8.  8. 10.  7. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3. 29.] 
adversary cards in discard: [ 1.  0. 14.  3.  0.  0.  6.  1.  3. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1] -> size -> 19 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 82.9728775024414



action possibilites: [-1.] 
expected returns: [[48.35318]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3] -> size -> 20 
action values: 2 
buys: 0 
player value: 2 
card supply: [30. 27. 30. 28. 30.  8.  8. 10.  7. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3. 29.] 
adversary cards in discard: [ 1.  0. 14.  3.  0.  0.  6.  1.  3. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1] -> size -> 19 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 108.39501953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 57.4471  ]
 [ 76.012085]
 [ 69.50325 ]
 [ 51.218838]
 [ 45.135723]
 [ 68.43753 ]
 [ 81.867874]
 [ 69.12535 ]
 [101.55997 ]
 [ 93.30928 ]
 [ 56.075527]
 [ 73.70143 ]
 [ 62.722797]
 [ 55.389412]
 [ 74.36874 ]
 [ 56.693077]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 28. 30.  8.  8. 10.  7. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3. 29.] 
adversary cards in discard: [ 1.  0. 14.  3.  0.  0.  6.  1.  3. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1] -> size -> 19 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 48.353179931640625



buy possibilites: [-1] 
expected returns: [[58.231216]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  8. 10.  7. 10.  8.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3. 29.] 
adversary cards in discard: [ 1.  0. 14.  3.  0.  0.  6.  1.  3. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1] -> size -> 19 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 425 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 101.55996704101562






Player: 1 
cards in hand: [ 0.  0. 10.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3. 29.] 
cards in discard: [ 1.  0. 14.  3.  0.  0.  6.  1.  3. 10.  6.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  8. 10.  7. 10.  8.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  0. 11.] 
adversary cards in discard: [25. 29. 10. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25] -> size -> 21 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 1.  0. 14.  3.  0.  0.  6.  1.  3. 10.  6.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 28. 30.  8.  8. 10.  7. 10.  8.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  0. 11.] 
adversary cards in discard: [25. 29. 10. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25] -> size -> 21 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 14.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1] -> size -> 19 
action values: 2 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 28. 30.  8.  8. 10.  7. 10.  8.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  0. 11.] 
adversary cards in discard: [25. 29. 10. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25] -> size -> 21 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 27. 30. 28. 30.  8.  8. 10.  7. 10.  8.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11. 11.] 
adversary cards in discard: [25. 29. 10. 29.  3.  3.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25] -> size -> 21 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 27. 30. 28. 30.  8.  8. 10.  7. 10.  8.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11. 11.] 
adversary cards in discard: [25. 29. 10. 29.  3.  3.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25] -> size -> 21 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 26. 30. 28. 30.  8.  8. 10.  7. 10.  8.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11. 11.] 
adversary cards in discard: [25. 29. 10. 29.  3.  3.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25] -> size -> 21 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[37.43365]
 [51.70899]
 [51.70899]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.] 
cards in discard: [25. 29. 10. 29.  3.  3.  0.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 28. 30.  8.  8. 10.  7. 10.  8.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  6.] 
adversary cards in discard: [ 1. 29. 10. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1] -> size -> 20 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0 411   0] 
sum of rewards: 526 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 166.03543090820312



action possibilites: [-1] 
expected returns: [[17.60074]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.] 
cards in discard: [25. 29. 10. 29.  3.  3.  0.  0.  0.  3.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 28. 30.  8.  8. 10.  7. 10.  8.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  6.] 
adversary cards in discard: [ 1. 29. 10. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1] -> size -> 20 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 48.994224548339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.583257 ]
 [ 5.1389875]
 [18.92717  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [25. 29. 10. 29.  3.  3.  0.  0.  0.  3.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 26. 30. 28. 30.  8.  8. 10.  7. 10.  8.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  6.] 
adversary cards in discard: [ 1. 29. 10. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1] -> size -> 20 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.600740432739258






Player: 1 
cards in hand: [ 3.  0.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  6.] 
cards in discard: [ 1. 29. 10. 14.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 28. 30.  8.  8. 10.  7. 10.  8.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11. 25.] 
adversary cards in discard: [25. 29. 10. 29.  3.  3.  0.  0.  0.  3.  0. 10. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10] -> size -> 22 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  6.] 
cards in discard: [ 1. 29. 10. 14.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 26. 30. 28. 30.  8.  8. 10.  7. 10.  8.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11. 25.] 
adversary cards in discard: [25. 29. 10. 29.  3.  3.  0.  0.  0.  3.  0. 10. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10] -> size -> 22 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  6.] 
cards in discard: [ 1. 29. 10. 14.  0.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 26. 30. 28. 30.  8.  8. 10.  7. 10.  8.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11. 25.] 
adversary cards in discard: [25. 29. 10. 29.  3.  3.  0.  0.  0.  3.  0. 10. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10] -> size -> 22 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[52.36106]
 [58.3383 ]
 [65.50916]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11. 25.] 
cards in discard: [25. 29. 10. 29.  3.  3.  0.  0.  0.  3.  0. 10. 11.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  8. 10.  7. 10.  8.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 6. 1.] 
adversary cards in discard: [ 1. 29. 10. 14.  0.  0.  3.  0.  0.  3.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0] -> size -> 21 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 18.927167892456055



action possibilites: [-1] 
expected returns: [[35.90995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0. 10.] 
cards in discard: [25. 29. 10. 29.  3.  3.  0.  0.  0.  3.  0. 10. 11.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  7. 10.  7. 10.  8.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 6. 1.] 
adversary cards in discard: [ 1. 29. 10. 14.  0.  0.  3.  0.  0.  3.  0.  0. 10.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6] -> size -> 22 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 65.5048828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[32.844444]
 [48.621582]
 [44.78658 ]
 [21.62504 ]
 [54.87649 ]
 [43.74424 ]
 [39.79824 ]
 [39.236774]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.  0. 10.] 
cards in discard: [25. 29. 10. 29.  3.  3.  0.  0.  0.  3.  0. 10. 11.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 28. 30.  8.  7. 10.  7. 10.  8.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 6. 1.] 
adversary cards in discard: [ 1. 29. 10. 14.  0.  0.  3.  0.  0.  3.  0.  0. 10.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6] -> size -> 22 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.909950256347656



buy possibilites: [-1] 
expected returns: [[82.98634]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.  0. 10.] 
cards in discard: [25. 29. 10. 29.  3.  3.  0.  0.  0.  3.  0. 10. 11.  3. 11. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  7. 10.  6. 10.  8.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 6. 1.] 
adversary cards in discard: [ 1. 29. 10. 14.  0.  0.  3.  0.  0.  3.  0.  0. 10.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6] -> size -> 22 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 54.87651443481445






Player: 1 
cards in hand: [0. 0. 1. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 6. 1.] 
cards in discard: [ 1. 29. 10. 14.  0.  0.  3.  0.  0.  3.  0.  0. 10.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  7. 10.  6. 10.  8.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11. 29.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11] -> size -> 23 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 1.] 
cards in discard: [ 1. 29. 10. 14.  0.  0.  3.  0.  0.  3.  0.  0. 10.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 26. 30. 28. 30.  8.  7. 10.  6. 10.  8.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11. 29.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11] -> size -> 23 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 1.] 
cards in discard: [ 1. 29. 10. 14.  0.  0.  3.  0.  0.  3.  0.  0. 10.  6.  6. 22.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 28. 30.  8.  7. 10.  6. 10.  8.  7.  9. 10.  5.  9. 10.] 
adversary cards in hand: [11. 29.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11] -> size -> 23 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [11. 29.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[22.20214 ]
 [38.291084]
 [45.992413]
 [25.078478]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  7. 10.  6. 10.  8.  7.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 1.  1. 22.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22] -> size -> 23 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.98634338378906



action possibilites: [-1. 11. 10.] 
expected returns: [[28.439705]
 [48.05035 ]
 [32.72586 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 28. 30.  8.  7. 10.  6. 10.  8.  7.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 1.  1. 22.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22] -> size -> 23 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.52889633178711



action possibilites: [-1] 
expected returns: [[43.04625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 28. 30.  8.  7. 10.  6. 10.  8.  7.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 1.  1. 22.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22] -> size -> 23 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 212 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 53.09311294555664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[50.883854]
 [61.32652 ]
 [39.86585 ]
 [60.90304 ]
 [50.280167]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 28. 30.  8.  7. 10.  6. 10.  8.  7.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 1.  1. 22.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22] -> size -> 23 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.04624938964844



buy possibilites: [-1] 
expected returns: [[50.282978]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.] 
cards in discard: [10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8.  7. 10.  6. 10.  8.  7.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 1.  1. 22.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22] -> size -> 23 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 231 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 61.32651138305664






Player: 1 
cards in hand: [ 1.  1. 22.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 22.  1.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8.  7. 10.  6. 10.  8.  7.  9. 10.  4.  9. 10.] 
adversary cards in hand: [11.  0. 25.  3.  0.] 
adversary cards in discard: [10.  3. 29. 11.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3] -> size -> 25 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1. 3. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8.  7. 10.  6. 10.  8.  7.  9. 10.  4.  9. 10.] 
adversary cards in hand: [11.  0. 25.  3.  0.] 
adversary cards in discard: [10.  3. 29. 11.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3] -> size -> 25 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 3. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22] -> size -> 23 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 26. 30. 27. 30.  8.  7. 10.  6. 10.  8.  7.  9. 10.  4.  9. 10.] 
adversary cards in hand: [11.  0. 25.  3.  0.] 
adversary cards in discard: [10.  3. 29. 11.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3] -> size -> 25 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 3. 0. 3. 6.] 
cards in discard: [2.] 
cards in deck: 15 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 29. 27. 30.  8.  7. 10.  6. 10.  8.  7.  9. 10.  4.  9. 10.] 
adversary cards in hand: [11.  0. 25.  3.  0.] 
adversary cards in discard: [10.  3. 29. 11.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3] -> size -> 25 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [11.  0. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[40.377804]
 [47.86226 ]
 [54.857143]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 25.  3.  0.] 
cards in discard: [10.  3. 29. 11.  3. 10.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 29. 27. 30.  8.  7. 10.  6. 10.  8.  7.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [ 2. 22.  1.  1.  1.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2] -> size -> 24 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.28297805786133



action possibilites: [-1] 
expected returns: [[23.049042]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  0. 11.] 
cards in discard: [10.  3. 29. 11.  3. 10.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 29. 27. 30.  8.  6. 10.  6. 10.  8.  7.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [ 2. 22.  1.  1.  1.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6] -> size -> 25 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 55.98994827270508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 5.2693443 ]
 [11.664414  ]
 [13.250133  ]
 [ 0.67742133]
 [18.834337  ]
 [10.853551  ]
 [12.439279  ]
 [24.10306   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  0. 11.] 
cards in discard: [10.  3. 29. 11.  3. 10.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 29. 27. 30.  8.  6. 10.  6. 10.  8.  7.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [ 2. 22.  1.  1.  1.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6] -> size -> 25 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.049041748046875






Player: 1 
cards in hand: [ 0.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [ 2. 22.  1.  1.  1.  3.  0.  3.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 29. 27. 30.  8.  6. 10.  6. 10.  8.  7.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 25. 10.  0.  0.] 
adversary cards in discard: [10.  3. 29. 11.  3. 10.  3.  0. 25. 11.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3] -> size -> 25 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [ 2. 22.  1.  1.  1.  3.  0.  3.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 26. 29. 27. 30.  8.  6. 10.  6. 10.  8.  7.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 25. 10.  0.  0.] 
adversary cards in discard: [10.  3. 29. 11.  3. 10.  3.  0. 25. 11.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3] -> size -> 25 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [ 2. 22.  1.  1.  1.  3.  0.  3.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 26. 29. 27. 30.  8.  6. 10.  6. 10.  8.  7.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 25. 10.  0.  0.] 
adversary cards in discard: [10.  3. 29. 11.  3. 10.  3.  0. 25. 11.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3] -> size -> 25 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [ 2. 22.  1.  1.  1.  3.  0.  3.  6.  6. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 29. 27. 30.  8.  6. 10.  6. 10.  8.  6.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 25. 10.  0.  0.] 
adversary cards in discard: [10.  3. 29. 11.  3. 10.  3.  0. 25. 11.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3] -> size -> 25 
adversary victory points: 6
player victory points: -1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[17.654114]
 [34.077232]
 [15.881028]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 10.  0.  0.] 
cards in discard: [10.  3. 29. 11.  3. 10.  3.  0. 25. 11.  0.  3.  0.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 29. 27. 30.  8.  6. 10.  6. 10.  8.  6.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 6.  0.  1.  3. 14.] 
adversary cards in discard: [ 2. 22.  1.  1.  1.  3.  0.  3.  6.  6. 29. 10.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29] -> size -> 26 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 24.103052139282227



action possibilites: [-1] 
expected returns: [[2.3451145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 29. 10.] 
cards in discard: [10.  3. 29. 11.  3. 10.  3.  0. 25. 11.  0.  3.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 29. 27. 30.  8.  5. 10.  6. 10.  8.  6.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 6.  0.  1.  3. 14.] 
adversary cards in discard: [ 2. 22.  1.  1.  1.  3.  0.  3.  6.  6. 29. 10.  0.  0.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6] -> size -> 27 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 34.077205657958984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-11.9562    ]
 [  7.6456623 ]
 [  2.6774757 ]
 [-19.058815  ]
 [ 24.400457  ]
 [ -0.38585877]
 [ -4.1655354 ]
 [  2.7034972 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 29. 10.] 
cards in discard: [10.  3. 29. 11.  3. 10.  3.  0. 25. 11.  0.  3.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 29. 27. 30.  8.  5. 10.  6. 10.  8.  6.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 6.  0.  1.  3. 14.] 
adversary cards in discard: [ 2. 22.  1.  1.  1.  3.  0.  3.  6.  6. 29. 10.  0.  0.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6] -> size -> 27 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.3451144695281982



buy possibilites: [-1] 
expected returns: [[40.036922]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 29. 10.] 
cards in discard: [10.  3. 29. 11.  3. 10.  3.  0. 25. 11.  0.  3.  0.  0. 11. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 29. 27. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 6.  0.  1.  3. 14.] 
adversary cards in discard: [ 2. 22.  1.  1.  1.  3.  0.  3.  6.  6. 29. 10.  0.  0.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6] -> size -> 27 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 279 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 24.400493621826172






Player: 1 
cards in hand: [ 6.  0.  1.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  1.  3. 14.] 
cards in discard: [ 2. 22.  1.  1.  1.  3.  0.  3.  6.  6. 29. 10.  0.  0.  0.  0. 10.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 29. 27. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 10. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11] -> size -> 26 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1.  3. 14.] 
cards in discard: [ 2. 22.  1.  1.  1.  3.  0.  3.  6.  6. 29. 10.  0.  0.  0.  0. 10.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 29. 27. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 10. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11] -> size -> 26 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1.  3. 14.] 
cards in discard: [ 2. 22.  1.  1.  1.  3.  0.  3.  6.  6. 29. 10.  0.  0.  0.  0. 10.  6.
 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 29. 27. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  3.  9. 10.] 
adversary cards in hand: [ 0. 10. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11] -> size -> 26 
adversary victory points: 6
player victory points: -2 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[27.6394  ]
 [26.296356]
 [37.72562 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 29. 27. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  3.  9. 10.] 
adversary cards in hand: [22.  6. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10] -> size -> 28 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.036922454833984



action possibilites: [-1] 
expected returns: [[35.38603]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 29. 27. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [22.  6. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10] -> size -> 28 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 41.49986267089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.356328 ]
 [ 5.0442495]
 [35.801823 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 26. 29. 27. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [22.  6. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10] -> size -> 28 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.38602828979492






Player: 1 
cards in hand: [22.  6. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  6. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 29. 27. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [ 3. 11. 29. 10.  0.] 
adversary cards in discard: [10. 11.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10] -> size -> 27 
adversary victory points: 6
player victory points: -2 


action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  6.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 26. 29. 27. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [ 3. 11. 29. 10.  0.] 
adversary cards in discard: [10. 11.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10] -> size -> 27 
adversary victory points: 6
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 6. 3. 2.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 22. 10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 29. 27. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [ 3. 11. 29. 10.  0.] 
adversary cards in discard: [10. 11.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10] -> size -> 27 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 6. 3. 2.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 22. 10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 26. 29. 27. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [ 3. 11. 29. 10.  0.] 
adversary cards in discard: [10. 11.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10] -> size -> 27 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 6. 3. 2.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 22. 10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 26. 29. 26. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [ 3. 11. 29. 10.  0.] 
adversary cards in discard: [10. 11.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10] -> size -> 27 
adversary victory points: 6
player victory points: -1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[108.9751  ]
 [124.993805]
 [123.41734 ]
 [ 96.116776]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29. 10.  0.] 
cards in discard: [10. 11.  0. 10.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 29. 26. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [ 1.  6. 10.  0.  6.] 
adversary cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3] -> size -> 29 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 35.80181884765625



action possibilites: [-1] 
expected returns: [[21.997501]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10.  0.] 
cards in discard: [10. 11.  0. 10.  3.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 29. 26. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  1.  9. 10.] 
adversary cards in hand: [ 1.  6. 10.  0.  6.] 
adversary cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3] -> size -> 29 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 252 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 126.21429443359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 0.71037555]
 [-9.837025  ]
 [22.206358  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 10.  0.] 
cards in discard: [10. 11.  0. 10.  3.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 26. 29. 26. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  1.  9. 10.] 
adversary cards in hand: [ 1.  6. 10.  0.  6.] 
adversary cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3] -> size -> 29 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.997501373291016






Player: 1 
cards in hand: [ 1.  6. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 10.  0.  6.] 
cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 29. 26. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  1.  9. 10.] 
adversary cards in hand: [11. 10. 29. 11.  0.] 
adversary cards in discard: [10. 11.  0. 10.  3.  3. 10. 11.  3. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10] -> size -> 28 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 10.  0.  6.] 
cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 29. 26. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  1.  9. 10.] 
adversary cards in hand: [11. 10. 29. 11.  0.] 
adversary cards in discard: [10. 11.  0. 10.  3.  3. 10. 11.  3. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10] -> size -> 28 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 10.  0.  6.] 
cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 29. 26. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  1.  9. 10.] 
adversary cards in hand: [11. 10. 29. 11.  0.] 
adversary cards in discard: [10. 11.  0. 10.  3.  3. 10. 11.  3. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10] -> size -> 28 
adversary victory points: 6
player victory points: -1 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11. 10. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29. 11.] 
expected returns: [[23.865112]
 [31.636974]
 [20.778093]
 [32.96231 ]
 [31.636974]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29. 11.  0.] 
cards in discard: [10. 11.  0. 10.  3.  3. 10. 11.  3. 29. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 29. 26. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.  1.  1.  6. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1] -> size -> 30 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 22.206348419189453



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[33.095547]
 [41.559147]
 [29.59742 ]
 [41.559147]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  0.  0.] 
cards in discard: [10. 11.  0. 10.  3.  3. 10. 11.  3. 29. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 25. 29. 26. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.  1.  1.  6. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1] -> size -> 30 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 32.96229553222656



action possibilites: [-1] 
expected returns: [[78.33608]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0.] 
cards in discard: [10. 11.  0. 10.  3.  3. 10. 11.  3. 29. 10.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 25. 29. 26. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.  1.  1.  6. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1] -> size -> 30 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 272 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 44.50669860839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[67.28199 ]
 [78.90379 ]
 [76.85281 ]
 [61.638218]
 [85.088776]
 [75.278   ]
 [77.55607 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  0.] 
cards in discard: [10. 11.  0. 10.  3.  3. 10. 11.  3. 29. 10.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 25. 29. 26. 30.  8.  5. 10.  5. 10.  8.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.  1.  1.  6. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1] -> size -> 30 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.3360824584961



buy possibilites: [-1] 
expected returns: [[32.647415]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  0.] 
cards in discard: [10. 11.  0. 10.  3.  3. 10. 11.  3. 29. 10.  0. 10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 29. 26. 30.  8.  5. 10.  4. 10.  8.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.  1.  1.  6. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1] -> size -> 30 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 299 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 85.0887451171875






Player: 1 
cards in hand: [ 0.  1.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  0. 10.] 
cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.  1.  1.  6. 10.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 29. 26. 30.  8.  5. 10.  4. 10.  8.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  3.] 
adversary cards in discard: [10. 11.  0. 10.  3.  3. 10. 11.  3. 29. 10.  0. 10. 11. 29. 11. 10. 11.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11] -> size -> 30 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.  1.  1.  6. 10.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 25. 29. 26. 30.  8.  5. 10.  4. 10.  8.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  3.] 
adversary cards in discard: [10. 11.  0. 10.  3.  3. 10. 11.  3. 29. 10.  0. 10. 11. 29. 11. 10. 11.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11] -> size -> 30 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.  1.  1.  6. 10.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 25. 29. 26. 30.  8.  5. 10.  4. 10.  8.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  3.] 
adversary cards in discard: [10. 11.  0. 10.  3.  3. 10. 11.  3. 29. 10.  0. 10. 11. 29. 11. 10. 11.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11] -> size -> 30 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.  1.  1.  6. 10.  0.  6.
 22.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 25. 29. 26. 30.  8.  5. 10.  4. 10.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  3.] 
adversary cards in discard: [10. 11.  0. 10.  3.  3. 10. 11.  3. 29. 10.  0. 10. 11. 29. 11. 10. 11.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11] -> size -> 30 
adversary victory points: 6
player victory points: -1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[50.274273]
 [74.03194 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 25.  3.] 
cards in discard: [10. 11.  0. 10.  3.  3. 10. 11.  3. 29. 10.  0. 10. 11. 29. 11. 10. 11.
  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 29. 26. 30.  8.  5. 10.  4. 10.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [ 0.  1. 29.  3.  6.] 
adversary cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.  1.  1.  6. 10.  0.  6.
 22. 10.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22] -> size -> 31 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.64741516113281



action possibilites: [-1] 
expected returns: [[76.22301]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 11. 25.] 
cards in discard: [10. 11.  0. 10.  3.  3. 10. 11.  3. 29. 10.  0. 10. 11. 29. 11. 10. 11.
  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 29. 26. 30.  8.  4. 10.  4. 10.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [ 0.  1. 29.  3.  6.] 
adversary cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.  1.  1.  6. 10.  0.  6.
 22. 10.  0.  1.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6] -> size -> 32 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 74.03192138671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[69.14168 ]
 [82.97033 ]
 [58.05657 ]
 [81.443634]
 [77.713776]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 11. 25.] 
cards in discard: [10. 11.  0. 10.  3.  3. 10. 11.  3. 29. 10.  0. 10. 11. 29. 11. 10. 11.
  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 25. 29. 26. 30.  8.  4. 10.  4. 10.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [ 0.  1. 29.  3.  6.] 
adversary cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.  1.  1.  6. 10.  0.  6.
 22. 10.  0.  1.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6] -> size -> 32 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.22300720214844



buy possibilites: [-1] 
expected returns: [[47.203655]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 11. 25.] 
cards in discard: [10. 11.  0. 10.  3.  3. 10. 11.  3. 29. 10.  0. 10. 11. 29. 11. 10. 11.
  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 29. 25. 30.  8.  4. 10.  4. 10.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [ 0.  1. 29.  3.  6.] 
adversary cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.  1.  1.  6. 10.  0.  6.
 22. 10.  0.  1.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6] -> size -> 32 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 271 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 82.9703369140625






Player: 1 
cards in hand: [ 0.  1. 29.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.  3.  6.] 
cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.  1.  1.  6. 10.  0.  6.
 22. 10.  0.  1.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 29. 25. 30.  8.  4. 10.  4. 10.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [10.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3] -> size -> 31 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29.  3.  6.] 
cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.  1.  1.  6. 10.  0.  6.
 22. 10.  0.  1.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 25. 29. 25. 30.  8.  4. 10.  4. 10.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [10.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3] -> size -> 31 
adversary victory points: 7
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29.  3.  6.] 
cards in discard: [ 3. 29. 22. 10. 14.  6.  0.  0.  3.  6.  3.  2.  1.  1.  6. 10.  0.  6.
 22. 10.  0.  1.  0.  0.  0.  6.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 25. 29. 25. 30.  8.  4. 10.  4.  9.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [10.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3] -> size -> 31 
adversary victory points: 7
player victory points: -2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [10.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[148.77545]
 [134.26514]
 [134.26514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 29. 25. 30.  8.  4. 10.  4.  9.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [ 6. 22.  6. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8] -> size -> 33 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 47.20365524291992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[109.48202]
 [139.68195]
 [ 87.14185]
 [134.42004]
 [145.02136]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 25. 29. 25. 30.  8.  4. 10.  4.  9.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [ 6. 22.  6. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8] -> size -> 33 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 148.77540588378906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6. 22.  6. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 22.  6. 10.  1.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 29. 25. 30.  8.  4. 10.  4.  9.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [25. 11. 10.  3. 10.] 
adversary cards in discard: [10.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3] -> size -> 31 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 22.  6. 10.  1.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 25. 29. 25. 30.  8.  4. 10.  4.  9.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [25. 11. 10.  3. 10.] 
adversary cards in discard: [10.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3] -> size -> 31 
adversary victory points: 7
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 22.  6. 10.  1.] 
cards in discard: [8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 29. 25. 30.  8.  4. 10.  4.  8.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [25. 11. 10.  3. 10.] 
adversary cards in discard: [10.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3] -> size -> 31 
adversary victory points: 7
player victory points: -2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [25. 11. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10. 10.] 
expected returns: [[64.92171 ]
 [84.826744]
 [75.38848 ]
 [60.141266]
 [60.141266]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 10.  3. 10.] 
cards in discard: [10.  0.  3. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 29. 25. 30.  8.  4. 10.  4.  8.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [ 0.  3.  6.  0. 29.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8] -> size -> 34 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 145.02130126953125



action possibilites: [-1] 
expected returns: [[93.58645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3. 10.  3. 11.] 
cards in discard: [10.  0.  3. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 29. 25. 30.  8.  3. 10.  4.  8.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [ 0.  3.  6.  0. 29.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6] -> size -> 35 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 84.82671356201172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[80.40735]
 [72.43486]
 [92.86551]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  3. 10.  3. 11.] 
cards in discard: [10.  0.  3. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 25. 29. 25. 30.  8.  3. 10.  4.  8.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [ 0.  3.  6.  0. 29.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6] -> size -> 35 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.5864486694336






Player: 1 
cards in hand: [ 0.  3.  6.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6.  0. 29.] 
cards in discard: [ 8.  6. 22.  6. 10.  1.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 29. 25. 30.  8.  3. 10.  4.  8.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 11.] 
adversary cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3] -> size -> 31 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6.  0. 29.] 
cards in discard: [ 8.  6. 22.  6. 10.  1.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 25. 29. 25. 30.  8.  3. 10.  4.  8.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 11.] 
adversary cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3] -> size -> 31 
adversary victory points: 7
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6.  0. 29.] 
cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 25. 29. 25. 30.  8.  3. 10.  4.  8.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 11.] 
adversary cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3] -> size -> 31 
adversary victory points: 7
player victory points: -3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[105.57096 ]
 [102.445145]
 [122.180756]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 11.] 
cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 25. 30.  8.  3. 10.  4.  8.  8.  6.  9. 10.  0.  8. 10.] 
adversary cards in hand: [ 1.  0.  2. 10.  3.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0] -> size -> 36 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 92.86548614501953



action possibilites: [-1] 
expected returns: [[158.12251]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 25. 30.  8.  3. 10.  4.  8.  8.  6.  9. 10.  0.  8.  9.] 
adversary cards in hand: [ 1.  0.  2. 10.  3.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0] -> size -> 36 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 379 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 125.4703369140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[124.431915]
 [149.46947 ]
 [147.45882 ]
 [109.82367 ]
 [165.19554 ]
 [143.09102 ]
 [154.60373 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 29. 25. 30.  8.  3. 10.  4.  8.  8.  6.  9. 10.  0.  8.  9.] 
adversary cards in hand: [ 1.  0.  2. 10.  3.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0] -> size -> 36 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 158.1225128173828



buy possibilites: [-1] 
expected returns: [[108.11675]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 25. 30.  8.  3. 10.  3.  8.  8.  6.  9. 10.  0.  8.  9.] 
adversary cards in hand: [ 1.  0.  2. 10.  3.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0] -> size -> 36 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 369 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 165.19554138183594






Player: 1 
cards in hand: [ 1.  0.  2. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  2. 10.  3.] 
cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 25. 30.  8.  3. 10.  3.  8.  8.  6.  9. 10.  0.  8.  9.] 
adversary cards in hand: [11.  0. 10. 11.  0.] 
adversary cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15. 11. 11.  0.  0.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11] -> size -> 33 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  2. 10.  3.] 
cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 25. 29. 25. 30.  8.  3. 10.  3.  8.  8.  6.  9. 10.  0.  8.  9.] 
adversary cards in hand: [11.  0. 10. 11.  0.] 
adversary cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15. 11. 11.  0.  0.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11] -> size -> 33 
adversary victory points: 7
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  2. 10.  3.] 
cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 25. 29. 25. 30.  8.  3.  9.  3.  8.  8.  6.  9. 10.  0.  8.  9.] 
adversary cards in hand: [11.  0. 10. 11.  0.] 
adversary cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15. 11. 11.  0.  0.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11] -> size -> 33 
adversary victory points: 7
player victory points: -3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11.  0. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[54.056812]
 [72.25815 ]
 [50.857227]
 [72.25815 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 11.  0.] 
cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15. 11. 11.  0.  0.  0.
 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 25. 30.  8.  3.  9.  3.  8.  8.  6.  9. 10.  0.  8.  9.] 
adversary cards in hand: [ 6.  0. 29. 22.  6.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16] -> size -> 37 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 108.11675262451172



action possibilites: [-1] 
expected returns: [[65.718056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15. 11. 11.  0.  0.  0.
 10. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 25. 30.  8.  3.  9.  3.  8.  8.  6.  9. 10.  0.  8.  8.] 
adversary cards in hand: [ 6.  0. 29. 22.  6.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16] -> size -> 37 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 379 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 77.31034088134766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[49.324768]
 [67.31073 ]
 [35.369297]
 [65.07846 ]
 [64.7311  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15. 11. 11.  0.  0.  0.
 10. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 25. 29. 25. 30.  8.  3.  9.  3.  8.  8.  6.  9. 10.  0.  8.  8.] 
adversary cards in hand: [ 6.  0. 29. 22.  6.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16] -> size -> 37 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.71805572509766



buy possibilites: [-1] 
expected returns: [[103.81961]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15. 11. 11.  0.  0.  0.
 10. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 24. 30.  8.  3.  9.  3.  8.  8.  6.  9. 10.  0.  8.  8.] 
adversary cards in hand: [ 6.  0. 29. 22.  6.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16] -> size -> 37 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 361 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 67.31072998046875






Player: 1 
cards in hand: [ 6.  0. 29. 22.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 29. 22.  6.] 
cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 24. 30.  8.  3.  9.  3.  8.  8.  6.  9. 10.  0.  8.  8.] 
adversary cards in hand: [ 3. 10.  3. 11. 29.] 
adversary cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15. 11. 11.  0.  0.  0.
 10. 15.  3. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3] -> size -> 35 
adversary victory points: 8
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 29.  6.  8.  0.  6.] 
cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 24. 30.  8.  3.  9.  3.  8.  8.  6.  9. 10.  0.  8.  8.] 
adversary cards in hand: [ 3. 10.  3. 11. 29.] 
adversary cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15. 11. 11.  0.  0.  0.
 10. 15.  3. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3] -> size -> 35 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 29.  6.  8.  0.  6.] 
cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 25. 29. 24. 30.  8.  3.  9.  3.  8.  8.  6.  9. 10.  0.  8.  8.] 
adversary cards in hand: [ 3. 10.  3. 11. 29.] 
adversary cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15. 11. 11.  0.  0.  0.
 10. 15.  3. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3] -> size -> 35 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 29.  6.  8.  0.  6.] 
cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 24. 30.  8.  3.  9.  3.  7.  8.  6.  9. 10.  0.  8.  8.] 
adversary cards in hand: [ 3. 10.  3. 11. 29.] 
adversary cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15. 11. 11.  0.  0.  0.
 10. 15.  3. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3] -> size -> 35 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  3. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[103.514175]
 [103.06256 ]
 [128.26813 ]
 [144.28305 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3. 11. 29.] 
cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15. 11. 11.  0.  0.  0.
 10. 15.  3. 11.  0. 10. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 24. 30.  8.  3.  9.  3.  7.  8.  6.  9. 10.  0.  8.  8.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.  8. 22.  6.  0. 29.  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8] -> size -> 38 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 103.81961059570312



action possibilites: [-1. 10. 11.] 
expected returns: [[117.80464]
 [115.74179]
 [152.39955]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3. 11.] 
cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15. 11. 11.  0.  0.  0.
 10. 15.  3. 11.  0. 10. 11.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 25. 29. 24. 30.  8.  3.  9.  3.  7.  8.  6.  9. 10.  0.  8.  8.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.  8. 22.  6.  0. 29.  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8] -> size -> 38 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 115.09078979492188



action possibilites: [-1] 
expected returns: [[102.86197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.] 
cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15. 11. 11.  0.  0.  0.
 10. 15.  3. 11.  0. 10. 11.  0. 29. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 29. 24. 30.  8.  3.  9.  3.  7.  8.  6.  9. 10.  0.  8.  7.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.  8. 22.  6.  0. 29.  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8] -> size -> 38 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 419 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 160.27813720703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 94.75128]
 [ 76.49049]
 [100.50606]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.] 
cards in discard: [10.  0.  3. 10.  0. 25. 11. 10.  3. 10.  3. 11. 15. 11. 11.  0.  0.  0.
 10. 15.  3. 11.  0. 10. 11.  0. 29. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 25. 29. 24. 30.  8.  3.  9.  3.  7.  8.  6.  9. 10.  0.  8.  7.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.  8. 22.  6.  0. 29.  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8] -> size -> 38 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.86196899414062






Player: 1 
cards in hand: [1. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.  8. 22.  6.  0. 29.  6.  8.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 24. 30.  8.  3.  9.  3.  7.  8.  6.  9. 10.  0.  8.  7.] 
adversary cards in hand: [10. 10.  3.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15] -> size -> 36 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.  8. 22.  6.  0. 29.  6.  8.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 25. 29. 24. 30.  8.  3.  9.  3.  7.  8.  6.  9. 10.  0.  8.  7.] 
adversary cards in hand: [10. 10.  3.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15] -> size -> 36 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.  8. 22.  6.  0. 29.  6.  8.  0.  6. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 24. 30.  8.  3.  9.  3.  7.  8.  6.  8. 10.  0.  8.  7.] 
adversary cards in hand: [10. 10.  3.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15] -> size -> 36 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10. 10.  3.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 25.] 
expected returns: [[ 76.26376]
 [ 68.41636]
 [ 68.41636]
 [100.44899]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  3. 25.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 24. 30.  8.  3.  9.  3.  7.  8.  6.  8. 10.  0.  8.  7.] 
adversary cards in hand: [ 1. 10. 14.  1.  0.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.  8. 22.  6.  0. 29.  6.  8.  0.  6. 14.  1.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14] -> size -> 39 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 100.50607299804688



action possibilites: [-1] 
expected returns: [[93.900604]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 24. 30.  8.  2.  9.  3.  7.  8.  6.  8. 10.  0.  8.  7.] 
adversary cards in hand: [ 1. 10. 14.  1.  0.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.  8. 22.  6.  0. 29.  6.  8.  0.  6. 14.  1.  3.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6] -> size -> 40 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 100.448974609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[88.787476]
 [82.50685 ]
 [95.232124]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 25. 29. 24. 30.  8.  2.  9.  3.  7.  8.  6.  8. 10.  0.  8.  7.] 
adversary cards in hand: [ 1. 10. 14.  1.  0.] 
adversary cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.  8. 22.  6.  0. 29.  6.  8.  0.  6. 14.  1.  3.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6] -> size -> 40 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.90060424804688






Player: 1 
cards in hand: [ 1. 10. 14.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 14.  1.  0.] 
cards in discard: [ 8.  6. 22.  6. 10.  1.  6.  0.  0.  3.  6.  0. 29. 16.  1.  0.  2. 10.
  3.  8. 22.  6.  0. 29.  6.  8.  0.  6. 14.  1.  3.  0.  0.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 24. 30.  8.  2.  9.  3.  7.  8.  6.  8. 10.  0.  8.  7.] 
adversary cards in hand: [11. 11. 15.  0. 25.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15] -> size -> 36 
adversary victory points: 8
player victory points: -4 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 24. 30.  8.  2.  9.  3.  7.  8.  6.  8. 10.  0.  8.  7.] 
adversary cards in hand: [11. 11. 15.  0. 25.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15] -> size -> 36 
adversary victory points: 8
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 25. 29. 24. 30.  8.  2.  9.  3.  7.  8.  6.  8. 10.  0.  8.  7.] 
adversary cards in hand: [11. 11. 15.  0. 25.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15] -> size -> 36 
adversary victory points: 8
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  1.  0.  0.] 
cards in discard: [22.] 
cards in deck: 34 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 29. 24. 30.  8.  2.  9.  3.  7.  8.  6.  8. 10.  0.  7.  7.] 
adversary cards in hand: [11. 11. 15.  0. 25.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15] -> size -> 36 
adversary victory points: 8
player victory points: -4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [11. 11. 15.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15. 25.] 
expected returns: [[ 90.80356]
 [ 98.54906]
 [ 98.54906]
 [ 91.96051]
 [106.73979]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15.  0. 25.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 24. 30.  8.  2.  9.  3.  7.  8.  6.  8. 10.  0.  7.  7.] 
adversary cards in hand: [ 1.  8.  0.  6. 14.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22] -> size -> 41 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 95.23209381103516



action possibilites: [-1] 
expected returns: [[191.15656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15.  0.  0. 10.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 24. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  7.] 
adversary cards in hand: [ 1.  8.  0.  6. 14.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6] -> size -> 42 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 106.73979187011719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[168.12807]
 [196.48486]
 [145.02162]
 [192.63019]
 [192.77283]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 15.  0.  0. 10.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 25. 29. 24. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  7.] 
adversary cards in hand: [ 1.  8.  0.  6. 14.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6] -> size -> 42 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 191.15655517578125



buy possibilites: [-1] 
expected returns: [[163.19113]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 15.  0.  0. 10.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 23. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  7.] 
adversary cards in hand: [ 1.  8.  0.  6. 14.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6] -> size -> 42 
adversary victory points: -4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 401 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 196.48484802246094






Player: 1 
cards in hand: [ 1.  8.  0.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0.  6. 14.] 
cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 23. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  7.] 
adversary cards in hand: [10. 15.  3. 11. 15.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3] -> size -> 37 
adversary victory points: 9
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0.  6. 14.] 
cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 29. 23. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  7.] 
adversary cards in hand: [10. 15.  3. 11. 15.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3] -> size -> 37 
adversary victory points: 9
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0.  6. 14.] 
cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 29. 22. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  7.] 
adversary cards in hand: [10. 15.  3. 11. 15.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3] -> size -> 37 
adversary victory points: 9
player victory points: -4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10. 15.  3. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11. 15.] 
expected returns: [[74.18388]
 [73.63406]
 [84.66009]
 [92.95345]
 [84.66009]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  3. 11. 15.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 22. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  7.] 
adversary cards in hand: [ 0.  6.  6. 10. 22.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3] -> size -> 43 
adversary victory points: -4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 163.19113159179688



action possibilites: [-1] 
expected returns: [[116.764725]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  3. 15.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 22. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  6.] 
adversary cards in hand: [ 0.  6.  6. 10. 22.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3] -> size -> 43 
adversary victory points: -4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 439 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 97.40252685546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 93.798  ]
 [ 80.99698]
 [119.47539]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  3. 15.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 25. 29. 22. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  6.] 
adversary cards in hand: [ 0.  6.  6. 10. 22.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3] -> size -> 43 
adversary victory points: -4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 116.76472473144531






Player: 1 
cards in hand: [ 0.  6.  6. 10. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 10. 22.] 
cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 22. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  6.] 
adversary cards in hand: [ 0.  3. 11. 10.  0.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15] -> size -> 38 
adversary victory points: 9
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 10.  6.  1.  0.] 
cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 29. 22. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  6.] 
adversary cards in hand: [ 0.  3. 11. 10.  0.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15] -> size -> 38 
adversary victory points: 9
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 10.  6.  1.  0.] 
cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 25. 29. 22. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  6.] 
adversary cards in hand: [ 0.  3. 11. 10.  0.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15] -> size -> 38 
adversary victory points: 9
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 10.  6.  1.  0.] 
cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 24. 29. 22. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  6.] 
adversary cards in hand: [ 0.  3. 11. 10.  0.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15] -> size -> 38 
adversary victory points: 9
player victory points: -4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[128.02855 ]
 [147.60516 ]
 [121.867134]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 10.  0.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 29. 22. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  6.] 
adversary cards in hand: [ 3.  0.  6. 22.  0.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1] -> size -> 44 
adversary victory points: -4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 119.47538757324219



action possibilites: [-1] 
expected returns: [[86.22783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 29. 22. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  5.] 
adversary cards in hand: [ 3.  0.  6. 22.  0.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1] -> size -> 44 
adversary victory points: -4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 429 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 151.02151489257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[70.628494]
 [86.19543 ]
 [58.716698]
 [84.09613 ]
 [84.524765]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 24. 29. 22. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  5.] 
adversary cards in hand: [ 3.  0.  6. 22.  0.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1] -> size -> 44 
adversary victory points: -4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.22782897949219



buy possibilites: [-1] 
expected returns: [[41.959793]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 29. 21. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  5.] 
adversary cards in hand: [ 3.  0.  6. 22.  0.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1] -> size -> 44 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0 -50   0   0  16   0] 
sum of rewards: 401 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 86.1954574584961






Player: 1 
cards in hand: [ 3.  0.  6. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 22.  0.] 
cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 29. 21. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  5.] 
adversary cards in hand: [10.  3.  3. 11.  0.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.  3. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3] -> size -> 40 
adversary victory points: 10
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 3. 6. 6.] 
cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [22.  8. 29. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 29. 21. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  5.] 
adversary cards in hand: [10.  3.  3. 11.  0.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.  3. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3] -> size -> 40 
adversary victory points: 10
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 3. 6. 6.] 
cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [22.  8. 29. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 24. 29. 21. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  5.] 
adversary cards in hand: [10.  3.  3. 11.  0.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.  3. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3] -> size -> 40 
adversary victory points: 10
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 3. 6. 6.] 
cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [22.  8. 29. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  5.] 
adversary cards in hand: [10.  3.  3. 11.  0.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.  3. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3] -> size -> 40 
adversary victory points: 10
player victory points: -3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [10.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[14.35484 ]
 [ 8.189385]
 [21.570904]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 11.  0.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.  3. 11.  0.  3. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  5.] 
adversary cards in hand: [1. 0. 3. 6. 0.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.  3. 22.  8. 29. 16.  3.  0.  6.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3] -> size -> 45 
adversary victory points: -3
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.95979309082031



action possibilites: [-1] 
expected returns: [[77.7576]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.  3. 11.  0.  3. 10.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  4.] 
adversary cards in hand: [1. 0. 3. 6. 0.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.  3. 22.  8. 29. 16.  3.  0.  6.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3] -> size -> 45 
adversary victory points: -3
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0 -60   0   0  64   0] 
sum of rewards: 409 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 23.370906829833984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.422123]
 [17.840027]
 [77.75752 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  0.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.  3. 11.  0.  3. 10.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  4.] 
adversary cards in hand: [1. 0. 3. 6. 0.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.  3. 22.  8. 29. 16.  3.  0.  6.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3] -> size -> 45 
adversary victory points: -3
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 77.75759887695312






Player: 1 
cards in hand: [1. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 6. 0.] 
cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.  3. 22.  8. 29. 16.  3.  0.  6.  0.  3.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  4.] 
adversary cards in hand: [11.  0.  3. 10. 29.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.  3. 11.  0.  3. 10.  0. 15. 11. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15] -> size -> 41 
adversary victory points: 10
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 6. 0.] 
cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.  3. 22.  8. 29. 16.  3.  0.  6.  0.  3.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  7.  8.  6.  8. 10.  0.  7.  4.] 
adversary cards in hand: [11.  0.  3. 10. 29.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.  3. 11.  0.  3. 10.  0. 15. 11. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15] -> size -> 41 
adversary victory points: 10
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 6. 0.] 
cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.  3. 22.  8. 29. 16.  3.  0.  6.  0.  3.  6.  6. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  7.  8.  6.  7. 10.  0.  7.  4.] 
adversary cards in hand: [11.  0.  3. 10. 29.] 
adversary cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.  3. 11.  0.  3. 10.  0. 15. 11. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15] -> size -> 41 
adversary victory points: 10
player victory points: -3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11.  0.  3. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[50.834835]
 [80.065216]
 [45.571247]
 [87.34892 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 10. 29.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.  3. 11.  0.  3. 10.  0. 15. 11. 10.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  7.  8.  6.  7. 10.  0.  7.  4.] 
adversary cards in hand: [ 8.  3. 10.  2. 29.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.  3. 22.  8. 29. 16.  3.  0.  6.  0.  3.  6.  6. 14.
  1.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14] -> size -> 46 
adversary victory points: -3
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 77.75759887695312



action possibilites: [-1. 11. 29.] 
expected returns: [[15.524619]
 [59.999874]
 [72.85795 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 29.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.  3. 11.  0.  3. 10.  0. 15. 11. 10.  3.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  7.  8.  6.  7. 10.  0.  7.  4.] 
adversary cards in hand: [ 8.  3. 10.  2. 29.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.  3. 22.  8. 29. 16.  3.  0.  6.  0.  3.  6.  6. 14.
  1.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14] -> size -> 46 
adversary victory points: -3
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 61.71430587768555



action possibilites: [-1. 11. 11.] 
expected returns: [[ 57.937977]
 [100.006035]
 [100.006035]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.  3. 11.  0.  3. 10.  0. 15. 11. 10.  3.  3.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  7.  8.  6.  7. 10.  0.  7.  4.] 
adversary cards in hand: [ 8.  3. 10.  2. 29.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.  3. 22.  8. 29. 16.  3.  0.  6.  0.  3.  6.  6. 14.
  1.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14] -> size -> 46 
adversary victory points: -3
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 36.08961868286133



action possibilites: [-1] 
expected returns: [[65.85235]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.  3. 11.  0.  3. 10.  0. 15. 11. 10.  3.  3.  0. 10.  0.
 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  7.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 8.  3. 10.  2. 29.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.  3. 22.  8. 29. 16.  3.  0.  6.  0.  3.  6.  6. 14.
  1.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14] -> size -> 46 
adversary victory points: -3
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 390   0   0  60   0   0   0   0 -70   0   0  64   0] 
sum of rewards: 439 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 109.70722961425781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[47.906246]
 [63.70091 ]
 [33.916298]
 [61.01177 ]
 [65.85238 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [25. 10. 10.  3.  3.  0.  3.  3. 25. 11. 11. 15.  0.  0. 10. 15. 11. 10.
 15.  3. 15. 15.  3. 11.  0.  3. 10.  0. 15. 11. 10.  3.  3.  0. 10.  0.
 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  7.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 8.  3. 10.  2. 29.] 
adversary cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.  3. 22.  8. 29. 16.  3.  0.  6.  0.  3.  6.  6. 14.
  1.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14] -> size -> 46 
adversary victory points: -3
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 390   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.85234832763672






Player: 1 
cards in hand: [ 8.  3. 10.  2. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  2. 29.] 
cards in discard: [22. 10.  1. 14.  1.  0.  0.  6.  3.  1.  8.  0.  6. 14.  1. 22.  0.  6.
  6. 10.  6.  1.  0.  3. 22.  8. 29. 16.  3.  0.  6.  0.  3.  6.  6. 14.
  1.  0.  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  7.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15] -> size -> 42 
adversary victory points: 10
player victory points: -3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 2. 1.] 
cards in discard: [10.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 14  6  1  1  6  1  1  0  6 22  2
  6 29  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  7.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15] -> size -> 42 
adversary victory points: 10
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2.] 
cards in discard: [10.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  6  1  1  0  6 22  2  6 29
  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  7.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15] -> size -> 42 
adversary victory points: 10
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2.] 
cards in discard: [10.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  6  1  1  0  6 22  2  6 29
  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  7.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15] -> size -> 42 
adversary victory points: 10
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2.] 
cards in discard: [10.  8.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  6  1  1  0  6 22  2  6 29
  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  6.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15] -> size -> 42 
adversary victory points: 10
player victory points: -4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[163.19641]
 [158.55966]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  6.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 6. 10. 16.  3.  1.] 
adversary cards in discard: [10.  8. 29.  8.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  6  1  1  0  6 22  2  6 29
  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8] -> size -> 45 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 65.85234832763672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[136.06042 ]
 [158.52065 ]
 [159.75302 ]
 [118.160934]
 [173.5408  ]
 [154.81049 ]
 [169.07231 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  3.  6.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 6. 10. 16.  3.  1.] 
adversary cards in discard: [10.  8. 29.  8.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  6  1  1  0  6 22  2  6 29
  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8] -> size -> 45 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 163.1964111328125



buy possibilites: [-1] 
expected returns: [[138.41594]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [11.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  2.  6.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 6. 10. 16.  3.  1.] 
adversary cards in discard: [10.  8. 29.  8.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  6  1  1  0  6 22  2  6 29
  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8] -> size -> 45 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0 -80   0   0  54   0] 
sum of rewards: 389 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 173.54083251953125






Player: 1 
cards in hand: [ 6. 10. 16.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 16.  3.  1.] 
cards in discard: [10.  8. 29.  8.  2.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  6  1  1  0  6 22  2  6 29
  6 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  2.  6.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [15. 10. 11. 25. 15.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
adversary victory points: 10
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.] 
cards in discard: [10.  8. 29.  8.  2.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [15. 10. 11. 25. 15.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
adversary victory points: 10
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.] 
cards in discard: [10.  8. 29.  8.  2.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 24. 29. 20. 30.  8.  1.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [15. 10. 11. 25. 15.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
adversary victory points: 10
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 29. 20. 30.  8.  1.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [15. 10. 11. 25. 15.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
adversary victory points: 10
player victory points: -4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [15. 10. 11. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11. 25. 15.] 
expected returns: [[118.10896]
 [112.69164]
 [100.15828]
 [125.09117]
 [134.88521]
 [112.69164]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11. 25. 15.] 
cards in discard: [11.  3.  0.  0. 15.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 29. 20. 30.  8.  1.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 3. 29.  3.  0.  3.] 
adversary cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0] -> size -> 46 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 138.4159393310547



action possibilites: [-1] 
expected returns: [[84.77598]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11. 15.  3.  3.] 
cards in discard: [11.  3.  0.  0. 15.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 3. 29.  3.  0.  3.] 
adversary cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6] -> size -> 47 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 134.8852081298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[78.28051]
 [86.72342]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 11. 15.  3.  3.] 
cards in discard: [11.  3.  0.  0. 15.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 24. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 3. 29.  3.  0.  3.] 
adversary cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6] -> size -> 47 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.7759780883789






Player: 1 
cards in hand: [ 3. 29.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  3.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
adversary victory points: 10
player victory points: -5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 24. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
adversary victory points: 10
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 24. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
adversary victory points: 10
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 24. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
adversary victory points: 10
player victory points: -5 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[130.70654]
 [141.97343]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 29.  0.] 
cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [22.  6.  6.  1. 14.] 
adversary cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0] -> size -> 48 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 86.72341918945312



action possibilites: [-1.] 
expected returns: [[75.52434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 24. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [22.  6.  6.  1. 14.] 
adversary cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0] -> size -> 48 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 120.62183380126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[28.345444]
 [66.50951 ]
 [59.32214 ]
 [78.27332 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 24. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [22.  6.  6.  1. 14.] 
adversary cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0] -> size -> 48 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 75.52433776855469






Player: 1 
cards in hand: [22.  6.  6.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  6.  6.  1. 14.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [10. 10. 10.  3. 10.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
adversary victory points: 10
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  6.  6.  1. 14.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 24. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [10. 10. 10.  3. 10.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
adversary victory points: 10
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  6.  6.  1. 14.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 24. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [10. 10. 10.  3. 10.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
adversary victory points: 10
player victory points: -5 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [10. 10. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 10.] 
expected returns: [[60.85642]
 [55.40533]
 [55.40533]
 [55.40533]
 [55.40533]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  3. 10.] 
cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [14.  1.  1.  0. 14.] 
adversary cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0] -> size -> 49 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 78.27330780029297





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[38.87991]
 [56.80076]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.  3. 10.] 
cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 24. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [14.  1.  1.  0. 14.] 
adversary cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0] -> size -> 49 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 60.85641860961914



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  1.  1.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  1.  0. 14.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [11.  3. 15. 10. 11.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
adversary victory points: 10
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0. 14.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 24. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [15. 10. 11.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
adversary victory points: 10
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0. 14.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0] -> size -> 49 
action values: 0 
buys: 1 
player value: 7 
card supply: [25. 24. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [15. 10. 11.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
adversary victory points: 10
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0. 14.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 23. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [15. 10. 11.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
adversary victory points: 10
player victory points: -5 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [15. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11.] 
expected returns: [[-3.7399642]
 [-1.3722827]
 [-7.6272383]
 [ 6.093774 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11.] 
cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 6. 22.  0.  6.  0.] 
adversary cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.  1. 14.  1.  1.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0  1] -> size -> 50 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 102.47125244140625



action possibilites: [-1] 
expected returns: [[10.310056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.] 
cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 6. 22.  0.  6.  0.] 
adversary cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.  1. 14.  1.  1.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0  1] -> size -> 50 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0 -90   0   0  27   0] 
sum of rewards: 402 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -2.457566738128662





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-3.9832375]
 [10.31004  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.] 
cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 22. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 6. 22.  0.  6.  0.] 
adversary cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.  1. 14.  1.  1.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0  1] -> size -> 50 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.31005573272705






Player: 1 
cards in hand: [ 6. 22.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 22.  0.  6.  0.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.  1. 14.  1.  1.  0. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [11. 15.  0.  3. 11.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.  1. 11. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1] -> size -> 44 
adversary victory points: 10
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 6. 3. 6.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.  1. 14.  1.  1.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [22. 10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [11. 15.  0.  3. 11.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.  1. 11. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1] -> size -> 44 
adversary victory points: 10
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 6. 3. 6.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.  1. 14.  1.  1.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [22. 10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 22. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [11. 15.  0.  3. 11.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.  1. 11. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1] -> size -> 44 
adversary victory points: 10
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 6. 3. 6.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.  1. 14.  1.  1.  0. 14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [22. 10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0  1  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 22. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [11. 15.  0.  3. 11.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.  1. 11. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1] -> size -> 44 
adversary victory points: 10
player victory points: -5 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [11. 15.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11.] 
expected returns: [[-53.34326 ]
 [-26.096867]
 [-41.18345 ]
 [-26.096867]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0.  3. 11.] 
cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.  1. 11. 15. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [1. 0. 0. 6. 8.] 
adversary cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.  1. 14.  1.  1.  0. 14.  0. 22. 10.  8.  6.
  0.  6.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0  1  0] -> size -> 51 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 10.31005573272705



action possibilites: [-1] 
expected returns: [[113.211105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3. 11.] 
cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.  1. 11. 15. 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 21. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [1. 0. 0. 6. 8.] 
adversary cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.  1. 14.  1.  1.  0. 14.  0. 22. 10.  8.  6.
  0.  6.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0  1  0] -> size -> 51 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  450    0    0   20    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: 392 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -42.42585754394531





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 74.142334]
 [113.21109 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3. 11.] 
cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.  1. 11. 15. 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 21. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [1. 0. 0. 6. 8.] 
adversary cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.  1. 14.  1.  1.  0. 14.  0. 22. 10.  8.  6.
  0.  6.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0  1  0] -> size -> 51 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: 113.21110534667969






Player: 1 
cards in hand: [1. 0. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 6. 8.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.  1. 14.  1.  1.  0. 14.  0. 22. 10.  8.  6.
  0.  6.  0.  6.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  1  0  6 22  2  6 29  6
 10  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0
  0  1  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 21. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [10. 15.  3.  3. 11.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.  1. 11. 15. 10.  1. 11. 15.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1] -> size -> 45 
adversary victory points: 10
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.  1. 14.  1.  1.  0. 14.  0. 22. 10.  8.  6.
  0.  6.  0.  6.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 21. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [10. 15.  3.  3. 11.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.  1. 11. 15. 10.  1. 11. 15.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1] -> size -> 45 
adversary victory points: 10
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.  1. 14.  1.  1.  0. 14.  0. 22. 10.  8.  6.
  0.  6.  0.  6.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 21. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [10. 15.  3.  3. 11.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.  1. 11. 15. 10.  1. 11. 15.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1] -> size -> 45 
adversary victory points: 10
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [10.  8. 29.  8.  2.  8.  0. 16.  6. 10.  3.  6.  3.  6.  0. 29.  3.  0.
  3.  0. 22.  6.  6.  1. 14.  1. 14.  1.  1.  0. 14.  0. 22. 10.  8.  6.
  0.  6.  0.  6.  3.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 21. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [10. 15.  3.  3. 11.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.  1. 11. 15. 10.  1. 11. 15.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1] -> size -> 45 
adversary victory points: 10
player victory points: -5 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [10. 15.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11.] 
expected returns: [[53.78152 ]
 [46.958614]
 [69.02504 ]
 [86.7668  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  3.  3. 11.] 
cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.  1. 11. 15. 10.  1. 11. 15.  0.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 0.  0.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0] -> size -> 51 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 113.21110534667969



action possibilites: [-1] 
expected returns: [[128.48929]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  3.  3.] 
cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.  1. 11. 15. 10.  1. 11. 15.  0.  3. 11.
  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 0.  0.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0] -> size -> 51 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  450    0    0   20    0    0    0    0 -110    0    0
   27    0] 
sum of rewards: 382 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 66.28700256347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 86.65153]
 [128.48926]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  3.  3.] 
cards in discard: [11.  3.  0.  0. 15.  0. 25. 15. 10. 11. 15.  3.  3.  0. 29. 29.  3.  3.
  0. 10. 10. 10.  3. 10.  3. 11.  1. 11. 15. 10.  1. 11. 15.  0.  3. 11.
  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 0.  0.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0] -> size -> 51 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: 128.48928833007812






Player: 1 
cards in hand: [ 0.  0.  0.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 22.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [10. 11. 15. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1] -> size -> 46 
adversary victory points: 10
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1. 6. 8.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [10. 11. 15. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1] -> size -> 46 
adversary victory points: 10
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1. 6. 8.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0] -> size -> 51 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  6.  7. 10.  0.  7.  3.] 
adversary cards in hand: [10. 11. 15. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1] -> size -> 46 
adversary victory points: 10
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1. 6. 8.] 
cards in discard: [29.] 
cards in deck: 42 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29] -> size -> 52 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  5.  7. 10.  0.  7.  3.] 
adversary cards in hand: [10. 11. 15. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1] -> size -> 46 
adversary victory points: 10
player victory points: -5 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [10. 11. 15. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15. 25.] 
expected returns: [[170.97377]
 [149.71115]
 [176.97723]
 [163.04462]
 [185.75717]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15. 25.  0.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  5.  7. 10.  0.  7.  3.] 
adversary cards in hand: [14.  6. 10.  6.  3.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29] -> size -> 52 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 128.48928833007812



action possibilites: [-1] 
expected returns: [[102.507996]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  5.  7. 10.  0.  7.  3.] 
adversary cards in hand: [14.  6. 10.  6.  3.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29] -> size -> 52 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 185.7571258544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[ 85.35232 ]
 [104.54666 ]
 [101.406364]
 [ 94.01498 ]
 [114.92187 ]
 [ 98.991035]
 [117.479454]
 [ 87.13198 ]
 [106.32867 ]
 [100.98643 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 15.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  5.  7. 10.  0.  7.  3.] 
adversary cards in hand: [14.  6. 10.  6.  3.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29] -> size -> 52 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.50799560546875



buy possibilites: [-1] 
expected returns: [[66.82096]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 15.  0.  0.  1.] 
cards in discard: [29.] 
cards in deck: 39 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [14.  6. 10.  6.  3.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29] -> size -> 52 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  450    0    0   20    0    0    0    0 -120    0    0
  128    0] 
sum of rewards: 473 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 117.47947692871094






Player: 1 
cards in hand: [14.  6. 10.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6. 10.  6.  3.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [15. 11. 15. 25. 10.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
adversary victory points: 10
player victory points: -5 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  6.  3.  0.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.] 
cards in deck: 36 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29] -> size -> 52 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [15. 11. 15. 25. 10.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
adversary victory points: 10
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  6.  3.  0.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.] 
cards in deck: 36 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [15. 11. 15. 25. 10.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
adversary victory points: 10
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  6.  3.  0.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [15. 11. 15. 25. 10.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
adversary victory points: 10
player victory points: -5 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [15. 11. 15. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 15. 25. 10.] 
expected returns: [[185.01907]
 [171.4023 ]
 [178.91597]
 [171.4023 ]
 [180.64555]
 [166.99219]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 15. 25. 10.] 
cards in discard: [29. 25. 10. 11. 15.  0.  0.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 6. 22.  3. 10.  6.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29  0] -> size -> 53 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.82096099853516





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[155.8084 ]
 [186.95534]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11. 15. 25. 10.] 
cards in discard: [29. 25. 10. 11. 15.  0.  0.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
action values: 1 
buys: 1 
player value: 0 
card supply: [22. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 6. 22.  3. 10.  6.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29  0] -> size -> 53 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 185.01905822753906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6. 22.  3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 22.  3. 10.  6.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 0. 10.  3. 15. 15.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
adversary victory points: 10
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  6.  1. 10.  0.  3.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 0. 10.  3. 15. 15.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
adversary victory points: 10
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  6.  1. 10.  0.  3.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 0. 10.  3. 15. 15.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
adversary victory points: 10
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  6.  1. 10.  0.  3.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29  0  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 0. 10.  3. 15. 15.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
adversary victory points: 10
player victory points: -5 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 15.] 
expected returns: [[250.822  ]
 [235.02304]
 [249.615  ]
 [249.615  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 15. 15.] 
cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [0. 0. 8. 2. 6.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29  0  0] -> size -> 54 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 186.95533752441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[214.89417]
 [249.47998]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 15. 15.] 
cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [0. 0. 8. 2. 6.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29  0  0] -> size -> 54 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 250.822021484375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 8. 2. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 2. 6.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  6  1  0  6 22  2  6 29  6 10
  3  1 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0
  1  0  0 29  0  0] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [15.  3.  3. 11. 11.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
adversary victory points: 10
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [15.  3.  3. 11. 11.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
adversary victory points: 10
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 20. 29. 20. 30.  8.  0.  9.  2.  5.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [15.  3.  3. 11. 11.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
adversary victory points: 10
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 20. 29. 20. 30.  8.  0.  9.  2.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [15.  3.  3. 11. 11.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
adversary victory points: 10
player victory points: -4 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [15.  3.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 11.] 
expected returns: [[22.998081]
 [31.790668]
 [47.956497]
 [47.956497]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3. 11. 11.] 
cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 29. 20. 30.  8.  0.  9.  2.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [3. 6. 1. 0. 3.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8] -> size -> 53 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 249.48001098632812



action possibilites: [-1] 
expected returns: [[45.300648]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3. 11.] 
cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 19. 29. 20. 30.  8.  0.  9.  2.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [3. 6. 1. 0. 3.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8] -> size -> 53 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  420    0    0   20    0    0    0    0 -130    0    0
   27    0] 
sum of rewards: 332 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 27.80052947998047





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.935442]
 [45.30061 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  3. 11.] 
cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 19. 29. 20. 30.  8.  0.  9.  2.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [3. 6. 1. 0. 3.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8] -> size -> 53 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.3006477355957






Player: 1 
cards in hand: [3. 6. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 1. 0. 3.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 19. 29. 20. 30.  8.  0.  9.  2.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 3. 10. 11.  0.  1.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1] -> size -> 48 
adversary victory points: 10
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 0. 3.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 19. 29. 20. 30.  8.  0.  9.  2.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 3. 10. 11.  0.  1.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1] -> size -> 48 
adversary victory points: 10
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 0. 3.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 20. 30.  8.  0.  9.  2.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 3. 10. 11.  0.  1.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1] -> size -> 48 
adversary victory points: 10
player victory points: -4 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[21.43207 ]
 [13.017247]
 [40.137127]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  0.  1.] 
cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 20. 30.  8.  0.  9.  2.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 8. 22. 14.  0. 14.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.  3.  6.  1.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1] -> size -> 54 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 45.3006477355957



action possibilites: [-1] 
expected returns: [[121.48682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  1.] 
cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 17. 29. 20. 30.  8.  0.  9.  2.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 8. 22. 14.  0. 14.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.  3.  6.  1.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1] -> size -> 54 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  420    0    0   20    0    0    0    0 -140    0    0
   27    0] 
sum of rewards: 322 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 24.842479705810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[ 95.64106 ]
 [127.43004 ]
 [122.873634]
 [142.1941  ]
 [118.76873 ]
 [121.48677 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  1.] 
cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 17. 29. 20. 30.  8.  0.  9.  2.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 8. 22. 14.  0. 14.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.  3.  6.  1.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1] -> size -> 54 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 121.48681640625



buy possibilites: [-1] 
expected returns: [[32.083157]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  1.] 
cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.  1. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1
  1 11] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 17. 29. 20. 30.  8.  0.  9.  1.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 8. 22. 14.  0. 14.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.  3.  6.  1.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1] -> size -> 54 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  420    0    0   20    0    0    0    0 -150    0    0
   54    0] 
sum of rewards: 339 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 142.19415283203125






Player: 1 
cards in hand: [ 8. 22. 14.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22. 14.  0. 14.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.  3.  6.  1.  0.
  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 17. 29. 20. 30.  8.  0.  9.  1.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [11. 11.  0. 10.  3.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.  1. 11. 11.  3. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1
  1 11] -> size -> 50 
adversary victory points: 10
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22.  0. 14.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.  3.  6.  1.  0.
  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1] -> size -> 54 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 17. 29. 20. 30.  8.  0.  9.  1.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [11.  0.  3.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.  1. 11. 11.  3. 10.  0.  1. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1
  1 11] -> size -> 50 
adversary victory points: 10
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 22.  0. 14.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.  3.  6.  1.  0.
  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1] -> size -> 54 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 17. 29. 20. 30.  8.  0.  9.  1.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [11.  0.  3.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.  1. 11. 11.  3. 10.  0.  1. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1
  1 11] -> size -> 50 
adversary victory points: 10
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 22.  0. 14.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.  3.  6.  1.  0.
  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1  1] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 16. 29. 20. 30.  8.  0.  9.  1.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [11.  0.  3.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.  1. 11. 11.  3. 10.  0.  1. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1
  1 11] -> size -> 50 
adversary victory points: 10
player victory points: -4 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-4.371822 ]
 [ 5.8529615]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.] 
cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.  1. 11. 11.  3. 10.  0.  1. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1
  1 11] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 29. 20. 30.  8.  0.  9.  1.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [1. 6. 0. 6. 6.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.  3.  6.  1.  0.
  3.  1. 14.  8. 22.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1  1] -> size -> 55 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 169.11627197265625



action possibilites: [-1] 
expected returns: [[-22.522085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.  1. 11. 11.  3. 10.  0.  1. 11. 10.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1
  1 11  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 15. 29. 20. 30.  8.  0.  9.  1.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [1. 6. 0. 6. 6.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.  3.  6.  1.  0.
  3.  1. 14.  8. 22.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1  1] -> size -> 55 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  420    0    0   20    0    0    0    0 -160    0    0
   27    0] 
sum of rewards: 302 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -3.9533629417419434





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-39.196144]
 [-22.522102]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.  1. 11. 11.  3. 10.  0.  1. 11. 10.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1
  1 11  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 15. 29. 20. 30.  8.  0.  9.  1.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [1. 6. 0. 6. 6.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.  3.  6.  1.  0.
  3.  1. 14.  8. 22.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1  1] -> size -> 55 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: -22.522085189819336






Player: 1 
cards in hand: [1. 6. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 6. 6.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.  3.  6.  1.  0.
  3.  1. 14.  8. 22.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1  1] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 15. 29. 20. 30.  8.  0.  9.  1.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [0. 1. 3. 3. 3.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.  1. 11. 11.  3. 10.  0.  1. 11. 10.  1. 11.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1
  1 11  1] -> size -> 51 
adversary victory points: 10
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 6. 6.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.  3.  6.  1.  0.
  3.  1. 14.  8. 22.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1  1] -> size -> 55 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 15. 29. 20. 30.  8.  0.  9.  1.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [0. 1. 3. 3. 3.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.  1. 11. 11.  3. 10.  0.  1. 11. 10.  1. 11.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1
  1 11  1] -> size -> 51 
adversary victory points: 10
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 6. 6.] 
cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.  3.  6.  1.  0.
  3.  1. 14.  8. 22.  0. 14.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1  1  1] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 14. 29. 20. 30.  8.  0.  9.  1.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [0. 1. 3. 3. 3.] 
adversary cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.  1. 11. 11.  3. 10.  0.  1. 11. 10.  1. 11.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1
  1 11  1] -> size -> 51 
adversary victory points: 10
player victory points: -4 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [0. 1. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.736721]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 3. 3.] 
cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.  1. 11. 11.  3. 10.  0.  1. 11. 10.  1. 11.  0.
  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1
  1 11  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 14. 29. 20. 30.  8.  0.  9.  1.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 8. 29.  0.  0.  0.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.  3.  6.  1.  0.
  3.  1. 14.  8. 22.  0. 14.  1.  1.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1  1  1] -> size -> 56 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -22.522085189819336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[ 5.3318195]
 [30.591076 ]
 [25.95611  ]
 [47.739998 ]
 [21.92989  ]
 [31.73674  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 3.] 
cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.  1. 11. 11.  3. 10.  0.  1. 11. 10.  1. 11.  0.
  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1
  1 11  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 14. 29. 20. 30.  8.  0.  9.  1.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 8. 29.  0.  0.  0.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.  3.  6.  1.  0.
  3.  1. 14.  8. 22.  0. 14.  1.  1.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1  1  1] -> size -> 56 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 31.73672103881836



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 7 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 10 
Chapel: 0 
Witch: 2 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 1. 3. 3. 3.] 
cards in discard: [29. 25. 10. 11. 15.  0.  0.  1. 15. 11. 15. 25. 10.  0. 10.  3. 15. 15.
  1. 11. 15.  3.  3. 11.  1. 11. 11.  3. 10.  0.  1. 11. 10.  1. 11.  0.
  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 29 10  3 10 11  3 25 10 11 10
  3 11 10 10 10 11  3 15 11 15  3 15  3 15 15  3 15 15 11  1  1  1 29  1
  1 11  1 11] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 14. 29. 20. 30.  8.  0.  9.  0.  4.  8.  4.  7. 10.  0.  7.  3.] 
adversary cards in hand: [ 8. 29.  0.  0.  0.] 
adversary cards in discard: [29. 22. 29.  0.  0.  0.  0.  1.  6.  8.  0. 10. 14.  6.  6.  3.  0.  0.
 22. 10.  6.  3.  6.  1. 10.  0.  3.  8.  8.  0.  0.  1.  3.  6.  1.  0.
  3.  1. 14.  8. 22.  0. 14.  1.  1.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 29 10 14  6  1  0  6 22  6 29  6 10  3  1
 22  6  8  8  6  0 16  8 14  6 22  6  3  1  3 14  8  8  0  6  0  0  1  0
  0 29  0  0  8  1  1  1] -> size -> 56 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[     -5 3000000       0     420       0       0       0       0       0
       0       0    -170       0       0      27       0] 
sum of rewards: 3000272 

action type: buy - action 11.0
Learning step: 300022.4375
desired expected reward: 300070.1875



