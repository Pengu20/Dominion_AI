 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[53.67626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -60        0        0        0        0
        0        0        0      -90        0        0        8        0] 
sum of rewards: -3000147 

action type: buy - action 8.0
Learning step: -119999.21875
desired expected reward: -120165.78125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.454952]
 [54.291023]
 [49.959835]
 [-0.765882]
 [76.796005]
 [57.160954]
 [52.829765]
 [52.483124]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 52.429630279541016



buy possibilites: [-1] 
expected returns: [[57.935505]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 76.79600524902344






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[51.750477]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.93550491333008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[30.300133]
 [53.14966 ]
 [48.810215]
 [ 4.188034]
 [49.170517]
 [75.626114]
 [56.022495]
 [76.10512 ]
 [29.020947]
 [51.677387]
 [51.81492 ]
 [51.466206]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 46.90717315673828



buy possibilites: [-1] 
expected returns: [[72.22298]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 76.10511779785156






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[49.151085]
 [73.83075 ]
 [74.45839 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.22297668457031



action possibilites: [-1. 11.] 
expected returns: [[64.60358]
 [85.25186]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 70.93643188476562



action possibilites: [-1] 
expected returns: [[70.397995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 86.3162841796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[55.298584]
 [77.14473 ]
 [73.06877 ]
 [31.546711]
 [73.49736 ]
 [97.99487 ]
 [79.790146]
 [98.59599 ]
 [53.97024 ]
 [75.7142  ]
 [75.81355 ]
 [75.782715]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.39799499511719



buy possibilites: [-1] 
expected returns: [[81.31355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 98.59597778320312






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0.  0.  0.  3.  3. 22.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[99.09891]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 81.31355285644531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 78.51486 ]
 [101.10983 ]
 [ 96.746124]
 [ 52.635998]
 [122.22717 ]
 [103.86481 ]
 [ 99.5011  ]
 [100.28641 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 94.85676574707031



buy possibilites: [-1] 
expected returns: [[116.70816]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 122.2271728515625






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29. 29. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29. 29. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29. 29. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29. 29. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
expected returns: [[48.895027]
 [70.85715 ]
 [70.85715 ]
 [48.25346 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 116.70816040039062



action possibilites: [-1. 29. 10.] 
expected returns: [[71.893814]
 [93.80052 ]
 [71.38611 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 66.80805969238281



action possibilites: [-1. 10.] 
expected returns: [[102.283966]
 [101.43204 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 93.800537109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 85.8873  ]
 [106.933044]
 [102.739655]
 [ 61.997143]
 [103.45775 ]
 [128.18318 ]
 [109.600464]
 [128.91577 ]
 [ 84.449585]
 [105.33667 ]
 [105.418884]
 [106.24988 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 102.28396606445312



buy possibilites: [-1] 
expected returns: [[124.64943]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  3.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 128.915771484375






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [29. 29. 29. 10.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [29. 29. 29. 10.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[128.46059]
 [149.059  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [29. 29. 29. 10.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 22.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 124.64942932128906



action possibilites: [-1] 
expected returns: [[95.07318]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29. 29. 29. 10.  3.  0.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 22.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 149.71435546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 81.19585 ]
 [101.66647 ]
 [ 97.565704]
 [ 57.01224 ]
 [120.54849 ]
 [104.178635]
 [100.077866]
 [101.33153 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29. 29. 29. 10.  3.  0.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 22.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 95.07318115234375



buy possibilites: [-1] 
expected returns: [[108.52942]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29. 29. 29. 10.  3.  0.  0.  3. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 22.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 120.54850769042969






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0. 22.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  0.  0.  3.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 78.88512]
 [101.08249]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [ 0.  0. 22.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 108.5294189453125



action possibilites: [-1] 
expected returns: [[86.03909]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [ 0.  0. 22.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 99.89524841308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 72.55394]
 [ 91.9055 ]
 [ 88.06448]
 [ 49.85006]
 [111.70683]
 [ 94.27406]
 [ 90.43303]
 [ 91.42612]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [ 0.  0. 22.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.03909301757812



buy possibilites: [-1] 
expected returns: [[74.48563]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  5. 10. 10.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [ 0.  0. 22.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 111.70683288574219






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [ 0.  0. 22.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  5. 10. 10.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [ 0.  0. 22.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  5. 10. 10.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[122.83609]
 [144.33403]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 29.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  5. 10. 10.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [ 0.  0. 22.  0.  0.  3.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.48562622070312



action possibilites: [-1.] 
expected returns: [[147.79063]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  5. 10. 10.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [ 0.  0. 22.  0.  0.  3.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 138.7506561279297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[132.27686]
 [155.50313]
 [150.90186]
 [110.40564]
 [106.16643]
 [151.67616]
 [177.39404]
 [158.38574]
 [201.76909]
 [178.30153]
 [130.80484]
 [147.2518 ]
 [153.78355]
 [124.40817]
 [153.9265 ]
 [154.76254]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  5. 10. 10.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [ 0.  0. 22.  0.  0.  3.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 147.79063415527344



buy possibilites: [-1] 
expected returns: [[152.02855]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  5. 10.  9.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [ 0.  0. 22.  0.  0.  3.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 201.7690887451172






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [ 0.  0. 22.  0.  0.  3.  3.  0.  0. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  5. 10.  9.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [29. 10. 11. 11.  3.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 25. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25] -> size -> 21 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  5. 10.  9.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [29. 10. 11. 11.  3.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 25. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  5. 10.  9.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [29. 10. 11. 11.  3.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 25. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25] -> size -> 21 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  5. 10.  9.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [29. 10. 11. 11.  3.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 25. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25] -> size -> 21 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29. 10. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 11.] 
expected returns: [[52.598396]
 [70.77521 ]
 [51.99995 ]
 [70.127426]
 [70.127426]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11. 11.  3.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 25. 29.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  5. 10.  9.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 22.  3. 11.  3.] 
adversary cards in discard: [ 0. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 152.02854919433594



action possibilites: [-1. 10. 11. 11. 10.] 
expected returns: [[33.927063]
 [33.632896]
 [53.307106]
 [53.307106]
 [33.632896]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  3. 10.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 25. 29.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  5. 10.  9.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 22.  3. 11.  3.] 
adversary cards in discard: [ 0. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 68.65538024902344



action possibilites: [-1] 
expected returns: [[11.1536255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3. 10.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 25. 29.  0.  3.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  5. 10.  9.  7. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 22.  3. 11.  3.] 
adversary cards in discard: [ 0. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 57.03553009033203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -7.1936874]
 [-29.810715 ]
 [ 11.72393  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3. 10.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 25. 29.  0.  3.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  5. 10.  9.  7. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 22.  3. 11.  3.] 
adversary cards in discard: [ 0. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.15362548828125






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0. 22.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  3. 11.  3.] 
cards in discard: [ 0. 10.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  5. 10.  9.  7. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  3. 11.  3.] 
cards in discard: [ 0. 10.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  5. 10.  9.  7. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  3. 11.  3.] 
cards in discard: [ 0. 10.  0.  0.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 30. 30.  8. 10. 10.  5. 10.  9.  7. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 11.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[ 90.065704]
 [109.132904]
 [110.04451 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8. 10. 10.  5. 10.  9.  7. 10. 10.  5.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  0.  0.  3.  0.  0.  0.  0. 22.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 11.723907470703125



action possibilites: [-1. 11. 29.] 
expected returns: [[125.16914]
 [145.42705]
 [146.3662 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 30. 30.  8. 10. 10.  5. 10.  9.  7. 10. 10.  5.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  0.  0.  3.  0.  0.  0.  0. 22.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 105.75166320800781



action possibilites: [-1. 11.] 
expected returns: [[143.08067]
 [164.31483]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 30. 30.  8. 10. 10.  5. 10.  9.  7. 10. 10.  5.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  0.  0.  3.  0.  0.  0.  0. 22.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 146.36619567871094



action possibilites: [-1] 
expected returns: [[137.75395]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 30. 30.  8. 10. 10.  5. 10.  9.  7. 10. 10.  4.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  0.  0.  3.  0.  0.  0.  0. 22.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 168.85670471191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[123.49834 ]
 [145.10333 ]
 [140.70853 ]
 [102.416794]
 [ 98.28677 ]
 [141.51442 ]
 [166.33478 ]
 [147.87575 ]
 [190.93315 ]
 [167.22754 ]
 [122.046005]
 [137.33075 ]
 [143.41504 ]
 [115.97328 ]
 [143.53416 ]
 [144.53972 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 30. 30. 30. 30.  8. 10. 10.  5. 10.  9.  7. 10. 10.  4.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  0.  0.  3.  0.  0.  0.  0. 22.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 137.7539520263672



buy possibilites: [-1] 
expected returns: [[135.77821]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8. 10. 10.  5. 10.  8.  7. 10. 10.  4.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  0.  0.  3.  0.  0.  0.  0. 22.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 305 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 190.9331512451172






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  0.  0.  3.  0.  0.  0.  0. 22.  3. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8. 10. 10.  5. 10.  8.  7. 10. 10.  4.  9. 10.] 
adversary cards in hand: [11.  0. 29.  0.  0.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  0.  0.  3.  0.  0.  0.  0. 22.  3. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 30. 30. 30. 30.  8. 10. 10.  5. 10.  8.  7. 10. 10.  4.  9. 10.] 
adversary cards in hand: [11.  0. 29.  0.  0.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  0.  0.  3.  0.  0.  0.  0. 22.  3. 11.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 5 
card supply: [24. 30. 30. 30. 30.  8. 10. 10.  5. 10.  8.  7. 10. 10.  4.  9. 10.] 
adversary cards in hand: [11.  0. 29.  0.  0.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25] -> size -> 24 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[143.46664]
 [162.14763]
 [163.0111 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  0.  0.] 
cards in discard: [10. 25. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8. 10. 10.  5. 10.  8.  7. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 22.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 135.77821350097656



action possibilites: [-1. 11. 11.] 
expected returns: [[119.59268]
 [138.57439]
 [138.57439]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0. 11.] 
cards in discard: [10. 25. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 30. 30.  8. 10. 10.  5. 10.  8.  7. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 22.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 158.5287628173828



action possibilites: [-1] 
expected returns: [[100.91582]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [10. 25. 29. 29. 11.  0.  3.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 30. 30.  8. 10. 10.  5. 10.  8.  7. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 0. 22.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 142.48486328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 79.73979 ]
 [ 99.39371 ]
 [ 95.42764 ]
 [ 57.186073]
 [ 96.203   ]
 [118.260254]
 [101.88542 ]
 [119.140884]
 [ 78.32785 ]
 [ 97.86394 ]
 [ 97.96777 ]
 [ 99.00314 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [10. 25. 29. 29. 11.  0.  3.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 30. 30. 30. 30.  8. 10. 10.  5. 10.  8.  7. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 0. 22.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.91581726074219



buy possibilites: [-1] 
expected returns: [[55.723125]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [10. 25. 29. 29. 11.  0.  3.  0.  0. 10. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8. 10. 10.  5. 10.  8.  6. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 0. 22.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 119.14085388183594






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0. 22.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8. 10. 10.  5. 10.  8.  6. 10. 10.  3.  9. 10.] 
adversary cards in hand: [11. 10.  0. 10. 10.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0.  3.  0.  0. 10. 29. 29. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29] -> size -> 26 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8. 10. 10.  5. 10.  8.  6. 10. 10.  3.  9. 10.] 
adversary cards in hand: [11. 10.  0. 10. 10.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0.  3.  0.  0. 10. 29. 29. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29] -> size -> 26 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 30. 30. 30. 30.  8. 10. 10.  5. 10.  8.  6. 10. 10.  3.  9. 10.] 
adversary cards in hand: [11. 10.  0. 10. 10.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0.  3.  0.  0. 10. 29. 29. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29] -> size -> 26 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0. 0. 3.] 
cards in discard: [16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 30. 30.  8. 10.  9.  5. 10.  8.  6. 10. 10.  3.  9. 10.] 
adversary cards in hand: [11. 10.  0. 10. 10.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0.  3.  0.  0. 10. 29. 29. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29] -> size -> 26 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11. 10.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 10.] 
expected returns: [[16.079327]
 [29.910751]
 [15.260435]
 [15.260435]
 [15.260435]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 10. 10.] 
cards in discard: [10. 25. 29. 29. 11.  0.  3.  0.  0. 10. 29. 29. 11.  0.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8. 10.  9.  5. 10.  8.  6. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [16. 22.  0.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.72312545776367



action possibilites: [-1] 
expected returns: [[-4.5956798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [10. 25. 29. 29. 11.  0.  3.  0.  0. 10. 29. 29. 11.  0.  0.  0. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8. 10.  9.  5. 10.  8.  6. 10. 10.  2.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [16. 22.  0.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 32.847412109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-18.862139]
 [-34.6604  ]
 [ -5.072753]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [10. 25. 29. 29. 11.  0.  3.  0.  0. 10. 29. 29. 11.  0.  0.  0. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 30. 30.  8. 10.  9.  5. 10.  8.  6. 10. 10.  2.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [16. 22.  0.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -4.595679759979248






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [16. 22.  0.  0.  0.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8. 10.  9.  5. 10.  8.  6. 10. 10.  2.  9. 10.] 
adversary cards in hand: [25. 10. 25.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10] -> size -> 27 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [16. 22.  0.  0.  0.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 30. 30. 30. 30.  8. 10.  9.  5. 10.  8.  6. 10. 10.  2.  9. 10.] 
adversary cards in hand: [25. 10. 25.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10] -> size -> 27 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [16. 22.  0.  0.  0.  0.  0.  0.  3. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8. 10.  9.  5. 10.  8.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [25. 10. 25.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10] -> size -> 27 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [25. 10. 25.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 25.] 
expected returns: [[109.92767]
 [151.9977 ]
 [108.68242]
 [151.9977 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 25.  3.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8. 10.  9.  5. 10.  8.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [16. 22.  0.  0.  0.  0.  0.  0.  3. 14.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -5.072760581970215



action possibilites: [-1] 
expected returns: [[90.40169]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  3.  3. 29. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  9.  9.  5. 10.  8.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [16. 22.  0.  0.  0.  0.  0.  0.  3. 14.  0.  0.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 145.69117736816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[69.77478 ]
 [46.124428]
 [89.11345 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 25.  3.  3. 29. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  9.  9.  5. 10.  8.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [16. 22.  0.  0.  0.  0.  0.  0.  3. 14.  0.  0.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.40168762207031






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [11.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  3.] 
cards in discard: [16. 22.  0.  0.  0.  0.  0.  0.  3. 14.  0.  0.  0. 10.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  9.  9.  5. 10.  8.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [11. 11. 10.  0.  0.] 
adversary cards in discard: [25. 10. 25.  3.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10] -> size -> 27 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [16. 22.  0.  0.  0.  0.  0.  0.  3. 14.  0.  0.  0. 10.  0.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  8.  9.  5. 10.  8.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [11. 11. 10.  0.  0.] 
adversary cards in discard: [25. 10. 25.  3.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10] -> size -> 27 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [16. 22.  0.  0.  0.  0.  0.  0.  3. 14.  0.  0.  0. 10.  0.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 30. 30.  8.  8.  9.  5. 10.  8.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [11. 11. 10.  0.  0.] 
adversary cards in discard: [25. 10. 25.  3.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10] -> size -> 27 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [16. 22.  0.  0.  0.  0.  0.  0.  3. 14.  0.  0.  0. 10.  0.  6.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 30.  8.  8.  9.  5. 10.  8.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [11. 11. 10.  0.  0.] 
adversary cards in discard: [25. 10. 25.  3.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10] -> size -> 27 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [11. 11. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[74.70195]
 [92.08858]
 [92.08858]
 [73.74675]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.  0.  0.] 
cards in discard: [25. 10. 25.  3.  3. 29. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 30.  8.  8.  9.  5. 10.  8.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.11344909667969



action possibilites: [-1] 
expected returns: [[67.36839]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0.] 
cards in discard: [25. 10. 25.  3.  3. 29. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 30.  8.  8.  9.  5. 10.  8.  6.  9. 10.  1.  9. 10.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 95.16299438476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[49.026787]
 [63.15273 ]
 [28.408405]
 [68.88693 ]
 [66.4518  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  0.] 
cards in discard: [25. 10. 25.  3.  3. 29. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 29. 30.  8.  8.  9.  5. 10.  8.  6.  9. 10.  1.  9. 10.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 67.36839294433594



buy possibilites: [-1] 
expected returns: [[42.2759]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  0.] 
cards in discard: [25. 10. 25.  3.  3. 29. 10. 10.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 30.  8.  8.  9.  5.  9.  8.  6.  9. 10.  1.  9. 10.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 68.88694763183594






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [3. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 30.  8.  8.  9.  5.  9.  8.  6.  9. 10.  1.  9. 10.] 
adversary cards in hand: [10.  3. 11. 29. 11.] 
adversary cards in discard: [25. 10. 25.  3.  3. 29. 10. 10.  8. 11. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8] -> size -> 29 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 29. 30.  8.  8.  9.  5.  9.  8.  6.  9. 10.  1.  9. 10.] 
adversary cards in hand: [10.  3. 11. 29. 11.] 
adversary cards in discard: [25. 10. 25.  3.  3. 29. 10. 10.  8. 11. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8] -> size -> 29 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8.  9.  5.  9.  8.  6.  9. 10.  1.  9. 10.] 
adversary cards in hand: [10.  3. 11. 29. 11.] 
adversary cards in discard: [25. 10. 25.  3.  3. 29. 10. 10.  8. 11. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8] -> size -> 29 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10.  3. 11. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 11.] 
expected returns: [[ 2.4191246]
 [ 1.4362469]
 [15.495729 ]
 [16.169693 ]
 [15.495729 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11. 29. 11.] 
cards in discard: [25. 10. 25.  3.  3. 29. 10. 10.  8. 11. 11. 10.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8.  9.  5.  9.  8.  6.  9. 10.  1.  9. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [1. 3. 0. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.275901794433594



action possibilites: [-1. 10. 11. 11. 10.] 
expected returns: [[ -9.877882]
 [-11.076534]
 [  0.219738]
 [  0.219738]
 [-11.076534]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11. 11. 10.] 
cards in discard: [25. 10. 25.  3.  3. 29. 10. 10.  8. 11. 11. 10.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  8.  9.  5.  9.  8.  6.  9. 10.  1.  9. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [1. 3. 0. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 16.169694900512695



action possibilites: [-1] 
expected returns: [[-10.390828]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11. 10.] 
cards in discard: [25. 10. 25.  3.  3. 29. 10. 10.  8. 11. 11. 10.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  8.  9.  5.  9.  8.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [1. 3. 0. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 2.6512060165405273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-22.560755]
 [-36.544796]
 [-10.546903]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 11. 10.] 
cards in discard: [25. 10. 25.  3.  3. 29. 10. 10.  8. 11. 11. 10.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  8.  9.  5.  9.  8.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [1. 3. 0. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.390828132629395






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [1. 3. 0. 6. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8.  9.  5.  9.  8.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [29.  0.  0.  0. 10.] 
adversary cards in discard: [25. 10. 25.  3.  3. 29. 10. 10.  8. 11. 11. 10.  0.  0. 10. 29. 11. 10.
  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10] -> size -> 30 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [1. 3. 0. 6. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 29. 30.  8.  8.  9.  5.  9.  8.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [29.  0.  0.  0. 10.] 
adversary cards in discard: [25. 10. 25.  3.  3. 29. 10. 10.  8. 11. 11. 10.  0.  0. 10. 29. 11. 10.
  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10] -> size -> 30 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [ 1.  3.  0.  6.  0.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8.  9.  4.  9.  8.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [29.  0.  0.  0. 10.] 
adversary cards in discard: [25. 10. 25.  3.  3. 29. 10. 10.  8. 11. 11. 10.  0.  0. 10. 29. 11. 10.
  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10] -> size -> 30 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[-16.553413 ]
 [ -5.6845317]
 [-18.003195 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0. 10.] 
cards in discard: [25. 10. 25.  3.  3. 29. 10. 10.  8. 11. 11. 10.  0.  0. 10. 29. 11. 10.
  3. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8.  9.  4.  9.  8.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [ 1.  3.  0.  6.  0.  0. 11.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -10.546913146972656



action possibilites: [-1.] 
expected returns: [[13.3791275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25. 10. 25.  3.  3. 29. 10. 10.  8. 11. 11. 10.  0.  0. 10. 29. 11. 10.
  3. 11. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  8.  9.  4.  9.  8.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [ 1.  3.  0.  6.  0.  0. 11.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -16.85884666442871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ -0.9915209]
 [ 12.384588 ]
 [  9.478126 ]
 [-14.400533 ]
 [-17.25051  ]
 [ 10.349207 ]
 [ 24.318947 ]
 [ 14.0470085]
 [ 38.258514 ]
 [ 25.157776 ]
 [ -2.260984 ]
 [  7.41733  ]
 [ -5.958783 ]
 [ 11.115124 ]
 [ 12.709667 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25. 10. 25.  3.  3. 29. 10. 10.  8. 11. 11. 10.  0.  0. 10. 29. 11. 10.
  3. 11. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 29. 30. 29. 30.  8.  8.  9.  4.  9.  8.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [ 1.  3.  0.  6.  0.  0. 11.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 13.379127502441406



buy possibilites: [-1] 
expected returns: [[-2.4003596]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25. 10. 25.  3.  3. 29. 10. 10.  8. 11. 11. 10.  0.  0. 10. 29. 11. 10.
  3. 11. 10. 10. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8.  9.  4.  9.  7.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [ 1.  3.  0.  6.  0.  0. 11.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 295 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 38.25849914550781






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [ 1.  3.  0.  6.  0.  0. 11.  3. 14.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8.  9.  4.  9.  7.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0. 10. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25] -> size -> 31 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 1.  3.  0.  6.  0.  0. 11.  3. 14.  0.  0.  0. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  4.  9.  7.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0. 10. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25] -> size -> 31 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 1.  3.  0.  6.  0.  0. 11.  3. 14.  0.  0.  0. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  4.  9.  7.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0. 10. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25] -> size -> 31 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 1.  3.  0.  6.  0.  0. 11.  3. 14.  0.  0.  0. 16.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  4.  8.  7.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0. 10. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25] -> size -> 31 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 10. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
expected returns: [[28.939205]
 [27.56506 ]
 [27.56506 ]
 [43.61694 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 29.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  4.  8.  7.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 6. 16. 22.  0.  0.] 
adversary cards in discard: [ 1.  3.  0.  6.  0.  0. 11.  3. 14.  0.  0.  0. 16.  8. 11.  0.  0.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.400359630584717



action possibilites: [-1. 10. 10.] 
expected returns: [[28.745823]
 [27.31974 ]
 [27.31974 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  4.  8.  7.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 6. 16. 22.  0.  0.] 
adversary cards in discard: [ 1.  3.  0.  6.  0.  0. 11.  3. 14.  0.  0.  0. 16.  8. 11.  0.  0.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 28.836532592773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[14.792427 ]
 [28.676022 ]
 [25.722702 ]
 [-1.7028842]
 [42.06163  ]
 [30.39553  ]
 [28.868305 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  4.  8.  7.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 6. 16. 22.  0.  0.] 
adversary cards in discard: [ 1.  3.  0.  6.  0.  0. 11.  3. 14.  0.  0.  0. 16.  8. 11.  0.  0.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 28.745830535888672



buy possibilites: [-1] 
expected returns: [[49.750923]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [25. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  3.  8.  7.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 6. 16. 22.  0.  0.] 
adversary cards in discard: [ 1.  3.  0.  6.  0.  0. 11.  3. 14.  0.  0.  0. 16.  8. 11.  0.  0.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 42.06161880493164






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 6. 16. 22.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16. 22.  0.  0.] 
cards in discard: [ 1.  3.  0.  6.  0.  0. 11.  3. 14.  0.  0.  0. 16.  8. 11.  0.  0.  0.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  3.  8.  7.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [25. 11. 29.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  0.  0.  0.  3.  0.] 
cards in discard: [ 1.  3.  0.  6.  0.  0. 11.  3. 14.  0.  0.  0. 16.  8. 11.  0.  0.  0.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  3.  8.  7.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [25. 11. 29.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.  0.  0.  3.  0.] 
cards in discard: [ 1.  3.  0.  6.  0.  0. 11.  3. 14.  0.  0.  0. 16.  8. 11.  0.  0.  0.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  3.  8.  7.  6.  9. 10.  0.  9. 10.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [25. 11. 29.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.  0.  0.  3.  0.] 
cards in discard: [ 1.  3.  0.  6.  0.  0. 11.  3. 14.  0.  0.  0. 16.  8. 11.  0.  0.  0.
  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  3.  8.  7.  6.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [25. 11. 29.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[26.186016]
 [25.232796]
 [25.232796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [25. 11. 29.  0. 10. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  3.  8.  7.  6.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8 15] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.75092315673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[10.350342]
 [26.008993]
 [22.845188]
 [-7.530915]
 [41.096897]
 [27.973946]
 [25.760075]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [25. 11. 29.  0. 10. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  3.  8.  7.  6.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8 15] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 26.186016082763672



buy possibilites: [-1] 
expected returns: [[16.497522]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  2.  8.  7.  6.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8 15] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 41.09688949584961






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  2.  8.  7.  6.  9. 10.  0.  9.  9.] 
adversary cards in hand: [25.  3. 11. 29. 25.] 
adversary cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  2.  8.  7.  6.  9. 10.  0.  9.  9.] 
adversary cards in hand: [25.  3. 11. 29. 25.] 
adversary cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  1.] 
cards in discard: [8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8 15  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  2.  7.  7.  6.  9. 10.  0.  9.  9.] 
adversary cards in hand: [25.  3. 11. 29. 25.] 
adversary cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [25.  3. 11. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29. 25.] 
expected returns: [[-6.4153967]
 [14.916225 ]
 [ 3.2128086]
 [ 3.8474627]
 [14.916225 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 11. 29. 25.] 
cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8.  8.  2.  7.  7.  6.  9. 10.  0.  9.  9.] 
adversary cards in hand: [15.  3.  0.  0. 16.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8 15  8] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.497522354125977



action possibilites: [-1] 
expected returns: [[-15.327334]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29. 25. 10. 11.] 
cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  7.  8.  2.  7.  7.  6.  9. 10.  0.  9.  9.] 
adversary cards in hand: [15.  3.  0.  0. 16.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8 15  8  6] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 14.916223526000977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-26.575586]
 [-39.563854]
 [-15.424681]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 29. 25. 10. 11.] 
cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  7.  8.  2.  7.  7.  6.  9. 10.  0.  9.  9.] 
adversary cards in hand: [15.  3.  0.  0. 16.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8 15  8  6] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -15.3273344039917






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [15.  3.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  0. 16.] 
cards in discard: [ 8.  0. 10.  0.  0.  1.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3
  1 11 16  8 15  8  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  7.  8.  2.  7.  7.  6.  9. 10.  0.  9.  9.] 
adversary cards in hand: [10. 11. 10. 29.  0.] 
adversary cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0. 25.  3. 11. 29. 25.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.] 
cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1
 11 16  8 15  8  6  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  6.  8.  2.  7.  7.  6.  9. 10.  0.  9.  9.] 
adversary cards in hand: [10. 11. 10. 29.  0.] 
adversary cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0. 25.  3. 11. 29. 25.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.] 
cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1
 11 16  8 15  8  6  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  6.  8.  2.  7.  7.  6.  9. 10.  0.  9.  9.] 
adversary cards in hand: [10. 11. 10. 29.  0.] 
adversary cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0. 25.  3. 11. 29. 25.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [10. 11. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 29.] 
expected returns: [[-24.316006]
 [-26.07448 ]
 [-16.790684]
 [-26.07448 ]
 [-15.989412]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 29.  0.] 
cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0. 25.  3. 11. 29. 25.
 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  6.  8.  2.  7.  7.  6.  9. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1
 11 16  8 15  8  6  6] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -15.42467975616455



action possibilites: [-1. 10. 11. 10.  8.] 
expected returns: [[2.226029 ]
 [0.5669384]
 [9.362847 ]
 [0.5669384]
 [2.5981407]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  8.] 
cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0. 25.  3. 11. 29. 25.
 10. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  6.  8.  2.  7.  7.  6.  9. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1
 11 16  8 15  8  6  6] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -25.029123306274414



action possibilites: [-1] 
expected returns: [[-24.846935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.] 
cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0. 25.  3. 11. 29. 25.
 10. 11.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  6.  8.  2.  7.  7.  6.  9. 10.  0.  9.  8.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1
 11 16  8 15  8  6  6] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 189 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 10.944091796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-34.825333]
 [-46.274067]
 [-24.950874]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  8.] 
cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0. 25.  3. 11. 29. 25.
 10. 11.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  6.  8.  2.  7.  7.  6.  9. 10.  0.  9.  8.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1
 11 16  8 15  8  6  6] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: -24.846935272216797






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1
 11 16  8 15  8  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  6.  8.  2.  7.  7.  6.  9. 10.  0.  9.  8.] 
adversary cards in hand: [29.  3. 11.  3. 10.] 
adversary cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0. 25.  3. 11. 29. 25.
 10. 11.  0. 15. 29. 11. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1
 11 16  8 15  8  6  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 29. 30.  8.  6.  8.  2.  7.  7.  6.  9. 10.  0.  9.  8.] 
adversary cards in hand: [29.  3. 11.  3. 10.] 
adversary cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0. 25.  3. 11. 29. 25.
 10. 11.  0. 15. 29. 11. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1
 11 16  8 15  8  6  6 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  6.  8.  1.  7.  7.  6.  9. 10.  0.  9.  8.] 
adversary cards in hand: [29.  3. 11.  3. 10.] 
adversary cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0. 25.  3. 11. 29. 25.
 10. 11.  0. 15. 29. 11. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29.  3. 11.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
expected returns: [[-38.956726]
 [-28.919453]
 [-29.538307]
 [-40.043922]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11.  3. 10.] 
cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0. 25.  3. 11. 29. 25.
 10. 11.  0. 15. 29. 11. 10. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  6.  8.  1.  7.  7.  6.  9. 10.  0.  9.  8.] 
adversary cards in hand: [16. 11.  0.  8.  3.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0. 11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1
 11 16  8 15  8  6  6 11] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -24.95087432861328



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[-35.64961 ]
 [-27.204155]
 [-37.11154 ]
 [-37.11154 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10. 10.] 
cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0. 25.  3. 11. 29. 25.
 10. 11.  0. 15. 29. 11. 10. 10.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  6.  8.  1.  7.  7.  6.  9. 10.  0.  9.  8.] 
adversary cards in hand: [16. 11.  0.  8.  3.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0. 11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1
 11 16  8 15  8  6  6 11] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -39.10294723510742



action possibilites: [-1] 
expected returns: [[-37.914032]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.] 
cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0. 25.  3. 11. 29. 25.
 10. 11.  0. 15. 29. 11. 10. 10.  8.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  6.  8.  1.  7.  7.  6.  9. 10.  0.  9.  7.] 
adversary cards in hand: [16. 11.  0.  8.  3.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0. 11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1
 11 16  8 15  8  6  6 11] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 189 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -25.018035888671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-47.387405]
 [-58.769344]
 [-37.652378]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.] 
cards in discard: [25. 11. 29.  0. 10. 10.  0. 11.  0.  0. 10. 10.  0. 25.  3. 11. 29. 25.
 10. 11.  0. 15. 29. 11. 10. 10.  8.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  6.  8.  1.  7.  7.  6.  9. 10.  0.  9.  7.] 
adversary cards in hand: [16. 11.  0.  8.  3.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0. 11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1
 11 16  8 15  8  6  6 11] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: -37.914031982421875






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [16. 11.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  0.  8.  3.] 
cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0. 11.  0.  0.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1
 11 16  8 15  8  6  6 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  6.  8.  1.  7.  7.  6.  9. 10.  0.  9.  7.] 
adversary cards in hand: [10.  0. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.] 
cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0. 11.  0.  0.  0.  3.  0.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  7.  7.  6.  9. 10.  0.  9.  7.] 
adversary cards in hand: [10.  0. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3.] 
cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0. 11.  0.  0.  0.  3.  0.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  7.  7.  6.  9. 10.  0.  9.  7.] 
adversary cards in hand: [10.  0. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [10.  0. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[45.897484]
 [44.734966]
 [59.289745]
 [44.734966]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  7.  7.  6.  9. 10.  0.  9.  7.] 
adversary cards in hand: [11.  3.  0.  6.  0.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0. 11.  0.  0.  0.  3.  0.
  0. 16. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -37.65238571166992



action possibilites: [-1] 
expected returns: [[64.48187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  7.  7.  6.  9. 10.  0.  9.  6.] 
adversary cards in hand: [11.  3.  0.  6.  0.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0. 11.  0.  0.  0.  3.  0.
  0. 16. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 159 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 61.39376449584961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[46.630943]
 [60.067387]
 [26.450947]
 [65.55765 ]
 [63.282703]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  7.  7.  6.  9. 10.  0.  9.  6.] 
adversary cards in hand: [11.  3.  0.  6.  0.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0. 11.  0.  0.  0.  3.  0.
  0. 16. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 64.48187255859375



buy possibilites: [-1] 
expected returns: [[52.726513]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [15.  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  6.  7.  6.  9. 10.  0.  9.  6.] 
adversary cards in hand: [11.  3.  0.  6.  0.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0. 11.  0.  0.  0.  3.  0.
  0. 16. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 101 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 65.55764770507812






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [11.  3.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  6.  0.] 
cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0. 11.  0.  0.  0.  3.  0.
  0. 16. 11.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  6.  7.  6.  9. 10.  0.  9.  6.] 
adversary cards in hand: [10. 11. 10.  0. 15.] 
adversary cards in discard: [15.  8. 11. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8] -> size -> 37 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  6.  0.] 
cards in discard: [ 8.  0. 10.  0.  0.  1.  6.  6. 16. 15.  3.  0. 11.  0.  0.  0.  3.  0.
  0. 16. 11.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  6.  7.  6.  9. 10.  0.  9.  6.] 
adversary cards in hand: [10. 11. 10.  0. 15.] 
adversary cards in discard: [15.  8. 11. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8] -> size -> 37 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 11. 10.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 15.] 
expected returns: [[34.50985 ]
 [33.706608]
 [51.0927  ]
 [33.706608]
 [33.78663 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  0. 15.] 
cards in discard: [15.  8. 11. 10.  0. 10.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  6.  7.  6.  9. 10.  0.  9.  6.] 
adversary cards in hand: [10.  0.  6. 14. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 52.72651290893555



action possibilites: [-1] 
expected returns: [[19.431316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 15.] 
cards in discard: [15.  8. 11. 10.  0. 10.  0. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  6.  7.  6.  9. 10.  0.  9.  5.] 
adversary cards in hand: [10.  0.  6. 14. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 54.52177047729492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[  5.293558]
 [-10.665667]
 [ 19.252033]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 15.] 
cards in discard: [15.  8. 11. 10.  0. 10.  0. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  6.  7.  6.  9. 10.  0.  9.  5.] 
adversary cards in hand: [10.  0.  6. 14. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.431316375732422






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [10.  0.  6. 14. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6. 14. 22.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  6.  7.  6.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 11. 15. 10. 11.] 
adversary cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15] -> size -> 38 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6. 14. 22.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  6.  7.  6.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 11. 15. 10. 11.] 
adversary cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15] -> size -> 38 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 11. 15. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10. 11.] 
expected returns: [[-15.443288]
 [ -4.985874]
 [-16.484505]
 [-16.49081 ]
 [ -4.985874]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15. 10. 11.] 
cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  6.  7.  6.  9. 10.  0.  9.  5.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [10.  0.  6. 14. 22.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 19.252025604248047



action possibilites: [-1] 
expected returns: [[-22.171848]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10. 11.] 
cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  6.  7.  6.  9. 10.  0.  9.  4.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [10.  0.  6. 14. 22.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 129 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -2.5133447647094727





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-33.90374 ]
 [-47.31533 ]
 [-22.310017]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10. 11.] 
cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  6.  7.  6.  9. 10.  0.  9.  4.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [10.  0.  6. 14. 22.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -22.17184829711914






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [10.  0.  6. 14. 22.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  6.  7.  6.  9. 10.  0.  9.  4.] 
adversary cards in hand: [29. 29.  8.  3. 10.] 
adversary cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [10.  0.  6. 14. 22.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  6.  7.  6.  9. 10.  0.  9.  4.] 
adversary cards in hand: [29. 29.  8.  3. 10.] 
adversary cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [10.  0.  6. 14. 22.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  5.  7.  6.  9. 10.  0.  9.  4.] 
adversary cards in hand: [29. 29.  8.  3. 10.] 
adversary cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29. 29.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8. 10.] 
expected returns: [[-17.266392 ]
 [ -6.6263137]
 [ -6.6263137]
 [-16.292452 ]
 [-18.695171 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  8.  3. 10.] 
cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  5.  7.  6.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 1.  8. 16.  3.  6.] 
adversary cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -22.310014724731445



action possibilites: [-1. 29.  8. 25.] 
expected returns: [[-28.606583]
 [-19.404106]
 [-27.767632]
 [ -9.399011]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3. 25.] 
cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 29. 30.  8.  6.  8.  1.  5.  7.  6.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 1.  8. 16.  3.  6.] 
adversary cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -17.644750595092773



action possibilites: [-1] 
expected returns: [[-25.425869]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3. 10. 10.] 
cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 29. 30.  8.  5.  8.  1.  5.  7.  6.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 1.  8. 16.  3.  6.] 
adversary cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0  8  6] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -9.398999214172363





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-35.28534 ]
 [-46.765873]
 [-25.40681 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  3. 10. 10.] 
cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 29. 30.  8.  5.  8.  1.  5.  7.  6.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 1.  8. 16.  3.  6.] 
adversary cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0  8  6] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: -25.42586898803711






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 1.  8. 16.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 16.  3.  6.] 
cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16  8 15  8  6  6 11  0  8  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  5.  8.  1.  5.  7.  6.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 3. 11. 25.  0. 11.] 
adversary cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11. 10. 29. 25. 29.  8.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 6.] 
cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  5.  8.  1.  5.  7.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 3. 11. 25.  0. 11.] 
adversary cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11. 10. 29. 25. 29.  8.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6.] 
cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 29. 30.  8.  5.  8.  1.  5.  7.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 3. 11. 25.  0. 11.] 
adversary cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11. 10. 29. 25. 29.  8.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6.] 
cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  5.  8.  1.  5.  7.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 3. 11. 25.  0. 11.] 
adversary cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11. 10. 29. 25. 29.  8.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 3. 11. 25.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 11.] 
expected returns: [[-27.161331 ]
 [-18.915298 ]
 [ -8.1284485]
 [-18.915298 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 25.  0. 11.] 
cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11. 10. 29. 25. 29.  8.  3. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  5.  8.  1.  5.  7.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 16. 11.  3.  0.] 
adversary cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -25.406814575195312



action possibilites: [-1] 
expected returns: [[-97.96727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 11.  0.  0.] 
cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11. 10. 29. 25. 29.  8.  3. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  4.  8.  1.  5.  7.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 16. 11.  3.  0.] 
adversary cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6] -> size -> 36 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -8.12845230102539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[-123.59427 ]
 [-110.11978 ]
 [-117.32712 ]
 [-148.44652 ]
 [ -97.99399 ]
 [-107.561676]
 [ -97.96721 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 11.  0.  0.] 
cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11. 10. 29. 25. 29.  8.  3. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 28. 30.  8.  4.  8.  1.  5.  7.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 16. 11.  3.  0.] 
adversary cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6] -> size -> 36 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -97.96726989746094






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0. 16. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 11.  3.  0.] 
cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  4.  8.  1.  5.  7.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10. 29. 29. 25.  3.] 
adversary cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11. 10. 29. 25. 29.  8.  3. 10. 10. 25.  3. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 11.  3.  0.] 
cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 28. 30.  8.  4.  8.  1.  5.  7.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10. 29. 29. 25.  3.] 
adversary cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11. 10. 29. 25. 29.  8.  3. 10. 10. 25.  3. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 11.  3.  0.] 
cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 28. 30.  8.  4.  8.  1.  5.  7.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10. 29. 29. 25.  3.] 
adversary cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11. 10. 29. 25. 29.  8.  3. 10. 10. 25.  3. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [10. 29. 29. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29. 25.] 
expected returns: [[-49.957935]
 [-55.13047 ]
 [-37.103962]
 [-37.103962]
 [-24.582224]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 29. 25.  3.] 
cards in discard: [15.  8. 11. 10.  0. 10.  0. 15. 11. 10. 10.  0. 15. 15. 11.  0. 15. 10.
 11. 10. 29. 25. 29.  8.  3. 10. 10. 25.  3. 11.  0. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  4.  8.  1.  5.  7.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 11.  8.  0.  0.] 
adversary cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.  0.  0. 16. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0] -> size -> 37 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -97.96726989746094



action possibilites: [-1] 
expected returns: [[-1.795579]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 29.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  3.  8.  1.  5.  7.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 11.  8.  0.  0.] 
adversary cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.  0.  0. 16. 11.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6] -> size -> 38 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -24.582237243652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-14.91513  ]
 [-28.414543 ]
 [ -2.9661274]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 29.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 28. 30.  8.  3.  8.  1.  5.  7.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 11.  8.  0.  0.] 
adversary cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.  0.  0. 16. 11.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6] -> size -> 38 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.795578956604004






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  0.  0.] 
cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.  0.  0. 16. 11.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  3.  8.  1.  5.  7.  6.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 25. 11. 15.  0.] 
adversary cards in discard: [25. 10. 29. 29.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.  0.  0. 16. 11.  3.  0.  6. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  3.  8.  1.  5.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 25. 11. 15.  0.] 
adversary cards in discard: [25. 10. 29. 29.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.  0.  0. 16. 11.  3.  0.  6. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 28. 30.  8.  3.  8.  1.  5.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 25. 11. 15.  0.] 
adversary cards in discard: [25. 10. 29. 29.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.  0.  0. 16. 11.  3.  0.  6. 29.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  3.  8.  1.  5.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 25. 11. 15.  0.] 
adversary cards in discard: [25. 10. 29. 29.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [ 0. 25. 11. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 15.] 
expected returns: [[-1.143496]
 [24.084648]
 [10.20005 ]
 [-2.291462]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11. 15.  0.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  3.  8.  1.  5.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [15.  6. 11.  0.  3.] 
adversary cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.  0.  0. 16. 11.  3.  0.  6. 29.  1. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1] -> size -> 40 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -2.9661307334899902



action possibilites: [-1] 
expected returns: [[-12.607408]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15.  0.  3.  0.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  2.  8.  1.  5.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [15.  6. 11.  0.  3.] 
adversary cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.  0.  0. 16. 11.  3.  0.  6. 29.  1. 11.  0.  8.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6] -> size -> 41 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 24.084640502929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[-24.596144 ]
 [-12.682601 ]
 [-15.211196 ]
 [-38.00212  ]
 [ -1.0845909]
 [-11.160866 ]
 [-12.857903 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 15.  0.  3.  0.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 28. 30.  8.  2.  8.  1.  5.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [15.  6. 11.  0.  3.] 
adversary cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.  0.  0. 16. 11.  3.  0.  6. 29.  1. 11.  0.  8.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6] -> size -> 41 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -12.607407569885254



buy possibilites: [-1] 
expected returns: [[-14.524962]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 15.  0.  3.  0.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  2.  8.  0.  5.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [15.  6. 11.  0.  3.] 
adversary cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.  0.  0. 16. 11.  3.  0.  6. 29.  1. 11.  0.  8.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6] -> size -> 41 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -50   0   0  54   0] 
sum of rewards: 169 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -1.0845947265625






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [15.  6. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6. 11.  0.  3.] 
cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.  0.  0. 16. 11.  3.  0.  6. 29.  1. 11.  0.  8.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  2.  8.  0.  5.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11. 29. 10. 15. 10.] 
adversary cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11] -> size -> 40 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  0.  3.] 
cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.  0.  0. 16. 11.  3.  0.  6. 29.  1. 11.  0.  8.  0.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  2.  8.  0.  5.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11. 29. 10. 15. 10.] 
adversary cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11] -> size -> 40 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  0.  3.] 
cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.  0.  0. 16. 11.  3.  0.  6. 29.  1. 11.  0.  8.  0.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 28. 30.  8.  2.  8.  0.  5.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11. 29. 10. 15. 10.] 
adversary cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11] -> size -> 40 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  0.  3.] 
cards in discard: [10.  0.  6. 14. 22.  8.  0.  6.  0.  0.  0.  6. 15.  3. 16.  1.  3.  6.
  6.  0.  0. 16. 11.  3.  0.  6. 29.  1. 11.  0.  8.  0.  0.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 28. 30.  8.  2.  8.  0.  5.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [11. 29. 10. 15. 10.] 
adversary cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11] -> size -> 40 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [11. 29. 10. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 15. 10.] 
expected returns: [[-37.512047]
 [-29.897013]
 [-29.234838]
 [-38.813198]
 [-38.846855]
 [-38.813198]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10. 15. 10.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 28. 30.  8.  2.  8.  0.  5.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0] -> size -> 43 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.524962425231934



action possibilites: [-1. 15. 10. 25.] 
expected returns: [[-38.596973]
 [-40.173122]
 [-40.125324]
 [-21.516922]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 25.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 28. 30.  8.  2.  8.  0.  5.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0] -> size -> 43 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -37.90279006958008



action possibilites: [-1] 
expected returns: [[-42.20429]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10.  0.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 28. 30.  8.  1.  8.  0.  5.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6] -> size -> 44 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -21.516923904418945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-51.0078  ]
 [-44.34016 ]
 [-61.75313 ]
 [-41.345425]
 [-42.087463]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 10.  0.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 28. 30.  8.  1.  8.  0.  5.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6] -> size -> 44 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: -42.204288482666016



buy possibilites: [-1] 
expected returns: [[-34.664787]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 10.  0.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 28. 30.  8.  1.  8.  0.  4.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6] -> size -> 44 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -60   0   0  16   0] 
sum of rewards: 171 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -41.345428466796875






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 28. 30.  8.  1.  8.  0.  4.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [15. 10. 11. 15. 10.] 
adversary cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8] -> size -> 41 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [6. 3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  1.  8.  0.  4.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [15. 10. 11. 15. 10.] 
adversary cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8] -> size -> 41 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [6. 3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 27. 30.  8.  1.  8.  0.  4.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [15. 10. 11. 15. 10.] 
adversary cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8] -> size -> 41 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [15. 10. 11. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11. 15. 10.] 
expected returns: [[-45.31355 ]
 [-46.839622]
 [-46.798695]
 [-37.95726 ]
 [-46.839622]
 [-46.798695]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11. 15. 10.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  1.  8.  0.  4.  7.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [8. 6. 6. 0. 0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3] -> size -> 45 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -34.66478729248047



action possibilites: [-1] 
expected returns: [[-41.864544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 15. 10.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  1.  8.  0.  4.  7.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [8. 6. 6. 0. 0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3] -> size -> 45 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -70   0   0  64   0] 
sum of rewards: 189 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: -44.75395584106445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-51.066265]
 [-61.71385 ]
 [-41.86454 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 15. 10.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  1.  8.  0.  4.  7.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [8. 6. 6. 0. 0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3] -> size -> 45 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -41.86454391479492






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [8. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 0. 0.] 
cards in discard: [ 6.  3. 11.  0.  0.  0.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  6  6  3  1 11
 16 15  8  6  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  1.  8.  0.  4.  7.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 0.  8. 29. 11. 10.] 
adversary cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0. 15. 11. 15. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15] -> size -> 42 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 6.  3. 11.  0.  0.  0.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  3  1 11 16 15  8  6
  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  1.  8.  0.  4.  7.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 0.  8. 29. 11. 10.] 
adversary cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0. 15. 11. 15. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15] -> size -> 42 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6.  3. 11.  0.  0.  0.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  3  1 11 16 15  8  6
  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8.  1.  8.  0.  4.  7.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 0.  8. 29. 11. 10.] 
adversary cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0. 15. 11. 15. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15] -> size -> 42 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6.  3. 11.  0.  0.  0.  3.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  3  1 11 16 15  8  6
  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 27. 30.  8.  1.  8.  0.  4.  7.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 0.  8. 29. 11. 10.] 
adversary cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0. 15. 11. 15. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15] -> size -> 42 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0.  8. 29. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11. 10.] 
expected returns: [[-48.984676]
 [-48.36014 ]
 [-40.649223]
 [-41.34507 ]
 [-50.511906]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29. 11. 10.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0. 15. 11. 15. 10. 15. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 27. 30.  8.  1.  8.  0.  4.  7.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  3  1 11 16 15  8  6
  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3  0] -> size -> 42 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -41.86454391479492



action possibilites: [-1. 10.] 
expected returns: [[-56.521084]
 [-57.980465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0. 15. 11. 15. 10. 15. 10.  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 27. 30.  8.  1.  8.  0.  4.  7.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  3  1 11 16 15  8  6
  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3  0] -> size -> 42 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: -39.27667236328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-65.77571 ]
 [-59.076588]
 [-76.5421  ]
 [-55.93191 ]
 [-56.521088]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0. 15. 11. 15. 10. 15. 10.  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 27. 30.  8.  1.  8.  0.  4.  7.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  3  1 11 16 15  8  6
  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3  0] -> size -> 42 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -56.52110290527344



buy possibilites: [-1] 
expected returns: [[-55.380875]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0. 15. 11. 15. 10. 15. 10.  8. 11.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 27. 30.  8.  1.  8.  0.  3.  7.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  3  1 11 16 15  8  6
  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3  0] -> size -> 42 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -80   0   0  16   0] 
sum of rewards: 71 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -55.931922912597656






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 0.] 
cards in discard: [ 6.  3. 11.  0.  0.  0.  3.  0.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  3  1 11 16 15  8  6
  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 27. 30.  8.  1.  8.  0.  3.  7.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 0. 15. 11. 11. 10.] 
adversary cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0. 15. 11. 15. 10. 15. 10.  8. 11.  8. 29.  0. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15  8] -> size -> 43 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 8. 0.] 
cards in discard: [ 6.  3. 11.  0.  0.  0.  3.  0.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  3  1 11 16 15  8  6
  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 27. 30.  8.  1.  8.  0.  3.  7.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 0. 15. 11. 11. 10.] 
adversary cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0. 15. 11. 15. 10. 15. 10.  8. 11.  8. 29.  0. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15  8] -> size -> 43 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 15. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 11. 10.] 
expected returns: [[-55.28654 ]
 [-56.405716]
 [-46.951015]
 [-46.951015]
 [-56.386875]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11. 11. 10.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0. 15. 11. 15. 10. 15. 10.  8. 11.  8. 29.  0. 10.
  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 27. 30.  8.  1.  8.  0.  3.  7.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 3.  6. 29.  6.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  0.  3.  0.  8.  0.  0.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  3  1 11 16 15  8  6
  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3  0] -> size -> 42 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -55.38087463378906



action possibilites: [-1] 
expected returns: [[-55.48183]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11. 10.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0. 15. 11. 15. 10. 15. 10.  8. 11.  8. 29.  0. 10.
  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15  8 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 27. 30.  8.  1.  8.  0.  3.  7.  5.  9. 10.  0.  9.  1.] 
adversary cards in hand: [ 3.  6. 29.  6.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  0.  3.  0.  8.  0.  0.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  3  1 11 16 15  8  6
  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3  0] -> size -> 42 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -90   0   0  64   0] 
sum of rewards: 109 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: -54.27039337158203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-67.277664]
 [-82.58305 ]
 [-55.481827]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 11. 10.] 
cards in discard: [25. 10. 29. 29.  3. 10.  0. 11. 25.  0. 11. 15.  0.  3.  0. 11. 10.  8.
 29. 25. 15. 10. 10.  0. 15. 11. 15. 10. 15. 10.  8. 11.  8. 29.  0. 10.
  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15  8 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 27. 30.  8.  1.  8.  0.  3.  7.  5.  9. 10.  0.  9.  1.] 
adversary cards in hand: [ 3.  6. 29.  6.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  0.  3.  0.  8.  0.  0.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  3  1 11 16 15  8  6
  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3  0] -> size -> 42 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -55.48183059692383






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 3.  6. 29.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 29.  6.  0.] 
cards in discard: [ 6.  3. 11.  0.  0.  0.  3.  0.  8.  0.  0.  6.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  3  1 11 16 15  8  6
  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 27. 30.  8.  1.  8.  0.  3.  7.  5.  9. 10.  0.  9.  1.] 
adversary cards in hand: [11. 10. 11. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15  8 15] -> size -> 44 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 29.  6.  0.] 
cards in discard: [ 6.  3. 11.  0.  0.  0.  3.  0.  8.  0.  0.  6.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  3  1 11 16 15  8  6
  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 27. 30.  8.  1.  8.  0.  3.  7.  5.  9. 10.  0.  9.  1.] 
adversary cards in hand: [11. 10. 11. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15  8 15] -> size -> 44 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 29.  6.  0.] 
cards in discard: [ 6.  3. 11.  0.  0.  0.  3.  0.  8.  0.  0.  6.  8.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  3  1 11 16 15  8  6
  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 27. 30.  8.  1.  8.  0.  3.  7.  5.  9. 10.  0.  9.  1.] 
adversary cards in hand: [11. 10. 11. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15  8 15] -> size -> 44 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [11. 10. 11. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 15.  8.] 
expected returns: [[-5.5180535]
 [ 4.309573 ]
 [-6.869059 ]
 [ 4.309573 ]
 [-6.8780403]
 [-4.4271164]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 15.  8.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15  8 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 27. 30.  8.  1.  8.  0.  3.  7.  5.  9. 10.  0.  9.  1.] 
adversary cards in hand: [ 0.  0. 16. 22.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  0.  3.  0.  8.  0.  0.  6.  8.  0.  0.  3.  6. 29.
  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  3  1 11 16 15  8  6
  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3  0  0] -> size -> 43 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -55.48183059692383



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 4 
Witch: 3 
Poacher: 4 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10. 11. 15.  8.] 
cards in discard: [15.] 
cards in deck: 39 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 29 10 11 10 11 25 10 10 25
 10 29 10 10  8 10 25 11 11 15 15 15  8 15 15 11  8 15  8 15 15] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 27. 30.  8.  1.  8.  0.  3.  7.  5.  9. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  0. 16. 22.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  0.  3.  0.  8.  0.  0.  6.  8.  0.  0.  3.  6. 29.
  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0 10 22 11  0  0  0  0 16 14  3  1 11 16 15  8  6
  6 11  0  8  6 15  3  6  0  6 29  1  6  0  0  6  3  0  0] -> size -> 43 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     120       0       0      20       0       0
       0       0    -100       0       0      64       0] 
sum of rewards: 3000099 

action type: gain_card_n - action 8
Learning step: 120004.140625
desired expected reward: 119999.7109375



