 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.245245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1
Learning step: -15.644442558288574
desired expected reward: 0.8370161056518555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.23646 ]
 [22.395885]
 [21.799923]
 [19.692995]
 [24.054308]
 [23.490849]
 [22.894884]
 [23.519234]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6211016774177551
desired expected reward: 23.034048080444336



buy possibilites: [-1] 
expected returns: [[23.31614]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: -0.0370570570230484
desired expected reward: 22.35882568359375






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [15.  0.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.079803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5839647650718689
desired expected reward: 22.732173919677734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.623913]
 [24.783337]
 [24.187376]
 [22.08045 ]
 [24.124632]
 [26.441763]
 [25.878304]
 [26.590946]
 [24.334843]
 [25.28234 ]
 [25.494265]
 [25.90669 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6436758041381836
desired expected reward: 24.643890380859375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.746744]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [8. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6642341017723083
desired expected reward: 25.242454528808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.169847]
 [24.329273]
 [23.733309]
 [21.626385]
 [23.670567]
 [25.987698]
 [25.424238]
 [26.136877]
 [23.880774]
 [24.828272]
 [25.0402  ]
 [25.452623]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [8. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6411493420600891
desired expected reward: 24.403278350830078



buy possibilites: [-1] 
expected returns: [[26.774023]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [8. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 1.0
Learning step: -0.4637508988380432
desired expected reward: 23.865520477294922






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8. 0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8. 0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8. 0. 0. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.231424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6767171621322632
desired expected reward: 26.097305297851562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.1298  ]
 [25.28923 ]
 [24.693266]
 [22.58634 ]
 [26.947653]
 [26.384193]
 [25.788229]
 [26.412577]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6710768938064575
desired expected reward: 25.66258430480957



buy possibilites: [-1] 
expected returns: [[25.011007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1. 3. 0. 0. 0. 0. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: -0.10606126487255096
desired expected reward: 25.18316650390625






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  8. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 11. 15.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 1] -> size -> 13 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 15.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 1] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 15.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 1] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 15.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 1] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.06357]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  3. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.613916277885437
desired expected reward: 24.397090911865234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[25.528036]
 [26.68746 ]
 [24.932074]
 [26.091497]
 [24.580536]
 [23.984571]
 [26.028751]
 [28.345886]
 [27.782423]
 [29.442568]
 [28.49507 ]
 [26.238962]
 [25.644714]
 [27.186462]
 [24.485292]
 [27.398386]
 [27.810812]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 1] -> size -> 13 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 27. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  3. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6838153600692749
desired expected reward: 26.59370231628418



buy possibilites: [-1] 
expected returns: [[27.646366]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 27. 30. 29. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  3. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 3.0 

action type: buy - action 16.0
Learning step: -0.40057572722435
desired expected reward: 25.628177642822266






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  8.  3. 11. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [16.  0.  0.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  8.  3. 11. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 27. 30. 29. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [16.  0.  0.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  8.  3. 11. 15. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3  0 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [16.  0.  0.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.069632]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [16.  0.  0.  1.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3  0 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6940944790840149
desired expected reward: 26.952272415161133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.036055]
 [25.599518]
 [23.492594]
 [27.290443]
 [27.318834]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [16.  0.  0.  1.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3  0 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6914843916893005
desired expected reward: 26.479612350463867



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3  0 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3  0 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3  0 10  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.755953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3  0 10  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6660524010658264
desired expected reward: 26.65277862548828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.718822]
 [26.844345]
 [26.262949]
 [24.21271 ]
 [26.20275 ]
 [28.455307]
 [27.911179]
 [28.595913]
 [26.405067]
 [27.329786]
 [27.53059 ]
 [27.920153]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 29. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3  0 10  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6950559020042419
desired expected reward: 27.020946502685547



buy possibilites: [-1] 
expected returns: [[27.892027]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3  0 10  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 16.0
Learning step: 0.3167836666107178
desired expected reward: 26.519535064697266






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [8. 0. 0. 3. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  3  0 10  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [16.  3.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [8. 0. 0. 3. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 15 11  8  3  0 10  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [16.  3.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [8. 0. 0. 3. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 15 11  8  3  0 10  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [16.  3.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.629116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [16.  3.  3.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15. 11.  0.  0. 10.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3. 8. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8  3  0 10  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.68506920337677
desired expected reward: 27.20695686340332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[27.294352]
 [28.419876]
 [27.838476]
 [26.369635]
 [25.788239]
 [27.77828 ]
 [30.030836]
 [29.486708]
 [31.096157]
 [30.17144 ]
 [27.980597]
 [27.39769 ]
 [28.905315]
 [26.272171]
 [29.106115]
 [29.495682]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [16.  3.  3.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 27. 30. 29. 30.  8. 10.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15. 11.  0.  0. 10.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3. 8. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8  3  0 10  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7086225152015686
desired expected reward: 28.023910522460938



buy possibilites: [-1] 
expected returns: [[25.943619]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [16.  3.  3.  1.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 27. 30. 29. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15. 11.  0.  0. 10.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3. 8. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8  3  0 10  8] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.651239395141602
desired expected reward: 16.136999130249023






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [15. 11.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0.  0. 10.] 
cards in discard: [8. 0. 0. 3. 3. 3. 8. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  8  3  0 10  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16. 16.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6] -> size -> 16 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  0.  0. 10.] 
cards in discard: [8. 0. 0. 3. 3. 3. 8. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  8  3  0 10  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16. 16.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6] -> size -> 16 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  0.  0. 10.] 
cards in discard: [8. 0. 0. 3. 3. 3. 8. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  8  3  0 10  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16. 16.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6] -> size -> 16 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [16. 16.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
expected returns: [[26.923286]
 [25.205883]
 [25.205883]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8  3  0 10  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.65366131067276
desired expected reward: 25.28995704650879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.476376]
 [26.601896]
 [26.020504]
 [23.970264]
 [25.960304]
 [28.21286 ]
 [27.668732]
 [28.353462]
 [26.16262 ]
 [27.087336]
 [27.288141]
 [27.677704]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 16.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8  3  0 10  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6783061623573303
desired expected reward: 26.394514083862305



buy possibilites: [-1] 
expected returns: [[26.282967]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 16.  1.  0.  0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 27. 30. 29. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8  3  0 10  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.6383200883865356
desired expected reward: 24.83805274963379






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  8  3  0 10  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [ 0. 16. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0] -> size -> 17 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  8  3  0 10  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 29. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [ 0. 16. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0] -> size -> 17 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 1. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.293957]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [ 0. 16. 16.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8  3  0 10  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6717243194580078
desired expected reward: 25.611242294311523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.44283 ]
 [24.528418]
 [23.96764 ]
 [21.990147]
 [23.909538]
 [26.082191]
 [25.557377]
 [26.217768]
 [24.104694]
 [24.996603]
 [25.190287]
 [25.566027]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [ 0. 16. 16.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 29. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8  3  0 10  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6502400040626526
desired expected reward: 24.755918502807617



buy possibilites: [-1] 
expected returns: [[25.473497]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [ 0. 16. 16.  1.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 28. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8  3  0 10  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.5415574908256531
desired expected reward: 23.426082611083984






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 3.] 
cards in discard: [0. 3. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  8  3  0 10  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 3. 6. 0. 0.] 
adversary cards in discard: [ 0. 16. 16.  1.  0.  0.  3.  0.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [0. 3. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 15 11  3  0 10  8  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 3. 6. 0. 0.] 
adversary cards in discard: [ 0. 16. 16.  1.  0.  0.  3.  0.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0. 3. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 15 11  3  0 10  8  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 3. 6. 0. 0.] 
adversary cards in discard: [ 0. 16. 16.  1.  0.  0.  3.  0.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [1. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.895275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 6. 0. 0.] 
cards in discard: [ 0. 16. 16.  1.  0.  0.  3.  0.  1.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 10. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15 11  3  0 10  8  0] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6732338666915894
desired expected reward: 24.800264358520508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.144667]
 [22.230255]
 [21.669476]
 [19.69198 ]
 [21.611374]
 [23.784025]
 [23.259212]
 [23.919605]
 [21.806528]
 [22.698439]
 [22.89212 ]
 [23.26786 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 0. 0.] 
cards in discard: [ 0. 16. 16.  1.  0.  0.  3.  0.  1.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 28. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 10. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15 11  3  0 10  8  0] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6006746292114258
desired expected reward: 22.348949432373047



buy possibilites: [-1] 
expected returns: [[24.489925]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 0. 0.] 
cards in discard: [ 0. 16. 16.  1.  0.  0.  3.  0.  1.  0.  3.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 10. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15 11  3  0 10  8  0] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 1.0
Learning step: -0.42476335167884827
desired expected reward: 21.805490493774414






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 10. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 11. 15.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 11  3  0 10  8  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 1. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1] -> size -> 19 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 15.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3 15 11  3  0 10  8  0] -> size -> 11 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  9.  8.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 1. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1] -> size -> 19 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  3  3  3 15 11  3  0 10  8  0  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  9.  8.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 1. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1] -> size -> 19 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 3  3 15 11  3  0 10  8  0  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  9.  8.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 1. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 3  3 15 11  3  0 10  8  0  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  9.  8.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 1. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 3  3 15 11  3  0 10  8  0  8  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8.  9.  8.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 1. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1] -> size -> 19 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 1. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.254665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8.  9.  8.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 8.  0. 10. 11.  8. 15.] 
adversary owned cards: [ 3  3 15 11  3  0 10  8  0  8  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6179535984992981
desired expected reward: 23.871971130371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.338818]
 [24.46434 ]
 [23.882946]
 [21.832705]
 [26.075302]
 [25.531174]
 [24.949781]
 [25.54015 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 28. 30.  8.  9.  8.  9.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 8.  0. 10. 11.  8. 15.] 
adversary owned cards: [ 3  3 15 11  3  0 10  8  0  8  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6519720554351807
desired expected reward: 24.752233505249023



buy possibilites: [-1] 
expected returns: [[26.307802]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 6. 0.] 
cards in discard: [11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8.  9.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 8.  0. 10. 11.  8. 15.] 
adversary owned cards: [ 3  3 15 11  3  0 10  8  0  8  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.0936492308974266
desired expected reward: 25.235721588134766






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [ 8.  0. 10. 11.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11  3  0 10  8  0  8  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8.  9.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [11.  3.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [ 8.  0. 10. 11.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11  3  0 10  8  0  8  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 28. 30.  8.  9.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [11.  3.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [ 8.  0. 10. 11.  8. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  9.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [11.  3.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.52779]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [11.  3.  1.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  9.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  3. 11.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6703863143920898
desired expected reward: 25.63741683959961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[24.246767]
 [25.332537]
 [23.682348]
 [24.76812 ]
 [23.354303]
 [22.801693]
 [24.712461]
 [26.884466]
 [26.363111]
 [27.920033]
 [27.017601]
 [24.90172 ]
 [24.33684 ]
 [25.798695]
 [23.257637]
 [25.98749 ]
 [26.354239]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [11.  3.  1.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 26. 30. 27. 30.  8.  9.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  3. 11.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6481602787971497
desired expected reward: 24.95638656616211



buy possibilites: [-1] 
expected returns: [[23.81497]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [11.  3.  1.  3.  6.  0.  2.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 29. 27. 30.  8.  9.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  3. 11.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0 1700    0    0    0    0
   72    0] 
sum of rewards: 1767 

action type: buy - action 2.0
Learning step: 52.549583435058594
desired expected reward: 76.23193359375






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [10.  3. 11.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.  0. 15.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 29. 27. 30.  8.  9.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1. 16.  0. 16.  3.] 
adversary cards in discard: [11.  3.  1.  3.  6.  0.  2.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 11.  0. 15.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 29. 27. 30.  8.  9.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1. 16.  0. 16.  3.] 
adversary cards in discard: [11.  3.  1.  3.  6.  0.  2.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2] -> size -> 21 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1. 16.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
expected returns: [[21.484049]
 [19.876574]
 [19.876574]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  0. 16.  3.] 
cards in discard: [11.  3.  1.  3.  6.  0.  2.  0.  0.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 29. 27. 30.  8.  9.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 3.] 
adversary cards in discard: [10.  3. 11.  0. 15.] 
adversary owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.647053062915802
desired expected reward: 23.167917251586914



action possibilites: [-1] 
expected returns: [[27.28718]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  3.] 
cards in discard: [11.  3.  1.  3.  6.  0.  2.  0.  0.  1.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 29. 27. 30.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 3.] 
adversary cards in discard: [10.  3. 11.  0. 15.] 
adversary owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 2
Learning step: -8.97884750366211
desired expected reward: 14.8665771484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.561573]
 [26.07994 ]
 [24.108585]
 [27.66573 ]
 [27.656874]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  3.] 
cards in discard: [11.  3.  1.  3.  6.  0.  2.  0.  0.  1.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 29. 27. 30.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 3.] 
adversary cards in discard: [10.  3. 11.  0. 15.] 
adversary owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.09031522274017334
desired expected reward: 27.19686508178711






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 3.] 
cards in discard: [10.  3. 11.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 29. 27. 30.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6] -> size -> 21 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 3.] 
cards in discard: [10.  3. 11.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 29. 27. 30.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6] -> size -> 21 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 3.] 
cards in discard: [10.  3. 11.  0. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 29. 27. 30.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6] -> size -> 21 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [3. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.9014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 27. 30.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6961578130722046
desired expected reward: 26.960716247558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.448254]
 [26.55044 ]
 [25.977507]
 [23.964752]
 [25.921022]
 [28.125887]
 [27.59663 ]
 [28.261011]
 [26.113127]
 [27.0237  ]
 [27.215311]
 [27.587614]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 29. 27. 30.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6769403219223022
desired expected reward: 26.327665328979492



buy possibilites: [-1] 
expected returns: [[26.609507]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 29. 27. 30.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 1.0
Learning step: -0.5321134328842163
desired expected reward: 26.018325805664062






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 29. 27. 30.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [1. 3. 1. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6  1] -> size -> 22 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 29. 27. 30.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [1. 3. 1. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6  1] -> size -> 22 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  8.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 29. 27. 30.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [1. 3. 1. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6  1] -> size -> 22 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.76214]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [1. 3. 1. 3. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 27. 30.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3. 15.  8.  3.] 
adversary cards in discard: [ 0.  3. 10.  0.  0.  8.] 
adversary owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3  0  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6662458181381226
desired expected reward: 25.943260192871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[25.342363]
 [26.444546]
 [24.769434]
 [25.871618]
 [24.431791]
 [23.858862]
 [25.815132]
 [28.019993]
 [27.490738]
 [29.065695]
 [28.15512 ]
 [26.007238]
 [25.433815]
 [26.91781 ]
 [24.331633]
 [27.109425]
 [27.481718]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [1. 3. 1. 3. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 25. 29. 27. 30.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3. 15.  8.  3.] 
adversary cards in discard: [ 0.  3. 10.  0.  0.  8.] 
adversary owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3  0  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6741419434547424
desired expected reward: 26.18674659729004



buy possibilites: [-1] 
expected returns: [[25.87301]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [1. 3. 1. 3. 0. 0. 4.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6  1  4] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 29. 27. 29.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3. 15.  8.  3.] 
adversary cards in discard: [ 0.  3. 10.  0.  0.  8.] 
adversary owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3  0  0] -> size -> 14 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 7.5 

action type: buy - action 4.0
Learning step: -0.23628713190555573
desired expected reward: 24.19550323486328






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 15.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.  8.  3.] 
cards in discard: [ 0.  3. 10.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11  3  0 10  8  0  8  0  3  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 27. 29.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16. 11.  6.  6. 16.] 
adversary cards in discard: [1. 3. 1. 3. 0. 0. 4. 0. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6  1  4] -> size -> 23 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0.  3. 10.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3  0 10  8  0  8  0  3  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 27. 29.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16. 11.  6.  6. 16.] 
adversary cards in discard: [1. 3. 1. 3. 0. 0. 4. 0. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6  1  4] -> size -> 23 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  3. 10.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3  0 10  8  0  8  0  3  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 25. 29. 27. 29.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16. 11.  6.  6. 16.] 
adversary cards in discard: [1. 3. 1. 3. 0. 0. 4. 0. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6  1  4] -> size -> 23 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [16. 11.  6.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 16.] 
expected returns: [[21.798815]
 [20.19134 ]
 [22.317991]
 [20.19134 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  6.  6. 16.] 
cards in discard: [1. 3. 1. 3. 0. 0. 4. 0. 0. 1. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1 11  2  6  1  4] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 27. 29.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 10.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11  3  0 10  8  0  8  0  3  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7013341784477234
desired expected reward: 25.171676635742188



action possibilites: [-1] 
expected returns: [[24.28094]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 16.] 
cards in discard: [1. 3. 1. 3. 0. 0. 4. 0. 0. 1. 0. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 26. 29.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 10.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11  3  0 10  8  0  8  0  3  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 2
Learning step: 0.2145993709564209
desired expected reward: 20.559616088867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.40462 ]
 [20.990932]
 [24.42602 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 16.] 
cards in discard: [1. 3. 1. 3. 0. 0. 4. 0. 0. 1. 0. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 25. 29. 26. 29.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 10.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11  3  0 10  8  0  8  0  3  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.03723312169313431
desired expected reward: 24.24370574951172






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [11  3  0 10  8  0  8  0  3  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 26. 29.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 2. 3. 1. 3.] 
adversary cards in discard: [ 1.  3.  1.  3.  0.  0.  4.  0.  0.  1.  0.  0.  3. 16.  6.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3] -> size -> 23 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3  0 10  8  0  8  0  3  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 26. 29.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 2. 3. 1. 3.] 
adversary cards in discard: [ 1.  3.  1.  3.  0.  0.  4.  0.  0.  1.  0.  0.  3. 16.  6.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3] -> size -> 23 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3  0 10  8  0  8  0  3  0  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 29. 26. 29.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 2. 3. 1. 3.] 
adversary cards in discard: [ 1.  3.  1.  3.  0.  0.  4.  0.  0.  1.  0.  0.  3. 16.  6.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3] -> size -> 23 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  0.] 
cards in discard: [0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3  0 10  8  0  8  0  3  0  0  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 25. 29. 26. 29.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 2. 3. 1. 3.] 
adversary cards in discard: [ 1.  3.  1.  3.  0.  0.  4.  0.  0.  1.  0.  0.  3. 16.  6.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3] -> size -> 23 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [1. 2. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.40542]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 2. 3. 1. 3.] 
cards in discard: [ 1.  3.  1.  3.  0.  0.  4.  0.  0.  1.  0.  0.  3. 16.  6.  6. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 26. 29.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 8.] 
adversary cards in discard: [ 0.  0. 11.  8. 10.  0.  0.] 
adversary owned cards: [11  3  0 10  8  0  8  0  3  0  0  0  0] -> size -> 13 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6052160859107971
desired expected reward: 23.82080078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[24.356987]
 [25.414303]
 [23.803352]
 [24.860672]
 [23.477753]
 [22.92412 ]
 [24.809048]
 [26.923027]
 [26.419348]
 [27.92872 ]
 [27.04949 ]
 [24.986479]
 [24.4335  ]
 [25.865715]
 [23.376183]
 [26.043795]
 [26.390137]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 2. 3. 1. 3.] 
cards in discard: [ 1.  3.  1.  3.  0.  0.  4.  0.  0.  1.  0.  0.  3. 16.  6.  6. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 7 
card supply: [22. 25. 29. 26. 29.  8.  8.  8.  8.  7. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 8.] 
adversary cards in discard: [ 0.  0. 11.  8. 10.  0.  0.] 
adversary owned cards: [11  3  0 10  8  0  8  0  3  0  0  0  0] -> size -> 13 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6723834872245789
desired expected reward: 25.7623233795166



buy possibilites: [-1] 
expected returns: [[27.808907]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 2. 3. 1. 3.] 
cards in discard: [ 1.  3.  1.  3.  0.  0.  4.  0.  0.  1.  0.  0.  3. 16.  6.  6. 16. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 25. 29. 26. 29.  8.  8.  8.  8.  7.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 8.] 
adversary cards in discard: [ 0.  0. 11.  8. 10.  0.  0.] 
adversary owned cards: [11  3  0 10  8  0  8  0  3  0  0  0  0] -> size -> 13 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 7.5 

action type: buy - action 25.0
Learning step: -0.32086822390556335
desired expected reward: 27.60785675048828






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 8.] 
cards in discard: [ 0.  0. 11.  8. 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11  3  0 10  8  0  8  0  3  0  0  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 26. 29.  8.  8.  8.  8.  7.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25] -> size -> 24 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 0.  0. 11.  8. 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 26. 29.  8.  8.  8.  8.  7.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25] -> size -> 24 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0.  0. 11.  8. 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 29. 26. 29.  8.  8.  8.  8.  7.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25] -> size -> 24 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0.  0. 11.  8. 10.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 25. 29. 26. 29.  8.  8.  8.  8.  7.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25] -> size -> 24 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [ 0. 25.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[25.674992]
 [27.236904]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  6.  3.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 26. 29.  8.  8.  8.  8.  7.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  8.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7037527561187744
desired expected reward: 27.105154037475586



action possibilites: [-1] 
expected returns: [[27.56344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 26. 29.  8.  7.  8.  8.  7.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  8.  0. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6] -> size -> 13 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.08079654723405838
desired expected reward: 27.259626388549805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[26.218079]
 [27.291391]
 [26.729399]
 [24.763515]
 [26.677013]
 [28.822996]
 [28.311672]
 [28.951351]
 [26.857113]
 [27.749683]
 [27.930428]
 [28.282011]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 25. 29. 26. 29.  8.  7.  8.  8.  7.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  8.  0. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6] -> size -> 13 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.0860961303114891
desired expected reward: 27.477344512939453



buy possibilites: [-1] 
expected returns: [[24.806982]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 26. 29.  8.  7.  8.  8.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  8.  0. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6] -> size -> 13 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: 0.8019328117370605
desired expected reward: 29.753284454345703






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [10.  8.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 11.  0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 26. 29.  8.  7.  8.  8.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0. 16.  0.  2.] 
adversary cards in discard: [29. 25.  0.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29] -> size -> 25 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0. 11.  0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 29. 26. 29.  8.  7.  8.  8.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0. 16.  0.  2.] 
adversary cards in discard: [29. 25.  0.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29] -> size -> 25 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0. 11.  0.] 
cards in discard: [6. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 25. 29.  8.  7.  8.  8.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0. 16.  0.  2.] 
adversary cards in discard: [29. 25.  0.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29] -> size -> 25 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [16.  0. 16.  0.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
expected returns: [[23.470243]
 [21.922215]
 [21.922215]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 16.  0.  2.] 
cards in discard: [29. 25.  0.  6.  3.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 25. 29.  8.  7.  8.  8.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  3. 10.  8.  0. 11.  0.] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3] -> size -> 14 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.656000554561615
desired expected reward: 24.150981903076172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[21.885347]
 [22.920551]
 [22.378504]
 [21.02447 ]
 [20.48242 ]
 [22.327936]
 [24.397743]
 [23.904585]
 [25.382383]
 [24.521503]
 [22.501661]
 [21.960217]
 [23.36254 ]
 [20.925013]
 [23.53687 ]
 [23.875967]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 16.  0.  2.] 
cards in discard: [29. 25.  0.  6.  3.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 25. 29. 25. 29.  8.  7.  8.  8.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  3. 10.  8.  0. 11.  0.] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3] -> size -> 14 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6102336645126343
desired expected reward: 22.901941299438477



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6.  3. 10.  8.  0. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 25. 29.  8.  7.  8.  8.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 4. 1. 1. 1.] 
adversary cards in discard: [29. 25.  0.  6.  3.  0.  0.  0. 16.  0. 16.  0.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29] -> size -> 25 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6.  3. 10.  8.  0. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 25. 29. 25. 29.  8.  7.  8.  8.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 4. 1. 1. 1.] 
adversary cards in discard: [29. 25.  0.  6.  3.  0.  0.  0. 16.  0. 16.  0.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29] -> size -> 25 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6.  3. 10.  8.  0. 11.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 25. 29. 25. 29.  8.  7.  8.  7.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 4. 1. 1. 1.] 
adversary cards in discard: [29. 25.  0.  6.  3.  0.  0.  0. 16.  0. 16.  0.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29] -> size -> 25 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [1. 4. 1. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.18154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 4. 1. 1. 1.] 
cards in discard: [29. 25.  0.  6.  3.  0.  0.  0. 16.  0. 16.  0.  2.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 25. 29.  8.  7.  8.  7.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3 11] -> size -> 15 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6541218161582947
desired expected reward: 23.221843719482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[18.768894]
 [19.804096]
 [18.226843]
 [19.26205 ]
 [17.908012]
 [18.943222]
 [17.365965]
 [19.21148 ]
 [21.281292]
 [20.78813 ]
 [22.265928]
 [21.40505 ]
 [19.385206]
 [18.843761]
 [20.246084]
 [17.808558]
 [20.420412]
 [20.759512]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 4. 1. 1. 1.] 
cards in discard: [29. 25.  0.  6.  3.  0.  0.  0. 16.  0. 16.  0.  2.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 8 
card supply: [21. 25. 29. 25. 29.  8.  7.  8.  7.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3 11] -> size -> 15 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.544813871383667
desired expected reward: 19.66062355041504



buy possibilites: [-1] 
expected returns: [[25.726551]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 4. 1. 1. 1.] 
cards in discard: [29. 25.  0.  6.  3.  0.  0.  0. 16.  0. 16.  0.  2. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 25. 29. 25. 29.  8.  7.  8.  7.  7.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3 11] -> size -> 15 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 3.0 

action type: buy - action 29.0
Learning step: -0.2781379818916321
desired expected reward: 21.126914978027344






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 25. 29.  8.  7.  8.  7.  7.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 1.] 
adversary cards in discard: [29. 25.  0.  6.  3.  0.  0.  0. 16.  0. 16.  0.  2. 29.  1.  4.  1.  1.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29] -> size -> 26 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 29. 25. 29.  8.  7.  8.  7.  7.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 1.] 
adversary cards in discard: [29. 25.  0.  6.  3.  0.  0.  0. 16.  0. 16.  0.  2. 29.  1.  4.  1.  1.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29] -> size -> 26 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  8.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 25. 29. 25. 29.  8.  7.  8.  7.  7.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 1.] 
adversary cards in discard: [29. 25.  0.  6.  3.  0.  0.  0. 16.  0. 16.  0.  2. 29.  1.  4.  1.  1.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29] -> size -> 26 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [3. 0. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.963898]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 1.] 
cards in discard: [29. 25.  0.  6.  3.  0.  0.  0. 16.  0. 16.  0.  2. 29.  1.  4.  1.  1.
  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 29. 25. 29.  8.  7.  8.  7.  7.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  3.  0. 11.  0.  8.] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3 11  0] -> size -> 16 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6596755981445312
desired expected reward: 25.066875457763672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.1266  ]
 [24.150862]
 [23.610592]
 [21.733875]
 [25.609764]
 [25.125776]
 [24.585506]
 [25.073837]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 1.] 
cards in discard: [29. 25.  0.  6.  3.  0.  0.  0. 16.  0. 16.  0.  2. 29.  1.  4.  1.  1.
  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 25. 29. 25. 29.  8.  7.  8.  7.  7.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  3.  0. 11.  0.  8.] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3 11  0] -> size -> 16 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6424688100814819
desired expected reward: 24.321428298950195



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 0.  3.  0. 11.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 29. 25. 29.  8.  7.  8.  7.  7.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 6. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29] -> size -> 26 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 0.  3.  0. 11.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 25. 29. 25. 29.  8.  7.  8.  7.  7.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 6. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29] -> size -> 26 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 0.  3.  0. 11.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3 11  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [19. 25. 29. 25. 29.  8.  7.  8.  7.  7.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 6. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29] -> size -> 26 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [1. 6. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[29.87762]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 3. 3. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 25. 29.  8.  7.  8.  7.  7.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  6.  8.  0.  3.] 
adversary cards in discard: [ 0.  3.  0. 11.  0.  8.  0.  0.  0. 11.  0.  0.] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3 11  0  0] -> size -> 17 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5872491002082825
desired expected reward: 24.48658561706543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[28.201618]
 [28.703503]
 [26.757446]
 [30.274673]
 [30.220825]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 3. 3. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 29. 25. 29.  8.  7.  8.  7.  7.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  6.  8.  0.  3.] 
adversary cards in discard: [ 0.  3.  0. 11.  0.  8.  0.  0.  0. 11.  0.  0.] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3 11  0  0] -> size -> 17 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7441403269767761
desired expected reward: 29.25261688232422



buy possibilites: [-1] 
expected returns: [[24.889511]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 3. 3. 6.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 25. 29.  8.  7.  8.  7.  6.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  6.  8.  0.  3.] 
adversary cards in discard: [ 0.  3.  0. 11.  0.  8.  0.  0.  0. 11.  0.  0.] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3 11  0  0] -> size -> 17 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.5569003224372864
desired expected reward: 29.7177734375






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [10.  6.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  8.  0.  3.] 
cards in discard: [ 0.  3.  0. 11.  0.  8.  0.  0.  0. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  6  3 11  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 25. 29.  8.  7.  8.  7.  6.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 3. 1. 2.] 
adversary cards in discard: [8. 1. 6. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.] 
cards in discard: [ 0.  3.  0. 11.  0.  8.  0.  0.  0. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 25. 29.  8.  7.  8.  7.  6.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 3. 1. 2.] 
adversary cards in discard: [8. 1. 6. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8] -> size -> 27 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.] 
cards in discard: [ 0.  3.  0. 11.  0.  8.  0.  0.  0. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 29. 25. 29.  8.  7.  8.  7.  6.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 3. 1. 2.] 
adversary cards in discard: [8. 1. 6. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8] -> size -> 27 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.] 
cards in discard: [ 0.  3.  0. 11.  0.  8.  0.  0.  0. 11.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 25. 29. 25. 29.  8.  7.  8.  7.  6.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 3. 1. 2.] 
adversary cards in discard: [8. 1. 6. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8] -> size -> 27 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [0. 1. 3. 1. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.389183]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 1. 2.] 
cards in discard: [8. 1. 6. 3. 3. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 25. 29.  8.  7.  8.  7.  6.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0  0] -> size -> 17 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5769686102867126
desired expected reward: 24.312541961669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[29.09734 ]
 [30.159441]
 [28.537119]
 [29.599228]
 [28.209093]
 [29.271198]
 [27.653164]
 [29.54959 ]
 [31.67228 ]
 [31.170395]
 [32.68475 ]
 [31.7965  ]
 [29.721935]
 [29.163229]
 [30.61018 ]
 [28.101126]
 [30.784035]
 [31.116545]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 1. 2.] 
cards in discard: [8. 1. 6. 3. 3. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 8 
card supply: [18. 25. 29. 25. 29.  8.  7.  8.  7.  6.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0  0] -> size -> 17 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.743353009223938
desired expected reward: 29.705860137939453



buy possibilites: [-1] 
expected returns: [[30.01907]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 1. 2.] 
cards in discard: [ 8.  1.  6.  3.  3.  6. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 5 
card supply: [18. 25. 29. 25. 29.  8.  7.  8.  7.  6.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0  0] -> size -> 17 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 10.0
Learning step: -0.6181051135063171
desired expected reward: 29.99207305908203






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 25. 29.  8.  7.  8.  7.  6.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 4. 0. 1. 3.] 
adversary cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10] -> size -> 28 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0  0 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 25. 29.  8.  7.  8.  7.  6.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 4. 0. 1. 3.] 
adversary cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10] -> size -> 28 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0  0 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 25. 29. 25. 29.  8.  7.  8.  7.  6.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 4. 0. 1. 3.] 
adversary cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10] -> size -> 28 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [1. 4. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.261753]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 4. 0. 1. 3.] 
cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 25. 29.  8.  7.  8.  7.  6.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [29. 11.  0.  0. 11.  3.] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0  0 29] -> size -> 18 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7958745360374451
desired expected reward: 29.223196029663086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[22.29781 ]
 [23.322071]
 [22.7818  ]
 [21.441217]
 [20.90508 ]
 [22.733896]
 [24.780977]
 [24.296982]
 [25.757334]
 [24.900738]
 [22.900118]
 [22.361294]
 [23.756712]
 [21.337032]
 [23.924377]
 [24.24504 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 4. 0. 1. 3.] 
cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 25. 29. 25. 29.  8.  7.  8.  7.  6.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [29. 11.  0.  0. 11.  3.] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0  0 29] -> size -> 18 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.628451943397522
desired expected reward: 23.62845230102539



buy possibilites: [-1] 
expected returns: [[23.038458]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 4. 0. 1. 3.] 
cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 5 
card supply: [18. 25. 29. 25. 29.  8.  6.  8.  7.  6.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [29. 11.  0.  0. 11.  3.] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0  0 29] -> size -> 18 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.535248756408691
desired expected reward: 11.369832038879395






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [29. 11.  0.  0. 11.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0  0 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 25. 29.  8.  6.  8.  7.  6.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  0.  3. 25.] 
adversary cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.  6.  1.  4.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6] -> size -> 29 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [29. 11.  0.  0. 11.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0  0 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 25. 29. 25. 29.  8.  6.  8.  7.  6.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  0.  3. 25.] 
adversary cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.  6.  1.  4.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6] -> size -> 29 
adversary victory points: 5
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  0.  0.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[19.959116]
 [20.61481 ]
 [21.471405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3. 25.] 
cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.  6.  1.  4.  0.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 25. 29.  8.  6.  8.  7.  6.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [29. 11.  0.  0. 11.  3.  0.  0.  8.  0.  0.] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0  0 29] -> size -> 18 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6223368048667908
desired expected reward: 22.416120529174805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.959808]
 [18.443798]
 [16.56708 ]
 [19.95898 ]
 [19.907038]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3. 25.] 
cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.  6.  1.  4.  0.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 25. 29. 25. 29.  8.  6.  8.  7.  6.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [29. 11.  0.  0. 11.  3.  0.  0.  8.  0.  0.] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0  0 29] -> size -> 18 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5508939027786255
desired expected reward: 19.408220291137695



buy possibilites: [-1] 
expected returns: [[20.63947]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3. 25.] 
cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.  6.  1.  4.  0.  1.  3.
  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 25. 29.  8.  6.  8.  7.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [29. 11.  0.  0. 11.  3.  0.  0.  8.  0.  0.] 
adversary owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0  0 29] -> size -> 18 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.2920549809932709
desired expected reward: 19.66692543029785






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [29. 11.  0.  0. 11.  3.  0.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  3  0  0  0  0  0  3 11  0  0  0 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 25. 29.  8.  6.  8.  7.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  0. 16.  0.] 
adversary cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.  6.  1.  4.  0.  1.  3.
  8. 29.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8] -> size -> 30 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 11.  0.  0. 11.  3.  0.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  0  8  0  0  0  0  0  0  3 11  0  0  0 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 25. 29.  8.  6.  8.  7.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  0. 16.  0.] 
adversary cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.  6.  1.  4.  0.  1.  3.
  8. 29.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8] -> size -> 30 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 11.  0.  0. 11.  3.  0.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  0  8  0  0  0  0  0  0  3 11  0  0  0 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 25. 29. 25. 29.  8.  6.  8.  7.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  0. 16.  0.] 
adversary cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.  6.  1.  4.  0.  1.  3.
  8. 29.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8] -> size -> 30 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 11.  0.  0. 11.  3.  0.  0.  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  0  8  0  0  0  0  0  0  3 11  0  0  0 29  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 25. 29. 25. 29.  8.  6.  8.  7.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  0. 16.  0.] 
adversary cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.  6.  1.  4.  0.  1.  3.
  8. 29.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8] -> size -> 30 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [29.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
expected returns: [[24.117777]
 [24.748798]
 [22.663574]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 16.  0.] 
cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.  6.  1.  4.  0.  1.  3.
  8. 29.  0.  0.  3. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 25. 29.  8.  6.  8.  7.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  0  8  0  0  0  0  0  0  3 11  0  0  0 29  0] -> size -> 18 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.516927182674408
desired expected reward: 20.122541427612305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.300884]
 [23.28657 ]
 [22.766647]
 [20.960598]
 [24.690533]
 [24.224766]
 [23.704845]
 [24.174763]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 16.  0.] 
cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.  6.  1.  4.  0.  1.  3.
  8. 29.  0.  0.  3. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 25. 29. 25. 29.  8.  6.  8.  7.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  0  8  0  0  0  0  0  0  3 11  0  0  0 29  0] -> size -> 18 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6262680292129517
desired expected reward: 23.491506576538086



buy possibilites: [-1] 
expected returns: [[22.839611]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 16.  0.] 
cards in discard: [ 8.  1.  6.  3.  3.  6. 10.  0.  1.  3.  1.  2.  6.  1.  4.  0.  1.  3.
  8. 29.  0.  0.  3. 25. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 25. 29.  8.  6.  8.  6.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  0  8  0  0  0  0  0  0  3 11  0  0  0 29  0] -> size -> 18 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.08544255793094635
desired expected reward: 23.756505966186523






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  0  0  0  0  0  3 11  0  0  0 29  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 25. 29.  8.  6.  8.  6.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  6.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11] -> size -> 31 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 10  8  0  8  0  0  0  0  0  0  3 11  0  0  0 29  0] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 25. 29.  8.  6.  8.  6.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  6.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11] -> size -> 31 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 10  8  0  8  0  0  0  0  0  0  3 11  0  0  0 29  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 25. 29. 25. 29.  8.  6.  8.  6.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  6.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11] -> size -> 31 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 10  8  0  8  0  0  0  0  0  0  3 11  0  0  0 29  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 25. 29. 24. 29.  8.  6.  8.  6.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  6.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11] -> size -> 31 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 0.  1.  6.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[28.362743]
 [26.850471]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  6.  6. 16.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 24. 29.  8.  6.  8.  6.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 3. 10.  0.  3.  8.  0.  0.] 
adversary owned cards: [11 10  8  0  8  0  0  0  0  0  0  3 11  0  0  0 29  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5431287884712219
desired expected reward: 22.29648208618164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.681566]
 [27.72188 ]
 [27.16886 ]
 [25.283619]
 [29.200695]
 [28.7134  ]
 [28.160381]
 [28.635195]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  6.  6. 16.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 25. 29. 24. 29.  8.  6.  8.  6.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 3. 10.  0.  3.  8.  0.  0.] 
adversary owned cards: [11 10  8  0  8  0  0  0  0  0  0  3 11  0  0  0 29  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7086378335952759
desired expected reward: 27.711467742919922



buy possibilites: [-1] 
expected returns: [[25.628998]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  6.  6. 16.] 
cards in discard: [11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 24. 29.  8.  6.  8.  5.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 3. 10.  0.  3.  8.  0.  0.] 
adversary owned cards: [11 10  8  0  8  0  0  0  0  0  0  3 11  0  0  0 29  0  3] -> size -> 19 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.2169162929058075
desired expected reward: 28.983776092529297






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [ 3. 10.  0.  3.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  8  0  0  0  0  0  0  3 11  0  0  0 29  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 24. 29.  8.  6.  8.  5.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3.  1.  3. 10.] 
adversary cards in discard: [11.  0.  1.  6.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11 11] -> size -> 32 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3. 10.  0.  3.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 24. 29.  8.  6.  8.  5.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3.  1.  3. 10.] 
adversary cards in discard: [11.  0.  1.  6.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11 11] -> size -> 32 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 10.  0.  3.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 25. 29. 24. 29.  8.  6.  8.  5.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3.  1.  3. 10.] 
adversary cards in discard: [11.  0.  1.  6.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11 11] -> size -> 32 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 10.  0.  3.  8.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 25. 29. 24. 29.  8.  6.  8.  5.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3.  1.  3. 10.] 
adversary cards in discard: [11.  0.  1.  6.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11 11] -> size -> 32 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [29.  3.  1.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[28.441338]
 [29.116144]
 [27.981956]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  3. 10.] 
cards in discard: [11.  0.  1.  6.  6. 16.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 24. 29.  8.  6.  8.  5.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [ 3. 10.  0.  3.  8.  0.  0.  0.  8.  0.] 
adversary owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0] -> size -> 17 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6181658506393433
desired expected reward: 25.010831832885742



action possibilites: [-1. 29.] 
expected returns: [[26.477362]
 [27.152166]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  3.  0.] 
cards in discard: [11.  0.  1.  6.  6. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11 11] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 24. 29.  8.  6.  8.  5.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [ 3. 10.  0.  3.  8.  0.  0.  0.  8.  0.] 
adversary owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0] -> size -> 17 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.10726592689752579
desired expected reward: 27.877050399780273



action possibilites: [-1.] 
expected returns: [[31.06113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0. 4.] 
cards in discard: [11.  0.  1.  6.  6. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11 11] -> size -> 32 
action values: 2 
buys: 0 
player value: 1 
card supply: [16. 25. 29. 24. 29.  8.  6.  8.  5.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [ 3. 10.  0.  3.  8.  0.  0.  0.  8.  0.] 
adversary owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0] -> size -> 17 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0.5615768432617188
desired expected reward: 27.713743209838867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[29.009178]
 [30.034132]
 [29.489113]
 [27.626219]
 [29.443853]
 [31.512947]
 [31.02565 ]
 [31.632587]
 [29.60414 ]
 [30.47263 ]
 [30.638212]
 [30.947445]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 4.] 
cards in discard: [11.  0.  1.  6.  6. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 25. 29. 24. 29.  8.  6.  8.  5.  5.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [ 3. 10.  0.  3.  8.  0.  0.  0.  8.  0.] 
adversary owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0] -> size -> 17 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.4375997483730316
desired expected reward: 31.498729705810547



buy possibilites: [-1] 
expected returns: [[30.938759]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 4.] 
cards in discard: [11.  0.  1.  6.  6. 16. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11 11 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 24. 29.  8.  6.  8.  5.  5.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [ 3. 10.  0.  3.  8.  0.  0.  0.  8.  0.] 
adversary owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0] -> size -> 17 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 29.0
Learning step: 1.3858795166015625
desired expected reward: 33.018463134765625






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11.  0.] 
cards in discard: [ 3. 10.  0.  3.  8.  0.  0.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 24. 29.  8.  6.  8.  5.  5.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 1. 0. 0.] 
adversary cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11 11 29] -> size -> 33 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [ 3. 10.  0.  3.  8.  0.  0.  0.  8.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 24. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 1. 0. 0.] 
adversary cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11 11 29] -> size -> 33 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [ 3. 10.  0.  3.  8.  0.  0.  0.  8.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 25. 29. 24. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 1. 0. 0.] 
adversary cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11 11 29] -> size -> 33 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [ 3. 10.  0.  3.  8.  0.  0.  0.  8.  0.  8.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 29. 24. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 1. 0. 0.] 
adversary cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11 11 29] -> size -> 33 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [8. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[17.049175]
 [17.12356 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 1. 0. 0.] 
cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25
 29 29  8 10  6  8 11 11 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 29. 24. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1] -> size -> 19 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8986777663230896
desired expected reward: 30.040081024169922



action possibilites: [-1] 
expected returns: [[24.379803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 29. 24. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 6
Learning step: 0.2923475503921509
desired expected reward: 14.080361366271973





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.760914]
 [23.763912]
 [23.230717]
 [21.395292]
 [25.189651]
 [24.719847]
 [24.186651]
 [24.644436]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 24. 29. 24. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.02910982072353363
desired expected reward: 24.350692749023438



buy possibilites: [-1] 
expected returns: [[23.739616]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 24. 29. 24. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.016438521444797516
desired expected reward: 22.777353286743164






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 29. 24. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 2. 6. 0.] 
adversary cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0] -> size -> 32 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 24. 29. 24. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 2. 6. 0.] 
adversary cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0] -> size -> 32 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  0. 29.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 24. 29. 23. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 2. 6. 0.] 
adversary cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0] -> size -> 32 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 2. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.893803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 2. 6. 0.] 
cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.  0.  8.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 29. 23. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  0. 11.  1.] 
adversary cards in discard: [ 3.  0.  8.  0.  0. 29.] 
adversary owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3] -> size -> 20 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6533035039901733
desired expected reward: 23.086313247680664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[18.430576]
 [19.395697]
 [18.88264 ]
 [17.622986]
 [17.127504]
 [18.839996]
 [20.76759 ]
 [20.315525]
 [21.690063]
 [20.87855 ]
 [18.990955]
 [18.480543]
 [19.802471]
 [17.520815]
 [19.956074]
 [20.242943]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 2. 6. 0.] 
cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.  0.  8.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 24. 29. 23. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  0. 11.  1.] 
adversary cards in discard: [ 3.  0.  8.  0.  0. 29.] 
adversary owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3] -> size -> 20 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5390688180923462
desired expected reward: 19.354734420776367



buy possibilites: [-1] 
expected returns: [[16.75945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 2. 6. 0.] 
cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.  0.  8.  1.  0.
 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 24. 29. 23. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0. 11.  1.] 
adversary cards in discard: [ 3.  0.  8.  0.  0. 29.] 
adversary owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3] -> size -> 20 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 10.0
Learning step: -0.41877979040145874
desired expected reward: 18.906354904174805






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [10.  0.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.  1.] 
cards in discard: [ 3.  0.  8.  0.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 29. 23. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  3. 25. 16.  1.] 
adversary cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.  0.  8.  1.  0.
 10.  3.  0.  2.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10] -> size -> 33 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  1.  0.] 
cards in discard: [ 3.  0.  8.  0.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 24. 29. 23. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  3. 25. 16.  1.] 
adversary cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.  0.  8.  1.  0.
 10.  3.  0.  2.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10] -> size -> 33 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  1.  0.] 
cards in discard: [ 3.  0.  8.  0.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 24. 29. 23. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  3. 25. 16.  1.] 
adversary cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.  0.  8.  1.  0.
 10.  3.  0.  2.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10] -> size -> 33 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  1.  0.] 
cards in discard: [ 3.  0.  8.  0.  0. 29. 22.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3 22] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 29. 23. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  7.  9.  9.] 
adversary cards in hand: [11.  3. 25. 16.  1.] 
adversary cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.  0.  8.  1.  0.
 10.  3.  0.  2.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10] -> size -> 33 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [11.  3. 25. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 16.] 
expected returns: [[15.151426]
 [15.680048]
 [16.586359]
 [13.795004]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 25. 16.  1.] 
cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.  0.  8.  1.  0.
 10.  3.  0.  2.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 29. 23. 29.  8.  6.  8.  5.  4.  9.  6. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [ 3.  0.  8.  0.  0. 29. 22. 10.  0.  0. 11.  1.  0.] 
adversary owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3 22] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.48940521478652954
desired expected reward: 16.27004623413086



action possibilites: [-1] 
expected returns: [[16.147331]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 16.  1.] 
cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.  0.  8.  1.  0.
 10.  3.  0.  2.  6.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 29. 23. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [ 3.  0.  8.  0.  0. 29. 22. 10.  0.  0. 11.  1.  0.] 
adversary owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3 22] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0.6423153281211853
desired expected reward: 15.883370399475098





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.478854]
 [14.917848]
 [13.191158]
 [16.32525 ]
 [16.235622]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25. 16.  1.] 
cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.  0.  8.  1.  0.
 10.  3.  0.  2.  6.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 29. 23. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [ 3.  0.  8.  0.  0. 29. 22. 10.  0.  0. 11.  1.  0.] 
adversary owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3 22] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.12611296772956848
desired expected reward: 16.27344512939453



buy possibilites: [-1] 
expected returns: [[16.824429]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25. 16.  1.] 
cards in discard: [11.  0.  1.  6.  6. 16. 29. 10. 29.  3.  1.  3.  0.  4.  0.  8.  1.  0.
 10.  3.  0.  2.  6.  0. 14.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 29. 22. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [ 3.  0.  8.  0.  0. 29. 22. 10.  0.  0. 11.  1.  0.] 
adversary owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3 22] -> size -> 21 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.41912105679512024
desired expected reward: 15.336968421936035






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  8. 11.] 
cards in discard: [ 3.  0.  8.  0.  0. 29. 22. 10.  0.  0. 11.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3 22] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 29. 22. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [16.  0. 29.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3] -> size -> 35 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0.  8.  0.  0. 29. 22. 10.  0.  0. 11.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3 22] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 29. 22. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [16.  0. 29.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3] -> size -> 35 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0.  8.  0.  0. 29. 22. 10.  0.  0. 11.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3 22] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 29. 22. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [16.  0. 29.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3] -> size -> 35 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [16.  0. 29.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.  8.] 
expected returns: [[31.132076]
 [29.679754]
 [31.815392]
 [31.22804 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 29.  8.  1.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 29. 22. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [1. 8. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3 22] -> size -> 19 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3278948962688446
desired expected reward: 16.49653434753418





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.373837]
 [30.38558 ]
 [29.843878]
 [27.994957]
 [31.82081 ]
 [31.35077 ]
 [30.809063]
 [31.25481 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 29.  8.  1.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 24. 29. 22. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [1. 8. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3 22] -> size -> 19 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7619619369506836
desired expected reward: 30.363407135009766



buy possibilites: [-1] 
expected returns: [[32.126007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 29.  8.  1.] 
cards in discard: [0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 24. 29. 22. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [1. 8. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3 22] -> size -> 19 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.] 
sum of rewards: -6.0 

action type: buy - action 0.0
Learning step: -0.7238920331001282
desired expected reward: 28.649944305419922






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [1. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0  3 11  0  0  0 29  0  3  0  8  1  3 22] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 22. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  3. 16.  0.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0] -> size -> 36 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 22. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  3. 16.  0.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0] -> size -> 36 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 24. 29. 22. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  3. 16.  0.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0] -> size -> 36 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 21. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  3. 16.  0.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0] -> size -> 36 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 8.  0.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[21.610426]
 [21.70489 ]
 [20.180544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 16.  0.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 21. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 22.  3.  0.] 
adversary cards in discard: [3. 8. 1.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3] -> size -> 17 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8904114961624146
desired expected reward: 31.235595703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.932348]
 [20.395102]
 [18.574795]
 [21.878687]
 [21.784224]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 16.  0.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 24. 29. 21. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 22.  3.  0.] 
adversary cards in discard: [3. 8. 1.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3] -> size -> 17 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5800580978393555
desired expected reward: 21.03036880493164



buy possibilites: [-1] 
expected returns: [[21.437506]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 16.  0.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 24. 29. 21. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 22.  3.  0.] 
adversary cards in discard: [3. 8. 1.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3] -> size -> 17 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -2.  0.  0.  0.  0.] 
sum of rewards: -7.0 

action type: buy - action 0.0
Learning step: -0.5828766226768494
desired expected reward: 19.349472045898438






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 22.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 22.  3.  0.] 
cards in discard: [3. 8. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 21. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 2.  6.  4.  3. 10.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0] -> size -> 37 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0. 0. 0.] 
cards in discard: [3. 8. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 21. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 2.  6.  4.  3. 10.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0] -> size -> 37 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0. 0. 0.] 
cards in discard: [3. 8. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [13. 24. 29. 21. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 2.  6.  4.  3. 10.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0] -> size -> 37 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0. 0. 0.] 
cards in discard: [3. 8. 1. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [13. 24. 29. 20. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 2.  6.  4.  3. 10.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0] -> size -> 37 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [ 2.  6.  4.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[21.963232]
 [21.524351]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  6.  4.  3. 10.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 20. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 8. 11.  0. 10.  0.] 
adversary cards in discard: [ 3.  8.  1.  3. 22. 29.  0.  0.  3.  0.  0.  0.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5643545389175415
desired expected reward: 20.873151779174805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.225737]
 [21.221842]
 [20.688492]
 [18.868185]
 [22.63483 ]
 [22.172077]
 [21.638727]
 [22.07761 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  6.  4.  3. 10.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 24. 29. 20. 29.  8.  6.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 8. 11.  0. 10.  0.] 
adversary cards in discard: [ 3.  8.  1.  3. 22. 29.  0.  0.  3.  0.  0.  0.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5833600759506226
desired expected reward: 21.37987518310547



buy possibilites: [-1] 
expected returns: [[19.645205]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  6.  4.  3. 10.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 24. 29. 20. 29.  8.  5.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 8. 11.  0. 10.  0.] 
adversary cards in discard: [ 3.  8.  1.  3. 22. 29.  0.  0.  3.  0.  0.  0.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -3.
    0. -300.    0.    0.] 
sum of rewards: -308.0 

action type: buy - action 6.0
Learning step: -9.599770545959473
desired expected reward: 9.268414497375488






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0. 10.  0.] 
cards in discard: [ 3.  8.  1.  3. 22. 29.  0.  0.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 20. 29.  8.  5.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [25.  1.  6. 11. 29.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6] -> size -> 38 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0. 10.  0.] 
cards in discard: [ 3.  8.  1.  3. 22. 29.  0.  0.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 24. 29. 20. 29.  8.  5.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [25.  1.  6. 11. 29.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6] -> size -> 38 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  1.  6. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[17.837746]
 [19.272676]
 [18.366367]
 [18.475958]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  6. 11. 29.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 20. 29.  8.  5.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5435827374458313
desired expected reward: 19.101621627807617



action possibilites: [-1] 
expected returns: [[19.464565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  6. 29.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 20. 29.  8.  5.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -4  0  0  0  0] 
sum of rewards: 11 

action type: gain_card_n - action 0
Learning step: 0.06989424675703049
desired expected reward: 15.552682876586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.756918]
 [18.185396]
 [16.488724]
 [19.574055]
 [19.466198]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  6. 29.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 24. 29. 20. 29.  8.  5.  8.  5.  4.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.060840338468551636
desired expected reward: 19.525405883789062



buy possibilites: [-1] 
expected returns: [[17.45053]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  6. 29.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 20. 29.  8.  5.  8.  5.  3.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -5  0  0  8  0] 
sum of rewards: 18 

action type: buy - action 8.0
Learning step: 0.1360088437795639
desired expected reward: 19.710065841674805






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  3.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  0. 22.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 20. 29.  8.  5.  8.  5.  3.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [3. 1. 3. 0. 1.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8] -> size -> 40 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  0. 22.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 24. 29. 20. 29.  8.  5.  8.  5.  3.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [3. 1. 3. 0. 1.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8] -> size -> 40 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  0. 22.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  5.  3.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [3. 1. 3. 0. 1.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8] -> size -> 40 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [3. 1. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.53528]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0. 1.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  5.  3.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  3. 11.  8. 10.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 22.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3  0] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4473954439163208
desired expected reward: 17.00313377380371





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[19.765749]
 [20.732422]
 [20.21129 ]
 [18.948418]
 [18.447054]
 [20.174309]
 [22.1008  ]
 [21.655262]
 [23.030495]
 [22.213163]
 [20.316797]
 [19.80252 ]
 [21.13413 ]
 [18.835848]
 [21.28347 ]
 [21.543125]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 1.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  5.  3.  9.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  3. 11.  8. 10.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 22.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3  0] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5743420720100403
desired expected reward: 20.9609375



buy possibilites: [-1] 
expected returns: [[21.69015]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 1.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  5.  3.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  3. 11.  8. 10.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 22.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3  0] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -6  0  0 50  0] 
sum of rewards: 39 

action type: buy - action 25.0
Learning step: 0.7068317532539368
desired expected reward: 23.737323760986328






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 11.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  8. 10.] 
cards in discard: [ 0.  8.  0.  3.  0. 22.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  5.  3.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [10.  0.  3.  1. 14.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29. 25.  3.  1.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25] -> size -> 41 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  8.  1.] 
cards in discard: [ 0.  8.  0.  3.  0. 22.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1  3 22  3  3  0] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  5.  3.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [10.  0.  3.  1. 14.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29. 25.  3.  1.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25] -> size -> 41 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  1.] 
cards in discard: [ 0.  8.  0.  3.  0. 22.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  5.  3.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [10.  0.  3.  1. 14.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29. 25.  3.  1.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25] -> size -> 41 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  1.] 
cards in discard: [ 0.  8.  0.  3.  0. 22.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  5.  3.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [10.  0.  3.  1. 14.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29. 25.  3.  1.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25] -> size -> 41 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  1.] 
cards in discard: [ 0.  8.  0.  3.  0. 22.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  5.  2.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [10.  0.  3.  1. 14.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29. 25.  3.  1.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25] -> size -> 41 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [10.  0.  3.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
expected returns: [[19.187464]
 [18.772875]
 [17.94436 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  1. 14.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29. 25.  3.  1.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  5.  2.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 22.  8. 10.  8.  0. 11.  1.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6038776636123657
desired expected reward: 21.086271286010742



action possibilites: [-1] 
expected returns: [[24.502535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  1.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29. 25.  3.  1.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  5.  2.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 22.  8. 10.  8.  0. 11.  1. 29.  3.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.16894574463367462
desired expected reward: 18.113306045532227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[22.76785 ]
 [23.710732]
 [23.202425]
 [21.970629]
 [21.481606]
 [23.166355]
 [25.06785 ]
 [24.616209]
 [26.01026 ]
 [25.181746]
 [23.305332]
 [22.803713]
 [24.102556]
 [21.860828]
 [24.248217]
 [24.502535]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  1.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29. 25.  3.  1.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  5.  2.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 22.  8. 10.  8.  0. 11.  1. 29.  3.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.032005175948143005
desired expected reward: 24.470529556274414



buy possibilites: [-1] 
expected returns: [[26.258224]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  1.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29. 25.  3.  1.  3.  0.  1. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  4.  2.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 22.  8. 10.  8.  0. 11.  1. 29.  3.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.  -7.   0.   0.
  4.5  0. ] 
sum of rewards: 12.5 

action type: buy - action 11.0
Learning step: -0.10132426768541336
desired expected reward: 24.966529846191406






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8.  0.  3.  0. 22.  8. 10.  8.  0. 11.  1. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  4.  2.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [11.  6. 29.  0.  0.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29. 25.  3.  1.  3.  0.  1. 11. 14. 10.  0.  3.
  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11] -> size -> 42 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8.  0.  3.  0. 22.  8. 10.  8.  0. 11.  1. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  4.  2.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [11.  6. 29.  0.  0.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29. 25.  3.  1.  3.  0.  1. 11. 14. 10.  0.  3.
  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11] -> size -> 42 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8.  0.  3.  0. 22.  8. 10.  8.  0. 11.  1. 29.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  4.  1.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [11.  6. 29.  0.  0.] 
adversary cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29. 25.  3.  1.  3.  0.  1. 11. 14. 10.  0.  3.
  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11] -> size -> 42 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [11.  6. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[22.000853]
 [22.566088]
 [22.679995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 29.  0.  0.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29. 25.  3.  1.  3.  0.  1. 11. 14. 10.  0.  3.
  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  4.  1.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.701827347278595
desired expected reward: 25.556396484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.19946 ]
 [20.651033]
 [18.86296 ]
 [22.114517]
 [22.000853]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 29.  0.  0.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29. 25.  3.  1.  3.  0.  1. 11. 14. 10.  0.  3.
  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  4.  1.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5891526341438293
desired expected reward: 21.411699295043945



buy possibilites: [-1] 
expected returns: [[21.612444]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 29.  0.  0.] 
cards in discard: [ 0. 16.  0. 29.  8.  1.  0.  8.  0.  3. 16.  0.  6.  2.  6.  4.  3. 10.
  0.  8. 11. 25.  1.  6. 29. 25.  3.  1.  3.  0.  1. 11. 14. 10.  0.  3.
  1.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  4.  0.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -8  0  0  8  0] 
sum of rewards: -5 

action type: buy - action 8.0
Learning step: -0.5865047574043274
desired expected reward: 21.528011322021484






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [0. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  4.  0.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [0. 1. 1. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8] -> size -> 43 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 24. 29. 20. 29.  8.  5.  8.  4.  0.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [0. 1. 1. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8] -> size -> 43 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 24. 29. 19. 29.  8.  5.  8.  4.  0.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [0. 1. 1. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8] -> size -> 43 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 1. 1. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[26.155163]
 [26.268839]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 3. 8.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29
  8 10  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 19. 29.  8.  5.  8.  4.  0.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [3. 0. 3. 1. 0. 0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5230279564857483
desired expected reward: 21.08941650390625



action possibilites: [-1] 
expected returns: [[32.278454]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 19. 29.  8.  5.  8.  4.  0.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [3. 0. 3. 1. 0. 0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 6
Learning step: 0.12311479449272156
desired expected reward: 22.316747665405273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[30.675875]
 [31.680445]
 [31.136435]
 [29.304205]
 [33.100143]
 [32.095573]
 [32.50604 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 24. 29. 19. 29.  8.  5.  8.  4.  0.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [3. 0. 3. 1. 0. 0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.18424484133720398
desired expected reward: 32.094207763671875



buy possibilites: [-1] 
expected returns: [[26.413898]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6] -> size -> 42 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 24. 29. 19. 29.  8.  4.  8.  4.  0.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [3. 0. 3. 1. 0. 0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -7.
    0. -300.    0.    0.] 
sum of rewards: -292.0 

action type: buy - action 6.0
Learning step: -9.36177921295166
desired expected reward: 19.942424774169922






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [3. 0. 3. 1. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 19. 29.  8.  4.  8.  4.  0.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 3. 29.  3.  0. 10.] 
adversary cards in discard: [6. 8. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6] -> size -> 42 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 22.] 
cards in discard: [3. 0. 3. 1. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 19. 29.  8.  4.  8.  4.  0.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 3. 29.  3.  0. 10.] 
adversary cards in discard: [6. 8. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6] -> size -> 42 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3. 8. 0.] 
cards in discard: [3. 0. 3. 1. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 22.  8.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 19. 29.  8.  4.  8.  4.  0.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 3. 29.  3.  0. 10.] 
adversary cards in discard: [6. 8. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6] -> size -> 42 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3. 8. 0.] 
cards in discard: [3. 0. 3. 1. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 22.  8.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 24. 29. 19. 29.  8.  4.  8.  4.  0.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 3. 29.  3.  0. 10.] 
adversary cards in discard: [6. 8. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6] -> size -> 42 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3. 8. 0.] 
cards in discard: [ 3.  0.  3.  1.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 22.  8.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 24. 29. 19. 29.  8.  4.  8.  4.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 29.  3.  0. 10.] 
adversary cards in discard: [6. 8. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6] -> size -> 42 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 3. 29.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[24.970718]
 [25.681398]
 [24.56025 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0. 10.] 
cards in discard: [6. 8. 0. 1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 19. 29.  8.  4.  8.  4.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 11. 29.  8.  8.] 
adversary cards in discard: [ 3.  0.  3.  1.  0.  0. 10. 10. 22.  8.  0.  0.  0.  0.  3.  8.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6778913140296936
desired expected reward: 25.736007690429688



action possibilites: [-1. 29.] 
expected returns: [[25.522285]
 [26.232965]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [6. 8. 0. 1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 19. 29.  8.  4.  8.  4.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 11. 29.  8.  8.] 
adversary cards in discard: [ 3.  0.  3.  1.  0.  0. 10. 10. 22.  8.  0.  0.  0.  0.  3.  8.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.014346141368150711
desired expected reward: 24.545900344848633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[23.587685]
 [24.048246]
 [22.216017]
 [25.41785 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [6. 8. 0. 1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 24. 29. 19. 29.  8.  4.  8.  4.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 11. 29.  8.  8.] 
adversary cards in discard: [ 3.  0.  3.  1.  0.  0. 10. 10. 22.  8.  0.  0.  0.  0.  3.  8.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.06222455948591232
desired expected reward: 25.46006202697754



buy possibilites: [-1] 
expected returns: [[23.284374]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [6. 8. 0. 1. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 24. 29. 19. 29.  8.  4.  8.  4.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 11. 29.  8.  8.] 
adversary cards in discard: [ 3.  0.  3.  1.  0.  0. 10. 10. 22.  8.  0.  0.  0.  0.  3.  8.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -8.  0.  0.  0.  0.] 
sum of rewards: 7.0 

action type: buy - action 0.0
Learning step: -0.25314465165138245
desired expected reward: 23.33454132080078






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 29.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  8.  8.] 
cards in discard: [ 3.  0.  3.  1.  0.  0. 10. 10. 22.  8.  0.  0.  0.  0.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 29. 19. 29.  8.  4.  8.  4.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [16.  0. 25. 11.  4.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0] -> size -> 43 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  8.] 
cards in discard: [ 3.  0.  3.  1.  0.  0. 10. 10. 22.  8.  0.  0.  0.  0.  3.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 29. 19. 29.  8.  4.  8.  4.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [16.  0. 25. 11.  4.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0] -> size -> 43 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  8.  8.] 
cards in discard: [ 3.  0.  3.  1.  0.  0. 10. 10. 22.  8.  0.  0.  0.  0.  3.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 24. 29. 19. 29.  8.  4.  8.  4.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [16.  0. 25. 11.  4.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0] -> size -> 43 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [16.  0. 25. 11.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25. 11.] 
expected returns: [[18.298548]
 [16.994598]
 [19.746933]
 [18.849457]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 25. 11.  4.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 29. 19. 29.  8.  4.  8.  4.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [11.  3. 29.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0] -> size -> 23 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6518945693969727
desired expected reward: 22.63248062133789



action possibilites: [-1] 
expected returns: [[19.632698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 11.  4.  1.  3.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 29. 19. 29.  8.  3.  8.  4.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [11.  3. 29.  3.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0  6] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0.06373535096645355
desired expected reward: 19.8106689453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[17.843288]
 [18.81139 ]
 [18.287119]
 [16.52141 ]
 [20.179516]
 [19.211412]
 [19.60698 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 11.  4.  1.  3.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 24. 29. 19. 29.  8.  3.  8.  4.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [11.  3. 29.  3.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0  6] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.05994941666722298
desired expected reward: 19.69264793395996



buy possibilites: [-1] 
expected returns: [[18.129173]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 11.  4.  1.  3.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [11.  3. 29.  3.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0  6] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -9  0  0 18  0] 
sum of rewards: 24 

action type: buy - action 11.0
Learning step: 0.304970920085907
desired expected reward: 20.484485626220703






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [11.  3. 29.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29.  3.  8.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [11. 11.  3.  6.  8.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11] -> size -> 44 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 29.  3.  8.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0  6] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [11. 11.  3.  6.  8.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11] -> size -> 44 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 29.  3.  8.] 
cards in discard: [6. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [11. 11.  3.  6.  8.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11] -> size -> 44 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [11. 11.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[16.089357]
 [16.65421 ]
 [16.65421 ]
 [16.216333]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  6.  8.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  6  0  3  1  2  6  1  4  3 25 29 29  8 10
  6  8 11 11 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [ 6.  0. 11.  3. 29.  3.  8.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5211117267608643
desired expected reward: 17.608060836791992



action possibilites: [-1] 
expected returns: [[14.45115]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  0  3  1  2  6  1  4  3 25 29 29  8 10  6
  8 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [ 6.  0. 11.  3. 29.  3.  8.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 7
Learning step: 0.18240448832511902
desired expected reward: 14.160158157348633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.860636]
 [11.59884 ]
 [14.557615]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  0  3  1  2  6  1  4  3 25 29 29  8 10  6
  8 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [ 6.  0. 11.  3. 29.  3.  8.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.15628431737422943
desired expected reward: 14.607434272766113






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 8.] 
cards in discard: [ 6.  0. 11.  3. 29.  3.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 14. 29.  6.  0.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  0  3  1  2  6  1  4  3 25 29 29  8 10  6
  8 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11] -> size -> 41 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 8.] 
cards in discard: [ 6.  0. 11.  3. 29.  3.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 14. 29.  6.  0.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  0  3  1  2  6  1  4  3 25 29 29  8 10  6
  8 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11] -> size -> 41 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 14. 29.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
expected returns: [[17.41959 ]
 [16.2036  ]
 [18.104437]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 29.  6.  0.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  0  3  1  2  6  1  4  3 25 29 29  8 10  6
  8 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  1.] 
adversary cards in discard: [ 6.  0. 11.  3. 29.  3.  8.  0.  0.  0.  8.  8.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4038717746734619
desired expected reward: 14.153742790222168



action possibilites: [-1] 
expected returns: [[17.99968]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  6.  0.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  0  3  1  2  6  1  4  3 25 29 29  8 10  6
  8 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 10.  1.] 
adversary cards in discard: [ 6.  0. 11.  3. 29.  3.  8.  0.  0.  0.  8.  8.  0.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.15712474286556244
desired expected reward: 16.21952247619629





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[16.294842]
 [17.240755]
 [16.727583]
 [15.002486]
 [16.693127]
 [18.57611 ]
 [18.684763]
 [16.827394]
 [17.630201]
 [17.773308]
 [18.004509]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  6.  0.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  0  3  1  2  6  1  4  3 25 29 29  8 10  6
  8 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 10.  1.] 
adversary cards in discard: [ 6.  0. 11.  3. 29.  3.  8.  0.  0.  0.  8.  8.  0.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.09392240643501282
desired expected reward: 18.09360122680664



buy possibilites: [-1] 
expected returns: [[16.40439]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  6.  0.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  0  3  1  2  6  1  4  3 25 29 29  8 10  6
  8 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 10.  1.] 
adversary cards in discard: [ 6.  0. 11.  3. 29.  3.  8.  0.  0.  0.  8.  8.  0.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -7  0  0 32  0] 
sum of rewards: 40 

action type: buy - action 14.0
Learning step: 0.8674241900444031
desired expected reward: 17.6948184967041






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.] 
cards in discard: [ 6.  0. 11.  3. 29.  3.  8.  0.  0.  0.  8.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 8. 16.  0.  2.  1.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  0  3  1  2  6  1  4  3 25 29 29  8 10  6
  8 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14] -> size -> 42 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8.] 
cards in discard: [ 6.  0. 11.  3. 29.  3.  8.  0.  0.  0.  8.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8  1 22  3  3  0  8  8  3 10  0  6
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 8. 16.  0.  2.  1.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  0  3  1  2  6  1  4  3 25 29 29  8 10  6
  8 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14] -> size -> 42 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  0. 11.  3. 29.  3.  8.  0.  0.  0.  8.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 8. 16.  0.  2.  1.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  0  3  1  2  6  1  4  3 25 29 29  8 10  6
  8 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14] -> size -> 42 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  0. 11.  3. 29.  3.  8.  0.  0.  0.  8.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 8. 16.  0.  2.  1.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  0  3  1  2  6  1  4  3 25 29 29  8 10  6
  8 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14] -> size -> 42 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  0. 11.  3. 29.  3.  8.  0.  0.  0.  8.  8.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 8. 16.  0.  2.  1.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  1 16 16  0  3  1  2  6  1  4  3 25 29 29  8 10  6
  8 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14] -> size -> 42 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 8. 16.  0.  2.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[20.970175]
 [21.109041]
 [19.658792]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0.  2.  1.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  1 16 16  0  3  1  2  6  1  4  3 25 29 29  8 10  6
  8 29  0 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [ 6.  0. 11.  3. 29.  3.  8.  0.  0.  0.  8.  8.  0.  0.  0. 10.  8.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.42493629455566406
desired expected reward: 15.979454040527344



action possibilites: [-1] 
expected returns: [[16.361988]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1 16 16  0  3  1  6  1  4  3 25 29 29  8 10  6  8 29  0
 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [ 6.  0. 11.  3. 29.  3.  8.  0.  0.  0.  8.  8.  0.  0.  0. 10.  8.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 12
Learning step: 0.012613735161721706
desired expected reward: 20.318851470947266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.724346]
 [13.492628]
 [16.367054]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1 16 16  0  3  1  6  1  4  3 25 29 29  8 10  6  8 29  0
 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [ 6.  0. 11.  3. 29.  3.  8.  0.  0.  0.  8.  8.  0.  0.  0. 10.  8.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1183464378118515
desired expected reward: 16.480335235595703






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [ 6.  0. 11.  3. 29.  3.  8.  0.  0.  0.  8.  8.  0.  0.  0. 10.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  6. 25.  0.  1.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  3  1 16 16  0  3  1  6  1  4  3 25 29 29  8 10  6  8 29  0
 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14] -> size -> 39 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [ 6.  0. 11.  3. 29.  3.  8.  0.  0.  0.  8.  8.  0.  0.  0. 10.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 24. 29. 19. 29.  8.  3.  8.  3.  0.  8.  6.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  6. 25.  0.  1.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  3  1 16 16  0  3  1  6  1  4  3 25 29 29  8 10  6  8 29  0
 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14] -> size -> 39 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [ 6.  0. 11.  3. 29.  3.  8.  0.  0.  0.  8.  8.  0.  0.  0. 10.  8.  0.
  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 24. 29. 18. 29.  8.  3.  8.  3.  0.  8.  6.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  6. 25.  0.  1.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  3  1 16 16  0  3  1  6  1  4  3 25 29 29  8 10  6  8 29  0
 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14] -> size -> 39 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  6. 25.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[24.608274]
 [26.111317]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 25.  0.  1.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.  8. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 16 16  0  3  1  6  1  4  3 25 29 29  8 10  6  8 29  0
 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 29. 18. 29.  8.  3.  8.  3.  0.  8.  6.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 10.  3.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3731555938720703
desired expected reward: 15.993900299072266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[22.87558 ]
 [23.834238]
 [23.31415 ]
 [21.565817]
 [23.279219]
 [25.187592]
 [25.297699]
 [23.415316]
 [24.228931]
 [24.373976]
 [24.608274]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 25.  0.  1.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.  8. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 16 16  0  3  1  6  1  4  3 25 29 29  8 10  6  8 29  0
 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 24. 29. 18. 29.  8.  3.  8.  3.  0.  8.  6.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 10.  3.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6350650191307068
desired expected reward: 23.97321128845215



buy possibilites: [-1] 
expected returns: [[25.5618]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 25.  0.  1.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.  8. 16. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 16 16  0  3  1  6  1  4  3 25 29 29  8 10  6  8 29  0
 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 29. 18. 29.  8.  3.  8.  3.  0.  8.  5.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 10.  3.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -5  0  0 32  0] 
sum of rewards: 22 

action type: buy - action 29.0
Learning step: 0.16946782171726227
desired expected reward: 25.4671688079834






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0. 22.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 29. 18. 29.  8.  3.  8.  3.  0.  8.  5.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 29.  8. 10.  6.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.  8. 16. 29.  0.  6. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  1 16 16  0  3  1  6  1  4  3 25 29 29  8 10  6  8 29  0
 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14 29] -> size -> 40 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  6.  3.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [22.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 29. 18. 29.  8.  3.  8.  3.  0.  8.  5.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 29.  8. 10.  6.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.  8. 16. 29.  0.  6. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  1 16 16  0  3  1  6  1  4  3 25 29 29  8 10  6  8 29  0
 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14 29] -> size -> 40 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  6.  3.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [22.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 24. 29. 18. 29.  8.  3.  8.  3.  0.  8.  5.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 29.  8. 10.  6.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.  8. 16. 29.  0.  6. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  1 16 16  0  3  1  6  1  4  3 25 29 29  8 10  6  8 29  0
 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14 29] -> size -> 40 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  6.  3.  0.] 
cards in discard: [1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [22.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 18. 29.  8.  3.  8.  3.  0.  8.  5.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 29.  8. 10.  6.] 
adversary cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.  8. 16. 29.  0.  6. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  1 16 16  0  3  1  6  1  4  3 25 29 29  8 10  6  8 29  0
 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14 29] -> size -> 40 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29.  8. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
expected returns: [[19.85174 ]
 [20.551985]
 [19.9947  ]
 [19.466475]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8. 10.  6.] 
cards in discard: [ 6.  8.  0.  1.  0. 10.  3. 29.  3.  0.  0. 11. 25. 16.  0. 11.  4.  1.
  3.  8.  3. 14. 14.  0. 29.  6.  0.  8. 16. 29.  0.  6. 25.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 16 16  0  3  1  6  1  4  3 25 29 29  8 10  6  8 29  0
 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 18. 29.  8.  3.  8.  3.  0.  8.  5.  8. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7059785723686218
desired expected reward: 24.85582160949707



action possibilites: [-1.  8. 10.] 
expected returns: [[24.040075]
 [24.186094]
 [23.646471]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  1.] 
cards in discard: [6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  1 16 16  0  3  1  6  1  4  3 25 29 29  8 10  6  8 29  0
 10 14  3  0  0  6  0  8 25 11  8  6  0 11 14 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7. 23. 29. 18. 29.  8.  3.  8.  3.  0.  8.  5.  8. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 0
Learning step: 0.15927863121032715
desired expected reward: 18.251129150390625



action possibilites: [-1] 
expected returns: [[25.767637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 23. 29. 18. 29.  8.  3.  8.  3.  0.  8.  5.  8. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.6788468360900879
desired expected reward: 22.069290161132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[24.058128]
 [24.513197]
 [22.699137]
 [25.855997]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 23. 29. 18. 29.  8.  3.  8.  3.  0.  8.  5.  8. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.5352340340614319
desired expected reward: 26.302871704101562



buy possibilites: [-1] 
expected returns: [[26.965525]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6. 3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 17. 29.  8.  3.  8.  3.  0.  8.  5.  8. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1] -> size -> 27 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -4  0  0  8  0] 
sum of rewards: 39 

action type: buy - action 3.0
Learning step: 0.7185267210006714
desired expected reward: 25.205570220947266






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 17. 29.  8.  3.  8.  3.  0.  8.  5.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 8. 14. 25.  1.  1.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3] -> size -> 39 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 23. 29. 17. 29.  8.  3.  8.  3.  0.  8.  5.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 8. 14. 25.  1.  1.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3] -> size -> 39 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8. 14. 25.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 25.] 
expected returns: [[22.950693]
 [23.10318 ]
 [21.776764]
 [24.4554  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 25.  1.  1.] 
cards in discard: [ 6.  3. 29.  8.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 17. 29.  8.  3.  8.  3.  0.  8.  5.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  8.  0. 11.] 
adversary cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.  0.  0.  0.  8.  3.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1] -> size -> 27 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7138087153434753
desired expected reward: 26.25171661376953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[21.332808]
 [22.285383]
 [21.768341]
 [20.029694]
 [21.732452]
 [23.630257]
 [23.737574]
 [21.868307]
 [22.677675]
 [22.820883]
 [23.042236]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14. 25.  1.  1.] 
cards in discard: [ 6.  3. 29.  8.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 23. 29. 17. 29.  8.  3.  8.  3.  0.  8.  5.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  8.  0. 11.] 
adversary cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.  0.  0.  0.  8.  3.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1] -> size -> 27 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6016377210617065
desired expected reward: 22.349056243896484



buy possibilites: [-1] 
expected returns: [[22.435236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14. 25.  1.  1.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6] -> size -> 40 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  8.  0. 11.] 
adversary cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.  0.  0.  0.  8.  3.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -5.
    0. -300.    0.    0.] 
sum of rewards: -310.0 

action type: buy - action 6.0
Learning step: -9.66532039642334
desired expected reward: 10.364371299743652






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 11.] 
cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.  0.  0.  0.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 29.  0.  3.  8.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6] -> size -> 40 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  0. 11.] 
cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.  0.  0.  0.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 29.  0.  3.  8.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6] -> size -> 40 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  0. 11.] 
cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.  0.  0.  0.  8.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 0. 29.  0.  3.  8.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6] -> size -> 40 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[15.609685]
 [16.278725]
 [15.756423]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  8.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  8. 10.  5.  9.  9.] 
adversary cards in hand: [29.  8.  3.  0. 10.] 
adversary cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.  0.  0.  0.  8.  3. 10.  0.  0.  8.
  0. 11.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1 10] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6554661989212036
desired expected reward: 21.779769897460938



action possibilites: [-1.] 
expected returns: [[18.614614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  8. 10.  5.  9.  9.] 
adversary cards in hand: [29.  8.  3.  0. 10.] 
adversary cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.  0.  0.  0.  8.  3. 10.  0.  0.  8.
  0. 11.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1 10] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.19900843501091003
desired expected reward: 15.080507278442383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[17.020517]
 [17.937044]
 [17.439566]
 [15.766711]
 [17.405043]
 [19.231016]
 [19.334272]
 [17.535738]
 [18.31449 ]
 [18.452265]
 [18.66523 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  8. 10.  5.  9.  9.] 
adversary cards in hand: [29.  8.  3.  0. 10.] 
adversary cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.  0.  0.  0.  8.  3. 10.  0.  0.  8.
  0. 11.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1 10] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.08267772197723389
desired expected reward: 18.69729232788086



buy possibilites: [-1] 
expected returns: [[16.934118]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  9.] 
adversary cards in hand: [29.  8.  3.  0. 10.] 
adversary cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.  0.  0.  0.  8.  3. 10.  0.  0.  8.
  0. 11.] 
adversary owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1 10] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -6  0  0 32  0] 
sum of rewards: 41 

action type: buy - action 14.0
Learning step: 0.8817360401153564
desired expected reward: 18.4174747467041






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [29.  8.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3.  0. 10.] 
cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.  0.  0.  0.  8.  3. 10.  0.  0.  8.
  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  9.] 
adversary cards in hand: [16.  3. 11. 29. 16.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14] -> size -> 41 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0.] 
cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.  0.  0.  0.  8.  3. 10.  0.  0.  8.
  0. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  9.] 
adversary cards in hand: [16.  3. 11. 29. 16.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14] -> size -> 41 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.  0.  0.  0.  8.  3. 10.  0.  0.  8.
  0. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [10  8  0  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0
  0  3  1 10] -> size -> 28 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  9.] 
adversary cards in hand: [16.  3. 11. 29. 16.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14] -> size -> 41 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.  0.  0.  0.  8.  3. 10.  0.  0.  8.
  0. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [10  8  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0  0
  3  1 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  9.] 
adversary cards in hand: [16.  3. 11. 29. 16.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14] -> size -> 41 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 1. 22.  0. 10.  3.  0.  6.  3.  0.  0.  0.  0.  8.  3. 10.  0.  0.  8.
  0. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [10  8  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0  0
  3  1 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  9.] 
adversary cards in hand: [16.  3. 11. 29. 16.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14] -> size -> 41 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [16.  3. 11. 29. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 29. 16.] 
expected returns: [[17.373938]
 [16.131174]
 [17.931892]
 [18.03373 ]
 [16.131174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 11. 29. 16.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  9.] 
adversary cards in hand: [ 3. 10. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0  0
  3  1 10] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.47634148597717285
desired expected reward: 16.45777702331543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.7351465]
 [14.498661 ]
 [17.357134 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3. 11. 29. 16.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14] -> size -> 41 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  9.] 
adversary cards in hand: [ 3. 10. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0  0
  3  1 10] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5015134811401367
desired expected reward: 16.872425079345703



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 3. 10. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  0.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0  0
  3  1 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  9.] 
adversary cards in hand: [ 6.  0.  6. 11.  0.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14] -> size -> 41 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0 11  0  0  0 29  0  0  8 22  3  3  0  8  8  3 10  0  6  0  0
  3  1 10] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  9.] 
adversary cards in hand: [ 6.  0.  6. 11.  0.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14] -> size -> 41 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  0 11  0  0  0 29  0  0  8 22  3  0  8  8  3 10  0  6  0  0  3  1
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  9.] 
adversary cards in hand: [ 6.  0.  6. 11.  0.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14] -> size -> 41 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  0 11  0  0  0 29  0  0  8 22  3  0  8  8  3 10  0  6  0  0  3  1
 10] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  9.] 
adversary cards in hand: [ 6.  0.  6. 11.  0.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14] -> size -> 41 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 6.  0.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[20.330305]
 [20.918322]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 11.  0.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  9.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [10.  8. 10.  3.] 
adversary owned cards: [10  8  0 11  0  0  0 29  0  0  8 22  3  0  8  8  3 10  0  6  0  0  3  1
 10] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4535413086414337
desired expected reward: 16.903593063354492



action possibilites: [-1] 
expected returns: [[17.382082]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [10.  8. 10.  3.] 
adversary owned cards: [10  8  0 11  0  0  0 29  0  0  8 22  3  0  8  8  3 10  0  6  0  0  3  1
 10] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -7  0  0 16  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.259450763463974
desired expected reward: 21.694820404052734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[15.763438]
 [16.176691]
 [14.526952]
 [17.385424]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 23. 29. 17. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [10.  8. 10.  3.] 
adversary owned cards: [10  8  0 11  0  0  0 29  0  0  8 22  3  0  8  8  3 10  0  6  0  0  3  1
 10] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.09913718700408936
desired expected reward: 17.481218338012695



buy possibilites: [-1] 
expected returns: [[19.930655]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16. 15.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 16. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [10.  8. 10.  3.] 
adversary owned cards: [10  8  0 11  0  0  0 29  0  0  8 22  3  0  8  8  3 10  0  6  0  0  3  1
 10] -> size -> 25 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -8  0  0  8  0] 
sum of rewards: 15 

action type: buy - action 3.0
Learning step: 0.17623689770698547
desired expected reward: 16.352928161621094






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [10.  8. 10.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0 11  0  0  0 29  0  0  8 22  3  0  8  8  3 10  0  6  0  0  3  1
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 16. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 4. 29.  8.  0.  0.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16. 15.  3. 11.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3] -> size -> 43 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  8. 10.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0 11  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 16. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 4. 29.  8.  0.  0.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16. 15.  3. 11.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3] -> size -> 43 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  8. 10.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0 11  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 23. 29. 16. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 4. 29.  8.  0.  0.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16. 15.  3. 11.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3] -> size -> 43 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 4. 29.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[16.86425 ]
 [17.529585]
 [17.025465]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 29.  8.  0.  0.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16. 15.  3. 11.  6.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 16. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 0.  0. 11.  0.  8.] 
adversary cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.] 
adversary owned cards: [10  8  0 11  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5671334862709045
desired expected reward: 19.363521575927734



action possibilites: [-1.] 
expected returns: [[13.911057]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0. 3.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16. 15.  3. 11.  6.  0.  6.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7. 23. 29. 16. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 0.  0. 11.  0.  8.] 
adversary cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.] 
adversary owned cards: [10  8  0 11  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.11089759320020676
desired expected reward: 16.283180236816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[12.345258 ]
 [13.2260475]
 [12.747482 ]
 [11.137938 ]
 [14.478506 ]
 [13.588952 ]
 [13.911057 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0. 3.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16. 15.  3. 11.  6.  0.  6.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 23. 29. 16. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 0.  0. 11.  0.  8.] 
adversary cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.] 
adversary owned cards: [10  8  0 11  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.17279545962810516
desired expected reward: 14.083852767944336






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  8.] 
cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0 11  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 16. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [14.  6.  3.  0. 10.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16. 15.  3. 11.  6.  0.  6.  0.  8. 29.  4.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3] -> size -> 43 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 16. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [14.  6.  3.  0. 10.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16. 15.  3. 11.  6.  0.  6.  0.  8. 29.  4.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3] -> size -> 43 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 23. 29. 16. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [14.  6.  3.  0. 10.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16. 15.  3. 11.  6.  0.  6.  0.  8. 29.  4.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3] -> size -> 43 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 15. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [14.  6.  3.  0. 10.] 
adversary cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16. 15.  3. 11.  6.  0.  6.  0.  8. 29.  4.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3] -> size -> 43 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [14.  6.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[20.754183]
 [19.610744]
 [20.412638]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  3.  0. 10.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16. 15.  3. 11.  6.  0.  6.  0.  8. 29.  4.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 15. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [22.  0.  0.  3.  0.] 
adversary cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.  3.  8.  0.  0.] 
adversary owned cards: [10  8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.35357075929641724
desired expected reward: 13.557486534118652



action possibilites: [-1] 
expected returns: [[13.996698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 10.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16. 15.  3. 11.  6.  0.  6.  0.  8. 29.  4.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 23. 29. 15. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [22.  3.  0.] 
adversary cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.  3.  8.  0.  0.  0.  0.] 
adversary owned cards: [10  8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.008642921224236488
desired expected reward: 19.619388580322266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[12.411678 ]
 [13.304729 ]
 [12.819507 ]
 [11.187556 ]
 [14.565741 ]
 [13.6726885]
 [13.996698 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 10.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16. 15.  3. 11.  6.  0.  6.  0.  8. 29.  4.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 23. 29. 15. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [22.  3.  0.] 
adversary cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.  3.  8.  0.  0.  0.  0.] 
adversary owned cards: [10  8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1710374355316162
desired expected reward: 14.167736053466797



buy possibilites: [-1] 
expected returns: [[14.919899]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 10.] 
cards in discard: [ 6.  3. 29.  8.  0.  6.  8. 14. 25.  1.  1.  8. 14. 29.  0.  0.  3.  0.
 16.  3. 11. 29. 16. 15.  3. 11.  6.  0.  6.  0.  8. 29.  4.  0.  0.  3.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 23. 29. 15. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [22.  3.  0.] 
adversary cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.  3.  8.  0.  0.  0.  0.] 
adversary owned cards: [10  8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -9.  0.  0.  0.  0.] 
sum of rewards: 6.0 

action type: buy - action 0.0
Learning step: -0.03569137677550316
desired expected reward: 12.375986099243164






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [22.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  0.] 
cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.  3.  8.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 15. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 0. 11. 29.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0] -> size -> 44 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  3.  0.] 
cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.  3.  8.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 23. 29. 15. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 0. 11. 29.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0] -> size -> 44 
adversary victory points: 4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 11. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25.] 
expected returns: [[20.453566]
 [21.076052]
 [21.181421]
 [22.013655]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  0. 25.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 15. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [10.  0.  8.  1.  6.] 
adversary cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.  3.  8.  0.  0.  0.  0. 22.  3.  0.] 
adversary owned cards: [10  8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.37344643473625183
desired expected reward: 14.546452522277832



action possibilites: [-1. 11. 25. 29.] 
expected returns: [[23.642015]
 [24.241812]
 [25.1452  ]
 [24.343307]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 25. 29.] 
cards in discard: [0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 23. 29. 15. 29.  8.  2.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [10.  0.  8.  1.  6.] 
adversary cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.  3.  8.  0.  0.  0.  0. 22.  3.  0.] 
adversary owned cards: [10  8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 0
Learning step: 0.1442553997039795
desired expected reward: 18.911968231201172



action possibilites: [-1] 
expected returns: [[21.109724]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 14.  0.] 
cards in discard: [0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 23. 29. 15. 29.  8.  1.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [10.  0.  8.  1.  6.] 
adversary cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.  3.  8.  0.  0.  0.  0. 22.  3.  0.  6.] 
adversary owned cards: [10  8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10  3  6] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0.5172961950302124
desired expected reward: 25.662494659423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[19.462408]
 [20.40375 ]
 [19.89229 ]
 [18.172113]
 [21.732943]
 [20.791605]
 [21.133146]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29. 14.  0.] 
cards in discard: [0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 23. 29. 15. 29.  8.  1.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [10.  0.  8.  1.  6.] 
adversary cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.  3.  8.  0.  0.  0.  0. 22.  3.  0.  6.] 
adversary owned cards: [10  8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10  3  6] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.6322534084320068
desired expected reward: 21.74197769165039



buy possibilites: [-1] 
expected returns: [[20.00878]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29. 14.  0.] 
cards in discard: [0. 0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 23. 29. 15. 29.  8.  1.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [10.  0.  8.  1.  6.] 
adversary cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.  3.  8.  0.  0.  0.  0. 22.  3.  0.  6.] 
adversary owned cards: [10  8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10  3  6] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0. -10.   0.   0.
   0.   0.] 
sum of rewards: 25.0 

action type: buy - action 0.0
Learning step: 0.3762199878692627
desired expected reward: 19.8386287689209






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [10.  0.  8.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  1.  6.] 
cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.  3.  8.  0.  0.  0.  0. 22.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  6  0  0  3  1 10  3  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 15. 29.  8.  1.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 0. 14.  3. 29.  3.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0] -> size -> 45 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.  3.  8.  0.  0.  0.  0. 22.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  0  0  3 10  3  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 15. 29.  8.  1.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 0. 14.  3. 29.  3.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0] -> size -> 45 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  8. 10.  3.  8.  0.  0.  0.  3.  8.  0.  0.  0.  0. 22.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  0  0  3 10  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 23. 29. 15. 29.  8.  1.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 0. 14.  3. 29.  3.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0] -> size -> 45 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 0. 14.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
expected returns: [[14.028459]
 [12.943674]
 [14.693792]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3. 29.  3.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 15. 29.  8.  1.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 8.  0. 10. 22. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  0  0  3 10  3  6] -> size -> 21 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6027418375015259
desired expected reward: 19.406038284301758



action possibilites: [-1. 14. 25.] 
expected returns: [[18.447557]
 [17.381557]
 [19.881096]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3. 25.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 5. 23. 29. 15. 29.  8.  1.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 8.  0. 10. 22. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  0  0  3 10  3  6] -> size -> 21 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.253752201795578
desired expected reward: 13.386642456054688



action possibilites: [-1] 
expected returns: [[14.172468]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  8.  3.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 23. 29. 15. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 8.  0. 10. 22. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  0  0  3 10  3  6  6] -> size -> 22 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0.6023780703544617
desired expected reward: 20.483474731445312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[12.666325]
 [13.068638]
 [14.213413]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  8.  3.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 23. 29. 15. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 8.  0. 10. 22. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  0  0  3 10  3  6  6] -> size -> 22 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.7665295600891113
desired expected reward: 14.938997268676758



buy possibilites: [-1] 
expected returns: [[14.641281]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  8.  3.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 8.  0. 10. 22. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  0  0  3 10  3  6  6] -> size -> 22 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0 -11   0   0   8   0] 
sum of rewards: 32 

action type: buy - action 3.0
Learning step: 0.7216742634773254
desired expected reward: 13.790311813354492






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 10. 22. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 22. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 22. 29.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 29  0  0  8 22  0  8  8  3 10  0  0  0  3 10  3  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 6. 16.  3.  8.  6.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 46 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  0 29  0  0  8  0  8  8  3  0  0  0  3 10  3  6  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 6. 16.  3.  8.  6.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 46 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  0 29  0  0  8  0  8  8  3  0  0  0  3 10  3  6  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 6. 16.  3.  8.  6.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 46 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [ 6. 16.  3.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[16.253054]
 [15.038403]
 [16.437712]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  3.  8.  6.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14
  3  0  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 3.  0.  8.  0. 10.] 
adversary cards in discard: [ 6.  8.  0. 29.] 
adversary owned cards: [ 8  0  0  0 29  0  0  8  0  8  8  3  0  0  0  3 10  3  6  6] -> size -> 20 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.42107757925987244
desired expected reward: 14.220203399658203



action possibilites: [-1] 
expected returns: [[14.349464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14  3  0
  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 3.  0.  8.  0. 10.] 
adversary cards in discard: [ 6.  8.  0. 29.] 
adversary owned cards: [ 8  0  0  0 29  0  0  8  0  8  8  3  0  0  0  3 10  3  6  6] -> size -> 20 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 3
Learning step: 0.14834550023078918
desired expected reward: 15.225808143615723





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.793075]
 [14.34622 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14  3  0
  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 3.  0.  8.  0. 10.] 
adversary cards in discard: [ 6.  8.  0. 29.] 
adversary owned cards: [ 8  0  0  0 29  0  0  8  0  8  8  3  0  0  0  3 10  3  6  6] -> size -> 20 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.16362819075584412
desired expected reward: 14.513092994689941






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  0. 10.] 
cards in discard: [ 6.  8.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 29  0  0  8  0  8  8  3  0  0  0  3 10  3  6  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [6. 6. 8. 8. 0.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14  3  0
  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 44 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 6.  8.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [6. 6. 8. 8. 0.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14  3  0
  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 44 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6.  8.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [6. 6. 8. 8. 0.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14  3  0
  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 44 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6.  8.  0. 29.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [6. 6. 8. 8. 0.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14  3  0
  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 44 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [6. 6. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[12.418507 ]
 [12.5960455]
 [12.5960455]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 8. 0.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0  3  1  6  1  4  3 25 29 29  8  6  8 29  0 10 14  3  0
  0  6  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6.  8.  0. 29.  0.  8.] 
adversary owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0] -> size -> 17 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.44862520694732666
desired expected reward: 13.897594451904297



action possibilites: [-1] 
expected returns: [[14.326155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6
  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6.  8.  0. 29.  0.  8.] 
adversary owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0] -> size -> 17 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 5
Learning step: 0.27084651589393616
desired expected reward: 11.256783485412598





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.866343]
 [14.427532]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6
  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6.  8.  0. 29.  0.  8.] 
adversary owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0] -> size -> 17 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.16514745354652405
desired expected reward: 14.491302490234375






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6.  8.  0. 29.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [15.  0.  1.  6. 14.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6.] 
adversary owned cards: [ 0  0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6
  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 42 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6.  8.  0. 29.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [15.  0.  1.  6. 14.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6.] 
adversary owned cards: [ 0  0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6
  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 42 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6.  8.  0. 29.  0.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [15.  0.  1.  6. 14.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6.] 
adversary owned cards: [ 0  0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6
  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 42 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [15.  0.  1.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
expected returns: [[12.2164955]
 [12.03957  ]
 [11.150497 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.  6. 14.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6
  0  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [ 6.  8.  0. 29.  0.  8.  0.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0] -> size -> 18 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4580329358577728
desired expected reward: 13.969499588012695



action possibilites: [-1] 
expected returns: [[17.931475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 14.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0
  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [ 6.  8.  0. 29.  0.  8.  0.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0] -> size -> 18 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.2770933210849762
desired expected reward: 12.316664695739746





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[16.404633]
 [17.293707]
 [16.81062 ]
 [15.644179]
 [16.77156 ]
 [18.549349]
 [19.39936 ]
 [18.638912]
 [16.899822]
 [16.417095]
 [17.660276]
 [15.528023]
 [17.788898]
 [17.965822]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 14.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0
  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 23. 29. 14. 29.  8.  0.  8.  3.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [ 6.  8.  0. 29.  0.  8.  0.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0] -> size -> 18 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.09785779565572739
desired expected reward: 18.029333114624023



buy possibilites: [-1] 
expected returns: [[17.289755]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 14.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0
  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 23. 29. 14. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [ 6.  8.  0. 29.  0.  8.  0.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0] -> size -> 18 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.  -7.   0.   0.
  4.5  0. ] 
sum of rewards: 12.5 

action type: buy - action 11.0
Learning step: -0.0004183959972579032
desired expected reward: 18.548933029174805






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [0. 6. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [ 6.  8.  0. 29.  0.  8.  0.  0.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 14. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 3.  0. 29. 11.  0.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6. 11. 15.  1.  6. 14.] 
adversary owned cards: [ 0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0
  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11] -> size -> 42 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [ 6.  8.  0. 29.  0.  8.  0.  0.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 23. 29. 14. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 3.  0. 29. 11.  0.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6. 11. 15.  1.  6. 14.] 
adversary owned cards: [ 0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0
  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11] -> size -> 42 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [ 6.  8.  0. 29.  0.  8.  0.  0.  0.  3.  0.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 22. 29. 14. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [ 3.  0. 29. 11.  0.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6. 11. 15.  1.  6. 14.] 
adversary owned cards: [ 0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0
  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11] -> size -> 42 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 3.  0. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[18.252226]
 [18.94002 ]
 [18.854647]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 11.  0.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6. 11. 15.  1.  6. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0
  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 29. 14. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  5.  9.  8.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1] -> size -> 19 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4719873070716858
desired expected reward: 16.817768096923828



action possibilites: [-1] 
expected returns: [[25.930897]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6. 11. 15.  1.  6. 14. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0
  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 22. 29. 14. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  5.  9.  7.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1] -> size -> 19 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -8  0  0 16  0] 
sum of rewards: 23 

action type: gain_card_n - action 8
Learning step: 0.4089803695678711
desired expected reward: 18.852115631103516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[24.359983]
 [24.773123]
 [25.930897]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6. 11. 15.  1.  6. 14. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0
  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 22. 29. 14. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  5.  9.  7.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1] -> size -> 19 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.06329280883073807
desired expected reward: 25.867603302001953






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 29. 14. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  5.  9.  7.] 
adversary cards in hand: [ 4.  3. 16.  0.  0.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6. 11. 15.  1.  6. 14. 15. 11.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0
  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15] -> size -> 43 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 22. 29. 14. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  5.  9.  7.] 
adversary cards in hand: [ 4.  3. 16.  0.  0.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6. 11. 15.  1.  6. 14. 15. 11.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0
  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15] -> size -> 43 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 8.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 22. 29. 14. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 4.  3. 16.  0.  0.] 
adversary cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6. 11. 15.  1.  6. 14. 15. 11.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0
  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15] -> size -> 43 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 4.  3. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[15.70191 ]
 [14.517702]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  3. 16.  0.  0.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6. 11. 15.  1.  6. 14. 15. 11.  3.  0. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0  3  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0
  8 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 29. 14. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [10.  0.  0.  0.  8.  8.] 
adversary owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7680304646492004
desired expected reward: 25.162866592407227



action possibilites: [-1] 
expected returns: [[18.38739]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6. 11. 15.  1.  6. 14. 15. 11.  3.  0. 29.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0 16  0  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0  8
 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 22. 29. 14. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [10.  0.  0.  0.  8.  8.] 
adversary owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -8  0  0  0  0] 
sum of rewards: 7 

action type: gain_card_n - action 0
Learning step: -0.0841391384601593
desired expected reward: 16.156085968017578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[16.83843 ]
 [17.245792]
 [18.387392]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6. 11. 15.  1.  6. 14. 15. 11.  3.  0. 29.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0 16  0  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0  8
 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 22. 29. 14. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [10.  0.  0.  0.  8.  8.] 
adversary owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.08391231298446655
desired expected reward: 18.471302032470703



buy possibilites: [-1] 
expected returns: [[17.502323]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0.] 
cards in discard: [ 0.  0. 29. 25. 11.  0. 29. 14.  0.  3.  3. 29. 25.  0. 14.  3.  8.  3.
  8.  6.  6.  8.  6.  6. 11. 15.  1.  6. 14. 15. 11.  3.  0. 29.  0.  0.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0 16  0  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0  8
 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 22. 29. 13. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [10.  0.  0.  0.  8.  8.] 
adversary owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -9  0  0  8  0] 
sum of rewards: 14 

action type: buy - action 3.0
Learning step: 0.086400605738163
desired expected reward: 17.33219337463379






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [10.  0.  0.  0.  8.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 22. 29. 13. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 8.  6.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0  8
 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3] -> size -> 44 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [10.  0.  0.  0.  8.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 22. 29. 13. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 8.  6.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0  8
 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3] -> size -> 44 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [10.  0.  0.  0.  8.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 22. 29. 12. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 8.  6.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0  8
 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3] -> size -> 44 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 8.  6.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[19.824575]
 [20.025873]
 [19.5162  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0. 10.  1.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0  1  6  1  4  3 25 29 29  6  8 29  0 10 14  3  0  0  6  0  8
 25 11  8  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 22. 29. 12. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  8.  8.  3.  0.  0.  6.  0.  8.] 
adversary owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10  3] -> size -> 21 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.46678876876831055
desired expected reward: 17.035533905029297



action possibilites: [-1] 
expected returns: [[9.504837]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  0  1  4  3 25 29 29  6  8 29  0 14  3  0  0  6  0  8 25 11  8
  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 22. 29. 12. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  8.  8.  3.  0.  0.  6.  0.  8.] 
adversary owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10  3] -> size -> 21 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 13
Learning step: -0.05766277015209198
desired expected reward: 20.19112205505371





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[8.2177105]
 [9.749134 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  0  1  4  3 25 29 29  6  8 29  0 14  3  0  0  6  0  8 25 11  8
  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 22. 29. 12. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  8.  8.  3.  0.  0.  6.  0.  8.] 
adversary owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10  3] -> size -> 21 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.26078882813453674
desired expected reward: 9.765625953674316






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [10.  0.  0.  0.  8.  8.  3.  0.  0.  6.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 22. 29. 12. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  3. 29. 11.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0 16  0  1  4  3 25 29 29  6  8 29  0 14  3  0  0  6  0  8 25 11  8
  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3] -> size -> 41 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [10.  0.  0.  0.  8.  8.  3.  0.  0.  6.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 22. 29. 12. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  3. 29. 11.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0 16  0  1  4  3 25 29 29  6  8 29  0 14  3  0  0  6  0  8 25 11  8
  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3] -> size -> 41 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [10.  0.  0.  0.  8.  8.  3.  0.  0.  6.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 22. 29. 12. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  3. 29. 11.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0 16  0  1  4  3 25 29 29  6  8 29  0 14  3  0  0  6  0  8 25 11  8
  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3] -> size -> 41 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [10.  0.  0.  0.  8.  8.  3.  0.  0.  6.  0.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10  3  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 22. 29. 11. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  3. 29. 11.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0 16  0  1  4  3 25 29 29  6  8 29  0 14  3  0  0  6  0  8 25 11  8
  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3] -> size -> 41 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 0.  3. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[17.020689]
 [17.740335]
 [17.651564]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 11.  0.] 
cards in discard: [8. 0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0  1  4  3 25 29 29  6  8 29  0 14  3  0  0  6  0  8 25 11  8
  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 22. 29. 11. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 3.  3.  1.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10  3  3] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2584640681743622
desired expected reward: 9.490670204162598



action possibilites: [-1. 11.] 
expected returns: [[17.009302]
 [17.646418]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [ 8.  0.  3. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 16  0  1  4  3 25 29 29  6  8 29  0 14  3  0  0  6  0  8 25 11  8
  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 22. 29. 11. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 3.  3.  1.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10  3  3] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 6
Learning step: 0.22055834531784058
desired expected reward: 13.955662727355957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[15.470374 ]
 [16.390633 ]
 [15.8912735]
 [17.68689  ]
 [16.766302 ]
 [17.055206 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [ 8.  0.  3. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 16  0  1  4  3 25 29 29  6  8 29  0 14  3  0  0  6  0  8 25 11  8
  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 22. 29. 11. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 3.  3.  1.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10  3  3] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.11582834273576736
desired expected reward: 17.12512969970703



buy possibilites: [-1] 
expected returns: [[23.10036]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [ 8.  0.  3. 11.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 16  0  1  4  3 25 29 29  6  8 29  0 14  3  0  0  6  0  8 25 11  8
  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 22. 29. 11. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 3.  3.  1.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10  3  3] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -7.  0.  0.  0.  0.] 
sum of rewards: 8.0 

action type: buy - action 0.0
Learning step: 0.018442468717694283
desired expected reward: 15.488818168640137






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  1.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1.  6. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10  3  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 29. 11. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 6. 15.  3.  6.  0.] 
adversary cards in discard: [ 8.  0.  3. 11.  0. 29.  0.  0. 11.] 
adversary owned cards: [ 0  0 16  0  1  4  3 25 29 29  6  8 29  0 14  3  0  0  6  0  8 25 11  8
  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3  0] -> size -> 42 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [1. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10  3  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 22. 29. 11. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 6. 15.  3.  6.  0.] 
adversary cards in discard: [ 8.  0.  3. 11.  0. 29.  0.  0. 11.] 
adversary owned cards: [ 0  0 16  0  1  4  3 25 29 29  6  8 29  0 14  3  0  0  6  0  8 25 11  8
  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3  0] -> size -> 42 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [1. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10  3  3] -> size -> 21 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 1. 22. 29. 11. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 6. 15.  3.  6.  0.] 
adversary cards in discard: [ 8.  0.  3. 11.  0. 29.  0.  0. 11.] 
adversary owned cards: [ 0  0 16  0  1  4  3 25 29 29  6  8 29  0 14  3  0  0  6  0  8 25 11  8
  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3  0] -> size -> 42 
adversary victory points: 5
player victory points: 2 


Player 0 won the game! 



Player 0 bought cards:
Copper: 8 
Silver: 5 
Gold: 1 
Estate: 6 
Duchy: 1 
Province: 0 
Curse: 5 

Remodel: 2 
Workshop: 6 
Chapel: 4 
Witch: 2 
Poacher: 4 
Militia: 2 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 6. 15.  3.  6.  0.] 
cards in discard: [ 8.  0.  3. 11.  0. 29.  0.  0. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0  1  4  3 25 29 29  6  8 29  0 14  3  0  0  6  0  8 25 11  8
  6  0 11 14 29  3  6 14 15  3  0  0  3 11 15  0  3  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 11. 29.  8.  0.  8.  2.  0.  8.  5.  7. 10.  4.  9.  7.] 
adversary cards in hand: [3. 6. 3.] 
adversary cards in discard: [1. 3. 0.] 
adversary owned cards: [ 8 29  0  0  8  0  8  8  0  0  0  3  3  6  6  0  0  1 10  3  3  0] -> size -> 22 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5 500   0   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: buy - action -1
Learning step: 14.156988143920898
desired expected reward: 37.257347106933594



