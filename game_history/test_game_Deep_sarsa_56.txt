 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[58.544975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     270       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000285 

action type: take_action - action 25.0
Learning step: 300015.375
desired expected reward: 300146.59375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[56.98746 ]
 [82.17683 ]
 [73.37656 ]
 [42.330242]
 [89.110115]
 [71.365814]
 [63.30024 ]
 [56.34661 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 58.09067916870117



buy possibilites: [-1] 
expected returns: [[44.921074]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 89.11011505126953






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[57.41357]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.92107391357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 56.30417 ]
 [ 80.402824]
 [ 72.18215 ]
 [ 42.26793 ]
 [ 69.03828 ]
 [ 87.26058 ]
 [ 70.18551 ]
 [100.94205 ]
 [ 54.04147 ]
 [ 62.269363]
 [ 77.831436]
 [ 55.94628 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 55.43009948730469



buy possibilites: [-1] 
expected returns: [[25.495554]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 100.94203186035156






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[38.51838]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.495553970336914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[38.83716 ]
 [57.028008]
 [50.48137 ]
 [27.560097]
 [48.32187 ]
 [62.178825]
 [49.080193]
 [73.77208 ]
 [37.11695 ]
 [43.32839 ]
 [54.881897]
 [38.671387]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 37.877296447753906



buy possibilites: [-1] 
expected returns: [[22.58694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 73.7720718383789






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.  0.  0.] 
cards in discard: [11.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15.  0.  0.] 
cards in discard: [11.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15.  0.  0.] 
cards in discard: [11.  0.  0.  3.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[26.64849 ]
 [55.756516]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 29.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.58694076538086



action possibilites: [-1.] 
expected returns: [[61.764374]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 53.571929931640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 61.538223]
 [ 86.079636]
 [ 78.08556 ]
 [ 45.611206]
 [ 74.67299 ]
 [ 92.78336 ]
 [ 76.00523 ]
 [106.07401 ]
 [ 59.247772]
 [ 68.13946 ]
 [ 83.58922 ]
 [ 61.818443]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 61.764373779296875



buy possibilites: [-1] 
expected returns: [[21.740263]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 106.07400512695312






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3. 29.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[ 8.210865]
 [30.805552]
 [24.09876 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  8.  0.  3.] 
adversary cards in discard: [ 1.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.740262985229492



action possibilites: [-1. 11.] 
expected returns: [[14.587858]
 [33.134457]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  8.  0.  3.] 
adversary cards in discard: [ 1.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 29.229780197143555



action possibilites: [-1] 
expected returns: [[20.542759]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  8.  0.  3.] 
adversary cards in discard: [ 1.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 39.80023193359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.696035]
 [41.00917 ]
 [34.896946]
 [11.126183]
 [45.93463 ]
 [33.436554]
 [27.460018]
 [22.452494]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  8.  0.  3.] 
adversary cards in discard: [ 1.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.54275894165039



buy possibilites: [-1] 
expected returns: [[21.361734]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  8.  0.  3.] 
adversary cards in discard: [ 1.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 45.93463134765625






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8.  0.  3.] 
cards in discard: [ 1.  3.  0.  0. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3.] 
cards in discard: [ 1.  3.  0.  0. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3.] 
cards in discard: [ 1.  3.  0.  0. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[24.396051]
 [50.007004]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [10. 11. 29. 11.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.36173439025879



action possibilites: [-1.] 
expected returns: [[28.232996]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 11. 29. 11.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 47.631011962890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[32.033745]
 [49.398937]
 [43.064873]
 [26.17331 ]
 [21.228264]
 [41.136974]
 [54.07849 ]
 [41.771538]
 [71.81957 ]
 [64.0023  ]
 [30.286825]
 [46.696148]
 [36.249874]
 [29.629595]
 [47.2965  ]
 [31.219793]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 11. 29. 11.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 28.232995986938477



buy possibilites: [-1] 
expected returns: [[56.367283]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 11. 29. 11.  0.  3.  3.  0. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 71.81956481933594






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 10.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 15 11  8  1] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 10.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 15 11  8  1] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 10.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 15 11  8  1  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 10.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11. 10.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[ 5.5305448]
 [22.094027 ]
 [ 9.337307 ]
 [28.14152  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 15.  0.  3.  1.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8  1  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 56.36728286743164



action possibilites: [-1. 11. 10.] 
expected returns: [[20.20677 ]
 [37.320503]
 [23.339174]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 15.  0.  3.  1.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8  1  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 25.958091735839844



action possibilites: [-1] 
expected returns: [[-4.7667084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11. 15.  0.  3.  1.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8  1  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 42.03009033203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -3.4555845]
 [ 18.679213 ]
 [ 11.021637 ]
 [-12.311739 ]
 [ 23.673506 ]
 [  8.927885 ]
 [  0.6061368]
 [ -3.4660616]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11. 15.  0.  3.  1.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8  1  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: -4.7667083740234375



buy possibilites: [-1] 
expected returns: [[28.467878]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  9.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11. 15.  0.  3.  1.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8  1  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 23.67350959777832






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [11. 15.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0.  3.  1.] 
cards in discard: [0. 8. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  8  1  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  9.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  1.] 
cards in discard: [0. 8. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15 11  8  1  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  9.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  1.] 
cards in discard: [0. 8. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15 11  8  1  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  9.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  1.] 
cards in discard: [ 0.  8.  3. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15 11  8  1  0 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  9.  8.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[14.569475]
 [38.895836]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  3.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  9.  8.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.467878341674805



action possibilites: [-1.] 
expected returns: [[46.582436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  9.  8.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.8193359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[50.04998 ]
 [71.371414]
 [64.24366 ]
 [42.619267]
 [36.547695]
 [61.83613 ]
 [76.81582 ]
 [62.645958]
 [95.705894]
 [87.95644 ]
 [47.841713]
 [68.25652 ]
 [55.514263]
 [46.988297]
 [69.06636 ]
 [49.11853 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  9.  8.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 46.582435607910156



buy possibilites: [-1] 
expected returns: [[78.2914]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0.  3. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 95.70590209960938






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 11  8  1  0 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29. 25.  3. 11.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0.  3. 25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25] -> size -> 20 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29. 25.  3. 11.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0.  3. 25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25] -> size -> 20 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29. 25.  3. 11.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0.  3. 25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25] -> size -> 20 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [6. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29. 25.  3. 11.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  0.  3. 25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25] -> size -> 20 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29. 25.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11.] 
expected returns: [[-10.302536]
 [ 23.64776 ]
 [ 31.815073]
 [ 11.701529]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  3. 11.] 
cards in discard: [10. 11. 29. 11. 10.  0.  0.  3. 25. 29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  3.  3. 15. 25.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.29139709472656



action possibilites: [-1] 
expected returns: [[22.952303]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  3.  3. 15. 25.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 19.350677490234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.726542]
 [36.581417]
 [16.307798]
 [35.026474]
 [25.562035]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  3.  3. 15. 25.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.952302932739258



buy possibilites: [-1] 
expected returns: [[16.595713]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 11.  0.  3.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  3.  3. 15. 25.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 36.581417083740234






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  3. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 25.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3. 15. 25.] 
cards in discard: [ 6.  3. 11.  0.  0.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25. 29.  3.  0.] 
adversary cards in discard: [ 3. 25.  0. 29.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3] -> size -> 21 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3. 25.] 
cards in discard: [ 6.  3. 11.  0.  0.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25. 29.  3.  0.] 
adversary cards in discard: [ 3. 25.  0. 29.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3] -> size -> 21 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  3. 25.] 
cards in discard: [ 6.  3. 11.  0.  0.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25. 29.  3.  0.] 
adversary cards in discard: [ 3. 25.  0. 29.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3] -> size -> 21 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 0. 25. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[28.201883]
 [50.372505]
 [46.67676 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  3.  0.] 
cards in discard: [ 3. 25.  0. 29.  3. 11.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  6. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6] -> size -> 14 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.595712661743164



action possibilites: [-1] 
expected returns: [[30.5231]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0. 29. 11.] 
cards in discard: [ 3. 25.  0. 29.  3. 11.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  6. 25.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6] -> size -> 15 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 45.622013092041016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.040728]
 [37.988384]
 [24.100727]
 [37.153473]
 [30.83222 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  0. 29. 11.] 
cards in discard: [ 3. 25.  0. 29.  3. 11.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  6. 25.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6] -> size -> 15 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.523099899291992



buy possibilites: [-1] 
expected returns: [[30.484587]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  0. 29. 11.] 
cards in discard: [ 3. 25.  0. 29.  3. 11.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  6. 25.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6] -> size -> 15 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 37.988372802734375






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  6. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  6. 25.  1.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0. 10.  0.  0.] 
adversary cards in discard: [ 3. 25.  0. 29.  3. 11.  0.  3.  3. 25.  0. 29.  3.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3] -> size -> 22 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  6. 25.  1.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  6.  9.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0. 10.  0.  0.] 
adversary cards in discard: [ 3. 25.  0. 29.  3. 11.  0.  3.  3. 25.  0. 29.  3.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3] -> size -> 22 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  6. 25.  1.] 
cards in discard: [6. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  6.  8.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0. 10.  0.  0.] 
adversary cards in discard: [ 3. 25.  0. 29.  3. 11.  0.  3.  3. 25.  0. 29.  3.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3] -> size -> 22 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [11.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[19.139341]
 [28.450365]
 [20.12669 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  0.  0.] 
cards in discard: [ 3. 25.  0. 29.  3. 11.  0.  3.  3. 25.  0. 29.  3.  0. 29. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  6.  8.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [ 6.  8.  3. 15.  6. 25.  1.] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6  8] -> size -> 16 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.484586715698242



action possibilites: [-1] 
expected returns: [[-6.224327]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [ 3. 25.  0. 29.  3. 11.  0.  3.  3. 25.  0. 29.  3.  0. 29. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  6.  8.  7.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [ 6.  8.  3. 15.  6. 25.  1.] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6  8] -> size -> 16 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 29.4990291595459





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -7.4545727 ]
 [  4.397491  ]
 [  1.3865314 ]
 [-15.490528  ]
 [  7.8372636 ]
 [ -0.08717275]
 [ -3.1500509 ]
 [ -3.663014  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [ 3. 25.  0. 29.  3. 11.  0.  3.  3. 25.  0. 29.  3.  0. 29. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  6.  8.  7.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [ 6.  8.  3. 15.  6. 25.  1.] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6  8] -> size -> 16 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -6.224327087402344



buy possibilites: [-1] 
expected returns: [[9.056604]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [ 3. 25.  0. 29.  3. 11.  0.  3.  3. 25.  0. 29.  3.  0. 29. 11. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  8.  7.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [ 6.  8.  3. 15.  6. 25.  1.] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6  8] -> size -> 16 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 7.83725118637085






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [ 6.  8.  3. 15.  6. 25.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  8.  7.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  0.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11] -> size -> 24 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [ 6.  8.  3. 15.  6. 25.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  8.  7.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  0.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11] -> size -> 24 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [ 6.  8.  3. 15.  6. 25.  1.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6  8  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  0.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11] -> size -> 24 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [29.  0.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[11.76877 ]
 [31.138182]
 [13.61968 ]
 [13.61968 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  6.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6  8  8] -> size -> 17 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.056604385375977



action possibilites: [-1. 10. 10.] 
expected returns: [[27.153288]
 [30.368067]
 [30.368067]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 10.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  6.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6  8  8] -> size -> 17 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 26.770496368408203



action possibilites: [-1. 10. 29.] 
expected returns: [[44.567127]
 [48.944424]
 [77.66813 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11] -> size -> 24 
action values: 2 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  6.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6  8  8] -> size -> 17 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 30.368066787719727



action possibilites: [-1. 10.] 
expected returns: [[59.170868]
 [64.15805 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11] -> size -> 24 
action values: 2 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  6.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6  8  8] -> size -> 17 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 77.66810607910156



action possibilites: [-1.] 
expected returns: [[76.128586]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 10. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11] -> size -> 24 
action values: 3 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  6.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6  8  8] -> size -> 17 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 64.1580581665039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 88.10867 ]
 [112.45563 ]
 [104.350845]
 [ 71.72635 ]
 [101.507484]
 [118.731895]
 [102.48973 ]
 [131.36362 ]
 [ 85.513054]
 [ 94.38494 ]
 [109.86002 ]
 [ 86.91608 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 10. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  6.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6  8  8] -> size -> 17 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 76.12858581542969



buy possibilites: [-1] 
expected returns: [[106.975525]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 10. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  6.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6  8  8] -> size -> 17 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0 128   0] 
sum of rewards: 323 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 131.36361694335938






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 8.  6.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 11  8  1  0 25  6  3  6  6  8  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 10. 29.  0.] 
adversary cards in discard: [29. 29. 10. 29. 10.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29] -> size -> 25 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 15  8  1  0 25  6  3  6  6  8  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 10. 29.  0.] 
adversary cards in discard: [29. 29. 10. 29. 10.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29] -> size -> 25 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 15  8  1  0 25  6  3  6  6  8  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 10. 29.  0.] 
adversary cards in discard: [29. 29. 10. 29. 10.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29] -> size -> 25 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [ 3.  0. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[72.03313 ]
 [74.31879 ]
 [95.350945]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 29.  0.] 
cards in discard: [29. 29. 10. 29. 10.  0.  3.  3.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 6.] 
adversary cards in discard: [8. 6. 3.] 
adversary owned cards: [ 0  3  3  3 15  8  1  0 25  6  3  6  6  8  8] -> size -> 15 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 106.97552490234375



action possibilites: [-1. 10.] 
expected returns: [[42.756287]
 [45.698162]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [29. 29. 10. 29. 10.  0.  3.  3.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 6.] 
adversary cards in discard: [8. 6. 3.] 
adversary owned cards: [ 0  3  3  3 15  8  1  0 25  6  3  6  6  8  8] -> size -> 15 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 89.50994873046875



action possibilites: [-1. 11.] 
expected returns: [[29.138212]
 [38.49391 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [29. 29. 10. 29. 10.  0.  3.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29] -> size -> 25 
action values: 2 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 6.] 
adversary cards in discard: [8. 6. 3.] 
adversary owned cards: [ 0  3  3  3 15  8  1  0 25  6  3  6  6  8  8] -> size -> 15 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 45.698177337646484



action possibilites: [-1.] 
expected returns: [[75.97554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29. 29. 10. 29. 10.  0.  3.  3.  0.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 6.] 
adversary cards in discard: [8. 6. 3.] 
adversary owned cards: [ 0  3  3  3 15  8  1  0 25  6  3  6  6  8  8] -> size -> 15 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 202 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 41.478973388671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[61.959167]
 [66.39567 ]
 [66.51973 ]
 [62.544395]
 [61.573837]
 [70.79109 ]
 [64.45417 ]
 [71.25916 ]
 [63.88331 ]
 [64.97193 ]
 [67.6336  ]
 [73.08637 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29. 29. 10. 29. 10.  0.  3.  3.  0.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 6.] 
adversary cards in discard: [8. 6. 3.] 
adversary owned cards: [ 0  3  3  3 15  8  1  0 25  6  3  6  6  8  8] -> size -> 15 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 75.97554016113281






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 6.] 
cards in discard: [8. 6. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15  8  1  0 25  6  3  6  6  8  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11. 25.  0. 11. 25.] 
adversary cards in discard: [29. 29. 10. 29. 10.  0.  3.  3.  0.  3. 10. 29. 10. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10] -> size -> 26 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [8. 6. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11. 25.  0. 11. 25.] 
adversary cards in discard: [29. 29. 10. 29. 10.  0.  3.  3.  0.  3. 10. 29. 10. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10] -> size -> 26 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8. 6. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11. 25.  0. 11. 25.] 
adversary cards in discard: [29. 29. 10. 29. 10.  0.  3.  3.  0.  3. 10. 29. 10. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10] -> size -> 26 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [11. 25.  0. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 11. 25.] 
expected returns: [[86.116035]
 [93.38405 ]
 [97.25432 ]
 [93.38405 ]
 [97.25432 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  0. 11. 25.] 
cards in discard: [29. 29. 10. 29. 10.  0.  3.  3.  0.  3. 10. 29. 10. 11.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  5.  7.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  1. 15.  8.  3.] 
adversary cards in discard: [8. 6. 3. 8. 0.] 
adversary owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8] -> size -> 12 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 73.08641052246094



action possibilites: [-1] 
expected returns: [[18.487894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 25. 11.  3.] 
cards in discard: [29. 29. 10. 29. 10.  0.  3.  3.  0.  3. 10. 29. 10. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  5.  7.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  1. 15.  8.  3.] 
adversary cards in discard: [8. 6. 3. 8. 0. 6.] 
adversary owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6] -> size -> 13 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 97.43179321289062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.153687  ]
 [-0.42763758]
 [14.267998  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11. 25. 11.  3.] 
cards in discard: [29. 29. 10. 29. 10.  0.  3.  3.  0.  3. 10. 29. 10. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  5.  7.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  1. 15.  8.  3.] 
adversary cards in discard: [8. 6. 3. 8. 0. 6.] 
adversary owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6] -> size -> 13 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.48789405822754






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 6.  1. 15.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 15.  8.  3.] 
cards in discard: [8. 6. 3. 8. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  5.  7.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10] -> size -> 26 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1. 15.  8.  3.] 
cards in discard: [8. 6. 3. 8. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  5.  7.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10] -> size -> 26 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1. 15.  8.  3.] 
cards in discard: [8. 6. 3. 8. 0. 6. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  5.  6.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10] -> size -> 26 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [11.  0. 25. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 29.] 
expected returns: [[ 5.8970866]
 [17.690855 ]
 [34.467484 ]
 [26.763826 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 25. 29.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  5.  6.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  6.  6.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8] -> size -> 14 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 14.268009185791016



action possibilites: [-1] 
expected returns: [[51.098732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  5. 10.  5.  6.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  6.  6.  3. 25.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8  6] -> size -> 15 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 31.90496253967285





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[63.343155]
 [76.04407 ]
 [51.479412]
 [74.452324]
 [63.55443 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  5. 10.  5.  6.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  6.  6.  3. 25.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8  6] -> size -> 15 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.098731994628906



buy possibilites: [-1] 
expected returns: [[107.27951]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29.  0.  3.  3.] 
cards in discard: [3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  5. 10.  5.  6.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  6.  6.  3. 25.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8  6] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 211 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 76.04408264160156






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 3.  6.  6.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6.  3. 25.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  5. 10.  5.  6.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 29. 11.] 
adversary cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3] -> size -> 27 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 3. 3. 8.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  4. 10.  5.  6.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 29. 11.] 
adversary cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6] -> size -> 28 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 3. 3. 8.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  4. 10.  5.  6.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 29. 11.] 
adversary cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6] -> size -> 28 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [ 0. 11. 29. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29. 11.] 
expected returns: [[15.817551]
 [20.683775]
 [22.170877]
 [22.170877]
 [20.683775]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 29. 11.] 
cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  4. 10.  5.  6.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  6.  8.  8. 15.] 
adversary cards in discard: [ 6. 25.  3.  6.  6.  3.  3.  8.] 
adversary owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8  6] -> size -> 15 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[  -5    0    0  180    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 107.27951049804688



action possibilites: [-1. 11. 29. 11. 25.] 
expected returns: [[-7.2290955]
 [ 2.9741845]
 [ 6.270579 ]
 [ 2.9741845]
 [ 9.356335 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 11. 25.] 
cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 26. 30.  8.  4. 10.  5.  6.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  6.  8.  8. 15.] 
adversary cards in discard: [ 6. 25.  3.  6.  6.  3.  3.  8.] 
adversary owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8  6] -> size -> 15 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 22.234569549560547



action possibilites: [-1] 
expected returns: [[76.950775]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 11. 10. 10.] 
cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 26. 30.  8.  3. 10.  5.  6.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  6.  8.  8. 15.] 
adversary cards in discard: [ 6. 25.  3.  6.  6.  3.  3.  8.  6.] 
adversary owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8  6  6] -> size -> 16 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 9.356338500976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[58.06976 ]
 [74.17979 ]
 [45.980053]
 [70.735214]
 [69.469   ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29. 11. 10. 10.] 
cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 26. 30.  8.  3. 10.  5.  6.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  6.  8.  8. 15.] 
adversary cards in discard: [ 6. 25.  3.  6.  6.  3.  3.  8.  6.] 
adversary owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8  6  6] -> size -> 16 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.95077514648438



buy possibilites: [-1] 
expected returns: [[55.79158]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29. 11. 10. 10.] 
cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  3. 10.  5.  6.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  6.  8.  8. 15.] 
adversary cards in discard: [ 6. 25.  3.  6.  6.  3.  3.  8.  6.] 
adversary owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8  6  6] -> size -> 16 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 261 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 74.17977142333984






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 1.  6.  8.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  8.  8. 15.] 
cards in discard: [ 6. 25.  3.  6.  6.  3.  3.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8  6  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  3. 10.  5.  6.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  3.  0. 11.  0.] 
adversary cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.  3. 29. 25.  0. 11. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3] -> size -> 29 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  8.  8. 15.] 
cards in discard: [ 6. 25.  3.  6.  6.  3.  3.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8  6  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 25. 30.  8.  3. 10.  5.  6.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  3.  0. 11.  0.] 
adversary cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.  3. 29. 25.  0. 11. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3] -> size -> 29 
adversary victory points: 6
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[50.004528]
 [50.424576]
 [63.762512]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 11.  0.] 
cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.  3. 29. 25.  0. 11. 29. 11. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  3. 10.  5.  6.  7.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  3. 15.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8  6  6] -> size -> 16 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.79158020019531



action possibilites: [-1] 
expected returns: [[60.490906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.  3. 29. 25.  0. 11. 29. 11. 10. 10.
 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  3. 10.  5.  6.  7.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  3. 15.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8  6  6] -> size -> 16 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 67.264892578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[58.109535]
 [58.65313 ]
 [58.674877]
 [58.46124 ]
 [59.339108]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.  3. 29. 25.  0. 11. 29. 11. 10. 10.
 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 25. 30.  8.  3. 10.  5.  6.  7.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  3. 15.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8  6  6] -> size -> 16 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 60.49090576171875






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 15.  8.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  1  0 25  3  6  6  8  8  6  8  6  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  3. 10.  5.  6.  7.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3.  0.] 
adversary cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.  3. 29. 25.  0. 11. 29. 11. 10. 10.
 10. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10] -> size -> 30 
adversary victory points: 6
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  1 25  3  6  6  8  8  6  8  6  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  3. 10.  5.  6.  7.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3.  0.] 
adversary cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.  3. 29. 25.  0. 11. 29. 11. 10. 10.
 10. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10] -> size -> 30 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  1 25  3  6  6  8  8  6  8  6  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  3. 10.  5.  6.  7.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3.  0.] 
adversary cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.  3. 29. 25.  0. 11. 29. 11. 10. 10.
 10. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10] -> size -> 30 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  1 25  3  6  6  8  8  6  8  6  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  3. 10.  5.  6.  7.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3.  0.] 
adversary cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.  3. 29. 25.  0. 11. 29. 11. 10. 10.
 10. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10] -> size -> 30 
adversary victory points: 6
player victory points: -3 





Player: 0 
cards in hand: [ 0.  3. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 0.70257425]
 [19.939337  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.  0.] 
cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.  3. 29. 25.  0. 11. 29. 11. 10. 10.
 10. 11. 10.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  3. 10.  5.  6.  7.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [6. 3. 6. 6. 1.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 3  8  1 25  3  6  6  8  8  6  8  6  6  0] -> size -> 14 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 59.33911895751953



action possibilites: [-1. 10.] 
expected returns: [[67.60747 ]
 [66.952774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.  3. 29. 25.  0. 11. 29. 11. 10. 10.
 10. 11. 10.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  3. 10.  5.  6.  7.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [6. 3. 6. 6. 1.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 3  8  1 25  3  6  6  8  8  6  8  6  6  0] -> size -> 14 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 19.939332962036133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[60.210274]
 [75.9656  ]
 [71.798294]
 [49.19317 ]
 [81.323494]
 [69.73548 ]
 [65.56817 ]
 [66.301155]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.  3. 29. 25.  0. 11. 29. 11. 10. 10.
 10. 11. 10.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 25. 30.  8.  3. 10.  5.  6.  7.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [6. 3. 6. 6. 1.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 3  8  1 25  3  6  6  8  8  6  8  6  6  0] -> size -> 14 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 67.60743713378906



buy possibilites: [-1] 
expected returns: [[15.995283]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [ 3. 25. 11.  0. 29.  0.  3.  3.  6.  3. 29. 25.  0. 11. 29. 11. 10. 10.
 10. 11. 10.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [6. 3. 6. 6. 1.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 3  8  1 25  3  6  6  8  8  6  8  6  6  0] -> size -> 14 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 339 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 81.32347869873047






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [6. 3. 6. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 6. 1.] 
cards in discard: [0. 8. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  1 25  3  6  6  8  8  6  8  6  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11] -> size -> 31 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 6. 1.] 
cards in discard: [0. 8. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  1 25  3  6  6  8  8  6  8  6  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 25. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11] -> size -> 31 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 6. 1.] 
cards in discard: [0. 8. 8. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 25. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11] -> size -> 31 
adversary victory points: 6
player victory points: -3 





Player: 0 
cards in hand: [ 0. 29. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[31.909517]
 [50.90216 ]
 [34.17434 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  3.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 25.  8.  6.  3.] 
adversary cards in discard: [0. 8. 8. 0. 6. 3. 6. 6. 1.] 
adversary owned cards: [ 3  8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 15 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.995283126831055



action possibilites: [-1. 10.] 
expected returns: [[66.99022]
 [72.19291]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 25.  8.  6.  3.] 
adversary cards in discard: [0. 8. 8. 0. 6. 3. 6. 6. 1.] 
adversary owned cards: [ 3  8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 15 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 42.912559509277344



action possibilites: [-1. 11.] 
expected returns: [[64.15843]
 [92.22835]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11] -> size -> 31 
action values: 2 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 25.  8.  6.  3.] 
adversary cards in discard: [0. 8. 8. 0. 6. 3. 6. 6. 1.] 
adversary owned cards: [ 3  8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 15 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 72.19290161132812



action possibilites: [-1.] 
expected returns: [[51.60253]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 25.  8.  6.  3.] 
adversary cards in discard: [0. 8. 8. 0. 6. 3. 6. 6. 1.] 
adversary owned cards: [ 3  8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 15 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 352 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 100.00199127197266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[56.341755]
 [67.42004 ]
 [46.498257]
 [66.015755]
 [56.35418 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 25. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 25.  8.  6.  3.] 
adversary cards in discard: [0. 8. 8. 0. 6. 3. 6. 6. 1.] 
adversary owned cards: [ 3  8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 15 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 51.60253143310547



buy possibilites: [-1] 
expected returns: [[78.2254]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3.] 
cards in discard: [10.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 25.  8.  6.  3.] 
adversary cards in discard: [0. 8. 8. 0. 6. 3. 6. 6. 1.] 
adversary owned cards: [ 3  8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 15 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: 371 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 67.42001342773438






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 8. 25.  8.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  8.  6.  3.] 
cards in discard: [0. 8. 8. 0. 6. 3. 6. 6. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 10.] 
adversary cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3] -> size -> 33 
adversary victory points: 7
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  6.] 
cards in discard: [0. 8. 8. 0. 6. 3. 6. 6. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 10.] 
adversary cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3] -> size -> 33 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8.  6.] 
cards in discard: [0. 8. 8. 0. 6. 3. 6. 6. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 10.] 
adversary cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3] -> size -> 33 
adversary victory points: 7
player victory points: -4 





Player: 0 
cards in hand: [ 3.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[19.771479]
 [21.863312]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 10.] 
cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 0. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 14 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.22540283203125



action possibilites: [-1.] 
expected returns: [[33.280987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 0. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 14 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 20.764060974121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.824541]
 [27.163954]
 [13.965391]
 [25.597828]
 [28.767569]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 0. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 14 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.28098678588867






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [6. 0. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  0. 29. 11.] 
adversary cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3. 10.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3] -> size -> 33 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  0. 29. 11.] 
adversary cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3. 10.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3] -> size -> 33 
adversary victory points: 7
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  0.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[18.352354]
 [34.664932]
 [34.664932]
 [30.782656]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 29. 11.] 
cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3. 10.  3.  3.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  8.  1.  8. 25.] 
adversary cards in discard: [6. 0. 6. 3. 6.] 
adversary owned cards: [ 8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 14 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 28.767549514770508



action possibilites: [-1. 29. 11.] 
expected returns: [[37.08677 ]
 [51.075687]
 [47.908848]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 11.  3.] 
cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3. 10.  3.  3.  0.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  8.  1.  8. 25.] 
adversary cards in discard: [6. 0. 6. 3. 6.] 
adversary owned cards: [ 8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 14 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 34.664913177490234



action possibilites: [-1. 11.] 
expected returns: [[ 94.54942]
 [130.2096 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3. 10.  3.  3.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  8.  1.  8. 25.] 
adversary cards in discard: [6. 0. 6. 3. 6.] 
adversary owned cards: [ 8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 14 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 51.07569885253906



action possibilites: [-1] 
expected returns: [[129.44089]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3. 10.  3.  3.  0.  0.  6. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  8.  1.  8. 25.] 
adversary cards in discard: [6. 0. 6. 3. 6.] 
adversary owned cards: [ 8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 14 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 412 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 141.67462158203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[114.80281 ]
 [146.22418 ]
 [137.61284 ]
 [103.59042 ]
 [ 97.14319 ]
 [128.62427 ]
 [155.30122 ]
 [133.21959 ]
 [166.44395 ]
 [160.56877 ]
 [114.20867 ]
 [140.26573 ]
 [125.68524 ]
 [109.57187 ]
 [145.04968 ]
 [127.426315]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3. 10.  3.  3.  0.  0.  6. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  7.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  8.  1.  8. 25.] 
adversary cards in discard: [6. 0. 6. 3. 6.] 
adversary owned cards: [ 8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 14 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: take_action - action -1
Learning step: 0
desired expected reward: 129.44088745117188



buy possibilites: [-1] 
expected returns: [[112.14984]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3. 10.  3.  3.  0.  0.  6. 10. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  6.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  8.  1.  8. 25.] 
adversary cards in discard: [6. 0. 6. 3. 6.] 
adversary owned cards: [ 8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 14 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 635 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 166.44400024414062






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 8.  8.  1.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  1.  8. 25.] 
cards in discard: [6. 0. 6. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  6.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [25.  3.  0. 11. 29.] 
adversary cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3. 10.  3.  3.  0.  0.  6. 10. 25. 29.
 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25] -> size -> 35 
adversary victory points: 7
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 25.] 
cards in discard: [6. 0. 6. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  6.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [25.  3.  0. 11. 29.] 
adversary cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3. 10.  3.  3.  0.  0.  6. 10. 25. 29.
 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25] -> size -> 35 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 25.] 
cards in discard: [6. 0. 6. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 25  3  6  6  8  8  6  8  6  6  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  3. 10.  4.  6.  6.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [25.  3.  0. 11. 29.] 
adversary cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3. 10.  3.  3.  0.  0.  6. 10. 25. 29.
 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25] -> size -> 35 
adversary victory points: 7
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 25.] 
cards in discard: [6. 0. 6. 3. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 25  3  6  6  8  8  6  8  6  6  0  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  3. 10.  4.  6.  6.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [25.  3.  0. 11. 29.] 
adversary cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3. 10.  3.  3.  0.  0.  6. 10. 25. 29.
 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25] -> size -> 35 
adversary victory points: 7
player victory points: -4 





Player: 0 
cards in hand: [25.  3.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[105.8085 ]
 [139.33331]
 [125.61075]
 [132.43494]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0. 11. 29.] 
cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3. 10.  3.  3.  0.  0.  6. 10. 25. 29.
 29. 11.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  3. 10.  4.  6.  6.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 25  3  6  6  8  8  6  8  6  6  0  0  0] -> size -> 14 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 112.14984130859375



action possibilites: [-1] 
expected returns: [[43.704754]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 29. 10. 25.] 
cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3. 10.  3.  3.  0.  0.  6. 10. 25. 29.
 29. 11.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  2. 10.  4.  6.  6.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 6. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8 25  3  6  6  8  8  6  8  6  6  0  0  0  6] -> size -> 15 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 139.33331298828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[39.33705 ]
 [32.356396]
 [39.096893]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 29. 10. 25.] 
cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3. 10.  3.  3.  0.  0.  6. 10. 25. 29.
 29. 11.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 24. 30.  8.  2. 10.  4.  6.  6.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 6. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8 25  3  6  6  8  8  6  8  6  6  0  0  0  6] -> size -> 15 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.70475387573242



buy possibilites: [-1] 
expected returns: [[36.366512]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 29. 10. 25.] 
cards in discard: [10.  3. 29. 10. 11.  0.  3.  3.  3. 10.  3.  3.  0.  0.  6. 10. 25. 29.
 29. 11.  0.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  4.  6.  6.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 6. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8 25  3  6  6  8  8  6  8  6  6  0  0  0  6] -> size -> 15 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   0. 330.   0.   0.  20.   0.   0.   0.   0. -10.   0.   0.
   0.   0.] 
sum of rewards: 335.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 39.33707809448242






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [8. 0. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 6. 8.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25  3  6  6  8  8  6  8  6  6  0  0  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  4.  6.  6.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10. 10. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0] -> size -> 36 
adversary victory points: 7
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [25  3  6  8  8  6  8  6  6  0  0  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  4.  6.  6.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10. 10. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0] -> size -> 36 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [25  3  6  8  8  6  8  6  6  0  0  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  4.  6.  6.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10. 10. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0] -> size -> 36 
adversary victory points: 7
player victory points: -4 





Player: 0 
cards in hand: [ 0. 10. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 11.] 
expected returns: [[30.121546]
 [32.098747]
 [32.098747]
 [47.34654 ]
 [47.34654 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 11. 11.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  4.  6.  6.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 25.  3.  0.  8.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [25  3  6  8  8  6  8  6  6  0  0  6] -> size -> 12 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.366512298583984



action possibilites: [-1] 
expected returns: [[27.021658]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 11.] 
cards in discard: [10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  4.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 6. 25.  3.  0.  8.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [25  3  6  8  8  6  8  6  6  0  0  6] -> size -> 12 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0 -20   0   0  27   0] 
sum of rewards: 352 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 44.1031494140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[38.57277 ]
 [28.018953]
 [38.102333]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10. 11.] 
cards in discard: [10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  4.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 6. 25.  3.  0.  8.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [25  3  6  8  8  6  8  6  6  0  0  6] -> size -> 12 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.021657943725586



buy possibilites: [-1] 
expected returns: [[84.67391]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10. 11.] 
cards in discard: [10.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  4.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 6. 25.  3.  0.  8.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [25  3  6  8  8  6  8  6  6  0  0  6] -> size -> 12 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   0. 330.   0.   0.  20.   0.   0.   0.   0. -30.   0.   0.
   0.   0.] 
sum of rewards: 315.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 38.5727653503418






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 6. 25.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25.  3.  0.  8.] 
cards in discard: [6. 8. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [25  3  6  8  8  6  8  6  6  0  0  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  4.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10.  0. 10. 29.  3.] 
adversary cards in discard: [10.  0. 11.  0. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0] -> size -> 38 
adversary victory points: 7
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [6. 8. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [6 8 8 6 8 6 6 0 6] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  4.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10.  0. 10. 29.  3.] 
adversary cards in discard: [10.  0. 11.  0. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0] -> size -> 38 
adversary victory points: 7
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [6. 8. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [6 8 8 6 8 6 6 0 6] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  4.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10.  0. 10. 29.  3.] 
adversary cards in discard: [10.  0. 11.  0. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0] -> size -> 38 
adversary victory points: 7
player victory points: -5 





Player: 0 
cards in hand: [10.  0. 10. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
expected returns: [[18.471035]
 [19.626978]
 [19.626978]
 [35.620277]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 29.  3.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  4.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [6 8 8 6 8 6 6 0 6] -> size -> 9 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 84.67391204833984



action possibilites: [-1. 10. 10.] 
expected returns: [[35.50338]
 [37.02204]
 [37.02204]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3.  3.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  4.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [6 8 8 6 8 6 6 0 6] -> size -> 9 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.257171630859375



action possibilites: [-1. 10. 25.] 
expected returns: [[38.993797]
 [39.971916]
 [55.70949 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3. 25.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0] -> size -> 38 
action values: 2 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  4.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [6 8 8 6 8 6 6 0 6] -> size -> 9 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 37.02202606201172



action possibilites: [-1. 10. 11. 25.] 
expected returns: [[43.841892]
 [41.231567]
 [52.019882]
 [59.067184]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3. 11. 25.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 24. 30.  8.  1. 10.  4.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [6 8 8 6 8 6 6 0 6 6] -> size -> 10 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 55.70949172973633



action possibilites: [-1] 
expected returns: [[7.9078383]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3. 11.  0. 10.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 10. 25. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 24. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 8.] 
adversary cards in discard: [6. 6.] 
adversary owned cards: [6 8 8 6 8 6 6 0 6 6 6] -> size -> 11 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 59.067161560058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 8.025509]
 [19.415876]
 [17.322086]
 [26.028175]
 [15.015606]
 [13.103846]
 [19.008324]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3. 11.  0. 10.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 10. 25. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 24. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 8.] 
adversary cards in discard: [6. 6.] 
adversary owned cards: [6 8 8 6 8 6 6 0 6 6 6] -> size -> 11 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.907838344573975



buy possibilites: [-1] 
expected returns: [[194.49243]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3. 11.  0. 10.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 10. 25. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 8.] 
adversary cards in discard: [6. 6.] 
adversary owned cards: [6 8 8 6 8 6 6 0 6 6 6] -> size -> 11 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0  80   0   0   0   0 -40   0   0  54   0] 
sum of rewards: 449 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 26.02820587158203






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [6. 6. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6. 8.] 
cards in discard: [6. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [6 8 8 6 8 6 6 0 6 6 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  3. 10. 29.  3.] 
adversary cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11] -> size -> 39 
adversary victory points: 7
player victory points: -7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [6. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 8 6 6 6 6 6] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  3. 10. 29.  3.] 
adversary cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11] -> size -> 39 
adversary victory points: 7
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [6. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 8 6 6 6 6 6] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  3. 10. 29.  3.] 
adversary cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11] -> size -> 39 
adversary victory points: 7
player victory points: -6 





Player: 0 
cards in hand: [ 6.  3. 10. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[ 87.38986]
 [ 83.71805]
 [106.49206]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 10. 29.  3.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 8 6 6 6 6 6] -> size -> 9 
adversary victory points: -6
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 194.492431640625



action possibilites: [-1. 10.] 
expected returns: [[151.96375]
 [151.65813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 10.  3.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 24. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 8 6 6 6 6 6] -> size -> 9 
adversary victory points: -6
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 94.69268798828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[144.57654]
 [149.18648]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 10.  3.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11] -> size -> 39 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 24. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 8 6 6 6 6 6] -> size -> 9 
adversary victory points: -6
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 151.96371459960938






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [6. 6. 6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 8. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 8 6 6 6 6 6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11. 29.] 
adversary cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0. 29.  6.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11] -> size -> 39 
adversary victory points: 7
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 6 6 6 6 6] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11. 29.] 
adversary cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0. 29.  6.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11] -> size -> 39 
adversary victory points: 7
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 6 6 6 6 6] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11. 29.] 
adversary cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0. 29.  6.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11] -> size -> 39 
adversary victory points: 7
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 6 6 6 6 6 0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11. 29.] 
adversary cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0. 29.  6.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11] -> size -> 39 
adversary victory points: 7
player victory points: -5 





Player: 0 
cards in hand: [ 0.  0.  3. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[21.009657]
 [31.679094]
 [35.136692]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11. 29.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0. 29.  6.  3. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 6. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 6 6 6 6 6 0] -> size -> 9 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 149.18646240234375



action possibilites: [-1. 11.] 
expected returns: [[-0.6214273]
 [20.623198 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0. 29.  6.  3. 10.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 6. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 6 6 6 6 6 0] -> size -> 9 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 28.550294876098633



action possibilites: [-1] 
expected returns: [[21.952616]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0. 29.  6.  3. 10.  3.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [6. 6. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 6 6 6 6 6 0] -> size -> 9 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0 -50   0   0  64   0] 
sum of rewards: 409 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 27.428287506103516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[17.122843]
 [34.456795]
 [29.753096]
 [40.305557]
 [27.52794 ]
 [22.824244]
 [21.952604]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0. 29.  6.  3. 10.  3.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [6. 6. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 6 6 6 6 6 0] -> size -> 9 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.95261573791504



buy possibilites: [-1] 
expected returns: [[8.424595]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0. 29.  6.  3. 10.  3.  3. 15. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  2.  6.  6.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [6. 6. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 6 6 6 6 6 0] -> size -> 9 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0 -60   0   0  54   0] 
sum of rewards: 389 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 40.30556869506836






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [6. 6. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 6. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 6 6 6 6 6 0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  2.  6.  6.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10.  3. 11.  0. 29.] 
adversary cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0. 29.  6.  3. 10.  3.  3. 15. 11. 29. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11] -> size -> 41 
adversary victory points: 7
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 6. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 6 6 6 6 6 0] -> size -> 9 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  2.  6.  6.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10.  3. 11.  0. 29.] 
adversary cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0. 29.  6.  3. 10.  3.  3. 15. 11. 29. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11] -> size -> 41 
adversary victory points: 7
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  3. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[ 88.63269]
 [ 81.8313 ]
 [106.62069]
 [111.29279]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.  0. 29.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0. 29.  6.  3. 10.  3.  3. 15. 11. 29. 11.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  2.  6.  6.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [8. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 6 6 6 6 6 0] -> size -> 9 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.42459487915039



action possibilites: [-1. 11. 25.] 
expected returns: [[38.14009]
 [60.55796]
 [79.92844]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 25.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0. 29.  6.  3. 10.  3.  3. 15. 11. 29. 11.  0.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  2.  6.  6.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [8. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 6 6 6 6 6 0] -> size -> 9 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 95.88252258300781



action possibilites: [-1] 
expected returns: [[19.472399]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0. 29.  6.  3. 10.  3.  3. 15. 11. 29. 11.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  2.  6.  6.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [8. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 6 6 6 6 6 0] -> size -> 9 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 79.92848205566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 7.9351554]
 [34.363857 ]
 [28.080946 ]
 [43.918636 ]
 [24.097902 ]
 [17.725029 ]
 [19.472363 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0. 29.  6.  3. 10.  3.  3. 15. 11. 29. 11.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  2.  6.  6.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [8. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 6 6 6 6 6 0] -> size -> 9 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.47239875793457



buy possibilites: [-1] 
expected returns: [[110.980644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [10.  0. 11.  0. 10. 10. 11. 11. 29. 10. 25. 25.  0. 10.  3.  3. 11.  0.
 10.  0. 29.  6.  3. 10.  3.  3. 15. 11. 29. 11.  0.  0.  3. 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [8. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 6 6 6 6 6 0] -> size -> 9 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0 -70   0   0  54   0] 
sum of rewards: 379 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 43.918636322021484






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [8. 0. 6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 8. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 6 6 6 6 6 0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10.  3.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11] -> size -> 42 
adversary victory points: 7
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 6 6 6 0] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10.  3.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11] -> size -> 42 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 6 6 6 0] -> size -> 7 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10.  3.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11] -> size -> 42 
adversary victory points: 7
player victory points: -4 





Player: 0 
cards in hand: [10.  3.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[32.382034]
 [34.490196]
 [34.490196]
 [34.490196]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [0. 6. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 6 6 0] -> size -> 7 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.98064422607422



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[35.937496]
 [34.74643 ]
 [34.74643 ]
 [50.809814]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 10. 29.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [0. 6. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 6 6 0] -> size -> 7 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 29.45635414123535



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[47.665092]
 [49.865257]
 [49.865257]
 [63.17769 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 11.] 
cards in discard: [3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11] -> size -> 42 
action values: 2 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [0. 6. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 6 6 0] -> size -> 7 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 40.69647979736328



action possibilites: [-1. 10. 10.] 
expected returns: [[39.25731]
 [36.75545]
 [36.75545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.] 
cards in discard: [ 3. 15.] 
cards in deck: 35 
card top of deck: [] 
played cards: [10. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 6. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 6 6 0] -> size -> 7 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  60   0   0   0   0 -80   0   0  64   0] 
sum of rewards: 369 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 68.78361511230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[32.7392  ]
 [40.039116]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.] 
cards in discard: [ 3. 15.] 
cards in deck: 35 
card top of deck: [] 
played cards: [10. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15] -> size -> 43 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 6. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 6 6 0] -> size -> 7 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 39.25731658935547






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 6. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6. 6.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 6 6 0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 3.  6.  0.  0. 25.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15] -> size -> 43 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 6.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 6 6 0] -> size -> 7 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 3.  6.  0.  0. 25.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15] -> size -> 43 
adversary victory points: 7
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 6.] 
cards in discard: [0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 6 6 0 0] -> size -> 8 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 3.  6.  0.  0. 25.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15] -> size -> 43 
adversary victory points: 7
player victory points: -4 





Player: 0 
cards in hand: [ 3.  6.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[20.063807]
 [39.419106]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0.  0. 25.] 
cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [6. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 6 6 0 0] -> size -> 8 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 40.039119720458984



action possibilites: [-1] 
expected returns: [[79.535675]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0.  0. 29. 11.] 
cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [6. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 6 6 0 0] -> size -> 8 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 39.41911697387695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[75.46952 ]
 [81.94304 ]
 [79.252106]
 [90.393036]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0.  0. 29. 11.] 
cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [6. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 6 6 0 0] -> size -> 8 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.53567504882812






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [6. 0. 6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 8. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 6 6 0 0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [29. 11. 25. 11.  0.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15] -> size -> 43 
adversary victory points: 7
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 6 0 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [29. 11. 25. 11.  0.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15] -> size -> 43 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 6 0 0] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [29. 11. 25. 11.  0.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15] -> size -> 43 
adversary victory points: 7
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 6 0 0 0] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [29. 11. 25. 11.  0.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15] -> size -> 43 
adversary victory points: 7
player victory points: -2 





Player: 0 
cards in hand: [29. 11. 25. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 25. 11.] 
expected returns: [[ 60.387077]
 [ 98.94334 ]
 [ 89.80424 ]
 [109.472786]
 [ 89.80424 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 25. 11.  0.] 
cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 0 0 0] -> size -> 7 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 90.39309692382812



action possibilites: [-1] 
expected returns: [[12.273674]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 11.  0.  0.  0.] 
cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 0 0 0] -> size -> 7 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 109.47278594970703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 2.2160606]
 [29.734419 ]
 [22.1701   ]
 [40.140728 ]
 [17.93174  ]
 [10.833914 ]
 [12.115465 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11. 11.  0.  0.  0.] 
cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 24. 30.  8.  0. 10.  1.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 0 0 0] -> size -> 7 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.273674011230469



buy possibilites: [-1] 
expected returns: [[15.644812]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11. 11.  0.  0.  0.] 
cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0. 10.  0.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 0 0 0] -> size -> 7 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -90   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 40.140743255615234






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 0 0 0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0. 10.  0.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  3. 11. 11.  0.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11] -> size -> 44 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 0 0 0] -> size -> 7 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 24. 30.  8.  0. 10.  0.  6.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  3. 11. 11.  0.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11] -> size -> 44 
adversary victory points: 7
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 0 0 0 8] -> size -> 8 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  3. 11. 11.  0.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11] -> size -> 44 
adversary victory points: 7
player victory points: -2 





Player: 0 
cards in hand: [10.  3. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[60.22882]
 [63.19609]
 [79.72834]
 [79.72834]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11. 11.  0.] 
cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [6. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 0 0 0 8] -> size -> 8 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.644811630249023



action possibilites: [-1] 
expected returns: [[87.44154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.  0.] 
cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [6. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 0 0 0 8] -> size -> 8 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: 212 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 74.57052612304688





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[87.27285]
 [87.44154]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 11.  0.] 
cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [6. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 0 0 0 8] -> size -> 8 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.44154357910156






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 0 0 0 8] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [15. 10.  3. 11.  0.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1. 11. 10.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1] -> size -> 45 
adversary victory points: 7
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 0 0 0 8] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [15. 10.  3. 11.  0.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1. 11. 10.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1] -> size -> 45 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 0 0 0 8] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [15. 10.  3. 11.  0.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1. 11. 10.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1] -> size -> 45 
adversary victory points: 7
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 0 0 0 8 0] -> size -> 8 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [15. 10.  3. 11.  0.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1. 11. 10.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1] -> size -> 45 
adversary victory points: 7
player victory points: -2 





Player: 0 
cards in hand: [15. 10.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11.] 
expected returns: [[73.042564]
 [78.863785]
 [71.60094 ]
 [83.94823 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  3. 11.  0.] 
cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1. 11. 10.  3. 11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 8. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0 0 0 8 0] -> size -> 8 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 87.44154357910156



action possibilites: [-1] 
expected returns: [[101.259995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  3.  0.] 
cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1. 11. 10.  3. 11.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 8. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0 0 0 8 0] -> size -> 8 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -110    0    0
   27    0] 
sum of rewards: 202 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 79.12773895263672





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 95.37463]
 [101.25998]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  3.  0.] 
cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1. 11. 10.  3. 11.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 8. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0 0 0 8 0] -> size -> 8 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.25999450683594






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 0 0 8 0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11.  3. 29. 10. 10.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1. 11. 10.  3. 11.  0.  1. 11. 15. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1] -> size -> 46 
adversary victory points: 7
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 0 8 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11.  3. 29. 10. 10.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1. 11. 10.  3. 11.  0.  1. 11. 15. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1] -> size -> 46 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 0 8 0] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 27. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11.  3. 29. 10. 10.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1. 11. 10.  3. 11.  0.  1. 11. 15. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1] -> size -> 46 
adversary victory points: 7
player victory points: -2 





Player: 0 
cards in hand: [11.  3. 29. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 10.] 
expected returns: [[135.16583]
 [141.18994]
 [142.81137]
 [129.33408]
 [129.33408]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29. 10. 10.] 
cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1. 11. 10.  3. 11.  0.  1. 11. 15. 10.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [6. 8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0 8 0] -> size -> 6 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 101.25999450683594



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[102.33679]
 [ 96.10445]
 [ 96.10445]
 [ 96.10445]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.] 
cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1. 11. 10.  3. 11.  0.  1. 11. 15. 10.  3.  0. 11.
  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [6. 8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0 8 0] -> size -> 6 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 135.3081817626953





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 85.78929]
 [102.33679]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.] 
cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1. 11. 10.  3. 11.  0.  1. 11. 15. 10.  3.  0. 11.
  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1] -> size -> 46 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [6. 8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0 8 0] -> size -> 6 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 102.33674621582031






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [6. 8. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 8 0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 3.  0.  3.  0. 25.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1. 11. 10.  3. 11.  0.  1. 11. 15. 10.  3.  0. 11.
  3. 29. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1] -> size -> 46 
adversary victory points: 7
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 8] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 3.  0.  3.  0. 25.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1. 11. 10.  3. 11.  0.  1. 11. 15. 10.  3.  0. 11.
  3. 29. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1] -> size -> 46 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 8] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 27. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 3.  0.  3.  0. 25.] 
adversary cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1. 11. 10.  3. 11.  0.  1. 11. 15. 10.  3.  0. 11.
  3. 29. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1] -> size -> 46 
adversary victory points: 7
player victory points: -1 





Player: 0 
cards in hand: [ 3.  0.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[114.774376]
 [154.88187 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 25.] 
cards in discard: [ 3. 15. 10. 29. 11.  3. 10. 10. 25.  3.  6.  0.  0. 29. 11. 11. 25. 29.
 11. 11.  0.  0.  0.  1. 11. 10.  3. 11.  0.  1. 11. 15. 10.  3.  0. 11.
  3. 29. 10. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8] -> size -> 3 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 102.33674621582031



action possibilites: [-1] 
expected returns: [[49.533012]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8] -> size -> 3 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 154.8818817138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[63.526398]
 [84.593025]
 [77.65168 ]
 [76.096115]
 [68.91768 ]
 [62.036545]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8] -> size -> 3 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.53301239013672



buy possibilites: [-1] 
expected returns: [[98.47703]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 8] -> size -> 3 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -120    0    0
   54    0] 
sum of rewards: 189 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 84.593017578125






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 8] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [25. 29.  1.  3. 11.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1] -> size -> 47 
adversary victory points: 7
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [25. 29.  1.  3. 11.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1] -> size -> 47 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [25. 29.  1.  3. 11.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1] -> size -> 47 
adversary victory points: 7
player victory points: -1 





Player: 0 
cards in hand: [25. 29.  1.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 11.] 
expected returns: [[49.29055 ]
 [73.919365]
 [69.63747 ]
 [63.965874]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  1.  3. 11.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 98.4770278930664



action possibilites: [-1] 
expected returns: [[47.691376]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3. 11. 29. 11.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 71.7253189086914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[46.11458]
 [52.59153]
 [50.94169]
 [52.78621]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  3. 11. 29. 11.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.691375732421875






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  0. 10.  3. 15.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1] -> size -> 47 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  0. 10.  3. 15.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1] -> size -> 47 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  0. 10.  3. 15.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1] -> size -> 47 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [10.  0. 10.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 15.] 
expected returns: [[123.106995]
 [119.85483 ]
 [119.85483 ]
 [129.72076 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3. 15.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11
 29 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 52.78623962402344



action possibilites: [-1] 
expected returns: [[135.46132]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 26. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 129.7207489013672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[130.69817]
 [134.9423 ]
 [134.87198]
 [133.68657]
 [133.61621]
 [137.08763]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 135.46131896972656






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 11. 10. 10. 11.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1] -> size -> 46 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 11. 10. 10. 11.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1] -> size -> 46 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 11. 10. 10. 11.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1] -> size -> 46 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [10. 11. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 10. 11.] 
expected returns: [[ 89.18606]
 [ 87.3071 ]
 [103.29287]
 [ 87.3071 ]
 [ 87.3071 ]
 [103.29287]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 10. 11.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 137.08763122558594



action possibilites: [-1] 
expected returns: [[139.1509]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 11.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: 132 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 97.33320617675781





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[129.29565]
 [139.15091]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10. 11.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 25. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 139.15089416503906






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [29. 25.  1.  3. 11.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1] -> size -> 47 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [29. 25.  1.  3. 11.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1] -> size -> 47 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 25. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [29. 25.  1.  3. 11.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1] -> size -> 47 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [29. 25.  1.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11.] 
expected returns: [[14.213228]
 [45.1677  ]
 [53.679443]
 [38.454437]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  1.  3. 11.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 139.15089416503906



action possibilites: [-1] 
expected returns: [[74.24116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3. 11. 10.  6.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 53.679443359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[66.56974 ]
 [73.680145]
 [71.81297 ]
 [74.241135]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  3. 11. 10.  6.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 25. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.24115753173828






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 11. 11. 29. 11.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1] -> size -> 47 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 11. 11. 29. 11.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1] -> size -> 47 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 25. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 11. 11. 29. 11.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1] -> size -> 47 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 25. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 11. 11. 29. 11.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1] -> size -> 47 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [10. 11. 11. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 29. 11.] 
expected returns: [[166.66617]
 [159.04355]
 [168.43057]
 [168.43057]
 [167.0955 ]
 [168.43057]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 29. 11.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 74.24115753173828



action possibilites: [-1] 
expected returns: [[161.03946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29. 11.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -130    0    0
   27    0] 
sum of rewards: 122 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 163.09756469726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[145.96037]
 [161.03946]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 29. 11.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 24. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 161.03945922851562






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 15. 10. 11.  0.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.  1. 11. 10. 11.
 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1] -> size -> 48 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 24. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 15. 10. 11.  0.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.  1. 11. 10. 11.
 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1] -> size -> 48 
adversary victory points: 7
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 15. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11.] 
expected returns: [[219.97925]
 [231.6917 ]
 [217.34673]
 [240.16205]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10. 11.  0.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.  1. 11. 10. 11.
 29. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 161.03945922851562



action possibilites: [-1] 
expected returns: [[214.15305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10.  0.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.  1. 11. 10. 11.
 29. 11.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -140    0    0
   27    0] 
sum of rewards: 112 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 231.18209838867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[203.79709]
 [227.04694]
 [222.90173]
 [214.15302]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10.  0.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.  1. 11. 10. 11.
 29. 11.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 30. 24. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 214.15304565429688



buy possibilites: [-1] 
expected returns: [[119.01429]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10.  0.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.  1. 11. 10. 11.
 29. 11.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -150    0    0
   16    0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 227.0469512939453






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.  1. 11. 10. 11.
 29. 11.  1.  3. 11.  0. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3] -> size -> 50 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.  1. 11. 10. 11.
 29. 11.  1.  3. 11.  0. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3] -> size -> 50 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 23. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.  1. 11. 10. 11.
 29. 11.  1.  3. 11.  0. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3] -> size -> 50 
adversary victory points: 8
player victory points: 0 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.854994]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.  1. 11. 10. 11.
 29. 11.  1.  3. 11.  0. 15. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 119.01428985595703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[16.601873]
 [21.075535]
 [20.224201]
 [19.373983]
 [18.52265 ]
 [19.85498 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.  1. 11. 10. 11.
 29. 11.  1.  3. 11.  0. 15. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 23. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.85499382019043



buy possibilites: [-1] 
expected returns: [[-1.5653954]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 1. 25.  3.  0.  3.  0.  3.  0. 25. 29.  1.  3. 11. 29. 11. 15. 10. 10.
  3.  1. 11. 10. 10. 10. 11. 25. 29.  1.  3. 11. 10.  6.  1. 11. 10. 11.
 29. 11.  1.  3. 11.  0. 15. 10.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  240    0    0    0    0    0    0    0 -160    0    0
   54    0] 
sum of rewards: 129 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 21.0755558013916






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [29.  1.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1] -> size -> 51 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [29.  1.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1] -> size -> 51 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 22. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [29.  1.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1] -> size -> 51 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [29.  1.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1] -> size -> 51 
adversary victory points: 8
player victory points: 0 





Player: 0 
cards in hand: [29.  1.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[45.67122]
 [62.43463]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.5653953552246094



action possibilites: [-1.] 
expected returns: [[74.680176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3.] 
cards in discard: [ 0. 29.] 
cards in deck: 45 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 22. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 52.52467727661133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[65.21208 ]
 [75.134315]
 [74.26026 ]
 [68.14964 ]
 [71.62362 ]
 [75.99718 ]
 [66.232475]
 [70.747856]
 [76.248535]
 [77.29109 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3.] 
cards in discard: [ 0. 29.] 
cards in deck: 45 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 22. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 74.68017578125






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 11.  3.  0. 10.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1] -> size -> 51 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 11.  3.  0. 10.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1] -> size -> 51 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 22. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 11.  3.  0. 10.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1] -> size -> 51 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 11.  3.  0. 10.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1] -> size -> 51 
adversary victory points: 8
player victory points: 0 





Player: 0 
cards in hand: [10. 11.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[106.16136 ]
 [108.586075]
 [122.42203 ]
 [108.586075]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  0. 10.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 77.29109191894531



action possibilites: [-1] 
expected returns: [[98.36208]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 10.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -170    0    0
   27    0] 
sum of rewards: 112 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 118.40995788574219





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[95.22729 ]
 [97.102325]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 10.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 21. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 98.3620834350586






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11.  0.  0.  3. 11.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1] -> size -> 52 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11.  0.  0.  3. 11.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1] -> size -> 52 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 21. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11.  0.  0.  3. 11.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1] -> size -> 52 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11.  0.  0.  3. 11.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1] -> size -> 52 
adversary victory points: 8
player victory points: 0 





Player: 0 
cards in hand: [11.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[39.651905]
 [48.518097]
 [48.518097]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3. 11.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 97.10233306884766



action possibilites: [-1] 
expected returns: [[25.00284]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 20. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -180    0    0
   27    0] 
sum of rewards: 102 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 45.711673736572266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[21.05121 ]
 [32.025948]
 [30.328768]
 [23.133684]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 20. 30. 23. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.002840042114258



buy possibilites: [-1] 
expected returns: [[149.17914]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 20. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -190    0    0
   16    0] 
sum of rewards: 111 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 32.025970458984375






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 1.  3.  6. 11.  3.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3] -> size -> 54 
adversary victory points: 9
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 20. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 1.  3.  6. 11.  3.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3] -> size -> 54 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 20. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 1.  3.  6. 11.  3.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3] -> size -> 54 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 1.  3.  6. 11.  3.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3] -> size -> 54 
adversary victory points: 9
player victory points: 0 





Player: 0 
cards in hand: [ 1.  3.  6. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[111.47907]
 [116.94975]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  6. 11.  3.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 149.17913818359375



action possibilites: [-1] 
expected returns: [[147.17046]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 6. 3.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -200    0    0
   27    0] 
sum of rewards: 112 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 110.70536804199219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[131.00703]
 [138.6169 ]
 [135.90453]
 [147.1705 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 3.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1] -> size -> 55 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 19. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 147.1704559326172






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [25. 11. 29. 10.  0.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1] -> size -> 55 
adversary victory points: 9
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [25. 11. 29. 10.  0.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1] -> size -> 55 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 19. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [25. 11. 29. 10.  0.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1] -> size -> 55 
adversary victory points: 9
player victory points: 0 





Player: 0 
cards in hand: [25. 11. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29. 10.] 
expected returns: [[ 64.57404 ]
 [103.29946 ]
 [ 82.653435]
 [ 89.92891 ]
 [ 58.318043]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 29. 10.  0.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 147.1704559326172



action possibilites: [-1] 
expected returns: [[21.517065]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10.  0. 10.  3.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 103.29947662353516





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[17.92337 ]
 [21.517057]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 10.  0. 10.  3.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1] -> size -> 55 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 19. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.517065048217773






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  1. 11.  3.  0.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1] -> size -> 55 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 19. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  1. 11.  3.  0.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1] -> size -> 55 
adversary victory points: 9
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  1. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[113.624115]
 [105.45549 ]
 [119.736115]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 11.  3.  0.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 21.517065048217773



action possibilites: [-1] 
expected returns: [[125.587875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  0.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 18. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -210    0    0
   27    0] 
sum of rewards: 102 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 112.35258483886719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[111.50387]
 [121.74521]
 [121.12541]
 [118.12009]
 [117.50029]
 [125.58786]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  0.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1] -> size -> 56 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 18. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 125.58787536621094






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 18. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 1.  1. 15. 15. 11.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1] -> size -> 56 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 18. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 1.  1. 15. 15. 11.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1] -> size -> 56 
adversary victory points: 9
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1.  1. 15. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 11.] 
expected returns: [[254.65921]
 [257.51813]
 [257.51813]
 [263.56238]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 15. 15. 11.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 18. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 125.58787536621094



action possibilites: [-1] 
expected returns: [[245.14157]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 15. 15.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 17. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -220    0    0
   27    0] 
sum of rewards: 92 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 256.8559875488281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[233.47766]
 [256.51413]
 [251.29486]
 [243.4796 ]
 [247.58801]
 [271.4886 ]
 [233.2433 ]
 [242.36526]
 [256.2769 ]
 [245.14159]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 15. 15.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1] -> size -> 57 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 17. 30. 22. 30.  8.  0. 10.  0.  5.  6.  6. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 245.14157104492188



buy possibilites: [-1] 
expected returns: [[88.246506]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 15. 15.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.  1. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 17. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -230    0    0
  128    0] 
sum of rewards: 183 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 271.4885559082031






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 17. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [25.  1. 29.  1.  0.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.  1. 29. 11.  1.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29] -> size -> 58 
adversary victory points: 9
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 17. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [25.  1. 29.  1.  0.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.  1. 29. 11.  1.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29] -> size -> 58 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 17. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [25.  1. 29.  1.  0.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.  1. 29. 11.  1.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29] -> size -> 58 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 17. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [25.  1. 29.  1.  0.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.  1. 29. 11.  1.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29] -> size -> 58 
adversary victory points: 9
player victory points: 0 





Player: 0 
cards in hand: [25.  1. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[122.05065]
 [114.99978]
 [112.07515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 29.  1.  0.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.  1. 29. 11.  1.  1. 15. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 17. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 88.24650573730469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[101.31383 ]
 [112.003334]
 [113.47195 ]
 [ 94.29882 ]
 [105.40379 ]
 [110.56244 ]
 [114.99979 ]
 [112.07515 ]
 [103.19355 ]
 [109.97535 ]
 [111.78399 ]
 [ 97.21702 ]
 [114.25237 ]
 [122.05066 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1. 29.  1.  0.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.  1. 29. 11.  1.  1. 15. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29] -> size -> 58 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 17. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 122.05068969726562



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 17. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 11. 11. 10.  3.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.  1. 29. 11.  1.  1. 15. 15. 25.  1. 29.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29] -> size -> 58 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 17. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 11. 11. 10.  3.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.  1. 29. 11.  1.  1. 15. 15. 25.  1. 29.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29] -> size -> 58 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 17. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 11. 11. 10.  3.] 
adversary cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.  1. 29. 11.  1.  1. 15. 15. 25.  1. 29.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29] -> size -> 58 
adversary victory points: 9
player victory points: 0 





Player: 0 
cards in hand: [10. 11. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 10.] 
expected returns: [[ 9.708101]
 [ 4.041072]
 [29.193571]
 [29.193571]
 [ 4.041072]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 10.  3.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.  1. 29. 11.  1.  1. 15. 15. 25.  1. 29.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 17. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 122.05068969726562



action possibilites: [-1] 
expected returns: [[45.35817]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  3.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.  1. 29. 11.  1.  1. 15. 15. 25.  1. 29.  1.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 16. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -240    0    0
   27    0] 
sum of rewards: 72 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 16.335853576660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[30.392118]
 [45.358147]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.  3.] 
cards in discard: [ 0. 29. 29.  1.  0.  3.  1. 11. 10.  3.  0. 10.  1.  3. 11.  0.  0.  3.
 11.  1. 11.  1.  3.  6.  3. 25. 11. 29. 10.  0. 10.  3.  1. 11. 10.  1.
  3.  0.  1. 29. 11.  1.  1. 15. 15. 25.  1. 29.  1.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1] -> size -> 59 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 16. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.35816955566406






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 16. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [29. 11.  3. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1] -> size -> 59 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 16. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [29. 11.  3. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1] -> size -> 59 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 16. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [29. 11.  3. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1] -> size -> 59 
adversary victory points: 9
player victory points: 0 





Player: 0 
cards in hand: [29. 11.  3. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 25.] 
expected returns: [[ 7.8232274]
 [21.495647 ]
 [18.174767 ]
 [ 6.3414006]
 [24.855633 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3. 10. 25.] 
cards in discard: [] 
cards in deck: 54 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 45.35816955566406



action possibilites: [-1] 
expected returns: [[196.30887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3. 10. 11.  1.] 
cards in discard: [] 
cards in deck: 52 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 24.855642318725586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[180.05612]
 [201.6529 ]
 [196.7146 ]
 [197.314  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  3. 10. 11.  1.] 
cards in discard: [] 
cards in deck: 52 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1] -> size -> 59 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 16. 30. 22. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 196.30886840820312



buy possibilites: [-1] 
expected returns: [[159.60764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  3. 10. 11.  1.] 
cards in discard: [3.] 
cards in deck: 52 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 21. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -250    0    0
   16    0] 
sum of rewards: 81 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 201.65286254882812






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 21. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  3. 29.  0. 10.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 16. 30. 21. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10.  3. 29.  0. 10.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 21. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [10.  3. 29.  0. 10.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
adversary victory points: 10
player victory points: 0 





Player: 0 
cards in hand: [10.  3. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[ 5.5360436]
 [ 5.092462 ]
 [22.896757 ]
 [ 5.092462 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29.  0. 10.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 21. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0 10] -> size -> 5 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 159.60763549804688



action possibilites: [-1. 10. 10.] 
expected returns: [[-4.730024]
 [-8.472416]
 [-8.472416]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3.] 
cards in deck: 46 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 16. 30. 21. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0 10] -> size -> 5 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 11.346517562866211





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-14.355806]
 [ -4.730024]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3.] 
cards in deck: 46 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
action values: 1 
buys: 1 
player value: 1 
card supply: [10. 16. 30. 21. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0 10] -> size -> 5 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -4.730045318603516






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 10] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 21. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 3. 15.  3. 25.  3.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0 10] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 21. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 3. 15.  3. 25.  3.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0 10] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 16. 30. 21. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 3. 15.  3. 25.  3.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0 10  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 20. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 3. 15.  3. 25.  3.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
adversary victory points: 10
player victory points: 1 





Player: 0 
cards in hand: [ 3. 15.  3. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[78.78033]
 [79.64948]
 [94.31724]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3. 25.  3.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 20. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0 10  3] -> size -> 5 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -4.730045318603516



action possibilites: [-1] 
expected returns: [[83.013176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  3. 29.  0.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 20. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0 10  3] -> size -> 5 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 94.3172607421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[74.10649]
 [83.01318]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  3. 29.  0.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 16. 30. 20. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0 10  3] -> size -> 5 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.01317596435547






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0 10  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 20. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1.  0. 11.  3.  0.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
adversary victory points: 10
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  0  0 10  3] -> size -> 5 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 20. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1.  0. 11.  3.  0.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
adversary victory points: 10
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  0 10] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 20. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1.  0. 11.  3.  0.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
adversary victory points: 10
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  0 10] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 16. 30. 20. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1.  0. 11.  3.  0.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
adversary victory points: 10
player victory points: 0 





Player: 0 
cards in hand: [ 1.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[129.76443]
 [154.00058]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  3.  0.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 20. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 10] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 83.01317596435547



action possibilites: [-1] 
expected returns: [[96.22915]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 15. 30. 20. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 10] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -260    0    0
   27    0] 
sum of rewards: 82 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 147.77317810058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 83.08762 ]
 [ 98.06047 ]
 [ 95.73888 ]
 [ 88.430084]
 [ 92.479   ]
 [107.90821 ]
 [ 84.18883 ]
 [ 90.143845]
 [ 98.884636]
 [ 96.22916 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1] -> size -> 61 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 15. 30. 20. 30.  8.  0. 10.  0.  5.  6.  5. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 10] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 96.2291488647461



buy possibilites: [-1] 
expected returns: [[136.73965]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29] -> size -> 62 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 15. 30. 20. 30.  8.  0. 10.  0.  5.  6.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 10] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -270    0    0
  128    0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 107.90821075439453






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 10] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 15. 30. 20. 30.  8.  0. 10.  0.  5.  6.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1.  3. 10.  6.  1.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29] -> size -> 62 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  0 10] -> size -> 3 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 15. 30. 20. 30.  8.  0. 10.  0.  5.  6.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1.  3. 10.  6.  1.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29] -> size -> 62 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  0 10] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 15. 30. 20. 30.  8.  0. 10.  0.  5.  6.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1.  3. 10.  6.  1.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29] -> size -> 62 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  0 10  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 15. 30. 20. 30.  8.  0. 10.  0.  5.  6.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1.  3. 10.  6.  1.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29] -> size -> 62 
adversary victory points: 10
player victory points: 0 





Player: 0 
cards in hand: [ 1.  3. 10.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[228.37234]
 [221.74872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10.  6.  1.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 15. 30. 20. 30.  8.  0. 10.  0.  5.  6.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 10  0] -> size -> 4 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 136.73965454101562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[207.56107]
 [242.70543]
 [235.23071]
 [222.11232]
 [229.10818]
 [284.72534]
 [207.68835]
 [221.74873]
 [242.33815]
 [228.37236]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  6.  1.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29] -> size -> 62 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 15. 30. 20. 30.  8.  0. 10.  0.  5.  6.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 10  0] -> size -> 4 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 228.37234497070312



buy possibilites: [-1] 
expected returns: [[142.47357]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  6.  1.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29] -> size -> 63 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 15. 30. 20. 30.  8.  0. 10.  0.  5.  6.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 10  0] -> size -> 4 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0    0    0    0    0    0 -280    0    0
  128    0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 284.725341796875






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 10  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 15. 30. 20. 30.  8.  0. 10.  0.  5.  6.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 29. 11.  3. 11.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29] -> size -> 63 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 15. 30. 20. 30.  8.  0. 10.  0.  5.  6.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 29. 11.  3. 11.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29] -> size -> 63 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 15. 30. 20. 30.  8.  0. 10.  0.  5.  6.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 29. 11.  3. 11.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29] -> size -> 63 
adversary victory points: 10
player victory points: 0 





Player: 0 
cards in hand: [ 1. 29. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[ 54.907654]
 [111.00075 ]
 [ 95.55916 ]
 [ 95.55916 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 11.  3. 11.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 15. 30. 20. 30.  8.  0. 10.  0.  5.  6.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 142.47357177734375



action possibilites: [-1. 11. 11.] 
expected returns: [[-139.14261]
 [-132.43985]
 [-132.43985]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 11.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29] -> size -> 63 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 15. 30. 20. 30.  8.  0. 10.  0.  5.  6.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 81.10904693603516



action possibilites: [-1] 
expected returns: [[18.6019]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1] -> size -> 64 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 14. 30. 20. 30.  8.  0. 10.  0.  5.  6.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   40    0    0    0    0 -290    0    0
   27    0] 
sum of rewards: 72 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -133.58824157714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[ 7.7612033]
 [42.744152 ]
 [33.28721  ]
 [28.688189 ]
 [19.429764 ]
 [18.601858 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1] -> size -> 64 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 14. 30. 20. 30.  8.  0. 10.  0.  5.  6.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.601900100708008



buy possibilites: [-1] 
expected returns: [[110.46234]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1] -> size -> 65 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 13. 30. 20. 30.  8.  0. 10.  0.  5.  6.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   40    0    0    0    0 -300    0    0
   54    0] 
sum of rewards: 89 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 42.744163513183594






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 13. 30. 20. 30.  8.  0. 10.  0.  5.  6.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1.  0. 29. 25. 10.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1] -> size -> 65 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 13. 30. 20. 30.  8.  0. 10.  0.  5.  6.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1.  0. 29. 25. 10.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1] -> size -> 65 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 13. 30. 20. 30.  8.  0. 10.  0.  5.  6.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1.  0. 29. 25. 10.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1] -> size -> 65 
adversary victory points: 10
player victory points: 0 





Player: 0 
cards in hand: [ 1.  0. 29. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10.] 
expected returns: [[ 73.6209  ]
 [107.71063 ]
 [119.13922 ]
 [ 70.382675]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 25. 10.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1] -> size -> 65 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 13. 30. 20. 30.  8.  0. 10.  0.  5.  6.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.46234130859375



action possibilites: [-1] 
expected returns: [[-17.922625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 10.  1.  1.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1] -> size -> 65 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 13. 30. 20. 30.  8.  0. 10.  0.  5.  6.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 119.13922119140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-24.730953  ]
 [-11.610561  ]
 [-27.644938  ]
 [-14.613228  ]
 [-29.900757  ]
 [-19.118275  ]
 [-16.74405   ]
 [  9.351065  ]
 [  0.37556314]
 [-24.827784  ]
 [-14.144817  ]
 [-19.658     ]
 [-27.202026  ]
 [-11.707383  ]
 [-17.922619  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29. 10.  1.  1.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1] -> size -> 65 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 9. 13. 30. 20. 30.  8.  0. 10.  0.  5.  6.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -17.922624588012695



buy possibilites: [-1] 
expected returns: [[-23.343983]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29. 10.  1.  1.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25] -> size -> 66 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 13. 30. 20. 30.  8.  0. 10.  0.  5.  5.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5.     0.     0.   300.     0.     0.    20.     0.     0.     0.
    0.  -310.     0.     0.    62.5    0. ] 
sum of rewards: 67.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 9.35106086730957






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 13. 30. 20. 30.  8.  0. 10.  0.  5.  5.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 10.  1. 15. 10.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25] -> size -> 66 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 13. 30. 20. 30.  8.  0. 10.  0.  5.  5.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 10.  1. 15. 10.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25] -> size -> 66 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 13. 30. 20. 30.  8.  0. 10.  0.  5.  5.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 10.  1. 15. 10.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25] -> size -> 66 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 13. 30. 20. 30.  8.  0. 10.  0.  5.  5.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 10.  1. 15. 10.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25] -> size -> 66 
adversary victory points: 10
player victory points: 0 





Player: 0 
cards in hand: [ 1. 10.  1. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 10.] 
expected returns: [[ 7.575176 ]
 [ 6.4342227]
 [16.179605 ]
 [ 6.4342227]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  1. 15. 10.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25] -> size -> 66 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 13. 30. 20. 30.  8.  0. 10.  0.  5.  5.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -23.343982696533203



action possibilites: [-1] 
expected returns: [[29.17819]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  1. 10.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25] -> size -> 66 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 13. 30. 20. 30.  8.  0. 10.  0.  5.  5.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 16.17958641052246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[24.052862]
 [35.475895]
 [32.69938 ]
 [28.84173 ]
 [30.851572]
 [43.72724 ]
 [23.875072]
 [28.075071]
 [35.279186]
 [29.178186]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  1. 10.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25] -> size -> 66 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 13. 30. 20. 30.  8.  0. 10.  0.  5.  5.  3. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.178190231323242



buy possibilites: [-1] 
expected returns: [[5.582828]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  1. 10.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29] -> size -> 67 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 13. 30. 20. 30.  8.  0. 10.  0.  5.  5.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -320    0    0
  128    0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 43.72724151611328






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 13. 30. 20. 30.  8.  0. 10.  0.  5.  5.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  1.  1. 10. 11.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1. 29. 15.  1. 10.
  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29] -> size -> 67 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 13. 30. 20. 30.  8.  0. 10.  0.  5.  5.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  1.  1. 10. 11.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1. 29. 15.  1. 10.
  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29] -> size -> 67 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 13. 30. 20. 30.  8.  0. 10.  0.  5.  5.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  1.  1. 10. 11.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1. 29. 15.  1. 10.
  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29] -> size -> 67 
adversary victory points: 10
player victory points: 0 





Player: 0 
cards in hand: [ 0.  1.  1. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[193.5896 ]
 [187.58882]
 [210.4408 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1. 10. 11.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1. 29. 15.  1. 10.
  1. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29] -> size -> 67 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 13. 30. 20. 30.  8.  0. 10.  0.  5.  5.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.582828044891357



action possibilites: [-1] 
expected returns: [[83.28228]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1. 10.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1. 29. 15.  1. 10.
  1. 10.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1] -> size -> 68 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 12. 30. 20. 30.  8.  0. 10.  0.  5.  5.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -330    0    0
   27    0] 
sum of rewards: 12 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 204.33590698242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 70.24958 ]
 [ 83.07477 ]
 [ 81.25927 ]
 [ 64.89357 ]
 [ 74.36903 ]
 [ 78.20669 ]
 [101.863556]
 [ 94.93559 ]
 [ 71.29253 ]
 [ 79.99868 ]
 [ 76.64851 ]
 [ 67.377655]
 [ 83.860374]
 [ 83.28229 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1. 10.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1. 29. 15.  1. 10.
  1. 10.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1] -> size -> 68 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 12. 30. 20. 30.  8.  0. 10.  0.  5.  5.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.28227996826172



buy possibilites: [-1] 
expected returns: [[78.468605]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1. 10.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1. 29. 15.  1. 10.
  1. 10.  1. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25] -> size -> 69 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 12. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -340    0    0
  250    0] 
sum of rewards: 225 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 101.86354064941406






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 12. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [11. 11.  1.  3.  0.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1. 29. 15.  1. 10.
  1. 10.  1. 25. 11.  0.  1.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25] -> size -> 69 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 12. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [11. 11.  1.  3.  0.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1. 29. 15.  1. 10.
  1. 10.  1. 25. 11.  0.  1.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25] -> size -> 69 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 12. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [11. 11.  1.  3.  0.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1. 29. 15.  1. 10.
  1. 10.  1. 25. 11.  0.  1.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25] -> size -> 69 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 12. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [11. 11.  1.  3.  0.] 
adversary cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1. 29. 15.  1. 10.
  1. 10.  1. 25. 11.  0.  1.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25] -> size -> 69 
adversary victory points: 10
player victory points: 0 





Player: 0 
cards in hand: [11. 11.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[147.89478]
 [169.08032]
 [169.08032]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  1.  3.  0.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1. 29. 15.  1. 10.
  1. 10.  1. 25. 11.  0.  1.  1. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25] -> size -> 69 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 12. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.4686050415039



action possibilites: [-1] 
expected returns: [[37.842335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  0.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1. 29. 15.  1. 10.
  1. 10.  1. 25. 11.  0.  1.  1. 10.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1] -> size -> 70 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 11. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -350    0    0
   27    0] 
sum of rewards: -8 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 160.84872436523438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[32.98148 ]
 [44.68336 ]
 [41.481163]
 [39.948532]
 [36.903744]
 [37.842342]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  0.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1. 29. 15.  1. 10.
  1. 10.  1. 25. 11.  0.  1.  1. 10.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1] -> size -> 70 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 11. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.84233474731445



buy possibilites: [-1] 
expected returns: [[41.02402]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  0.] 
cards in discard: [ 3. 25. 29. 11.  3. 10. 11.  1.  0.  3. 29. 10. 10.  3. 25.  3. 15.  3.
  3. 29.  0.  1. 29. 11.  1.  0.  3.  0. 29.  1.  3. 10.  6.  1. 11.  3.
  1.  1. 29. 11.  1. 11. 25. 25.  1.  0. 29. 10.  1.  1. 29. 15.  1. 10.
  1. 10.  1. 25. 11.  0.  1.  1. 10.  1.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1] -> size -> 71 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 10. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -360    0    0
   54    0] 
sum of rewards: 9 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 44.68335723876953






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 10. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [10.  3. 25. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1] -> size -> 71 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 10. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [10.  3. 25. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1] -> size -> 71 
adversary victory points: 10
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  3. 25. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 10.] 
expected returns: [[45.41333 ]
 [44.898724]
 [73.71231 ]
 [44.898724]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 25. 10.  0.] 
cards in discard: [] 
cards in deck: 66 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1] -> size -> 71 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 10. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.02402114868164



action possibilites: [-1] 
expected returns: [[121.89742]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  0.  1. 29.] 
cards in discard: [] 
cards in deck: 64 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1] -> size -> 71 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 10. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 73.71231079101562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[112.17723 ]
 [132.00282 ]
 [127.43713 ]
 [124.29483 ]
 [119.715164]
 [121.89744 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  0.  1. 29.] 
cards in discard: [] 
cards in deck: 64 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1] -> size -> 71 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 10. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 121.89742279052734



buy possibilites: [-1] 
expected returns: [[144.85785]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  0.  1. 29.] 
cards in discard: [1.] 
cards in deck: 64 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1] -> size -> 72 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6.  9. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -370    0    0
   54    0] 
sum of rewards: -1 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 132.00282287597656






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6.  9. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [10.  6.  1. 11. 25.] 
adversary cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1] -> size -> 72 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6.  9. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [10.  6.  1. 11. 25.] 
adversary cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1] -> size -> 72 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6.  9. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [10.  6.  1. 11. 25.] 
adversary cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1] -> size -> 72 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5.  9. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [10.  6.  1. 11. 25.] 
adversary cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1] -> size -> 72 
adversary victory points: 10
player victory points: 0 





Player: 0 
cards in hand: [10.  6.  1. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25.] 
expected returns: [[55.611115]
 [56.523083]
 [64.405754]
 [70.396255]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  1. 11. 25.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29.] 
cards in deck: 59 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1] -> size -> 72 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5.  9. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 144.85784912109375



action possibilites: [-1] 
expected returns: [[10.03928]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  1. 11.  1.  1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29.] 
cards in deck: 57 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1] -> size -> 72 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5.  9. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 70.39625549316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 1.5946479]
 [19.698162 ]
 [-1.9625418]
 [14.960131 ]
 [-4.8572564]
 [ 9.106125 ]
 [12.10541  ]
 [32.965714 ]
 [27.146566 ]
 [ 1.4802003]
 [16.220629 ]
 [ 7.800077 ]
 [-1.4271872]
 [19.238607 ]
 [10.039278 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  1. 11.  1.  1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29.] 
cards in deck: 57 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1] -> size -> 72 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 5.  9. 30. 20. 30.  8.  0. 10.  0.  5.  4.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.03927993774414



buy possibilites: [-1] 
expected returns: [[70.34325]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  1. 11.  1.  1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25.] 
cards in deck: 57 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25] -> size -> 73 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5.  9. 30. 20. 30.  8.  0. 10.  0.  5.  3.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5.     0.     0.   300.     0.     0.    20.     0.     0.     0.
    0.  -380.     0.     0.    62.5    0. ] 
sum of rewards: -2.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 32.96571350097656






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5.  9. 30. 20. 30.  8.  0. 10.  0.  5.  3.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [29.  1.  3. 25.  1.] 
adversary cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25] -> size -> 73 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5.  9. 30. 20. 30.  8.  0. 10.  0.  5.  3.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [29.  1.  3. 25.  1.] 
adversary cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25] -> size -> 73 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5.  9. 30. 20. 30.  8.  0. 10.  0.  5.  3.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [29.  1.  3. 25.  1.] 
adversary cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25] -> size -> 73 
adversary victory points: 10
player victory points: 0 





Player: 0 
cards in hand: [29.  1.  3. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[73.310394]
 [86.97296 ]
 [91.661224]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3. 25.  1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1.] 
cards in deck: 52 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25] -> size -> 73 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5.  9. 30. 20. 30.  8.  0. 10.  0.  5.  3.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.34324645996094



action possibilites: [-1] 
expected returns: [[8.083031]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3.  1.  0.  1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1.] 
cards in deck: 50 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25] -> size -> 73 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5.  9. 30. 20. 30.  8.  0. 10.  0.  5.  3.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 91.6612319946289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-2.2330418]
 [21.03274  ]
 [-6.5190363]
 [15.017563 ]
 [-9.844538 ]
 [ 7.941686 ]
 [11.583647 ]
 [46.910133 ]
 [37.851257 ]
 [-2.3501177]
 [16.5157   ]
 [ 6.098169 ]
 [-5.9285126]
 [20.209425 ]
 [ 8.083008 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  3.  1.  0.  1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1.] 
cards in deck: 50 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25] -> size -> 73 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 5.  9. 30. 20. 30.  8.  0. 10.  0.  5.  3.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.083030700683594



buy possibilites: [-1] 
expected returns: [[17.976164]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  3.  1.  0.  1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25.] 
cards in deck: 50 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25] -> size -> 74 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5.  9. 30. 20. 30.  8.  0. 10.  0.  5.  2.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5.     0.     0.   300.     0.     0.    20.     0.     0.     0.
    0.  -390.     0.     0.    62.5    0. ] 
sum of rewards: -12.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 46.91014862060547






         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5.  9. 30. 20. 30.  8.  0. 10.  0.  5.  2.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 10. 11. 11.  1.] 
adversary cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25] -> size -> 74 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5.  9. 30. 20. 30.  8.  0. 10.  0.  5.  2.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 10. 11. 11.  1.] 
adversary cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25] -> size -> 74 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4.  9. 30. 20. 30.  8.  0. 10.  0.  5.  2.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 10. 11. 11.  1.] 
adversary cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25] -> size -> 74 
adversary victory points: 10
player victory points: 0 





Player: 0 
cards in hand: [ 1. 10. 11. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[-37.07949 ]
 [-37.80494 ]
 [-18.601349]
 [-18.601349]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 11. 11.  1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25] -> size -> 74 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4.  9. 30. 20. 30.  8.  0. 10.  0.  5.  2.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.976163864135742



action possibilites: [-1] 
expected returns: [[-61.61631]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 11.  1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.  1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25  1] -> size -> 75 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4.  8. 30. 20. 30.  8.  0. 10.  0.  5.  2.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -400    0    0
   27    0] 
sum of rewards: -58 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -25.647729873657227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-68.34354 ]
 [-57.156784]
 [-59.843983]
 [-64.254425]
 [-62.040768]
 [-49.58137 ]
 [-68.17461 ]
 [-64.05674 ]
 [-57.22589 ]
 [-61.61635 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 11.  1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.  1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25  1] -> size -> 75 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4.  8. 30. 20. 30.  8.  0. 10.  0.  5.  2.  2. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -61.616310119628906



buy possibilites: [-1] 
expected returns: [[-7.8920393]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 11.  1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.  1. 29.] 
cards in deck: 45 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25  1 29] -> size -> 76 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4.  8. 30. 20. 30.  8.  0. 10.  0.  5.  2.  1. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -410    0    0
  128    0] 
sum of rewards: 33 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -49.581298828125






         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4.  8. 30. 20. 30.  8.  0. 10.  0.  5.  2.  1. 10. 10.  1. 10.  7.] 
adversary cards in hand: [11. 29.  1.  3.  1.] 
adversary cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.  1. 29. 11.  1. 10. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25  1 29] -> size -> 76 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4.  8. 30. 20. 30.  8.  0. 10.  0.  5.  2.  1. 10. 10.  1. 10.  7.] 
adversary cards in hand: [11. 29.  1.  3.  1.] 
adversary cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.  1. 29. 11.  1. 10. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25  1 29] -> size -> 76 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4.  8. 30. 20. 30.  8.  0. 10.  0.  5.  2.  1. 10. 10.  1. 10.  7.] 
adversary cards in hand: [11. 29.  1.  3.  1.] 
adversary cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.  1. 29. 11.  1. 10. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25  1 29] -> size -> 76 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3.  8. 30. 20. 30.  8.  0. 10.  0.  5.  2.  1. 10. 10.  1. 10.  7.] 
adversary cards in hand: [11. 29.  1.  3.  1.] 
adversary cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.  1. 29. 11.  1. 10. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25  1 29] -> size -> 76 
adversary victory points: 10
player victory points: 0 





Player: 0 
cards in hand: [11. 29.  1.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[-37.703796]
 [-11.65741 ]
 [ -2.934187]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  1.  3.  1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.  1. 29. 11.  1. 10. 11.  1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25  1 29] -> size -> 76 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3.  8. 30. 20. 30.  8.  0. 10.  0.  5.  2.  1. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -7.8920392990112305



action possibilites: [-1.] 
expected returns: [[-99.212875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.  1. 29. 11.  1. 10. 11.  1. 11.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25  1 29] -> size -> 76 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3.  8. 30. 20. 30.  8.  0. 10.  0.  5.  2.  1. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -20.879470825195312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-106.07667 ]
 [ -97.6863  ]
 [ -99.409355]
 [-109.0447  ]
 [-103.265854]
 [-101.56497 ]
 [ -86.62035 ]
 [ -91.51427 ]
 [-105.86686 ]
 [-100.009605]
 [-102.8988  ]
 [-107.5677  ]
 [ -97.13493 ]
 [ -99.212814]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.  1. 29. 11.  1. 10. 11.  1. 11.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25  1 29] -> size -> 76 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3.  8. 30. 20. 30.  8.  0. 10.  0.  5.  2.  1. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -99.21287536621094



buy possibilites: [-1] 
expected returns: [[-11.893024]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.  1. 29. 11.  1. 10. 11.  1. 11.  0. 25.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25  1 29 25] -> size -> 77 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3.  8. 30. 20. 30.  8.  0. 10.  0.  5.  1.  1. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -420    0    0
  250    0] 
sum of rewards: 145 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -86.62035369873047






         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3.  8. 30. 20. 30.  8.  0. 10.  0.  5.  1.  1. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 3. 25.  1. 10. 29.] 
adversary cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.  1. 29. 11.  1. 10. 11.  1. 11.  0. 25. 29.  1.
  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25  1 29 25] -> size -> 77 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3.  8. 30. 20. 30.  8.  0. 10.  0.  5.  1.  1. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 3. 25.  1. 10. 29.] 
adversary cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.  1. 29. 11.  1. 10. 11.  1. 11.  0. 25. 29.  1.
  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25  1 29 25] -> size -> 77 
adversary victory points: 10
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 25.  1. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29.] 
expected returns: [[144.89725]
 [177.70349]
 [136.48892]
 [166.85149]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  1. 10. 29.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.  1. 29. 11.  1. 10. 11.  1. 11.  0. 25. 29.  1.
  3.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25  1 29 25] -> size -> 77 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3.  8. 30. 20. 30.  8.  0. 10.  0.  5.  1.  1. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -11.893024444580078



action possibilites: [-1] 
expected returns: [[120.877144]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 10. 29.  0.  1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.  1. 29. 11.  1. 10. 11.  1. 11.  0. 25. 29.  1.
  3.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25  1 29 25] -> size -> 77 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3.  8. 30. 20. 30.  8.  0. 10.  0.  5.  1.  1. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 177.70346069335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[102.677864]
 [131.84715 ]
 [127.181274]
 [ 89.24127 ]
 [115.446175]
 [121.79512 ]
 [154.55016 ]
 [145.72414 ]
 [102.52124 ]
 [126.75787 ]
 [115.503784]
 [ 96.22947 ]
 [132.49171 ]
 [120.87718 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 10. 29.  0.  1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.  1. 29. 11.  1. 10. 11.  1. 11.  0. 25. 29.  1.
  3.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25  1 29 25] -> size -> 77 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3.  8. 30. 20. 30.  8.  0. 10.  0.  5.  1.  1. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 120.87714385986328



Player 0 won the game! 



Player 0 bought cards:
Copper: 2 
Silver: 5 
Gold: 0 
Estate: 8 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 9 
Chapel: 0 
Witch: 9 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3.  1. 10. 29.  0.  1.] 
cards in discard: [ 1. 25. 10.  3. 10.  0.  1. 29. 25. 25. 10.  6.  1. 11.  1.  1. 25. 25.
 29.  1.  3.  1.  0.  1.  1. 29. 11.  1. 10. 11.  1. 11.  0. 25. 29.  1.
  3.  1. 25.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 10 11 25  3  3 10 11 29
 10  3  6  3 10 11 10  3 10 25  0 10  0 11 15 11 11 15 11  1  1  1  1  1
  1  3  1  1  1  3  1  1  1 29  1  3  1 29 29  1  1 25 29  1 25  1  1  1
 25 25  1 29 25 25] -> size -> 78 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3.  8. 30. 20. 30.  8.  0. 10.  0.  5.  0.  1. 10. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[     -5 3000000       0     300       0       0      20       0       0
       0       0    -430       0       0     125       0] 
sum of rewards: 3000010 

action type: buy - action 25.0
Learning step: 299985.5625
desired expected reward: 300140.125



