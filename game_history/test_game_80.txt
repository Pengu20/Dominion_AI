 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[9.734688]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -240        0        0        0        0
        0        0        0     -190        0     -300        0        0] 
sum of rewards: -3000735 

action type: buy - action 6.0
Learning step: -120022.4140625
desired expected reward: -120196.8125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  9.204718 ]
 [ 25.123138 ]
 [ 12.489586 ]
 [-70.961044 ]
 [ 20.016123 ]
 [ 21.19999  ]
 [ 10.2735615]
 [ 32.22146  ]
 [ 20.200544 ]
 [ 18.446096 ]
 [ 23.92982  ]
 [  8.091986 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 9.417428970336914



buy possibilites: [-1] 
expected returns: [[-3.0619369]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 32.221466064453125






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [16.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [16.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [16.  0.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.95076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -3.061936855316162





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -15.74342  ]
 [  -0.2883892]
 [ -12.672937 ]
 [-103.32538  ]
 [  -4.1346946]
 [ -14.587702 ]
 [  -6.7474146]
 [ -16.502115 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -18.652225494384766



buy possibilites: [-1] 
expected returns: [[-15.857929]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.28838086128234863






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-16.671522 ]
 [  5.3749833]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 16.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -15.857929229736328



action possibilites: [-1.] 
expected returns: [[-8.520952]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 16.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 4.253425598144531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -9.17292   ]
 [  5.6732154 ]
 [ -6.036295  ]
 [-43.674175  ]
 [-85.53903   ]
 [  1.1243668 ]
 [  2.268406  ]
 [ -8.060278  ]
 [  6.2798095 ]
 [ 12.105314  ]
 [  1.3521538 ]
 [  5.9635453 ]
 [ -0.29901552]
 [  0.28423953]
 [  4.71561   ]
 [ -9.553232  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 16.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -8.520952224731445



buy possibilites: [-1] 
expected returns: [[2.3286953]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 16.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 47.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 12.105316162109375






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 16.] 
cards in discard: [16.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [29. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [16.  0.  3.  0.  0.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0 16 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  7. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [29. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [16.  0.  3.  0.  0.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0 16 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10.  7. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [29. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [16.  0.  3.  0.  0.  0. 16.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0 16 16  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  7. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [29. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 3. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-17.160423]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [29. 29.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  7. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  8.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0 16 16  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.328695297241211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -16.845968 ]
 [  -2.3224068]
 [ -13.732098 ]
 [-114.621155 ]
 [  -6.8086486]
 [  -5.945018 ]
 [ -16.150406 ]
 [   3.87543  ]
 [  -6.782542 ]
 [  -8.396225 ]
 [  -3.5362227]
 [ -16.584244 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [29. 29.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10.  7. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  8.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0 16 16  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.537277221679688



buy possibilites: [-1] 
expected returns: [[2.748948]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [29. 29.  0.  0.  0.  0.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  7. 10.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  8.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0 16 16  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 3.8754396438598633






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [16.  8.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0 16 16  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  7. 10.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 16  0 16 16  8 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  7. 10.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 16  0 16 16  8 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  7. 10.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[27.993286]
 [45.09253 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  7. 10.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [10. 16.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  0 16 16  8 10] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.748948097229004



action possibilites: [-1. 29.] 
expected returns: [[40.708614]
 [58.965805]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  7. 10.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [10. 16.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  0 16 16  8 10] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 40.80236053466797



action possibilites: [-1.] 
expected returns: [[-0.89518166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10.  7. 10.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [10. 16.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  0 16 16  8 10] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 58.96580505371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[   1.6264448]
 [  17.663406 ]
 [   5.46997  ]
 [ -44.682922 ]
 [-117.538895 ]
 [  13.319498 ]
 [  14.3959255]
 [   2.5256972]
 [  18.315086 ]
 [  24.00014  ]
 [  13.512623 ]
 [  18.014006 ]
 [  11.65597  ]
 [  12.48299  ]
 [  16.780094 ]
 [   2.7817144]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10.  7. 10.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [10. 16.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  0 16 16  8 10] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.8951816558837891



buy possibilites: [-1] 
expected returns: [[-7.535108]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  7. 10.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [10. 16.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  0 16 16  8 10] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 60.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 127.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 24.000146865844727






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  0.] 
cards in discard: [10. 16.  8.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16  0 16 16  8 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  7. 10.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 16.  8.  0.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16  0 16 16  8 10  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  7. 10.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 16.  8.  0.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16  0 16 16  8 10  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  9.  7. 10.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 16.  8.  0.  3.  6. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16  0 16 16  8 10  6 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  7.  9.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [3. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[7.1826825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  7.  9.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 16 16  8 10  6 11] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -7.5351080894470215





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[   4.9118953]
 [  20.827728 ]
 [   8.242584 ]
 [ -38.37454  ]
 [-106.33088  ]
 [  15.818016 ]
 [  16.513668 ]
 [   5.2337337]
 [  21.072289 ]
 [  27.587944 ]
 [  15.646345 ]
 [  20.82865  ]
 [  13.877132 ]
 [  14.649889 ]
 [  19.195724 ]
 [   5.1095767]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8.  9.  7.  9.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 16 16  8 10  6 11] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.891046047210693



buy possibilites: [-1] 
expected returns: [[-20.43339]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  9.  7.  9.  9. 10.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0 16 16  8 10  6 11] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 90.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 117.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 27.587942123413086






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [10. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0 16 16  8 10  6 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  7.  9.  9. 10.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3 16  0 16 16  8 10  6 11] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  7.  9.  9. 10.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  3 16  0 16 16  8 10  6 11  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  7.  9.  9. 10.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  3 16  0 16 16  8 10  6 11  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  8.  7.  9.  9. 10.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  3 16  0 16 16  8 10  6 11  6  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8.  7.  9.  9. 10.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0.  0.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[51.892582]
 [71.77849 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8.  7.  9.  9. 10.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0. 11.] 
adversary cards in discard: [ 6.  1. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16  0 16 16  8 10  6 11  6  1] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -20.43338966369629



action possibilites: [-1.] 
expected returns: [[14.776358]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  8.  7.  9.  9. 10.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0. 11.] 
adversary cards in discard: [ 6.  1. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16  0 16 16  8 10  6 11  6  1] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 66.79960632324219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  20.376373]
 [  35.844532]
 [ -36.752556]
 [  24.703754]
 [ -43.023003]
 [-120.235054]
 [  32.065315]
 [  33.119694]
 [  18.856836]
 [  36.55286 ]
 [  41.551632]
 [  32.313858]
 [  36.267776]
 [  30.512194]
 [  31.371614]
 [  35.226467]
 [  22.704628]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 28. 30. 30. 30.  8.  8.  7.  9.  9. 10.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0. 11.] 
adversary cards in discard: [ 6.  1. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16  0 16 16  8 10  6 11  6  1] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 14.776357650756836



buy possibilites: [-1] 
expected returns: [[-1.4213367]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  8.  7.  9.  9. 10.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0. 11.] 
adversary cards in discard: [ 6.  1. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16  0 16 16  8 10  6 11  6  1] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. 120.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 167.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 41.5516357421875






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 16.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0. 11.] 
cards in discard: [ 6.  1. 10. 16.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16  0 16 16  8 10  6 11  6  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8.  7.  9.  9. 10.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0. 29.] 
adversary cards in discard: [29. 29.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [ 6.  1. 10. 16.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3 16  0 16 16  8 10  6 11  6  1  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8.  7.  9.  8. 10.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0. 29.] 
adversary cards in discard: [29. 29.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [ 6.  1. 10. 16.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3 16  0 16 16  8 10  6 11  6  1  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  8.  7.  9.  8. 10.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0. 29.] 
adversary cards in discard: [29. 29.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [29. 29.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-16.231695 ]
 [  2.1808257]
 [  2.1808257]
 [  2.1808257]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0. 29.] 
cards in discard: [29. 29.  0.  0.  1.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8.  7.  9.  8. 10.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  8.  6. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 16  0 16 16  8 10  6 11  6  1  8] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.4213366508483887



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-20.456028 ]
 [ -0.6127877]
 [ -0.6127877]
 [ -0.6127877]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 29. 29.] 
cards in discard: [29. 29.  0.  0.  1.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  8.  7.  9.  8. 10.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  8.  6. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 16  0 16 16  8 10  6 11  6  1  8] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 2.699868679046631



action possibilites: [-1. 29. 29.] 
expected returns: [[-2.5432613]
 [18.509863 ]
 [18.509863 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29.  3.] 
cards in discard: [29. 29.  0.  0.  1.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  8.  7.  9.  8. 10.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  8.  6. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 16  0 16 16  8 10  6 11  6  1  8] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -0.6127760410308838



action possibilites: [-1. 29.] 
expected returns: [[ 1.2288852]
 [21.81652  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  0.] 
cards in discard: [29. 29.  0.  0.  1.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  8.  7.  9.  8. 10.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  8.  6. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 16  0 16 16  8 10  6 11  6  1  8] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 18.509876251220703



action possibilites: [-1.] 
expected returns: [[16.683426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29. 29.  0.  0.  1.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8.  8.  7.  9.  8. 10.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  8.  6. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 16  0 16 16  8 10  6 11  6  1  8] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 21.816524505615234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 19.754862 ]
 [ 34.233974 ]
 [-13.13485  ]
 [ 22.728718 ]
 [-13.4278965]
 [ 26.661957 ]
 [-55.76235  ]
 [ 29.80992  ]
 [ 30.608328 ]
 [ 20.555853 ]
 [ 34.590435 ]
 [ 40.315056 ]
 [ 29.795813 ]
 [ 34.34108  ]
 [ 28.209555 ]
 [ 28.85642  ]
 [ 32.98244  ]
 [ 19.977617 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29. 29.  0.  0.  1.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 8 
card supply: [29. 28. 30. 30. 30.  8.  8.  7.  9.  8. 10.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  8.  6. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 16  0 16 16  8 10  6 11  6  1  8] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 16.683425903320312



buy possibilites: [-1] 
expected returns: [[36.22149]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29. 29.  0.  0.  1.  0.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8.  8.  7.  9.  8. 10.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  8.  6. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 16  0 16 16  8 10  6 11  6  1  8] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. 120.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 227.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 40.31505584716797






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [16.  8.  6. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  6. 16.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  0 16 16  8 10  6 11  6  1  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8.  7.  9.  8. 10.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3.] 
cards in discard: [2.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  0 16 16  8 10  6 11  6  1  8  2] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 29. 30. 30.  8.  8.  7.  9.  8. 10.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3.] 
cards in discard: [2.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  0 16 16  8 10  6 11  6  1  8  2] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 28. 29. 30. 30.  8.  8.  7.  9.  8. 10.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3.] 
cards in discard: [2. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 30. 30.  8.  8.  7.  9.  8. 10.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 1.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-31.877382]
 [-14.690849]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 30. 30.  8.  8.  7.  9.  8. 10.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  1.  6.  8. 16.] 
adversary cards in discard: [ 2.  0. 16.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0] -> size -> 17 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.22148895263672



action possibilites: [-1. 29.] 
expected returns: [[68.04678 ]
 [87.072174]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 29. 30. 30.  8.  8.  7.  9.  8. 10.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  1.  6.  8. 16.] 
adversary cards in discard: [ 2.  0. 16.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0] -> size -> 17 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -30.65886688232422



action possibilites: [-1.] 
expected returns: [[56.58773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 29. 30. 30.  8.  8.  7.  9.  8. 10.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  1.  6.  8. 16.] 
adversary cards in discard: [ 2.  0. 16.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0] -> size -> 17 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 87.07218933105469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 62.097076]
 [ 77.04002 ]
 [ 27.180822]
 [ 65.74301 ]
 [ 25.590687]
 [-32.92389 ]
 [ 73.06115 ]
 [ 74.15161 ]
 [ 63.041634]
 [ 77.72376 ]
 [ 82.923775]
 [ 73.31503 ]
 [ 77.428406]
 [ 71.57735 ]
 [ 72.337036]
 [ 76.34259 ]
 [ 63.15203 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 28. 29. 30. 30.  8.  8.  7.  9.  8. 10.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  1.  6.  8. 16.] 
adversary cards in discard: [ 2.  0. 16.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0] -> size -> 17 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 56.587730407714844



buy possibilites: [-1] 
expected returns: [[29.633429]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 29. 30. 30.  8.  8.  7.  9.  8. 10.  2. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  1.  6.  8. 16.] 
adversary cards in discard: [ 2.  0. 16.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0] -> size -> 17 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. 120.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 187.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 82.92376708984375






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  6.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  6.  8. 16.] 
cards in discard: [ 2.  0. 16.  8.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 30. 30.  8.  8.  7.  9.  8. 10.  2. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [29. 29. 29.  1.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 8.] 
cards in discard: [ 2.  0. 16.  8.  6.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  2. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [29. 29. 29.  1.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 8.] 
cards in discard: [ 2.  0. 16.  8.  6.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  2. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [29. 29. 29.  1.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 8.] 
cards in discard: [ 2.  0. 16.  8.  6.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  2. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [29. 29. 29.  1.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0. 29.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-1.2601788]
 [20.503561 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3.  0.] 
cards in discard: [29. 29. 29.  1.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  2. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0.  0.] 
adversary cards in discard: [ 2.  0. 16.  8.  6.  3.  3.  0. 16.  1.  6.  8.] 
adversary owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3  0] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.6334285736084



action possibilites: [-1.] 
expected returns: [[11.01232]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29. 29. 29.  1.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  2. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0.  0.] 
adversary cards in discard: [ 2.  0. 16.  8.  6.  3.  3.  0. 16.  1.  6.  8.] 
adversary owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3  0] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 19.353961944580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 16.609425]
 [ 31.335073]
 [ 19.49208 ]
 [-74.02888 ]
 [ 26.860285]
 [ 27.788494]
 [ 17.87457 ]
 [ 37.68307 ]
 [ 26.938063]
 [ 25.361967]
 [ 30.186037]
 [ 16.606462]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29. 29. 29.  1.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  2. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0.  0.] 
adversary cards in discard: [ 2.  0. 16.  8.  6.  3.  3.  0. 16.  1.  6.  8.] 
adversary owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3  0] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 11.012319564819336



buy possibilites: [-1] 
expected returns: [[23.83821]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29. 29. 29.  1.  0.  0.  3.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0.  0.] 
adversary cards in discard: [ 2.  0. 16.  8.  6.  3.  3.  0. 16.  1.  6.  8.] 
adversary owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3  0] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 233 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 37.683082580566406






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0.  0.] 
cards in discard: [ 2.  0. 16.  8.  6.  3.  3.  0. 16.  1.  6.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29.  0. 29. 29.] 
adversary cards in discard: [29. 29. 29.  1.  0.  0.  3.  0. 29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  0.  0.] 
cards in discard: [ 2.  0. 16.  8.  6.  3.  3.  0. 16.  1.  6.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29.  0. 29. 29.] 
adversary cards in discard: [29. 29. 29.  1.  0.  0.  3.  0. 29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 29.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[103.11844 ]
 [120.086876]
 [120.086876]
 [120.086876]
 [120.086876]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 29. 29.] 
cards in discard: [29. 29. 29.  1.  0.  0.  3.  0. 29. 29.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  2. 16.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3  0] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.83820915222168



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[12.468145]
 [32.215332]
 [32.215332]
 [32.215332]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  2. 16.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3  0] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 117.83248901367188



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[ 7.0508647]
 [27.939436 ]
 [27.939436 ]
 [27.939436 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  2. 16.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3  0] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 32.21533966064453



action possibilites: [-1. 29. 29.] 
expected returns: [[27.975767]
 [48.805218]
 [48.805218]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  2. 16.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3  0] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.939443588256836



action possibilites: [-1. 29.] 
expected returns: [[43.497128]
 [62.903732]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 4 
card supply: [27. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  2. 16.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3  0] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 48.80522155761719



action possibilites: [-1.] 
expected returns: [[80.9111]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 5 
card supply: [27. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  2. 16.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3  0] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 62.903717041015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 84.41661 ]
 [ 98.5738  ]
 [ 52.286552]
 [ 87.69983 ]
 [ 51.07878 ]
 [ 90.34416 ]
 [  9.860542]
 [ 94.57348 ]
 [ 95.67666 ]
 [ 85.45288 ]
 [ 99.2266  ]
 [104.39796 ]
 [ 94.83971 ]
 [ 98.92933 ]
 [ 93.22442 ]
 [ 93.86072 ]
 [ 97.857216]
 [ 84.68362 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 8 
card supply: [27. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  2. 16.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3  0] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 80.91110229492188



buy possibilites: [-1] 
expected returns: [[52.604908]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  0. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  2. 16.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3  0] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.  90.   0.   0. 100.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 217.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 104.39796447753906






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0.  2. 16.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  2. 16.  8.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16 16  8 10  6 11  6  1  8  2  0  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  0. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 2. 0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0 16 16 10  6 11  6  1  8  2  0  3  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  0. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0 16 16 10  6 11  6  1  8  2  0  3  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 29. 29. 30.  8.  8.  7.  9.  8. 10.  0. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 0.] 
cards in discard: [0. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0 16 16 10  6 11  6  1  8  2  0  3  0  0  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 29. 29. 30.  8.  8.  7.  9.  7. 10.  0. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[30.867746]
 [49.53769 ]
 [49.53769 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29.  0.] 
cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 29. 30.  8.  8.  7.  9.  7. 10.  0. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16.  1. 11.  6.] 
adversary cards in discard: [ 0.  8. 16.  0.  2.  0.] 
adversary owned cards: [ 0  0  0  3  0 16 16 10  6 11  6  1  8  2  0  3  0  0  8] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 52.60490798950195



action possibilites: [-1.] 
expected returns: [[67.9103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  3.  3.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 29. 29. 30.  8.  8.  7.  9.  7. 10.  0. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16.  1. 11.  6.] 
adversary cards in discard: [ 0.  8. 16.  0.  2.  0.] 
adversary owned cards: [ 0  0  0  3  0 16 16 10  6 11  6  1  8  2  0  3  0  0  8] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 39.62836837768555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[71.995636]
 [86.5696  ]
 [74.937256]
 [34.978615]
 [-8.209234]
 [82.459816]
 [83.242355]
 [73.233345]
 [86.960045]
 [82.47348 ]
 [86.71999 ]
 [80.9044  ]
 [81.58368 ]
 [85.465004]
 [73.135086]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  3.  3.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 29. 29. 30.  8.  8.  7.  9.  7. 10.  0. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16.  1. 11.  6.] 
adversary cards in discard: [ 0.  8. 16.  0.  2.  0.] 
adversary owned cards: [ 0  0  0  3  0 16 16 10  6 11  6  1  8  2  0  3  0  0  8] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 67.9103012084961



buy possibilites: [-1] 
expected returns: [[163.66728]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  3.  3.  0. 29. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 29. 30.  8.  8.  7.  9.  7.  9.  0. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16.  1. 11.  6.] 
adversary cards in discard: [ 0.  8. 16.  0.  2.  0.] 
adversary owned cards: [ 0  0  0  3  0 16 16 10  6 11  6  1  8  2  0  3  0  0  8] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 355 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 86.9600601196289






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  1. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  1. 11.  6.] 
cards in discard: [ 0.  8. 16.  0.  2.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16 16 10  6 11  6  1  8  2  0  3  0  0  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 29. 30.  8.  8.  7.  9.  7.  9.  0. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.] 
cards in discard: [ 0.  8. 16.  0.  2.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0 16 16 10 11  6  1  8  2  0  3  0  0  8  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 11.] 
cards in discard: [ 0.  8. 16.  0.  2.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0 16 16 10 11  6  1  8  2  0  3  0  0  8  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 11.] 
cards in discard: [ 0.  8. 16.  0.  2.  0.  8. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0 16 16 10 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29. 29.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 4.944939]
 [25.888994]
 [25.888994]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  1.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 8. 3. 0.] 
adversary cards in discard: [ 0.  8. 16.  0.  2.  0.  8. 10. 16.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  3  0 16 16 10 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 163.6672821044922



action possibilites: [-1. 29.] 
expected returns: [[29.877588]
 [49.904434]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 29.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 8. 3. 0.] 
adversary cards in discard: [ 0.  8. 16.  0.  2.  0.  8. 10. 16.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  3  0 16 16 10 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 15.971080780029297



action possibilites: [-1.] 
expected returns: [[46.47876]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [29.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 28. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 8. 3. 0.] 
adversary cards in discard: [ 0.  8. 16.  0.  2.  0.  8. 10. 16.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  3  0 16 16 10 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 42.28843307495117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 47.929024]
 [ 62.556335]
 [ 51.55902 ]
 [-27.035097]
 [ 58.63192 ]
 [ 59.71123 ]
 [ 48.78888 ]
 [ 58.884743]
 [ 57.160767]
 [ 61.87394 ]
 [ 48.844128]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [29.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 8. 3. 0.] 
adversary cards in discard: [ 0.  8. 16.  0.  2.  0.  8. 10. 16.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  3  0 16 16 10 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 46.478759765625



buy possibilites: [-1] 
expected returns: [[60.503754]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [29.  1.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 8. 3. 0.] 
adversary cards in discard: [ 0.  8. 16.  0.  2.  0.  8. 10. 16.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  3  0 16 16 10 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 108.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 62.55634307861328






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [3. 6. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 3. 0.] 
cards in discard: [ 0.  8. 16.  0.  2.  0.  8. 10. 16.  0.  1. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16 16 10 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3. 29.] 
adversary cards in discard: [29.  1.  1. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1] -> size -> 23 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 3. 0.] 
cards in discard: [ 0.  8. 16.  0.  2.  0.  8. 10. 16.  0.  1. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16 16 10 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3. 29.] 
adversary cards in discard: [29.  1.  1. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1] -> size -> 23 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[17.54008 ]
 [36.492157]
 [36.492157]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3. 29.] 
cards in discard: [29.  1.  1. 29. 29.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 16. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16 16 10 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 60.503753662109375



action possibilites: [-1.] 
expected returns: [[8.677893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29.  1.  1. 29. 29.  0.  3.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 16. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16 16 10 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 28.6804256439209





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 12.568867]
 [ 26.952005]
 [ 15.843555]
 [-68.197586]
 [ 22.881813]
 [ 23.730984]
 [ 13.291578]
 [ 22.947489]
 [ 21.314705]
 [ 25.947098]
 [ 13.428946]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29.  1.  1. 29. 29.  0.  3.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 16. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16 16 10 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 8.677892684936523



buy possibilites: [-1] 
expected returns: [[61.714104]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29.  1.  1. 29. 29.  0.  3.  0. 29.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 16. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16 16 10 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 88.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 26.95200538635254






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 8. 16. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16 16 10 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  0. 25. 29.] 
adversary cards in discard: [29.  1.  1. 29. 29.  0.  3.  0. 29.  1. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1] -> size -> 24 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 16 16 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  0. 25. 29.] 
adversary cards in discard: [29.  1.  1. 29. 29.  0.  3.  0. 29.  1. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1] -> size -> 24 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 16 16 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  0. 25. 29.] 
adversary cards in discard: [29.  1.  1. 29. 29.  0.  3.  0. 29.  1. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1] -> size -> 24 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29. 29.  0. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25. 29.] 
expected returns: [[143.5936 ]
 [159.55727]
 [159.55727]
 [155.19414]
 [159.55727]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 25. 29.] 
cards in discard: [29.  1.  1. 29. 29.  0.  3.  0. 29.  1. 29.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  6.  1.] 
adversary cards in discard: [ 8. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0 16 16 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 61.71410369873047



action possibilites: [-1. 25. 29. 29.] 
expected returns: [[158.17093]
 [168.87889]
 [173.04205]
 [173.04205]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29. 29.] 
cards in discard: [29.  1.  1. 29. 29.  0.  3.  0. 29.  1. 29.  0.  0.  3.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  6.  1.] 
adversary cards in discard: [ 8. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0 16 16 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 154.3760528564453



action possibilites: [-1. 25.] 
expected returns: [[ 95.82519]
 [107.17581]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.] 
cards in discard: [29.  1.  1. 29. 29.  0.  3.  0. 29.  1. 29.  0.  0.  3.  0. 29. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 26. 29. 29. 30.  8.  8.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  6.  1.] 
adversary cards in discard: [ 8. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0 16 16 11  6  1  8  2  0  3  0  0  8  8 10] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 168.44277954101562



action possibilites: [-1] 
expected returns: [[102.43092]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.] 
cards in discard: [29.  1.  1. 29. 29.  0.  3.  0. 29.  1. 29.  0.  0.  3.  0. 29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 29. 29. 30.  8.  7.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  6.  1.] 
adversary cards in discard: [ 8. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  0 16 16 11  6  1  8  2  0  3  0  0  8  8 10  6] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 107.1758041381836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 98.71906 ]
 [112.3652  ]
 [102.26888 ]
 [ 15.672579]
 [109.286736]
 [109.877655]
 [ 99.18227 ]
 [109.28071 ]
 [107.657745]
 [111.617805]
 [102.02312 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29.] 
cards in discard: [29.  1.  1. 29. 29.  0.  3.  0. 29.  1. 29.  0.  0.  3.  0. 29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 29. 29. 30.  8.  7.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  6.  1.] 
adversary cards in discard: [ 8. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  0 16 16 11  6  1  8  2  0  3  0  0  8  8 10  6] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.43092346191406



buy possibilites: [-1] 
expected returns: [[129.62976]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29.] 
cards in discard: [29.  1.  1. 29. 29.  0.  3.  0. 29.  1. 29.  0.  0.  3.  0. 29. 29.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 29. 29. 30.  8.  7.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  6.  1.] 
adversary cards in discard: [ 8. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  0 16 16 11  6  1  8  2  0  3  0  0  8  8 10  6] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 128.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 112.365234375






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  6.  1.] 
cards in discard: [ 8. 16.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16 16 11  6  1  8  2  0  3  0  0  8  8 10  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 29. 29. 30.  8.  7.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1] -> size -> 25 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  6.  1.] 
cards in discard: [ 8. 16.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16 16 11  6  1  8  2  0  3  0  0  8  8 10  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 29. 29. 30.  8.  7.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1] -> size -> 25 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 29.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[ 5.133597]
 [24.484526]
 [24.484526]
 [24.484526]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 29. 29. 30.  8.  7.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  8.  0.] 
adversary cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  3  0 16 16 11  6  1  8  2  0  3  0  0  8  8 10  6] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 129.6297607421875



action possibilites: [-1. 29.] 
expected returns: [[ 7.6728997]
 [25.620245 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  1.] 
cards in discard: [29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 29. 29. 30.  8.  7.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  8.  0.] 
adversary cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  3  0 16 16 11  6  1  8  2  0  3  0  0  8  8 10  6] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 14.591955184936523



action possibilites: [-1. 29.] 
expected returns: [[11.671131]
 [29.981085]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.] 
cards in discard: [29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 25. 29. 29. 30.  8.  7.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  8.  0.] 
adversary cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  3  0 16 16 11  6  1  8  2  0  3  0  0  8  8 10  6] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 18.8947811126709



action possibilites: [-1.] 
expected returns: [[27.57237]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [29.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 25. 29. 29. 30.  8.  7.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  8.  0.] 
adversary cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  3  0 16 16 11  6  1  8  2  0  3  0  0  8  8 10  6] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 24.05690574645996





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 28.808931]
 [ 43.87156 ]
 [ 32.340023]
 [-52.62812 ]
 [ 39.782497]
 [ 40.800255]
 [ 29.783117]
 [ 39.968643]
 [ 38.24514 ]
 [ 43.040833]
 [ 29.875288]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [29.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 29. 29. 30.  8.  7.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  8.  0.] 
adversary cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  3  0 16 16 11  6  1  8  2  0  3  0  0  8  8 10  6] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.572370529174805



buy possibilites: [-1] 
expected returns: [[36.189808]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [29.  1.  3.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 24. 29. 29. 30.  8.  7.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  8.  0.] 
adversary cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  3  0 16 16 11  6  1  8  2  0  3  0  0  8  8 10  6] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 158.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 43.87156677246094






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 3. 16.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  8.  0.] 
cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16 16 11  6  1  8  2  0  3  0  0  8  8 10  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 29. 29. 30.  8.  7.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 29.  0.] 
adversary cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1] -> size -> 26 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 16 11  6  1  8  2  0  3  0  0  8  8 10  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 29. 29. 30.  8.  7.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 29.  0.] 
adversary cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1] -> size -> 26 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 16 11  6  1  8  2  0  3  0  0  8  8 10  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 24. 29. 29. 30.  8.  7.  7.  9.  6.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 29.  0.] 
adversary cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1] -> size -> 26 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 16 11  6  1  8  2  0  3  0  0  8  8 10  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 29. 29. 30.  8.  7.  7.  9.  5.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 29.  0.] 
adversary cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1] -> size -> 26 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 1.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[13.11437 ]
 [31.335253]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 29.  0.] 
cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 29. 29. 30.  8.  7.  7.  9.  5.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  2.  0. 11.  0.] 
adversary cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.  8.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0 16 11  6  1  8  2  0  3  0  0  8  8 10  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.1898078918457



action possibilites: [-1.] 
expected returns: [[57.32541]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 24. 29. 29. 30.  8.  7.  7.  9.  5.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  2.  0. 11.  0.] 
adversary cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.  8.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0 16 11  6  1  8  2  0  3  0  0  8  8 10  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 25.168251037597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 55.580067]
 [ 69.77147 ]
 [ 58.870514]
 [-19.192013]
 [ 65.78418 ]
 [ 66.643684]
 [ 56.248844]
 [ 65.868256]
 [ 64.24419 ]
 [ 68.8173  ]
 [ 56.448067]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 24. 29. 29. 30.  8.  7.  7.  9.  5.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  2.  0. 11.  0.] 
adversary cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.  8.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0 16 11  6  1  8  2  0  3  0  0  8  8 10  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 57.325408935546875



buy possibilites: [-1] 
expected returns: [[67.69564]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  5.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  2.  0. 11.  0.] 
adversary cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.  8.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0 16 11  6  1  8  2  0  3  0  0  8  8 10  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 118.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 69.7714614868164






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 8.  2.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  2.  0. 11.  0.] 
cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.  8.  8.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16 11  6  1  8  2  0  3  0  0  8  8 10  6  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  5.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  1.] 
adversary cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.  1.  1. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1] -> size -> 27 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.  8.  8.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  5.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  1.] 
adversary cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.  1.  1. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1] -> size -> 27 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.  8.  8.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  5.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  1.] 
adversary cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.  1.  1. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1] -> size -> 27 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 16.  0.  0.  6. 10.  3.  0.  6.  1.  8.  8.  3.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  4.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  1.] 
adversary cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.  1.  1. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1] -> size -> 27 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0. 29. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[64.89731]
 [81.13239]
 [81.13239]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29.  1.] 
cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.  1.  1. 29.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  4.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.69564056396484



action possibilites: [-1. 29.] 
expected returns: [[115.347824]
 [130.8938  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 29.] 
cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.  1.  1. 29.  0.  0.  0.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  4.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 76.1774673461914



action possibilites: [-1. 29.] 
expected returns: [[82.41009 ]
 [97.859055]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.] 
cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.  1.  1. 29.  0.  0.  0.  3. 29.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  4.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 126.08871459960938



action possibilites: [-1.] 
expected returns: [[126.16658]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.  1.  1. 29.  0.  0.  0.  3. 29.  1.
 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  4.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 93.09788513183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[123.37094 ]
 [137.56458 ]
 [127.048386]
 [ 87.589516]
 [ 45.15077 ]
 [134.16956 ]
 [135.00716 ]
 [124.019   ]
 [138.14232 ]
 [134.30733 ]
 [137.90596 ]
 [132.61948 ]
 [133.49213 ]
 [136.91054 ]
 [125.805176]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.  1.  1. 29.  0.  0.  0.  3. 29.  1.
 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  4.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 126.16658020019531



buy possibilites: [-1] 
expected returns: [[106.48064]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29.  1.  3.  1. 29. 29. 29.  0.  3.  1.  1. 29.  0.  0.  0.  3. 29.  1.
 29. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  4.  8.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 395 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 138.14231872558594






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [6. 6. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  4.  8.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 29. 25.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25] -> size -> 28 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  4.  8.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 29. 25.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25] -> size -> 28 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 8.] 
cards in discard: [8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  3.  8.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 29. 25.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25] -> size -> 28 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 1. 29. 25.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-4.3997517]
 [16.050814 ]
 [10.397804 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 25.  1.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  3.  8.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 1. 8. 8. 3.] 
adversary cards in discard: [8. 6. 6. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8  8] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 106.48063659667969



action possibilites: [-1. 25. 29.] 
expected returns: [[ 3.077664]
 [17.086546]
 [22.095625]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0. 29.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  3.  8.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 1. 8. 8. 3.] 
adversary cards in discard: [8. 6. 6. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8  8] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 7.086721897125244



action possibilites: [-1. 25. 29.] 
expected returns: [[12.731913]
 [24.64094 ]
 [29.28831 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29.] 
cards in discard: [1. 1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  3.  8.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 1. 8. 8. 3.] 
adversary cards in discard: [8. 6. 6. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8  8] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 16.367185592651367



action possibilites: [-1. 25.] 
expected returns: [[61.072388]
 [73.13002 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.] 
cards in discard: [1. 1. 3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 23. 29. 29. 30.  8.  7.  7.  9.  3.  8.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 1. 8. 8. 3.] 
adversary cards in discard: [8. 6. 6. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8  8] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 24.268945693969727



action possibilites: [-1] 
expected returns: [[47.649406]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [1. 1. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 23. 29. 29. 30.  8.  6.  7.  9.  3.  8.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 1. 8. 8. 3.] 
adversary cards in discard: [8. 6. 6. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 73.13003540039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 45.464287]
 [ 59.582348]
 [ 13.955738]
 [ 48.50742 ]
 [ 13.621147]
 [-27.557434]
 [ 55.339912]
 [ 56.18865 ]
 [ 46.181274]
 [ 59.94759 ]
 [ 55.411484]
 [ 59.707027]
 [ 53.826263]
 [ 54.509148]
 [ 58.398506]
 [ 45.979305]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [1. 1. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 7 
card supply: [26. 23. 29. 29. 30.  8.  6.  7.  9.  3.  8.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 1. 8. 8. 3.] 
adversary cards in discard: [8. 6. 6. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.64940643310547



buy possibilites: [-1] 
expected returns: [[50.25791]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 1.  1.  3. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 23. 29. 29. 30.  8.  6.  7.  9.  3.  7.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 1. 8. 8. 3.] 
adversary cards in discard: [8. 6. 6. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 227.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 59.94760513305664






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [8. 1. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 8. 8. 3.] 
cards in discard: [8. 6. 6. 0. 0. 8. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16  6  1  8  0  3  0  0  8  8 10  6  8  8  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 29. 30.  8.  6.  7.  9.  3.  7.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0. 29.] 
adversary cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25] -> size -> 29 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3.] 
cards in discard: [8. 6. 6. 0. 0. 8. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8 10  6  8  8  8  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 29. 30.  8.  6.  7.  9.  3.  7.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0. 29.] 
adversary cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25] -> size -> 29 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3.] 
cards in discard: [8. 6. 6. 0. 0. 8. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8 10  6  8  8  8  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 23. 29. 29. 30.  8.  6.  7.  9.  3.  7.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0. 29.] 
adversary cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25] -> size -> 29 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3.] 
cards in discard: [8. 6. 6. 0. 0. 8. 6. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8 10  6  8  8  8  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 29. 29. 30.  8.  6.  7.  9.  3.  7.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0. 29.] 
adversary cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25] -> size -> 29 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [29. 29.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[ 8.800316]
 [25.893604]
 [25.893604]
 [25.893604]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0. 29.] 
cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 29. 29. 30.  8.  6.  7.  9.  3.  7.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0. 16.  0.] 
adversary cards in discard: [8. 6. 6. 0. 0. 8. 6. 0. 8. 8. 8. 3.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8 10  6  8  8  8  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.257911682128906



action possibilites: [-1. 29. 25.] 
expected returns: [[ 2.8322573]
 [21.000643 ]
 [16.007658 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 25.] 
cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 23. 29. 29. 30.  8.  6.  7.  9.  3.  7.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0. 16.  0.] 
adversary cards in discard: [8. 6. 6. 0. 0. 8. 6. 0. 8. 8. 8. 3.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8 10  6  8  8  8  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 20.717384338378906



action possibilites: [-1. 25.] 
expected returns: [[-15.980116 ]
 [ -3.4327505]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.] 
cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0. 29.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 23. 29. 29. 30.  8.  6.  7.  9.  3.  7.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0. 16.  0.] 
adversary cards in discard: [8. 6. 6. 0. 0. 8. 6. 0. 8. 8. 8. 3.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8 10  6  8  8  8  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 15.548009872436523



action possibilites: [-1] 
expected returns: [[27.627703]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0. 29.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 23. 29. 29. 30.  8.  5.  7.  9.  3.  7.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0. 16.  0.] 
adversary cards in discard: [8. 6. 6. 0. 0. 8. 6. 0. 8. 8. 8. 3. 6.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8 10  6  8  8  8  6  0  6] -> size -> 22 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -3.432715654373169





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 24.53763  ]
 [ 38.160385 ]
 [ -6.9182177]
 [ 27.749168 ]
 [ -8.109913 ]
 [ 30.114481 ]
 [-48.34353  ]
 [ 34.498737 ]
 [ 35.222088 ]
 [ 25.112663 ]
 [ 38.577686 ]
 [ 34.523148 ]
 [ 38.35778  ]
 [ 32.957104 ]
 [ 33.713978 ]
 [ 37.23103  ]
 [ 26.036087 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0. 29.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 8 
card supply: [25. 23. 29. 29. 30.  8.  5.  7.  9.  3.  7.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0. 16.  0.] 
adversary cards in discard: [8. 6. 6. 0. 0. 8. 6. 0. 8. 8. 8. 3. 6.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8 10  6  8  8  8  6  0  6] -> size -> 22 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.627702713012695



buy possibilites: [-1] 
expected returns: [[51.062653]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0. 29.  3. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 23. 29. 29. 30.  8.  5.  7.  9.  3.  6.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0. 16.  0.] 
adversary cards in discard: [8. 6. 6. 0. 0. 8. 6. 0. 8. 8. 8. 3. 6.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8 10  6  8  8  8  6  0  6] -> size -> 22 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  120.    0.    0.   60.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 237.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 38.577674865722656






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [10.  3.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 16.  0.] 
cards in discard: [8. 6. 6. 0. 0. 8. 6. 0. 8. 8. 8. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8 10  6  8  8  8  6  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 29. 29. 30.  8.  5.  7.  9.  3.  6.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0. 29.  3. 25. 29. 29. 25.  0.
  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25] -> size -> 30 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [8. 6. 6. 0. 0. 8. 6. 0. 8. 8. 8. 3. 6. 4.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 29. 29. 29.  8.  5.  7.  9.  3.  6.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0. 29.  3. 25. 29. 29. 25.  0.
  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25] -> size -> 30 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [8. 6. 6. 0. 0. 8. 6. 0. 8. 8. 8. 3. 6. 4.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 23. 29. 29. 29.  8.  5.  7.  9.  3.  6.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0. 29.  3. 25. 29. 29. 25.  0.
  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25] -> size -> 30 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [8. 6. 6. 0. 0. 8. 6. 0. 8. 8. 8. 3. 6. 4. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 29. 29. 29.  8.  5.  7.  9.  2.  6.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0. 29.  3. 25. 29. 29. 25.  0.
  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25] -> size -> 30 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-13.246391 ]
 [  3.5370355]
 [  3.5370355]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0. 29.] 
cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0. 29.  3. 25. 29. 29. 25.  0.
  0.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 29. 29. 29.  8.  5.  7.  9.  2.  6.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 51.062652587890625



action possibilites: [-1. 29.] 
expected returns: [[-13.507559 ]
 [  3.2489252]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.] 
cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0. 29.  3. 25. 29. 29. 25.  0.
  0.  1.  1. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 23. 29. 29. 29.  8.  5.  7.  9.  2.  6.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -1.6331337690353394



action possibilites: [-1.] 
expected returns: [[-21.890139]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0. 29.  3. 25. 29. 29. 25.  0.
  0.  1.  1. 29.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 23. 29. 29. 29.  8.  5.  7.  9.  2.  6.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -1.9451940059661865





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-23.41053  ]
 [ -9.985054 ]
 [-19.820845 ]
 [-84.182    ]
 [-13.54598  ]
 [-12.968252 ]
 [-23.7157   ]
 [-13.622311 ]
 [-15.265827 ]
 [-10.9958315]
 [-21.568214 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0. 29.  3. 25. 29. 29. 25.  0.
  0.  1.  1. 29.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 23. 29. 29. 29.  8.  5.  7.  9.  2.  6.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -21.890138626098633



buy possibilites: [-1] 
expected returns: [[-13.152611]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 1.  1.  3. 25. 29. 29. 29. 25.  0.  1.  0. 29.  3. 25. 29. 29. 25.  0.
  0.  1.  1. 29.  1.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 22. 29. 29. 29.  8.  5.  7.  9.  2.  6.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 108.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -9.985054016113281






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 29. 29. 29.  8.  5.  7.  9.  2.  6.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1] -> size -> 31 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 22. 29. 29. 29.  8.  5.  7.  9.  2.  6.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1] -> size -> 31 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 22. 29. 29. 29.  8.  5.  7.  9.  2.  6.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1] -> size -> 31 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29.  0. 25. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[-29.756376]
 [-11.547365]
 [-16.715466]
 [-11.547365]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25. 29.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 29. 29. 29.  8.  5.  7.  9.  2.  6.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 16.  8.  3.  8.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -13.152610778808594



action possibilites: [-1. 25. 29.] 
expected returns: [[-15.991787 ]
 [ -2.5510235]
 [  2.688311 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 29.] 
cards in discard: [29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 22. 29. 29. 29.  8.  5.  7.  9.  2.  6.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 16.  8.  3.  8.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -17.116065979003906



action possibilites: [-1. 25.] 
expected returns: [[11.990118]
 [25.18474 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.] 
cards in discard: [29.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 22. 29. 29. 29.  8.  5.  7.  9.  2.  6.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 16.  8.  3.  8.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -2.9217514991760254



action possibilites: [-1] 
expected returns: [[21.680315]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [29.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 22. 29. 29. 29.  8.  4.  7.  9.  2.  6.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 16.  8.  3.  8.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 25.18475914001465





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 19.768805]
 [ 33.11395 ]
 [ 23.181568]
 [-12.027294]
 [-51.006203]
 [ 29.633814]
 [ 30.545881]
 [ 20.333628]
 [ 33.701782]
 [ 29.821573]
 [ 33.45067 ]
 [ 28.235075]
 [ 28.976076]
 [ 32.473137]
 [ 21.02221 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [29.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 22. 29. 29. 29.  8.  4.  7.  9.  2.  6.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 16.  8.  3.  8.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.680315017700195



buy possibilites: [-1] 
expected returns: [[28.4615]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [29.  1. 25.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 29. 29. 29.  8.  4.  7.  9.  2.  5.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 16.  8.  3.  8.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 365 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 33.7017936706543






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 6. 16.  8.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  8.  3.  8.] 
cards in discard: [10.  0.  8.  0.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 29. 29. 29.  8.  4.  7.  9.  2.  5.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29. 25.] 
adversary cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25] -> size -> 32 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  8.  3.  8.] 
cards in discard: [10.  0.  8.  0.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 22. 29. 29. 29.  8.  4.  7.  9.  2.  5.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29. 25.] 
adversary cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25] -> size -> 32 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  3.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[11.088591]
 [29.129652]
 [29.129652]
 [24.170187]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 29. 25.] 
cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 29. 29. 29.  8.  4.  7.  9.  2.  5.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 6. 8. 8.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.  6.  6. 16.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.46150016784668



action possibilites: [-1. 25.] 
expected returns: [[30.71406]
 [42.01192]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.  0.] 
cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 22. 29. 29. 29.  8.  4.  7.  9.  2.  5.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 6. 8. 8.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.  6.  6. 16.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 23.718564987182617



action possibilites: [-1] 
expected returns: [[11.334236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 1.] 
cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 22. 29. 29. 29.  8.  3.  7.  9.  2.  5.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 6. 8. 8.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.  6.  6. 16.  8.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 42.011898040771484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  9.00861 ]
 [ 22.647638]
 [-22.429312]
 [ 12.206987]
 [-23.59655 ]
 [-63.719204]
 [ 18.965944]
 [ 19.674503]
 [  9.567968]
 [ 23.050451]
 [ 18.976545]
 [ 22.832977]
 [ 17.409399]
 [ 18.168682]
 [ 21.692408]
 [ 10.504292]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 1.] 
cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 7 
card supply: [25. 22. 29. 29. 29.  8.  3.  7.  9.  2.  5.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 6. 8. 8.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.  6.  6. 16.  8.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.334236145019531



buy possibilites: [-1] 
expected returns: [[29.198862]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 1.] 
cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0. 29. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 22. 29. 29. 29.  8.  3.  7.  9.  2.  4.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 6. 8. 8.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.  6.  6. 16.  8.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 187.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 23.050491333007812






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [0. 8. 6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 8. 8.] 
cards in discard: [10.  0.  8.  0.  0.  0.  6.  6. 16.  8.  3.  8.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 29. 29. 29.  8.  3.  7.  9.  2.  4.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  1. 29.] 
adversary cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0. 29. 25. 29. 25.  3.  0.  0.  1.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25] -> size -> 33 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 8. 8.] 
cards in discard: [10.  0.  8.  0.  0.  0.  6.  6. 16.  8.  3.  8.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 22. 29. 29. 29.  8.  3.  7.  9.  2.  4.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  1. 29.] 
adversary cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0. 29. 25. 29. 25.  3.  0.  0.  1.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25] -> size -> 33 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 8. 8.] 
cards in discard: [10.  0.  8.  0.  0.  0.  6.  6. 16.  8.  3.  8.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 22. 29. 29. 29.  8.  3.  7.  9.  2.  4.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  1. 29.] 
adversary cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0. 29. 25. 29. 25.  3.  0.  0.  1.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25] -> size -> 33 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0. 29.  1.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-23.171177 ]
 [ -6.4580426]
 [ -6.4580426]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  1. 29.] 
cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0. 29. 25. 29. 25.  3.  0.  0.  1.
  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 29. 29. 29.  8.  3.  7.  9.  2.  4.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 4. 3. 6. 8.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.  6.  6. 16.  8.  3.  8.  6.  0.  0.  8.  6.  8.
  8.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6  6  0] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.198862075805664



action possibilites: [-1. 29.] 
expected returns: [[-14.137211 ]
 [  1.7595425]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.  1.] 
cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0. 29. 25. 29. 25.  3.  0.  0.  1.
  1.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 22. 29. 29. 29.  8.  3.  7.  9.  2.  4.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 4. 3. 6. 8.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.  6.  6. 16.  8.  3.  8.  6.  0.  0.  8.  6.  8.
  8.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6  6  0] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -11.5880126953125



action possibilites: [-1. 25.] 
expected returns: [[-30.711708]
 [-26.036188]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25.] 
cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0. 29. 25. 29. 25.  3.  0.  0.  1.
  1.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 22. 29. 29. 29.  8.  3.  7.  9.  2.  4.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 4. 3. 6. 8.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.  6.  6. 16.  8.  3.  8.  6.  0.  0.  8.  6.  8.
  8.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6  6  0] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -3.162287712097168



action possibilites: [-1] 
expected returns: [[-10.148039]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1. 29.] 
cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0. 29. 25. 29. 25.  3.  0.  0.  1.
  1.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 22. 29. 29. 29.  8.  2.  7.  9.  2.  4.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 4. 3. 6. 8.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.  6.  6. 16.  8.  3.  8.  6.  0.  0.  8.  6.  8.
  8.  6.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6  6  0  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -26.036176681518555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -15.725042 ]
 [  -2.0559397]
 [ -46.32757  ]
 [ -12.138393 ]
 [ -47.755096 ]
 [-101.54169  ]
 [  -5.417049 ]
 [  -4.883432 ]
 [ -15.715931 ]
 [  -1.7044291]
 [  -5.5019207]
 [  -1.8837173]
 [  -7.1484885]
 [  -6.2136154]
 [  -3.0050406]
 [ -13.011665 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1. 29.] 
cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0. 29. 25. 29. 25.  3.  0.  0.  1.
  1.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 7 
card supply: [24. 22. 29. 29. 29.  8.  2.  7.  9.  2.  4.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 4. 3. 6. 8.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.  6.  6. 16.  8.  3.  8.  6.  0.  0.  8.  6.  8.
  8.  6.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6  6  0  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.148038864135742



buy possibilites: [-1] 
expected returns: [[-16.953056]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1. 29.] 
cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0. 29. 25. 29. 25.  3.  0.  0.  1.
  1.  1.  1. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 22. 29. 29. 29.  8.  2.  7.  9.  2.  3.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 4. 3. 6. 8.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.  6.  6. 16.  8.  3.  8.  6.  0.  0.  8.  6.  8.
  8.  6.] 
adversary owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6  6  0  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  120.    0.    0.   60.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 237.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -1.7044284343719482






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [6. 4. 3. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 4. 3. 6. 8.] 
cards in discard: [10.  0.  8.  0.  0.  0.  6.  6. 16.  8.  3.  8.  6.  0.  0.  8.  6.  8.
  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10
  6  6  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 29. 29. 29.  8.  2.  7.  9.  2.  3.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25.  3.  3. 29.  0.] 
adversary cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0. 29. 25. 29. 25.  3.  0.  0.  1.
  1.  1.  1. 25. 29. 29. 25.  0.  1.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25] -> size -> 34 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 4. 6.] 
cards in discard: [10.  0.  8.  0.  0.  0.  6.  6. 16.  8.  3.  8.  6.  0.  0.  8.  6.  8.
  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6
  6  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 29. 29. 29.  8.  2.  7.  9.  2.  3.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25.  3.  3. 29.  0.] 
adversary cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0. 29. 25. 29. 25.  3.  0.  0.  1.
  1.  1.  1. 25. 29. 29. 25.  0.  1.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25] -> size -> 34 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 4. 6.] 
cards in discard: [10.  0.  8.  0.  0.  0.  6.  6. 16.  8.  3.  8.  6.  0.  0.  8.  6.  8.
  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6
  6  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 22. 29. 29. 29.  8.  2.  7.  9.  2.  3.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25.  3.  3. 29.  0.] 
adversary cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0. 29. 25. 29. 25.  3.  0.  0.  1.
  1.  1.  1. 25. 29. 29. 25.  0.  1.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25] -> size -> 34 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [25.  3.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-14.343136 ]
 [ -2.4099195]
 [  2.3680844]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  3. 29.  0.] 
cards in discard: [29.  1. 25. 29. 29. 25.  0.  0. 29.  0. 29. 25. 29. 25.  3.  0.  0.  1.
  1.  1.  1. 25. 29. 29. 25.  0.  1.  1. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 29. 29. 29.  8.  2.  7.  9.  2.  3.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6
  6  0  6] -> size -> 27 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.95305633544922



action possibilites: [-1. 25. 25.] 
expected returns: [[19.711794]
 [32.49059 ]
 [32.49059 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0. 25.] 
cards in discard: [3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 22. 29. 29. 29.  8.  2.  7.  9.  2.  3.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6
  6  0  6] -> size -> 27 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -2.7599611282348633



action possibilites: [-1] 
expected returns: [[12.290098]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.  1. 25.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 22. 29. 29. 29.  8.  1.  7.  9.  2.  3.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6
  6  0  6  6] -> size -> 28 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 32.4906120300293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 13.066553]
 [ 26.415878]
 [ 16.427044]
 [-60.898796]
 [ 23.12467 ]
 [ 24.066349]
 [ 13.916637]
 [ 23.357824]
 [ 21.767223]
 [ 25.90491 ]
 [ 14.750212]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 25.  1. 25.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 22. 29. 29. 29.  8.  1.  7.  9.  2.  3.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6
  6  0  6  6] -> size -> 28 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.290098190307617



buy possibilites: [-1] 
expected returns: [[-3.3554778]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 25.  1. 25.] 
cards in discard: [3. 1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 21. 29. 29. 29.  8.  1.  7.  9.  2.  3.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6
  6  0  6  6] -> size -> 28 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: 228.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 26.4158878326416






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [8. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6
  6  0  6  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 21. 29. 29. 29.  8.  1.  7.  9.  2.  3.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 25. 29.  0. 29.] 
adversary cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1] -> size -> 35 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6  6  0  6
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 21. 29. 29. 29.  8.  1.  7.  9.  2.  3.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 25. 29.  0. 29.] 
adversary cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1] -> size -> 35 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6  6  0  6
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 21. 29. 29. 29.  8.  1.  7.  9.  2.  3.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 25. 29.  0. 29.] 
adversary cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1] -> size -> 35 
adversary victory points: 3
player victory points: -4 





Player: 0 
cards in hand: [25. 25. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29. 29.] 
expected returns: [[-21.522202]
 [-13.657034]
 [-13.657034]
 [-10.300491]
 [-10.300491]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 29.  0. 29.] 
cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 21. 29. 29. 29.  8.  1.  7.  9.  2.  3.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [6. 8. 8.] 
adversary owned cards: [ 0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6  6  0  6
  6] -> size -> 25 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -3.355477809906006



action possibilites: [-1. 25. 25. 29.] 
expected returns: [[15.189096]
 [26.657671]
 [26.657671]
 [31.202421]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0. 29.] 
cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 21. 29. 29. 29.  8.  1.  7.  9.  2.  3.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [6. 8. 8.] 
adversary owned cards: [ 0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6  6  0  6
  6] -> size -> 25 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -11.851137161254883



action possibilites: [-1. 25. 25.] 
expected returns: [[-5.9879475]
 [ 5.0433393]
 [ 5.0433393]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.] 
cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 21. 29. 29. 29.  8.  1.  7.  9.  2.  3.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [6. 8. 8.] 
adversary owned cards: [ 0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6  6  0  6
  6] -> size -> 25 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 26.28631591796875



action possibilites: [-1] 
expected returns: [[-5.8810287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25.  1.] 
cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 21. 29. 29. 29.  8.  0.  7.  9.  2.  3.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [6. 8. 8. 6.] 
adversary owned cards: [ 0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6  6  0  6
  6  6] -> size -> 26 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 5.043335437774658





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -8.263094  ]
 [  5.16534   ]
 [ -4.7730236 ]
 [-39.52687   ]
 [  1.8271079 ]
 [  2.3264704 ]
 [ -8.280228  ]
 [  5.4849687 ]
 [  1.7205343 ]
 [  5.312836  ]
 [  0.10731101]
 [  1.0238438 ]
 [  4.187618  ]
 [ -5.632824  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 25.  1.] 
cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 21. 29. 29. 29.  8.  0.  7.  9.  2.  3.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [6. 8. 8. 6.] 
adversary owned cards: [ 0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6  6  0  6
  6  6] -> size -> 26 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.881028652191162



buy possibilites: [-1] 
expected returns: [[5.4438434]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 25.  1.] 
cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 21. 29. 29. 29.  8.  0.  7.  9.  2.  2.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [6. 8. 8. 6.] 
adversary owned cards: [ 0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6  6  0  6
  6  6] -> size -> 26 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0 -10   0   0 250   0] 
sum of rewards: 505 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 5.484978199005127






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [6. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [6. 8. 8. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6  6  0  6
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 21. 29. 29. 29.  8.  0.  7.  9.  2.  2.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  1. 29.] 
adversary cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1. 25. 29. 29. 25. 25.  0. 25.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25] -> size -> 36 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [6. 8. 8. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6  6  0  6
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 21. 29. 29. 29.  8.  0.  7.  9.  2.  2.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  1. 29.] 
adversary cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1. 25. 29. 29. 25. 25.  0. 25.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25] -> size -> 36 
adversary victory points: 3
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [6. 8. 8. 6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6  6  0  6
  6  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 21. 29. 29. 29.  8.  0.  7.  9.  2.  2.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  1. 29.] 
adversary cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1. 25. 29. 29. 25. 25.  0. 25.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25] -> size -> 36 
adversary victory points: 3
player victory points: -5 





Player: 0 
cards in hand: [ 0. 29.  1.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-34.07969 ]
 [-23.823652]
 [-23.823652]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  1. 29.] 
cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1. 25. 29. 29. 25. 25.  0. 25.
  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 29. 29. 29.  8.  0.  7.  9.  2.  2.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 8. 6. 0. 8.] 
adversary cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0.] 
adversary owned cards: [ 0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6  6  0  6
  6  6  0] -> size -> 27 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.443843364715576



action possibilites: [-1. 25.] 
expected returns: [[-28.126059]
 [-16.126976]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 25.] 
cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1. 25. 29. 29. 25. 25.  0. 25.
  1.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 21. 29. 29. 29.  8.  0.  7.  9.  2.  2.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 8. 6. 0. 8.] 
adversary cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0.] 
adversary owned cards: [ 0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6  6  0  6
  6  6  0] -> size -> 27 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -27.023115158081055



action possibilites: [-1] 
expected returns: [[52.861736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0. 29.] 
cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1. 25. 29. 29. 25. 25.  0. 25.
  1.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 21. 29. 29. 29.  8.  0.  7.  9.  2.  2.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 8. 6. 0. 8.] 
adversary cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0.] 
adversary owned cards: [ 0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6  6  0  6
  6  6  0] -> size -> 27 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -16.126964569091797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[48.82599 ]
 [62.743057]
 [17.675863]
 [53.05562 ]
 [15.333956]
 [59.815342]
 [60.520996]
 [48.68261 ]
 [63.32807 ]
 [59.90712 ]
 [63.12494 ]
 [58.122513]
 [59.193268]
 [62.21795 ]
 [52.449497]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0. 29.] 
cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1. 25. 29. 29. 25. 25.  0. 25.
  1.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25] -> size -> 36 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 21. 29. 29. 29.  8.  0.  7.  9.  2.  2.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 8. 6. 0. 8.] 
adversary cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0.] 
adversary owned cards: [ 0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6  6  0  6
  6  6  0] -> size -> 27 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 52.86173629760742



buy possibilites: [-1] 
expected returns: [[19.318323]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0. 29.] 
cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1. 25. 29. 29. 25. 25.  0. 25.
  1.  0. 29. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 21. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 8. 6. 0. 8.] 
adversary cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0.] 
adversary owned cards: [ 0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6  6  0  6
  6  6  0] -> size -> 27 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  240.    0.    0.   40.    0.    0.    0.    0.  -20.
   0.    0.   62.5   0. ] 
sum of rewards: 317.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 63.32806396484375






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [6. 8. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 0. 8.] 
cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  6  8  0  3  0  0  8  8  6  8  8  8  6  0  6  4  8 10  6  6  0  6
  6  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  3. 29.] 
adversary cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1. 25. 29. 29. 25. 25.  0. 25.
  1.  0. 29. 25. 29. 25.  1.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25] -> size -> 37 
adversary victory points: 3
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  3. 29.] 
adversary cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1. 25. 29. 29. 25. 25.  0. 25.
  1.  0. 29. 25. 29. 25.  1.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25] -> size -> 37 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 21. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  3. 29.] 
adversary cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1. 25. 29. 29. 25. 25.  0. 25.
  1.  0. 29. 25. 29. 25.  1.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25] -> size -> 37 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  3. 29.] 
adversary cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1. 25. 29. 29. 25. 25.  0. 25.
  1.  0. 29. 25. 29. 25.  1.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25] -> size -> 37 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [ 1.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-33.83328 ]
 [-17.117836]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  3. 29.] 
cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1. 25. 29. 29. 25. 25.  0. 25.
  1.  0. 29. 25. 29. 25.  1.  1.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 6. 3. 6.] 
adversary cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0. 0. 8.] 
adversary owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.318323135375977



action possibilites: [-1.] 
expected returns: [[-7.6533275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3.] 
cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1. 25. 29. 29. 25. 25.  0. 25.
  1.  0. 29. 25. 29. 25.  1.  1.  0. 29.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 21. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 6. 3. 6.] 
adversary cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0. 0. 8.] 
adversary owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -22.249963760375977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ -9.86865   ]
 [  4.0299788 ]
 [ -5.9829464 ]
 [  0.5058389 ]
 [  1.1167135 ]
 [-10.26595   ]
 [  0.45504832]
 [ -1.2781155 ]
 [  3.0871263 ]
 [ -7.583278  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3.] 
cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1. 25. 29. 29. 25. 25.  0. 25.
  1.  0. 29. 25. 29. 25.  1.  1.  0. 29.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 21. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 6. 3. 6.] 
adversary cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0. 0. 8.] 
adversary owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -7.653327465057373



buy possibilites: [-1] 
expected returns: [[-9.116229]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3.] 
cards in discard: [ 3.  1. 29. 25.  3.  0. 25.  1. 25. 29.  1. 25. 29. 29. 25. 25.  0. 25.
  1.  0. 29. 25. 29. 25.  1.  1.  0. 29.  0. 29.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 20. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 6. 3. 6.] 
adversary cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0. 0. 8.] 
adversary owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   20.    0.    0.    0.    0.  -30.
   0.    0.   13.5   0. ] 
sum of rewards: 178.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 4.0299973487854






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [6. 0. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3. 6.] 
cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0. 0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 20. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1] -> size -> 38 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 6.] 
cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0. 0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 20. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1] -> size -> 38 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 6.] 
cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0. 0. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 20. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1] -> size -> 38 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [25. 29.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[-16.162111  ]
 [ -3.8954883 ]
 [  0.82743263]
 [  0.82743263]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  1. 29.  0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  0.  6.  4. 10.] 
adversary cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0. 0. 8. 0. 6. 0. 6. 3. 6.] 
adversary owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -9.116229057312012



action possibilites: [-1. 29.] 
expected returns: [[-4.212326]
 [14.624048]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.] 
cards in discard: [25. 29.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 20. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  0.  6.  4. 10.] 
adversary cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0. 0. 8. 0. 6. 0. 6. 3. 6.] 
adversary owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -4.3433403968811035



action possibilites: [-1.] 
expected returns: [[-5.294964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [25. 29.  0. 25.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 20. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  0.  6.  4. 10.] 
adversary cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0. 0. 8. 0. 6. 0. 6. 3. 6.] 
adversary owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 8.960763931274414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-5.5397434]
 [ 9.184513 ]
 [-2.0417829]
 [ 4.9520564]
 [ 5.978173 ]
 [-4.8657637]
 [ 5.130322 ]
 [ 3.4266806]
 [ 8.273357 ]
 [-5.1484995]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [25. 29.  0. 25.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 20. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  0.  6.  4. 10.] 
adversary cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0. 0. 8. 0. 6. 0. 6. 3. 6.] 
adversary owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.294963836669922



buy possibilites: [-1] 
expected returns: [[13.899878]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [25. 29.  0. 25.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 19. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  0.  6.  4. 10.] 
adversary cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0. 0. 8. 0. 6. 0. 6. 3. 6.] 
adversary owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   40.    0.    0.    0.    0.  -40.
   0.    0.   13.5   0. ] 
sum of rewards: 188.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 9.18453598022461






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [16.  0.  6.  4. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  4. 10.] 
cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0. 0. 8. 0. 6. 0. 6. 3. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 19. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 29. 29.  1.  0.] 
adversary cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1] -> size -> 39 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  4.  8.] 
cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0. 0. 8. 0. 6. 0. 6. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 19. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 29. 29.  1.  0.] 
adversary cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1] -> size -> 39 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  4.  8.] 
cards in discard: [6. 8. 8. 6. 0. 6. 0. 8. 0. 0. 0. 8. 0. 6. 0. 6. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 19. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 29. 29.  1.  0.] 
adversary cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1] -> size -> 39 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [ 1. 29. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-51.1231  ]
 [-38.562626]
 [-38.562626]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.  1.  0.] 
cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 19. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.899877548217773



action possibilites: [-1. 29.] 
expected returns: [[-13.860224 ]
 [  2.7155929]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  1.] 
cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 19. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -43.42985534667969



action possibilites: [-1.] 
expected returns: [[-19.183647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 19. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -2.427126407623291





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-22.747198]
 [ -9.064763]
 [-18.966986]
 [-12.286615]
 [-11.762745]
 [-22.914602]
 [-12.363647]
 [-14.051701]
 [ -9.944084]
 [-19.656404]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 19. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -19.18364715576172



buy possibilites: [-1] 
expected returns: [[12.940115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 18. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   40.    0.    0.    0.    0.  -50.
   0.    0.   13.5   0. ] 
sum of rewards: 178.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -9.064746856689453






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  6.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  1. 29.  0.] 
adversary cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1] -> size -> 40 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  8. 16.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  0  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 29. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  1. 29.  0.] 
adversary cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1] -> size -> 40 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8.] 
cards in discard: [3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [16  3  0  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 28. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  1. 29.  0.] 
adversary cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1] -> size -> 40 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 16.  8.] 
owned cards: [16  3  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 28. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  1. 29.  0.] 
adversary cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1] -> size -> 40 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 16.  8.] 
owned cards: [16  3  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 18. 29. 28. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  1. 29.  0.] 
adversary cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1] -> size -> 40 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [3. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 16.  8.] 
owned cards: [16  3  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0  0  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 18. 29. 28. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  1. 29.  0.] 
adversary cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1] -> size -> 40 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [29. 25.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[59.919533]
 [74.70189 ]
 [70.6069  ]
 [74.70189 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  1. 29.  0.] 
cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 18. 29. 28. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [ 3.  0. 10. 16.  8.  6.] 
adversary owned cards: [16  3  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0  0  3
  0] -> size -> 25 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.940114974975586



action possibilites: [-1. 25.] 
expected returns: [[39.3012  ]
 [50.273556]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25.] 
cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1. 25. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 18. 29. 28. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [ 3.  0. 10. 16.  8.  6.] 
adversary owned cards: [16  3  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0  0  3
  0] -> size -> 25 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 70.13938903808594



action possibilites: [-1] 
expected returns: [[4.67683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 25.] 
cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1. 25. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 18. 29. 28. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [ 3.  0. 10. 16.  8.  6.] 
adversary owned cards: [16  3  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0  0  3
  0] -> size -> 25 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 50.2735595703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-0.5900035 ]
 [12.887545  ]
 [ 3.203529  ]
 [ 9.867643  ]
 [10.522474  ]
 [-0.47545862]
 [ 9.915262  ]
 [ 8.248421  ]
 [12.243153  ]
 [ 2.5383582 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29. 25.] 
cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1. 25. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 18. 29. 28. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [ 3.  0. 10. 16.  8.  6.] 
adversary owned cards: [16  3  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0  0  3
  0] -> size -> 25 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.676829814910889



buy possibilites: [-1] 
expected returns: [[-0.6770711]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29. 25.] 
cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1. 25. 29.
  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 17. 29. 28. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [ 3.  0. 10. 16.  8.  6.] 
adversary owned cards: [16  3  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0  0  3
  0] -> size -> 25 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.   40.    0.    0.    0.    0.  -60.
   0.    0.   13.5   0. ] 
sum of rewards: 138.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 12.887535095214844






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [6. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [ 3.  0. 10. 16.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  0  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0  0  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 17. 29. 28. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  1. 25.  0.] 
adversary cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1. 25. 29.
  1. 29. 25.  1.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 3.  0. 10. 16.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0  0  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 17. 29. 28. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  1. 25.  0.] 
adversary cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1. 25. 29.
  1. 29. 25.  1.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 3.  0. 10. 16.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0  0  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 17. 29. 28. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  1. 25.  0.] 
adversary cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1. 25. 29.
  1. 29. 25.  1.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [29.  0.  1. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-5.320267]
 [11.4667  ]
 [ 6.700566]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1. 25.  0.] 
cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1. 25. 29.
  1. 29. 25.  1.  0. 29. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 17. 29. 28. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6. 0.] 
adversary cards in discard: [ 3.  0. 10. 16.  8.  6.  8.  6.  0.  0.] 
adversary owned cards: [16  3  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0  0  3  0] -> size -> 24 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6770710945129395



action possibilites: [-1. 25.] 
expected returns: [[-30.477772]
 [-18.544481]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25.] 
cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1. 25. 29.
  1. 29. 25.  1.  0. 29. 25. 25.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 17. 29. 28. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6. 0.] 
adversary cards in discard: [ 3.  0. 10. 16.  8.  6.  8.  6.  0.  0.] 
adversary owned cards: [16  3  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0  0  3  0] -> size -> 24 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 6.298264026641846



action possibilites: [-1] 
expected returns: [[18.449629]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1. 25. 29.
  1. 29. 25.  1.  0. 29. 25. 25.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 17. 29. 28. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6. 0.] 
adversary cards in discard: [ 3.  0. 10. 16.  8.  6.  8.  6.  0.  0.] 
adversary owned cards: [16  3  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0  0  3  0] -> size -> 24 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -18.544483184814453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 15.972925]
 [ 29.744375]
 [ 19.822851]
 [-13.570116]
 [ 26.270811]
 [ 26.80297 ]
 [ 15.482258]
 [ 30.097654]
 [ 26.167665]
 [ 29.915922]
 [ 24.449427]
 [ 25.436878]
 [ 28.74621 ]
 [ 18.449623]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1. 25. 29.
  1. 29. 25.  1.  0. 29. 25. 25.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 17. 29. 28. 29.  8.  0.  7.  9.  2.  1.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6. 0.] 
adversary cards in discard: [ 3.  0. 10. 16.  8.  6.  8.  6.  0.  0.] 
adversary owned cards: [16  3  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0  0  3  0] -> size -> 24 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.449628829956055



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 12 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 10 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [25. 29.  0. 25.  1. 29. 29.  1.  0.  0.  1. 25.  1. 29. 29.  1. 25. 29.
  1. 29. 25.  1.  0. 29. 25. 25.  0. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25  1  1
  1  1  1 25 25 25  1 25 25 25  1 25 25  1  1  1  1 25] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 17. 29. 28. 29.  8.  0.  7.  9.  2.  0.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6. 0.] 
adversary cards in discard: [ 3.  0. 10. 16.  8.  6.  8.  6.  0.  0.] 
adversary owned cards: [16  3  8  8  8  8  8  6  0  6  4  8 10  6  6  0  6  6  6  0  0  0  3  0] -> size -> 24 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     150       0       0      40       0       0
       0       0     -70       0       0     125       0] 
sum of rewards: 3000240 

action type: buy - action 25.0
Learning step: 120008.3984375
desired expected reward: 120038.5



