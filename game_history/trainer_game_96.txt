 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[283.56702]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   6  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 521 

action type: buy - action -1.0
Learning step: 21.999784469604492
desired expected reward: 103.0041275024414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[254.74504]
 [273.1041 ]
 [266.5026 ]
 [219.6086 ]
 [284.49783]
 [266.52655]
 [263.5322 ]
 [288.45416]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.289677619934082
desired expected reward: 276.4985046386719



buy possibilites: [-1] 
expected returns: [[249.18301]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 11.0
Learning step: -7.818275451660156
desired expected reward: 276.6795959472656






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  0.  3.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[276.6116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.336974143981934
desired expected reward: 242.84603881835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[259.76746]
 [278.07996]
 [269.6636 ]
 [226.82199]
 [267.4719 ]
 [286.2694 ]
 [272.6088 ]
 [271.39902]
 [242.77513]
 [267.1414 ]
 [257.94214]
 [285.92917]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.870067119598389
desired expected reward: 268.671142578125



buy possibilites: [-1] 
expected returns: [[276.5824]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -6.710076808929443
desired expected reward: 262.9535217285156






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[271.45184]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.230396270751953
desired expected reward: 269.35198974609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[241.64096]
 [257.79788]
 [250.83952]
 [207.36526]
 [248.50517]
 [266.46347]
 [252.74742]
 [251.75786]
 [224.22668]
 [248.72653]
 [240.24696]
 [268.84335]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -7.576025485992432
desired expected reward: 265.7005920410156



buy possibilites: [-1] 
expected returns: [[273.65448]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 41 

action type: buy - action 15.0
Learning step: -3.8051230907440186
desired expected reward: 236.4418487548828






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [15.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  3.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [15.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  3.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [15.  0.  3.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  3.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 3. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[288.36194]
 [288.4813 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.  0.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -6.742954254150391
desired expected reward: 266.9115295410156



action possibilites: [-1] 
expected returns: [[233.38643]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [15.  0.  0.  0.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    3    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -282 

action type: gain_card_n - action 3
Learning step: -23.53985595703125
desired expected reward: 270.2811584472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[210.9256 ]
 [220.19695]
 [172.65378]
 [222.25941]
 [236.54031]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [15.  0.  0.  0.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -5.89120626449585
desired expected reward: 227.49522399902344






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[253.13753]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11.  0. 10. 15.  0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -6.239776134490967
desired expected reward: 230.30050659179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[222.85147]
 [240.37114]
 [234.29254]
 [188.0848 ]
 [249.77454]
 [233.71774]
 [231.31387]
 [253.29247]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11.  0. 10. 15.  0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.43808126449585
desired expected reward: 245.3280792236328



buy possibilites: [-1] 
expected returns: [[250.441]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11.  0. 10. 15.  0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -5.52970552444458
desired expected reward: 228.76284790039062






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [11.  0. 10. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 15.  0.] 
cards in discard: [8. 3. 0. 3. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 11.  3.  6.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 15.  0.] 
cards in discard: [8. 3. 0. 3. 0. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  8.  9. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 11.  3.  6.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6  3] -> size -> 15 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 15.  0.] 
cards in discard: [8. 3. 0. 3. 0. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  8.  9. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 11.  3.  6.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6  3] -> size -> 15 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 15.  0.] 
cards in discard: [8. 3. 0. 3. 0. 3. 6. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 11.  3.  6.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6  3] -> size -> 15 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 0.  3. 11.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[222.54518]
 [221.96208]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.  6.] 
cards in discard: [3. 3. 0. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: -6.645389080047607
desired expected reward: 243.7956085205078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[187.95468]
 [157.09581]
 [210.95186]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.  6.] 
cards in discard: [3. 3. 0. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -5.199914455413818
desired expected reward: 203.25714111328125



buy possibilites: [-1] 
expected returns: [[223.02644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.  6.] 
cards in discard: [3. 3. 0. 0. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -11.0 

action type: buy - action 0.0
Learning step: -4.9296393394470215
desired expected reward: 183.02503967285156






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[188.58221]
 [163.70673]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 15  6  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [3. 8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -6.706912517547607
desired expected reward: 216.3195343017578



action possibilites: [-1] 
expected returns: [[190.62056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [3. 8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action 15.0
Learning step: -2.4045753479003906
desired expected reward: 160.4661865234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[169.8008 ]
 [184.49179]
 [161.21347]
 [177.24118]
 [149.4779 ]
 [138.65706]
 [176.41428]
 [188.54703]
 [180.0899 ]
 [200.73036]
 [178.91084]
 [152.57011]
 [161.30066]
 [173.87375]
 [145.46922]
 [166.29596]
 [188.91377]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [3. 8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1
Learning step: -4.128219127655029
desired expected reward: 186.49234008789062



buy possibilites: [-1] 
expected returns: [[201.44415]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [3. 8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.  10.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 33.5 

action type: buy - action 1.0
Learning step: -3.0170962810516357
desired expected reward: 181.47470092773438






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [3. 8. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 3. 3. 0. 3.] 
adversary cards in discard: [ 1. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [3. 8. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 3. 3. 0. 3.] 
adversary cards in discard: [ 1. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [3. 8. 0. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 3. 3. 0. 3.] 
adversary cards in discard: [ 1. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [6. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[166.95938]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 3.] 
cards in discard: [ 1. 15.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  0.  0.  3.  6.] 
adversary cards in discard: [3. 8. 0. 0. 0. 0. 0. 3. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8  3  0] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -5.82958459854126
desired expected reward: 195.61456298828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[146.50674]
 [122.1813 ]
 [169.7111 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 3.] 
cards in discard: [ 1. 15.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  0.  0.  3.  6.] 
adversary cards in discard: [3. 8. 0. 0. 0. 0. 0. 3. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8  3  0] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -4.595332622528076
desired expected reward: 163.96571350097656



buy possibilites: [-1] 
expected returns: [[166.67325]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 3.] 
cards in discard: [ 1. 15.  0.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  7. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  0.  0.  3.  6.] 
adversary cards in discard: [3. 8. 0. 0. 0. 0. 0. 3. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8  3  0] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -302.0 

action type: buy - action 6.0
Learning step: -17.45891761779785
desired expected reward: 104.72239685058594






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [15.  0.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  3.  6.] 
cards in discard: [3. 8. 0. 0. 0. 0. 0. 3. 0. 8. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  7. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [ 1. 15.  0.  0.  0.  6.  6.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  3.  6.] 
cards in discard: [3. 8. 0. 0. 0. 0. 0. 3. 0. 8. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  7. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [ 1. 15.  0.  0.  0.  6.  6.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  3.  6.] 
cards in discard: [3. 8. 0. 0. 0. 0. 0. 3. 0. 8. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8  3  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [ 1. 15.  0.  0.  0.  6.  6.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[189.5216]
 [188.1279]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [ 1. 15.  0.  0.  0.  6.  6.  3.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8  3  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -4.314940929412842
desired expected reward: 162.35830688476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[169.79468]
 [178.08351]
 [142.00325]
 [177.92186]
 [190.19736]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [ 1. 15.  0.  0.  0.  6.  6.  3.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8  3  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -5.345617294311523
desired expected reward: 178.28111267089844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 15 11  8  6  8  3  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [15.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[166.70804]
 [142.55591]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [ 0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -6.106530666351318
desired expected reward: 184.09080505371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[149.58324]
 [165.58446]
 [157.35216]
 [112.44134]
 [172.19011]
 [160.9431 ]
 [154.89287]
 [170.44806]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  8.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [ 0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -4.80283784866333
desired expected reward: 160.5438995361328



buy possibilites: [-1] 
expected returns: [[151.25044]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  3.  0.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [ 0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 11.0
Learning step: -4.406369209289551
desired expected reward: 167.78370666503906






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0.  0.] 
cards in discard: [ 0.  8.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 1. 3. 6. 0.] 
adversary cards in discard: [11. 15.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.  0.] 
cards in discard: [ 0.  8.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 1. 3. 6. 0.] 
adversary cards in discard: [11. 15.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.  0.] 
cards in discard: [ 0.  8.  0. 11. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 1. 3. 6. 0.] 
adversary cards in discard: [11. 15.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 1. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[166.714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 6. 0.] 
cards in discard: [11. 15.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  8.  0. 11. 14.  0.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0 14] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -4.033451557159424
desired expected reward: 147.2169952392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[143.45218]
 [158.23889]
 [150.95699]
 [110.9616 ]
 [149.74205]
 [164.3909 ]
 [154.1884 ]
 [153.00969]
 [127.44306]
 [149.15967]
 [141.5462 ]
 [163.80226]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 6. 0.] 
cards in discard: [11. 15.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  8.  0. 11. 14.  0.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0 14] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -4.782779216766357
desired expected reward: 156.50926208496094



buy possibilites: [-1] 
expected returns: [[122.23319]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 6. 0.] 
cards in discard: [11. 15.  0.  0.  3.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  8.  0. 11. 14.  0.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0 14] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 29.0
Learning step: -3.0850186347961426
desired expected reward: 143.6202850341797






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [ 0.  8.  0. 11. 14.  0.  0. 15.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0 14] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  6. 11.] 
adversary cards in discard: [11. 15.  0.  0.  3.  0. 29.  0.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [ 0.  8.  0. 11. 14.  0.  0. 15.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0 14] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  6. 11.] 
adversary cards in discard: [11. 15.  0.  0.  3.  0. 29.  0.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  0.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[137.4167 ]
 [136.99408]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  6. 11.] 
cards in discard: [11. 15.  0.  0.  3.  0. 29.  0.  1.  3.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [ 0.  8.  0. 11. 14.  0.  0. 15.  0.  0.  3.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0 14] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -3.240800142288208
desired expected reward: 118.99239349365234



action possibilites: [-1] 
expected returns: [[118.89735]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6.] 
cards in discard: [11. 15.  0.  0.  3.  0. 29.  0.  1.  3.  6.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [ 0.  8.  0. 11. 14.  0.  0. 15.  0.  0.  3.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0 14] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 27 

action type: gain_card_n - action 9
Learning step: -2.6294350624084473
desired expected reward: 130.4630584716797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[103.57403 ]
 [ 74.07015 ]
 [123.271805]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6.] 
cards in discard: [11. 15.  0.  0.  3.  0. 29.  0.  1.  3.  6.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [ 0.  8.  0. 11. 14.  0.  0. 15.  0.  0.  3.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0 14] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -2.695728063583374
desired expected reward: 116.20162200927734






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [ 0.  8.  0. 11. 14.  0.  0. 15.  0.  0.  3.  3.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0 14] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [ 0.  8.  0. 11. 14.  0.  0. 15.  0.  0.  3.  3.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0 14] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  7.  8. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [ 0.  8.  0. 11. 14.  0.  0. 15.  0.  0.  3.  3.  0.  8.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0 14  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  7. 10.  7.  8. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10] -> size -> 20 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 1.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[124.294304]
 [111.32273 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  7. 10.  7.  8. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0 14  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -4.133308410644531
desired expected reward: 119.13848876953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[103.32129 ]
 [118.62656 ]
 [111.19485 ]
 [ 73.39515 ]
 [109.86179 ]
 [124.39132 ]
 [113.94874 ]
 [112.714066]
 [ 86.75287 ]
 [108.7158  ]
 [100.96205 ]
 [124.18542 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 26. 30.  8.  7. 10.  7.  8. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0 14  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -4.233451843261719
desired expected reward: 118.10838317871094



buy possibilites: [-1] 
expected returns: [[91.53338]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  0.  3.] 
cards in discard: [14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  7. 10.  7.  8. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0 14  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 20 

action type: buy - action 14.0
Learning step: -1.2781429290771484
desired expected reward: 85.4747314453125






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 11  8  6  8  3  0  0  0 14  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  7. 10.  7.  8. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 3. 3. 6.] 
adversary cards in discard: [14.  1.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14] -> size -> 21 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  7. 10.  7.  8. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 3. 3. 6.] 
adversary cards in discard: [14.  1.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14] -> size -> 21 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  7. 10.  7.  8. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 3. 3. 6.] 
adversary cards in discard: [14.  1.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14] -> size -> 21 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[99.06442]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 6.] 
cards in discard: [14.  1.  0. 10.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  7. 10.  7.  8. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 14. 15.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -3.4886415004730225
desired expected reward: 88.04473876953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[77.35883 ]
 [50.773174]
 [97.76547 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 6.] 
cards in discard: [14.  1.  0. 10.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  7. 10.  7.  8. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 14. 15.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -4.177793025970459
desired expected reward: 93.06788635253906



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14. 15.] 
cards in discard: [8. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  7. 10.  7.  8. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  3.  0. 15.] 
adversary cards in discard: [14.  1.  0. 10.  0.  3.  0.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14] -> size -> 21 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [8. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  7. 10.  7.  8. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [11.  0. 15.] 
adversary cards in discard: [14.  1.  0. 10.  0.  3.  0.  3.  3.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14] -> size -> 21 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [8. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 29. 30. 26. 30.  8.  7. 10.  7.  8. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [11.  0. 15.] 
adversary cards in discard: [14.  1.  0. 10.  0.  3.  0.  3.  3.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14] -> size -> 21 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [8. 0. 0. 4.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  8. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [11.  0. 15.] 
adversary cards in discard: [14.  1.  0. 10.  0.  3.  0.  3.  3.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14] -> size -> 21 
adversary victory points: 3
player victory points: 8 





Player: 0 
cards in hand: [11.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[145.08116 ]
 [144.55887 ]
 [121.839035]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 15.] 
cards in discard: [14.  1.  0. 10.  0.  3.  0.  3.  3.  3.  6.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  8. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 11.  3.] 
adversary cards in discard: [ 8.  0.  0.  4. 14.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    3  -50    0    0    0    0    0    0    0    0    0 -600
   43    0] 
sum of rewards: -609 

action type: discard_down_to_3_cards - action 3
Learning step: -31.167993545532227
desired expected reward: 42.94806671142578



action possibilites: [-1] 
expected returns: [[135.46782]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.] 
cards in discard: [14.  1.  0. 10.  0.  3.  0.  3.  3.  3.  6.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 11.  3.] 
adversary cards in discard: [ 8.  0.  0.  4. 14.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -23 

action type: gain_card_n - action 9
Learning step: -5.210257530212402
desired expected reward: 136.95541381835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[119.055084]
 [ 89.84195 ]
 [137.75754 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.] 
cards in discard: [14.  1.  0. 10.  0.  3.  0.  3.  3.  3.  6.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 11.  3.] 
adversary cards in discard: [ 8.  0.  0.  4. 14.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1
Learning step: -5.684267520904541
desired expected reward: 129.78355407714844



buy possibilites: [-1] 
expected returns: [[126.06049]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.] 
cards in discard: [14.  1.  0. 10.  0.  3.  0.  3.  3.  3.  6.  0.  3. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 26. 29.  8.  7. 10.  7.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 11.  3.] 
adversary cards in discard: [ 8.  0.  0.  4. 14.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -62.0 

action type: buy - action 0.0
Learning step: -6.061061859130859
desired expected reward: 112.9940185546875






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  3.] 
cards in discard: [ 8.  0.  0.  4. 14.  0.  0.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  7. 10.  7.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  0. 29.  6.] 
adversary cards in discard: [14.  1.  0. 10.  0.  3.  0.  3.  3.  3.  6.  0.  3. 10.  0. 11.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0] -> size -> 23 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  3.] 
cards in discard: [ 8.  0.  0.  4. 14.  0.  0.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 26. 29.  8.  7. 10.  7.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  0. 29.  6.] 
adversary cards in discard: [14.  1.  0. 10.  0.  3.  0.  3.  3.  3.  6.  0.  3. 10.  0. 11.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0] -> size -> 23 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  3.] 
cards in discard: [ 8.  0.  0.  4. 14.  0.  0.  0. 15.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 26. 29.  8.  7. 10.  7.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  0. 29.  6.] 
adversary cards in discard: [14.  1.  0. 10.  0.  3.  0.  3.  3.  3.  6.  0.  3. 10.  0. 11.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0] -> size -> 23 
adversary victory points: 3
player victory points: 8 





Player: 0 
cards in hand: [11.  0.  0. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[63.9651  ]
 [63.789486]
 [54.64965 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29.  6.] 
cards in discard: [14.  1.  0. 10.  0.  3.  0.  3.  3.  3.  6.  0.  3. 10.  0. 11.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  7. 10.  7.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [ 8.  0.  0.  4. 14.  0.  0.  0. 15.  0.  3.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0] -> size -> 21 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1
Learning step: -7.522282600402832
desired expected reward: 118.5382080078125



action possibilites: [-1. 11.] 
expected returns: [[105.23382]
 [103.56307]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 26. 29.  8.  7. 10.  7.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [ 8.  0.  0.  4. 14.  0.  0.  0. 15.  0.  3.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0] -> size -> 21 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action 29.0
Learning step: -1.9801619052886963
desired expected reward: 52.66949462890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 84.12975 ]
 [ 98.853546]
 [ 94.356895]
 [ 62.179195]
 [106.32905 ]
 [ 92.6037  ]
 [ 90.62021 ]
 [108.673035]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 26. 29.  8.  7. 10.  7.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [ 8.  0.  0.  4. 14.  0.  0.  0. 15.  0.  3.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0] -> size -> 21 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -4.720673561096191
desired expected reward: 100.51315307617188



buy possibilites: [-1] 
expected returns: [[137.59572]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  6.  3.] 
cards in discard: [11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [ 8.  0.  0.  4. 14.  0.  0.  0. 15.  0.  3.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0] -> size -> 21 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -14 

action type: buy - action 11.0
Learning step: -2.9205501079559326
desired expected reward: 103.40852355957031






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [ 8.  0.  0.  4. 14.  0.  0.  0. 15.  0.  3.  0.  0. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 15. 10.  0.  0.] 
adversary cards in discard: [11. 29. 11.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11] -> size -> 24 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [ 8.  0.  0.  4. 14.  0.  0.  0. 15.  0.  3.  0.  0. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 26. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 15. 10.  0.  0.] 
adversary cards in discard: [11. 29. 11.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11] -> size -> 24 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [ 8.  0.  0.  4. 14.  0.  0.  0. 15.  0.  3.  0.  0. 11.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 26. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 15. 10.  0.  0.] 
adversary cards in discard: [11. 29. 11.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11] -> size -> 24 
adversary victory points: 3
player victory points: 8 





Player: 0 
cards in hand: [ 0. 15. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[64.21209]
 [46.13651]
 [51.51144]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10.  0.  0.] 
cards in discard: [11. 29. 11.  0.  0.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0] -> size -> 22 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1
Learning step: -8.28396224975586
desired expected reward: 129.31175231933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[47.194836]
 [59.24896 ]
 [54.794968]
 [25.338053]
 [64.010445]
 [54.486458]
 [51.760635]
 [64.45968 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10.  0.  0.] 
cards in discard: [11. 29. 11.  0.  0.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 26. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0] -> size -> 22 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1.0
Learning step: -4.444110870361328
desired expected reward: 57.08387756347656



buy possibilites: [-1] 
expected returns: [[81.77053]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10.  0.  0.] 
cards in discard: [11. 29. 11.  0.  0.  6.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 29. 30. 26. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0] -> size -> 22 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -82.0 

action type: buy - action 0.0
Learning step: -4.6199049949646
desired expected reward: 42.57493591308594






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [11. 29. 11.  0.  0.  6.  3.  0.  0. 15. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11
  0] -> size -> 25 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 26. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [11. 29. 11.  0.  0.  6.  3.  0.  0. 15. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11
  0] -> size -> 25 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 25. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [11. 29. 11.  0.  0.  6.  3.  0.  0. 15. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11
  0] -> size -> 25 
adversary victory points: 3
player victory points: 9 





Player: 0 
cards in hand: [0. 3. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[74.80827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 1.] 
cards in discard: [11. 29. 11.  0.  0.  6.  3.  0.  0. 15. 10.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 25. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [3. 0. 4. 0. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3] -> size -> 23 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -62 

action type: buy - action -1
Learning step: -5.505340576171875
desired expected reward: 76.26519012451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[64.96307 ]
 [76.90598 ]
 [72.455055]
 [45.872604]
 [69.874916]
 [80.11794 ]
 [72.19314 ]
 [71.22271 ]
 [54.094456]
 [68.61322 ]
 [63.426594]
 [79.84804 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 1.] 
cards in discard: [11. 29. 11.  0.  0.  6.  3.  0.  0. 15. 10.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 29. 30. 25. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [3. 0. 4. 0. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3] -> size -> 23 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -62 

action type: take_action - action -1.0
Learning step: -5.2562031745910645
desired expected reward: 69.55207061767578



buy possibilites: [-1] 
expected returns: [[34.79214]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 1.] 
cards in discard: [11. 29. 11.  0.  0.  6.  3.  0.  0. 15. 10.  0.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11
  0 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 25. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [3. 0. 4. 0. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3] -> size -> 23 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -30 

action type: buy - action 15.0
Learning step: -3.8885066509246826
desired expected reward: 59.5380859375






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [3. 0. 4. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 4. 0. 3.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 25. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 11. 14. 10.  3.] 
adversary cards in discard: [11. 29. 11.  0.  0.  6.  3.  0.  0. 15. 10.  0.  0. 15.  0.  3.  0.  6.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11
  0 15] -> size -> 26 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 4. 0. 3.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 25. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 11. 14. 10.  3.] 
adversary cards in discard: [11. 29. 11.  0.  0.  6.  3.  0.  0. 15. 10.  0.  0. 15.  0.  3.  0.  6.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11
  0 15] -> size -> 26 
adversary victory points: 3
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 11. 14. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 10.] 
expected returns: [[32.876236 ]
 [35.162712 ]
 [ 1.2682047]
 [20.401373 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 14. 10.  3.] 
cards in discard: [11. 29. 11.  0.  0.  6.  3.  0.  0. 15. 10.  0.  0. 15.  0.  3.  0.  6.
  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11
  0 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 25. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 0. 14.  0.  0. 15.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3. 3. 0. 4. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3] -> size -> 23 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -62 

action type: buy - action -1
Learning step: -4.283830165863037
desired expected reward: 30.508310317993164



action possibilites: [-1] 
expected returns: [[60.13934]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  3.] 
cards in discard: [11. 29. 11.  0.  0.  6.  3.  0.  0. 15. 10.  0.  0. 15.  0.  3.  0.  6.
  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11
  0 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 25. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 0.  0. 15.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  3.  0.  4.  0.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3] -> size -> 23 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action 14.0
Learning step: -0.8102748990058899
desired expected reward: 0.4579240679740906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[52.176376]
 [57.830433]
 [34.4108  ]
 [59.596397]
 [64.72947 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.  3.] 
cards in discard: [11. 29. 11.  0.  0.  6.  3.  0.  0. 15. 10.  0.  0. 15.  0.  3.  0.  6.
  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11
  0 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 25. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 0.  0. 15.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  3.  0.  4.  0.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3] -> size -> 23 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1
Learning step: -3.8535053730010986
desired expected reward: 56.28583526611328



buy possibilites: [-1] 
expected returns: [[25.558508]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.  3.] 
cards in discard: [11. 29. 11.  0.  0.  6.  3.  0.  0. 15. 10.  0.  0. 15.  0.  3.  0.  6.
  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11
  0 15  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 0.  0. 15.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  3.  0.  4.  0.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3] -> size -> 23 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -23 

action type: buy - action 3.0
Learning step: -3.4664559364318848
desired expected reward: 54.363990783691406






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  3.  0.  4.  0.  3.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11
  0 15  3] -> size -> 27 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  3.  0.  4.  0.  3.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 24. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11
  0 15  3] -> size -> 27 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  3.  0.  4.  0.  3.  0. 14.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11
  0 15  3] -> size -> 27 
adversary victory points: 4
player victory points: 10 





Player: 0 
cards in hand: [15.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[66.37223]
 [52.99531]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11
  0 15  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  3.  0.  4.  0.  3.  0. 14.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3] -> size -> 24 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: buy - action -1
Learning step: -3.0561139583587646
desired expected reward: 22.50239372253418



action possibilites: [-1] 
expected returns: [[25.598013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 29. 30. 23. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  3.  0.  4.  0.  3.  0. 14.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3] -> size -> 24 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action 15.0
Learning step: -3.878117799758911
desired expected reward: 45.38947677612305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[14.949817 ]
 [21.42435  ]
 [19.555817 ]
 [ 3.3495018]
 [-1.9558178]
 [17.733837 ]
 [23.978336 ]
 [18.881905 ]
 [28.148151 ]
 [18.427366 ]
 [ 5.6313686]
 [11.357071 ]
 [17.419666 ]
 [ 1.4941423]
 [14.310971 ]
 [23.670475 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 29. 30. 23. 29.  8.  7. 10.  6.  8. 10.  9.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  3.  0.  4.  0.  3.  0. 14.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3] -> size -> 24 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action -1
Learning step: -2.9414517879486084
desired expected reward: 22.65656089782715



buy possibilites: [-1] 
expected returns: [[66.60874]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 23. 29.  8.  7. 10.  6.  8. 10.  8.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  3.  0.  4.  0.  3.  0. 14.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3] -> size -> 24 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -33.0 

action type: buy - action 29.0
Learning step: -1.0726714134216309
desired expected reward: 17.35468864440918






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  0.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  3.  0.  4.  0.  3.  0. 14.  3.  0.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  7. 10.  6.  8. 10.  8.  8. 10.  7. 10.  7.] 
adversary cards in hand: [11.  6. 15.  0.  0.] 
adversary cards in discard: [29. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29] -> size -> 27 
adversary victory points: 4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.  0.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  3.  0.  4.  0.  3.  0. 14.  3.  0.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 23. 29.  8.  7. 10.  6.  8. 10.  8.  8. 10.  7. 10.  7.] 
adversary cards in hand: [11.  6. 15.  0.  0.] 
adversary cards in discard: [29. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29] -> size -> 27 
adversary victory points: 4
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.  0.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  3.  0.  4.  0.  3.  0. 14.  3.  0.  0. 15.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 23. 29.  8.  7. 10.  6.  8. 10.  8.  8. 10.  7. 10.  7.] 
adversary cards in hand: [11.  6. 15.  0.  0.] 
adversary cards in discard: [29. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29] -> size -> 27 
adversary victory points: 4
player victory points: 10 





Player: 0 
cards in hand: [11.  6. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[31.52688 ]
 [32.182938]
 [23.35916 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 15.  0.  0.] 
cards in discard: [29. 15.  0.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 23. 29.  8.  7. 10.  6.  8. 10.  8.  8. 10.  7. 10.  7.] 
adversary cards in hand: [8. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1] -> size -> 25 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: buy - action -1
Learning step: -5.717672824859619
desired expected reward: 60.89106750488281



action possibilites: [-1] 
expected returns: [[48.240692]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.  0.] 
cards in discard: [29. 15.  0.  3.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 23. 29.  8.  7. 10.  6.  8. 10.  7.  8. 10.  7. 10.  7.] 
adversary cards in hand: [8. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1] -> size -> 25 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -25 

action type: gain_card_n - action 7
Learning step: -1.1145572662353516
desired expected reward: 17.884899139404297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[40.128304]
 [43.57905 ]
 [23.401718]
 [43.90965 ]
 [47.553146]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0.  0.] 
cards in discard: [29. 15.  0.  3.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 23. 29.  8.  7. 10.  6.  8. 10.  7.  8. 10.  7. 10.  7.] 
adversary cards in hand: [8. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1] -> size -> 25 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action -1
Learning step: -3.536968231201172
desired expected reward: 44.7037239074707



buy possibilites: [-1] 
expected returns: [[0.8155849]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0.  0.] 
cards in discard: [29. 15.  0.  3.  0. 29.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  8. 10.  7. 10.  7.] 
adversary cards in hand: [8. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1] -> size -> 25 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -22 

action type: buy - action 3.0
Learning step: -3.2606022357940674
desired expected reward: 40.31845474243164






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 14.  0.  0. 29.] 
adversary cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3] -> size -> 29 
adversary victory points: 5
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 14.  0.  0. 29.] 
adversary cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3] -> size -> 29 
adversary victory points: 5
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3. 8.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 14.  0.  0. 29.] 
adversary cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3] -> size -> 29 
adversary victory points: 5
player victory points: 10 





Player: 0 
cards in hand: [ 3. 14.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
expected returns: [[62.247856]
 [48.178402]
 [56.838947]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0. 29.] 
cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  8. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 8. 0. 3. 3. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0] -> size -> 26 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1
Learning step: -1.2602049112319946
desired expected reward: -0.4446200132369995



action possibilites: [-1] 
expected returns: [[20.911472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.] 
cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  8. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 8. 0. 3. 3. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0] -> size -> 26 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action 14.0
Learning step: -3.4384124279022217
desired expected reward: 44.739994049072266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.705435]
 [25.108732]
 [23.330965]
 [13.447026]
 [23.418705]
 [24.68242 ]
 [24.259504]
 [23.80468 ]
 [16.655756]
 [21.98127 ]
 [20.077032]
 [23.55522 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.] 
cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 28. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  8. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 8. 0. 3. 3. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0] -> size -> 26 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1
Learning step: -2.041123151779175
desired expected reward: 18.870349884033203



buy possibilites: [-1] 
expected returns: [[19.848595]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.] 
cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 8. 0. 3. 3. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0] -> size -> 26 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 2 

action type: buy - action 14.0
Learning step: -0.28619512915611267
desired expected reward: 16.36957359313965






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 8. 0. 3. 3. 8. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 3. 6. 3.] 
adversary cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0. 14. 14.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14] -> size -> 30 
adversary victory points: 5
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 8. 0. 3. 3. 8. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 3. 6. 3.] 
adversary cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0. 14. 14.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14] -> size -> 30 
adversary victory points: 5
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 8. 0. 3. 3. 8. 0. 3. 1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 3. 6. 3.] 
adversary cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0. 14. 14.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14] -> size -> 30 
adversary victory points: 5
player victory points: 10 





Player: 0 
cards in hand: [0. 3. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[60.313286]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 6. 3.] 
cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0. 14. 14.  3.  0.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [14.  3.  3.  0. 11.] 
adversary cards in discard: [0. 8. 0. 3. 3. 8. 0. 3. 1. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0  1] -> size -> 27 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1
Learning step: -2.135380983352661
desired expected reward: 17.713212966918945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[50.06183 ]
 [34.38474 ]
 [61.171265]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 3.] 
cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0. 14. 14.  3.  0.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [14.  3.  3.  0. 11.] 
adversary cards in discard: [0. 8. 0. 3. 3. 8. 0. 3. 1. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0  1] -> size -> 27 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: take_action - action -1.0
Learning step: -4.372780799865723
desired expected reward: 55.94050598144531



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [14.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  0. 11.] 
cards in discard: [0. 8. 0. 3. 3. 8. 0. 3. 1. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [11.  3.  0. 11. 10.] 
adversary cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0. 14. 14.  3.  0.  0. 29.
  0.  3.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14] -> size -> 30 
adversary victory points: 5
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.] 
cards in discard: [0. 8. 0. 3. 3. 8. 0. 3. 1. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 27. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [11.  3. 11.] 
adversary cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0. 14. 14.  3.  0.  0. 29.
  0.  3.  3.  6.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14] -> size -> 30 
adversary victory points: 5
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 11.] 
cards in discard: [0. 8. 0. 3. 3. 8. 0. 3. 1. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [11.  3. 11.] 
adversary cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0. 14. 14.  3.  0.  0. 29.
  0.  3.  3.  6.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14] -> size -> 30 
adversary victory points: 5
player victory points: 10 





Player: 0 
cards in hand: [11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[54.85238 ]
 [56.255913]
 [56.255913]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.] 
cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0. 14. 14.  3.  0.  0. 29.
  0.  3.  3.  6.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 0. 3. 4.] 
adversary cards in discard: [ 0.  8.  0.  3.  3.  8.  0.  3.  1.  0.  0.  0. 14.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0  1] -> size -> 27 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[  -5    0    5  -50    0    0    0    0    0    0    0    0    0 -600
  116    0] 
sum of rewards: -534 

action type: discard_down_to_3_cards - action 1
Learning step: -27.457447052001953
desired expected reward: 12.833686828613281



action possibilites: [-1] 
expected returns: [[29.549438]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.] 
cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0. 14. 14.  3.  0.  0. 29.
  0.  3.  3.  6.  3.  0. 10.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 0. 3. 4.] 
adversary cards in discard: [ 0.  8.  0.  3.  3.  8.  0.  3.  1.  0.  0.  0. 14.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0  1] -> size -> 27 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -21 

action type: gain_card_n - action 1
Learning step: -2.8587825298309326
desired expected reward: 46.614112854003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.19295 ]
 [ 9.018412]
 [29.682095]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [29. 15.  0.  3.  0. 29.  3. 11.  6. 15.  0.  0. 14. 14.  3.  0.  0. 29.
  0.  3.  3.  6.  3.  0. 10.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 0. 3. 4.] 
adversary cards in discard: [ 0.  8.  0.  3.  3.  8.  0.  3.  1.  0.  0.  0. 14.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0  1] -> size -> 27 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1
Learning step: -2.4953906536102295
desired expected reward: 27.054048538208008






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 4.] 
cards in discard: [ 0.  8.  0.  3.  3.  8.  0.  3.  1.  0.  0.  0. 14.  3.  3.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [14. 29.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1] -> size -> 31 
adversary victory points: 5
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 4.] 
cards in discard: [ 0.  8.  0.  3.  3.  8.  0.  3.  1.  0.  0.  0. 14.  3.  3.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 22. 29.  8.  7. 10.  6.  8. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [14. 29.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1] -> size -> 31 
adversary victory points: 5
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 4.] 
cards in discard: [ 0.  8.  0.  3.  3.  8.  0.  3.  1.  0.  0.  0. 14.  3.  3.  0. 11.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0  1  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 22. 29.  8.  7. 10.  6.  7. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [14. 29.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1] -> size -> 31 
adversary victory points: 5
player victory points: 10 





Player: 0 
cards in hand: [14. 29.  3.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29. 10.] 
expected returns: [[17.177528]
 [ 5.896091]
 [14.716267]
 [13.029793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 29.  3.  1. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 29.  8.  7. 10.  6.  7. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [15.  1.  0.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3.  8.  0.  3.  1.  0.  0.  0. 14.  3.  3.  0. 11.  8.
  0.  0.  0.  3.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0  1  8] -> size -> 28 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1.0
Learning step: -3.6802749633789062
desired expected reward: 26.001815795898438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.522392 ]
 [16.60875  ]
 [ 2.5498471]
 [17.65884  ]
 [19.04437  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 29.  3.  1. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 22. 29.  8.  7. 10.  6.  7. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [15.  1.  0.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3.  8.  0.  3.  1.  0.  0.  0. 14.  3.  3.  0. 11.  8.
  0.  0.  0.  3.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0  1  8] -> size -> 28 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: take_action - action -1.0
Learning step: -3.0221900939941406
desired expected reward: 14.155336380004883



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [15.  1.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  0.  3.  0.] 
cards in discard: [ 0.  8.  0.  3.  3.  8.  0.  3.  1.  0.  0.  0. 14.  3.  3.  0. 11.  8.
  0.  0.  0.  3.  4.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3
  1  0  1  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 29.  8.  7. 10.  6.  7. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 0. 15.  6. 14. 15.] 
adversary cards in discard: [14. 29.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1] -> size -> 31 
adversary victory points: 5
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0.] 
cards in discard: [ 0.  8.  0.  3.  3.  8.  0.  3.  1.  0.  0.  0. 14.  3.  3.  0. 11.  8.
  0.  0.  0.  3.  4.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 26. 30. 22. 29.  8.  7. 10.  6.  7. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 0. 15.  6. 14. 15.] 
adversary cards in discard: [14. 29.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1] -> size -> 31 
adversary victory points: 5
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [ 0.  8.  0.  3.  3.  8.  0.  3.  1.  0.  0.  0. 14.  3.  3.  0. 11.  8.
  0.  0.  0.  3.  4.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 26. 30. 22. 29.  8.  7. 10.  6.  7. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 0. 15.  6. 14. 15.] 
adversary cards in discard: [14. 29.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1] -> size -> 31 
adversary victory points: 5
player victory points: 10 





Player: 0 
cards in hand: [ 0. 15.  6. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 15.] 
expected returns: [[43.2374  ]
 [33.85571 ]
 [28.008282]
 [33.85571 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6. 14. 15.] 
cards in discard: [14. 29.  3.  1. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 29.  8.  7. 10.  6.  7. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 3. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8] -> size -> 27 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1.0
Learning step: -2.6364426612854004
desired expected reward: 16.40792465209961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[36.3621  ]
 [23.182308]
 [44.127144]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6. 14. 15.] 
cards in discard: [14. 29.  3.  1. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 22. 29.  8.  7. 10.  6.  7. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 3. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8] -> size -> 27 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: take_action - action -1.0
Learning step: -3.8458847999572754
desired expected reward: 39.391502380371094



buy possibilites: [-1] 
expected returns: [[5.8075557]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6. 14. 15.] 
cards in discard: [14. 29.  3.  1. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 22. 29.  8.  7. 10.  6.  7. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 3. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8] -> size -> 27 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -80.0 

action type: buy - action 0.0
Learning step: -5.68743371963501
desired expected reward: 30.674638748168945






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 4.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  7. 10.  6.  7. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  3. 29.  3. 29.] 
adversary cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0] -> size -> 32 
adversary victory points: 5
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 4.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 22. 29.  8.  7. 10.  6.  7. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  3. 29.  3. 29.] 
adversary cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0] -> size -> 32 
adversary victory points: 5
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 4.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  7. 10.  6.  6. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  3. 29.  3. 29.] 
adversary cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0] -> size -> 32 
adversary victory points: 5
player victory points: 10 





Player: 0 
cards in hand: [ 3.  3. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[8.858341]
 [8.218033]
 [8.218033]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  3. 29.] 
cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  7. 10.  6.  6. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 4.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8] -> size -> 28 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1
Learning step: -2.598954916000366
desired expected reward: 3.2086007595062256



action possibilites: [-1. 29.] 
expected returns: [[32.70487]
 [20.70403]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 29.  0.] 
cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 22. 29.  8.  7. 10.  6.  6. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 4.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8] -> size -> 28 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -29 

action type: take_action - action 29.0
Learning step: -1.235944151878357
desired expected reward: 6.982082843780518



action possibilites: [-1.] 
expected returns: [[51.895123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 1.] 
cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 26. 30. 22. 29.  8.  7. 10.  6.  6. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 4.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8] -> size -> 28 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  40   0   0   0   0   0   0   0   0   2] 
sum of rewards: -8 

action type: take_action - action 29.0
Learning step: -0.26756152510643005
desired expected reward: 20.436471939086914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[35.76357 ]
 [46.53946 ]
 [42.04104 ]
 [25.154673]
 [21.527912]
 [40.44873 ]
 [49.768063]
 [42.543365]
 [58.637905]
 [41.63164 ]
 [26.73358 ]
 [31.819202]
 [39.274124]
 [23.868412]
 [34.367424]
 [49.386696]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 1.] 
cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 26. 30. 22. 29.  8.  7. 10.  6.  6. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 4.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8] -> size -> 28 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1.0
Learning step: -2.155102252960205
desired expected reward: 49.740020751953125



buy possibilites: [-1] 
expected returns: [[30.49968]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 1.] 
cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 26. 30. 21. 29.  8.  7. 10.  6.  6. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 4.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8] -> size -> 28 
adversary victory points: 10
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6. -40.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: 3.0 

action type: buy - action 3.0
Learning step: -1.265809178352356
desired expected reward: 40.775230407714844






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [8. 0. 3. 3. 0. 4.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 21. 29.  8.  7. 10.  6.  6. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.  3. 29. 29.  3.  3.  3.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3] -> size -> 33 
adversary victory points: 6
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [8. 0. 3. 3. 0. 4.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 21. 29.  8.  7. 10.  6.  6. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.  3. 29. 29.  3.  3.  3.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3] -> size -> 33 
adversary victory points: 6
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [8. 0. 3. 3. 0. 4. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 26. 30. 21. 29.  8.  7. 10.  6.  6. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.  3. 29. 29.  3.  3.  3.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3] -> size -> 33 
adversary victory points: 6
player victory points: 10 





Player: 0 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-16.528496]
 [-17.596935]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.  3. 29. 29.  3.  3.  3.  0.
  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 29.  8.  7. 10.  6.  6. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [1. 0. 0. 1. 3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 4. 0. 8. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8  0] -> size -> 29 
adversary victory points: 10
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: buy - action -1
Learning step: -3.8567490577697754
desired expected reward: 26.64293098449707



action possibilites: [-1] 
expected returns: [[4.10348]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.  3. 29. 29.  3.  3.  3.  0.
  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 29.  8.  6. 10.  6.  6. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [1. 0. 0. 1. 3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 4. 0. 8. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8  0] -> size -> 29 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[  -5    0    5  -50    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -330 

action type: gain_card_n - action 3
Learning step: -15.654899597167969
desired expected reward: -30.710336685180664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -6.006315  ]
 [  2.4086542 ]
 [ -0.09393311]
 [-18.335026  ]
 [ -1.8737404 ]
 [  3.7559023 ]
 [ -0.6697111 ]
 [ -1.0843787 ]
 [-11.807001  ]
 [ -1.6544852 ]
 [ -5.368733  ]
 [  4.002135  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.  3. 29. 29.  3.  3.  3.  0.
  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 26. 30. 21. 29.  8.  6. 10.  6.  6. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [1. 0. 0. 1. 3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 4. 0. 8. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8  0] -> size -> 29 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1
Learning step: -1.7456616163253784
desired expected reward: 2.357818126678467



buy possibilites: [-1] 
expected returns: [[-25.10317]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.  3. 29. 29.  3.  3.  3.  0.
  1.  6.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 25. 30. 21. 29.  8.  6. 10.  6.  6. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [1. 0. 0. 1. 3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 4. 0. 8. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8  0] -> size -> 29 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    5.  -50.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -25.5 

action type: buy - action 1.0
Learning step: -1.8013397455215454
desired expected reward: -2.5709714889526367






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [1. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 1. 3.] 
cards in discard: [8. 0. 3. 3. 0. 4. 0. 8. 0. 0. 3. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 29.  8.  6. 10.  6.  6. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  6. 11.  3.  3.] 
adversary cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.  3. 29. 29.  3.  3.  3.  0.
  1.  6.  1. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1] -> size -> 35 
adversary victory points: 5
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 3.] 
cards in discard: [8. 0. 3. 3. 0. 4. 0. 8. 0. 0. 3. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 6 
card supply: [18. 25. 30. 21. 29.  8.  6. 10.  6.  6. 10.  7.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  6. 11.  3.  3.] 
adversary cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.  3. 29. 29.  3.  3.  3.  0.
  1.  6.  1. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1] -> size -> 35 
adversary victory points: 5
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 3.] 
cards in discard: [ 8.  0.  3.  3.  0.  4.  0.  8.  0.  0.  3.  3. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8  0 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 25. 30. 21. 29.  8.  6. 10.  6.  6. 10.  7.  6. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  6. 11.  3.  3.] 
adversary cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.  3. 29. 29.  3.  3.  3.  0.
  1.  6.  1. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1] -> size -> 35 
adversary victory points: 5
player victory points: 10 





Player: 0 
cards in hand: [ 3.  6. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-8.89219 ]
 [-9.154368]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 11.  3.  3.] 
cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.  3. 29. 29.  3.  3.  3.  0.
  1.  6.  1. 11.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 29.  8.  6. 10.  6.  6. 10.  7.  6. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 14.  8. 15.  0.] 
adversary cards in discard: [ 8.  0.  3.  3.  0.  4.  0.  8.  0.  0.  3.  3. 14.  1.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8  0 14] -> size -> 30 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1
Learning step: -1.447338581085205
desired expected reward: -26.550508499145508



action possibilites: [-1] 
expected returns: [[4.7519894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 3.] 
cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.  3. 29. 29.  3.  3.  3.  0.
  1.  6.  1. 11.  0.  0.  0.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 29.  8.  6. 10.  6.  6. 10.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 14.  8. 15.  0.] 
adversary cards in discard: [ 8.  0.  3.  3.  0.  4.  0.  8.  0.  0.  3.  3. 14.  1.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8  0 14] -> size -> 30 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0  -1   0   0  16   0] 
sum of rewards: -15 

action type: gain_card_n - action 8
Learning step: -0.0808693915605545
desired expected reward: -11.32508659362793





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -2.7769933]
 [-12.203274 ]
 [  3.8967693]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3.] 
cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.  3. 29. 29.  3.  3.  3.  0.
  1.  6.  1. 11.  0.  0.  0.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 25. 30. 21. 29.  8.  6. 10.  6.  6. 10.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 14.  8. 15.  0.] 
adversary cards in discard: [ 8.  0.  3.  3.  0.  4.  0.  8.  0.  0.  3.  3. 14.  1.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8  0 14] -> size -> 30 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1
Learning step: -1.7902271747589111
desired expected reward: 2.9617621898651123



buy possibilites: [-1] 
expected returns: [[-17.52095]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3.] 
cards in discard: [14. 29.  3.  1. 10.  0.  0. 15.  6. 14. 15.  3. 29. 29.  3.  3.  3.  0.
  1.  6.  1. 11.  0.  0.  0.  0. 14.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 29.  8.  5. 10.  6.  6. 10.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 14.  8. 15.  0.] 
adversary cards in discard: [ 8.  0.  3.  3.  0.  4.  0.  8.  0.  0.  3.  3. 14.  1.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8  0 14] -> size -> 30 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[  -5    0    4  -60    0    0   20    0    0    0    0   -2    0 -300
    0    0] 
sum of rewards: -343 

action type: buy - action 6.0
Learning step: -16.934057235717773
desired expected reward: -29.137332916259766






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  8. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  8. 15.  0.] 
cards in discard: [ 8.  0.  3.  3.  0.  4.  0.  8.  0.  0.  3.  3. 14.  1.  0.  0.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1
  0  1  8  8  0 14] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 29.  8.  5. 10.  6.  6. 10.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6] -> size -> 37 
adversary victory points: 4
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  8.] 
cards in discard: [ 8.  0.  3.  3.  0.  4.  0.  8.  0.  0.  3.  3. 14.  1.  0.  0.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 25. 30. 21. 29.  8.  5. 10.  6.  6. 10.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6] -> size -> 37 
adversary victory points: 4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  8.] 
cards in discard: [ 8.  0.  3.  3.  0.  4.  0.  8.  0.  0.  3.  3. 14.  1.  0.  0.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 25. 30. 21. 29.  8.  5. 10.  6.  6. 10.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6] -> size -> 37 
adversary victory points: 4
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  8.] 
cards in discard: [ 8.  0.  3.  3.  0.  4.  0.  8.  0.  0.  3.  3. 14.  1.  0.  0.  1.  3.
  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 21. 29.  8.  5. 10.  6.  6. 10.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6] -> size -> 37 
adversary victory points: 4
player victory points: 10 





Player: 0 
cards in hand: [ 6.  0.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[21.56676 ]
 [21.481085]
 [14.269535]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 21. 29.  8.  5. 10.  6.  6. 10.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  3.  0.  4.  0.  8.  0.  0.  3.  3. 14.  1.  0.  0.  1.  3.
  1. 15.  3. 14.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1] -> size -> 30 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: buy - action -1
Learning step: -1.7341850996017456
desired expected reward: -19.25513458251953



action possibilites: [-1. 11.] 
expected returns: [[31.902468]
 [31.68907 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11.  6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 21. 29.  8.  5. 10.  6.  6. 10.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  3.  0.  4.  0.  8.  0.  0.  3.  3. 14.  1.  0.  0.  1.  3.
  1. 15.  3. 14.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1] -> size -> 30 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action 10.0
Learning step: -2.0476434230804443
desired expected reward: 12.221891403198242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.680817]
 [30.891539]
 [14.506342]
 [31.23628 ]
 [35.01138 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11.  6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 24. 30. 21. 29.  8.  5. 10.  6.  6. 10.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  3.  0.  4.  0.  8.  0.  0.  3.  3. 14.  1.  0.  0.  1.  3.
  1. 15.  3. 14.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1] -> size -> 30 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action -1.0
Learning step: -2.9894444942474365
desired expected reward: 28.91301918029785



buy possibilites: [-1] 
expected returns: [[13.7351055]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11.  6.] 
cards in discard: [3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 20. 29.  8.  5. 10.  6.  6. 10.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  3.  0.  4.  0.  8.  0.  0.  3.  3. 14.  1.  0.  0.  1.  3.
  1. 15.  3. 14.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1] -> size -> 30 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0  -3   0   0   8   0] 
sum of rewards: -25 

action type: buy - action 3.0
Learning step: -2.48553729057312
desired expected reward: 28.406005859375






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  3.  0.  4.  0.  8.  0.  0.  3.  3. 14.  1.  0.  0.  1.  3.
  1. 15.  3. 14.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 20. 29.  8.  5. 10.  6.  6. 10.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  0. 14. 29.  1.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3] -> size -> 38 
adversary victory points: 5
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  3.  0.  4.  0.  8.  0.  0.  3.  3. 14.  1.  0.  0.  1.  3.
  1. 15.  3. 14.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 24. 30. 20. 29.  8.  5. 10.  6.  6. 10.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  0. 14. 29.  1.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3] -> size -> 38 
adversary victory points: 5
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  3.  0.  4.  0.  8.  0.  0.  3.  3. 14.  1.  0.  0.  1.  3.
  1. 15.  3. 14.  8. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 24. 30. 20. 29.  8.  5. 10.  5.  6. 10.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  0. 14. 29.  1.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3] -> size -> 38 
adversary victory points: 5
player victory points: 10 





Player: 0 
cards in hand: [ 3.  0. 14. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
expected returns: [[ 6.049632 ]
 [-1.9169427]
 [ 1.1333625]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14. 29.  1.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 20. 29.  8.  5. 10.  5.  6. 10.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  0.  3. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1 11] -> size -> 31 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1
Learning step: -3.130007266998291
desired expected reward: 10.605098724365234



action possibilites: [-1] 
expected returns: [[14.150763]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  1.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 24. 30. 20. 29.  8.  5. 10.  5.  6. 10.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 11.  8.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1 11] -> size -> 31 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action 14.0
Learning step: -1.0857609510421753
desired expected reward: -3.0027003288269043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 8.535964 ]
 [11.359049 ]
 [10.916622 ]
 [ 5.14184  ]
 [ 3.6035388]
 [ 9.654931 ]
 [13.480736 ]
 [10.080208 ]
 [14.561455 ]
 [ 9.99134  ]
 [ 6.5159454]
 [ 7.8875933]
 [10.594925 ]
 [ 4.8324013]
 [ 9.125154 ]
 [14.03993  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  1.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 24. 30. 20. 29.  8.  5. 10.  5.  6. 10.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 11.  8.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1 11] -> size -> 31 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1
Learning step: -1.97539222240448
desired expected reward: 12.175370216369629



buy possibilites: [-1] 
expected returns: [[-7.6116734]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  1.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25.] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3 25] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 20. 29.  8.  5. 10.  5.  6.  9.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 11.  8.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1 11] -> size -> 31 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0  -4   0   0  50   0] 
sum of rewards: 16 

action type: buy - action 25.0
Learning step: -0.09933576732873917
desired expected reward: 14.462126731872559






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.] 
cards in discard: [3. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 20. 29.  8.  5. 10.  5.  6.  9.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [11.  3. 14.  3. 29.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3 25] -> size -> 39 
adversary victory points: 5
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  8.] 
cards in discard: [3. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1 11] -> size -> 31 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 24. 30. 20. 29.  8.  5. 10.  5.  6.  9.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [11.  3. 14.  3. 29.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3 25] -> size -> 39 
adversary victory points: 5
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  8.] 
cards in discard: [3. 0. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 20. 29.  8.  5. 10.  5.  6.  9.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [11.  3. 14.  3. 29.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3 25] -> size -> 39 
adversary victory points: 5
player victory points: 10 





Player: 0 
cards in hand: [11.  3. 14.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 29.] 
expected returns: [[-16.652767]
 [-16.249428]
 [-22.614632]
 [-20.081339]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 14.  3. 29.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 20. 29.  8.  5. 10.  5.  6.  9.  7.  5. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [ 3.  0.  0.  3. 11.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1 11  0] -> size -> 32 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1
Learning step: -2.534008741378784
desired expected reward: -10.145682334899902



action possibilites: [-1] 
expected returns: [[15.660103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  3. 29.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 20. 29.  8.  5. 10.  5.  6.  9.  7.  5. 10.  7. 10.  6.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [ 3.  0.  0.  3. 11.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1 11  0] -> size -> 32 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0  -5   0   0  16   0] 
sum of rewards: -19 

action type: gain_card_n - action 10
Learning step: 0.4752958416938782
desired expected reward: -20.98357391357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.544354 ]
 [ 4.1204953]
 [16.620167 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  3. 29.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 24. 30. 20. 29.  8.  5. 10.  5.  6.  9.  7.  5. 10.  7. 10.  6.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [ 3.  0.  0.  3. 11.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1 11  0] -> size -> 32 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1
Learning step: -2.023491382598877
desired expected reward: 13.636611938476562






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 3.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0
  1  8  8  0 14  1 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 20. 29.  8.  5. 10.  5.  6.  9.  7.  5. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 15.  0.  6. 15.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15] -> size -> 40 
adversary victory points: 5
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 20. 29.  8.  5. 10.  5.  6.  9.  7.  5. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 15.  0.  6. 15.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15] -> size -> 40 
adversary victory points: 5
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 24. 30. 20. 29.  8.  5. 10.  5.  6.  9.  7.  5. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 15.  0.  6. 15.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15] -> size -> 40 
adversary victory points: 5
player victory points: 9 





Player: 0 
cards in hand: [ 0. 15.  0.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[-6.4554935]
 [-6.173001 ]
 [-6.173001 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  6. 15.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0
 15  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 20. 29.  8.  5. 10.  5.  6.  9.  7.  5. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 11.  3. 14.  1.] 
adversary cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3.] 
adversary owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0] -> size -> 29 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -40 

action type: buy - action -1.0
Learning step: -2.9716413021087646
desired expected reward: 13.648523330688477



action possibilites: [-1] 
expected returns: [[16.591818]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 24. 30. 20. 29.  8.  5. 10.  5.  6.  9.  7.  5. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 11.  3. 14.  1.] 
adversary cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3.] 
adversary owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0] -> size -> 29 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: take_action - action 15.0
Learning step: -0.3180336654186249
desired expected reward: -6.491042137145996





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[11.095103 ]
 [16.799694 ]
 [14.181362 ]
 [-7.5285378]
 [13.568388 ]
 [17.805725 ]
 [15.232901 ]
 [14.485764 ]
 [ 1.9057894]
 [12.353281 ]
 [ 9.215518 ]
 [16.396347 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 24. 30. 20. 29.  8.  5. 10.  5.  6.  9.  7.  5. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 11.  3. 14.  1.] 
adversary cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3.] 
adversary owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0] -> size -> 29 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: take_action - action -1
Learning step: -1.5493401288986206
desired expected reward: 15.04247760772705



buy possibilites: [-1] 
expected returns: [[-1.7779609]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 24. 30. 19. 29.  8.  5. 10.  5.  6.  9.  7.  5. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 11.  3. 14.  1.] 
adversary cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3.] 
adversary owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0] -> size -> 29 
adversary victory points: 9
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6. -30.   0.   0.  20.   0.   0.   0.   0.  -5.   0.   0.
   2.   0.] 
sum of rewards: -12.0 

action type: buy - action 3.0
Learning step: -1.3490720987319946
desired expected reward: 12.832287788391113






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  3. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 14.  1.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 19. 29.  8.  5. 10.  5.  6.  9.  7.  5. 10.  7. 10.  6.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3] -> size -> 40 
adversary victory points: 6
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  1.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 24. 30. 19. 29.  8.  5. 10.  5.  6.  9.  7.  5. 10.  7. 10.  6.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3] -> size -> 40 
adversary victory points: 6
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  1.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 24. 30. 19. 29.  8.  5. 10.  5.  6.  9.  7.  5. 10.  7. 10.  6.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3] -> size -> 40 
adversary victory points: 6
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  1.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 19. 29.  8.  5. 10.  5.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3] -> size -> 40 
adversary victory points: 6
player victory points: 9 





Player: 0 
cards in hand: [3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-19.065306]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 19. 29.  8.  5. 10.  5.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  0. 14.  1.  0.] 
adversary cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1.] 
adversary owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23] -> size -> 30 
adversary victory points: 9
player victory points: 6 

Reward from previous game state: 
[   -5     0     6   -30     0     0     0     0     0     0     0    -5
     0 -1200   164     0] 
sum of rewards: -1070 

action type: discard_down_to_3_cards - action 1
Learning step: -54.10860824584961
desired expected reward: -50.51588821411133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-27.022001]
 [-25.822035]
 [-19.926605]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 24. 30. 19. 29.  8.  5. 10.  5.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  0. 14.  1.  0.] 
adversary cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1.] 
adversary owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23] -> size -> 30 
adversary victory points: 9
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: take_action - action -1.0
Learning step: -1.02511727809906
desired expected reward: -20.090423583984375



buy possibilites: [-1] 
expected returns: [[13.319492]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 24. 30. 19. 29.  8.  4. 10.  5.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  0. 14.  1.  0.] 
adversary cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1.] 
adversary owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23] -> size -> 30 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    5.  -40.    0.    0.    0.    0.    0.    0.    0.   -6.
    0. -300.    0.    0.] 
sum of rewards: -346.0 

action type: buy - action 6.0
Learning step: -15.709210395812988
desired expected reward: -41.5312385559082






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  1.  0.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 19. 29.  8.  4. 10.  5.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [ 0. 29.  3.  6. 11.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.  6.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6] -> size -> 41 
adversary victory points: 5
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 24. 30. 19. 29.  8.  4. 10.  5.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [ 0. 29.  6.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.  6.  3.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6] -> size -> 41 
adversary victory points: 5
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23] -> size -> 30 
action values: 0 
buys: 1 
player value: 7 
card supply: [17. 24. 30. 19. 29.  8.  4. 10.  5.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [ 0. 29.  6.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.  6.  3.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6] -> size -> 41 
adversary victory points: 5
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 24. 30. 19. 29.  8.  4. 10.  4.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [ 0. 29.  6.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.  6.  3.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6] -> size -> 41 
adversary victory points: 5
player victory points: 9 





Player: 0 
cards in hand: [ 0. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-5.267606]
 [-6.364752]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  6.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.  6.  3.  0.  3.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 19. 29.  8.  4. 10.  4.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [0. 3. 4. 0. 3.] 
adversary cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1. 11. 14.  0.  0.
  1.  0.] 
adversary owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23 11] -> size -> 31 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[   -5     0     5   -40     0     0     0     0     0     0     0    -6
     0 -1500   164     0] 
sum of rewards: -1382 

action type: discard_down_to_3_cards - action 9
Learning step: -69.2968978881836
desired expected reward: -67.93212890625



action possibilites: [-1.] 
expected returns: [[-6.3473597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.  6.  3.  0.  3.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 24. 30. 19. 29.  8.  4. 10.  4.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [0. 3. 4. 0. 3.] 
adversary cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1. 11. 14.  0.  0.
  1.  0.] 
adversary owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23 11] -> size -> 31 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -18 

action type: take_action - action 29.0
Learning step: -0.7245782017707825
desired expected reward: -7.08932638168335





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -8.265017 ]
 [ -7.6591296]
 [ -6.734232 ]
 [-22.336834 ]
 [ -8.447184 ]
 [ -6.515486 ]
 [ -8.647352 ]
 [ -8.505437 ]
 [-10.412973 ]
 [ -7.794893 ]
 [ -7.4413023]
 [ -6.3473682]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.  6.  3.  0.  3.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 24. 30. 19. 29.  8.  4. 10.  4.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [0. 3. 4. 0. 3.] 
adversary cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1. 11. 14.  0.  0.
  1.  0.] 
adversary owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23 11] -> size -> 31 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: take_action - action -1.0
Learning step: -0.8761802911758423
desired expected reward: -7.22353982925415



buy possibilites: [-1] 
expected returns: [[-6.6925693]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.  6.  3.  0.  3.  3. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 24. 30. 19. 29.  8.  4. 10.  3.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [0. 3. 4. 0. 3.] 
adversary cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1. 11. 14.  0.  0.
  1.  0.] 
adversary owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23 11] -> size -> 31 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    5.  -40.    0.    0.   20.    0.    0.    0.    0.   -7.
   0.    0.    4.5   0. ] 
sum of rewards: -22.5 

action type: buy - action 11.0
Learning step: -0.9498085975646973
desired expected reward: -7.465292453765869






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [0. 3. 4. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 4. 0. 3.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1. 11. 14.  0.  0.
  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 19. 29.  8.  4. 10.  3.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [14.  1.  0.  3. 10.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.  6.  3.  0.  3.  3. 11. 11. 29.  0.  6.
  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11] -> size -> 42 
adversary victory points: 5
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 4. 0. 3.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1. 11. 14.  0.  0.
  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 24. 30. 19. 29.  8.  4. 10.  3.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [14.  1.  0.  3. 10.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.  6.  3.  0.  3.  3. 11. 11. 29.  0.  6.
  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11] -> size -> 42 
adversary victory points: 5
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 4. 0. 3.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1. 11. 14.  0.  0.
  1.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23 11  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 18. 29.  8.  4. 10.  3.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [14.  1.  0.  3. 10.] 
adversary cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.  6.  3.  0.  3.  3. 11. 11. 29.  0.  6.
  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11] -> size -> 42 
adversary victory points: 5
player victory points: 10 





Player: 0 
cards in hand: [14.  1.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[-25.722406]
 [-21.805386]
 [-24.439575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  0.  3. 10.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.  6.  3.  0.  3.  3. 11. 11. 29.  0.  6.
  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 18. 29.  8.  4. 10.  3.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [15.  8.  0.  1.  8.] 
adversary cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1. 11. 14.  0.  0.
  1.  0.  3.  0.  3.  4.  0.  3.] 
adversary owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23 11  3] -> size -> 32 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1
Learning step: -2.6963534355163574
desired expected reward: -9.388922691345215





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-24.712399]
 [-25.723278]
 [-23.49778 ]
 [-28.677036]
 [-25.759438]
 [-26.463211]
 [-24.751724]
 [-25.974583]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  0.  3. 10.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.  6.  3.  0.  3.  3. 11. 11. 29.  0.  6.
  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 24. 30. 18. 29.  8.  4. 10.  3.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [15.  8.  0.  1.  8.] 
adversary cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1. 11. 14.  0.  0.
  1.  0.  3.  0.  3.  4.  0.  3.] 
adversary owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23 11  3] -> size -> 32 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: take_action - action -1.0
Learning step: -1.7705796957015991
desired expected reward: -27.745159149169922



buy possibilites: [-1] 
expected returns: [[10.524359]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  0.  3. 10.] 
cards in discard: [ 3. 10.  6.  0.  0. 11.  6. 25. 14.  3.  0. 29.  1. 15. 11.  3. 14.  3.
 29.  3. 15.  0.  6. 15.  0.  3.  6.  3.  0.  3.  3. 11. 11. 29.  0.  6.
  1. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 18. 29.  8.  4. 10.  2.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [15.  8.  0.  1.  8.] 
adversary cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1. 11. 14.  0.  0.
  1.  0.  3.  0.  3.  4.  0.  3.] 
adversary owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23 11  3] -> size -> 32 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0  -8   0   0  18   0] 
sum of rewards: -40 

action type: buy - action 11.0
Learning step: -0.4752304255962372
desired expected reward: -26.234661102294922






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [15.  8.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  1.  8.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1. 11. 14.  0.  0.
  1.  0.  3.  0.  3.  4.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15 11  8  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8
  0 14  1 11  0 23 11  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 18. 29.  8.  4. 10.  2.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [25.  3. 11.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11] -> size -> 43 
adversary victory points: 5
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1. 11. 14.  0.  0.
  1.  0.  3.  0.  3.  4.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 18. 29.  8.  4. 10.  2.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [25.  3. 11.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11] -> size -> 43 
adversary victory points: 5
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1. 11. 14.  0.  0.
  1.  0.  3.  0.  3.  4.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 24. 30. 18. 29.  8.  4. 10.  2.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [25.  3. 11.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11] -> size -> 43 
adversary victory points: 5
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1.] 
cards in discard: [ 3.  0.  0.  3. 11.  8.  8.  3. 23. 14.  0. 11.  3.  1. 11. 14.  0.  0.
  1.  0.  3.  0.  3.  4.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 24. 30. 17. 29.  8.  4. 10.  2.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [25.  3. 11.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11] -> size -> 43 
adversary victory points: 5
player victory points: 11 





Player: 0 
cards in hand: [25.  3. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11.] 
expected returns: [[13.553485]
 [14.738458]
 [12.576339]
 [12.576339]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 11.  3. 11.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 17. 29.  8.  4. 10.  2.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [ 0. 14.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3] -> size -> 32 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -60 

action type: buy - action -1
Learning step: -3.2200584411621094
desired expected reward: 7.304300308227539



action possibilites: [-1] 
expected returns: [[31.032211]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  3. 11.] 
cards in discard: [1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 17. 29.  8.  4. 10.  2.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [ 0. 14.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3] -> size -> 32 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0  20   0   0   0   0  -9   0   0   9   0] 
sum of rewards: -40 

action type: gain_card_n - action 1
Learning step: -1.8146034479141235
desired expected reward: 8.4419584274292





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.138409]
 [17.42403 ]
 [31.258553]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  3. 11.] 
cards in discard: [1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 23. 30. 17. 29.  8.  4. 10.  2.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [ 0. 14.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3] -> size -> 32 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -40 

action type: take_action - action -1
Learning step: -2.9835517406463623
desired expected reward: 28.048660278320312






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.  3.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 17. 29.  8.  4. 10.  2.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [11. 29.  6.  3. 14.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1] -> size -> 44 
adversary victory points: 5
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.  3.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 23. 30. 17. 29.  8.  4. 10.  2.  6.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [11. 29.  6.  3. 14.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1] -> size -> 44 
adversary victory points: 5
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.  3.  0.] 
cards in discard: [8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 23. 30. 17. 29.  8.  4. 10.  2.  5.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [11. 29.  6.  3. 14.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1] -> size -> 44 
adversary victory points: 5
player victory points: 11 





Player: 0 
cards in hand: [11. 29.  6.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 14.] 
expected returns: [[-35.88391 ]
 [-37.643272]
 [-44.82279 ]
 [-45.494358]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  6.  3. 14.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 17. 29.  8.  4. 10.  2.  5.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [ 8.  0. 14.  1.  3.  0.] 
adversary owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8] -> size -> 33 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -60 

action type: buy - action -1.0
Learning step: -5.4641547203063965
desired expected reward: 25.794416427612305



action possibilites: [-1. 11. 14. 10.] 
expected returns: [[-33.310024]
 [-34.709827]
 [-33.694633]
 [-34.734566]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3. 14. 10.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 23. 30. 17. 29.  8.  4. 10.  2.  5.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [ 8.  0. 14.  1.  3.  0.] 
adversary owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8] -> size -> 33 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -40 

action type: take_action - action 29.0
Learning step: -0.5231634378433228
desired expected reward: -45.345951080322266



action possibilites: [-1. 11. 14.] 
expected returns: [[-18.584045]
 [-18.753212]
 [-24.33033 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3. 14.  0.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1] -> size -> 44 
action values: 2 
buys: 0 
player value: 1 
card supply: [17. 23. 30. 17. 29.  8.  4. 10.  2.  5.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [ 8.  0. 14.  1.  3.  0.] 
adversary owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8] -> size -> 33 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0  40   0   0   0   0   0   0   0   0   1] 
sum of rewards: -19 

action type: take_action - action 10.0
Learning step: 0.3321433961391449
desired expected reward: -34.40242385864258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-22.553368]
 [-20.133442]
 [-25.10117 ]
 [-21.400993]
 [-17.285587]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  3. 14.  0.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 30. 17. 29.  8.  4. 10.  2.  5.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [ 8.  0. 14.  1.  3.  0.] 
adversary owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8] -> size -> 33 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: take_action - action -1.0
Learning step: -0.533824622631073
desired expected reward: -19.117887496948242



buy possibilites: [-1] 
expected returns: [[-8.958401]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  3. 14.  0.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 17. 29.  8.  4. 10.  2.  4.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [ 8.  0. 14.  1.  3.  0.] 
adversary owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8] -> size -> 33 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0  40   0   0   0   0 -10   0   0   8   0] 
sum of rewards: -22 

action type: buy - action 8.0
Learning step: -0.2315145581960678
desired expected reward: -21.632503509521484






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [0. 1. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [ 8.  0. 14.  1.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 17. 29.  8.  4. 10.  2.  4.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [15.  3. 29. 29. 14.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8] -> size -> 45 
adversary victory points: 5
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [ 8.  0. 14.  1.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 23. 30. 17. 29.  8.  4. 10.  2.  4.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [15.  3. 29. 29. 14.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8] -> size -> 45 
adversary victory points: 5
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [ 8.  0. 14.  1.  3.  0. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 23. 30. 17. 29.  8.  4. 10.  1.  4.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [15.  3. 29. 29. 14.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8] -> size -> 45 
adversary victory points: 5
player victory points: 11 





Player: 0 
cards in hand: [15.  3. 29. 29. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 29. 14.] 
expected returns: [[-24.589317]
 [-21.361282]
 [-23.157333]
 [-23.157333]
 [-19.88132 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 29. 29. 14.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 17. 29.  8.  4. 10.  1.  4.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  1. 11.  3.] 
adversary cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.] 
adversary owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11] -> size -> 34 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -60 

action type: buy - action -1
Learning step: -3.0465028285980225
desired expected reward: -12.004903793334961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-22.066761]
 [-18.632498]
 [-24.845509]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 29. 29. 14.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8] -> size -> 45 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 23. 30. 17. 29.  8.  4. 10.  1.  4.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  1. 11.  3.] 
adversary cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.] 
adversary owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11] -> size -> 34 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -60 

action type: take_action - action -1.0
Learning step: -2.2492005825042725
desired expected reward: -26.83851432800293



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  1. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 11.  3.] 
cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 17. 29.  8.  4. 10.  1.  4.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [ 1. 10.  0.  0. 11.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8] -> size -> 45 
adversary victory points: 5
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 11.  3.] 
cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 23. 30. 17. 29.  8.  4. 10.  1.  4.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [ 1. 10.  0.  0. 11.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8] -> size -> 45 
adversary victory points: 5
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 11.  3.] 
cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 23. 30. 17. 29.  8.  4. 10.  1.  4.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [ 1. 10.  0.  0. 11.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8] -> size -> 45 
adversary victory points: 5
player victory points: 11 





Player: 0 
cards in hand: [ 1. 10.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-13.853441]
 [-17.307634]
 [-13.459392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  0. 11.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 17. 29.  8.  4. 10.  1.  4.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [ 3.  8. 11.  0.  0.] 
adversary cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.] 
adversary owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11  0] -> size -> 35 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -60 

action type: buy - action -1.0
Learning step: -2.0866966247558594
desired expected reward: -26.932209014892578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-18.534382]
 [-16.646917]
 [-17.224594]
 [-19.740494]
 [-18.183651]
 [-14.546564]
 [-18.041634]
 [-18.041422]
 [-18.987785]
 [-17.560204]
 [-17.932247]
 [-14.77863 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.  0. 11.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 23. 30. 17. 29.  8.  4. 10.  1.  4.  9.  7.  5.  9.  7. 10.  6.] 
adversary cards in hand: [ 3.  8. 11.  0.  0.] 
adversary cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.] 
adversary owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11  0] -> size -> 35 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -60 

action type: take_action - action -1.0
Learning step: -2.6895480155944824
desired expected reward: -16.543006896972656



buy possibilites: [-1] 
expected returns: [[-16.47065]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.  0. 11.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 17. 29.  8.  4. 10.  1.  4.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [ 3.  8. 11.  0.  0.] 
adversary cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.] 
adversary owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11  0] -> size -> 35 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0   0   0   0   0   0 -11   0   0  32   0] 
sum of rewards: -39 

action type: buy - action 15.0
Learning step: -1.4224261045455933
desired expected reward: -19.354677200317383






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  0.  0.] 
cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 17. 29.  8.  4. 10.  1.  4.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [ 1.  3.  0.  0. 14.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15] -> size -> 46 
adversary victory points: 5
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 17. 29.  8.  4. 10.  1.  4.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [ 1.  3.  0.  0. 14.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15] -> size -> 46 
adversary victory points: 5
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 23. 30. 17. 29.  8.  4. 10.  1.  4.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [ 1.  3.  0.  0. 14.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15] -> size -> 46 
adversary victory points: 5
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11  0  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 23. 30. 17. 29.  8.  4. 10.  1.  4.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [ 1.  3.  0.  0. 14.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15] -> size -> 46 
adversary victory points: 5
player victory points: 11 





Player: 0 
cards in hand: [ 1.  3.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[ 2.7499597]
 [-8.004483 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 14.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 17. 29.  8.  4. 10.  1.  4.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [15.  0. 14.  3.  8.] 
adversary cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.  0. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11  0  0  0] -> size -> 37 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -60 

action type: buy - action -1
Learning step: -2.213977575302124
desired expected reward: -18.684627532958984



action possibilites: [-1] 
expected returns: [[-24.974085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 23. 30. 17. 29.  8.  4. 10.  1.  4.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [15.  0.  3.] 
adversary cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.  0. 11.  3.  8.  0.  0. 14.  8.] 
adversary owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11  0  0  0] -> size -> 37 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -40 

action type: take_action - action 14.0
Learning step: -2.161693572998047
desired expected reward: -10.166158676147461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-26.293661]
 [-26.182045]
 [-25.160147]
 [-24.996836]
 [-25.615812]
 [-24.721424]
 [-26.38839 ]
 [-25.664898]
 [-27.011198]
 [-27.056458]
 [-26.81498 ]
 [-25.0664  ]
 [-24.756231]
 [-25.742556]
 [-24.813858]
 [-25.33458 ]
 [-24.97409 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15] -> size -> 46 
action values: 0 
buys: 1 
player value: 6 
card supply: [14. 23. 30. 17. 29.  8.  4. 10.  1.  4.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [15.  0.  3.] 
adversary cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.  0. 11.  3.  8.  0.  0. 14.  8.] 
adversary owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11  0  0  0] -> size -> 37 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -40 

action type: take_action - action -1
Learning step: -1.325281023979187
desired expected reward: -26.299365997314453



buy possibilites: [-1] 
expected returns: [[1.4068668]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 23. 30. 17. 29.  8.  4. 10.  0.  4.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [15.  0.  3.] 
adversary cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.  0. 11.  3.  8.  0.  0. 14.  8.] 
adversary owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11  0  0  0] -> size -> 37 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    5.  -60.    0.    0.   20.    0.    0.    0.    0.  -12.
   0.    0.    4.5   0. ] 
sum of rewards: -47.5 

action type: buy - action 11.0
Learning step: -1.0601004362106323
desired expected reward: -26.725000381469727






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.] 
cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.  0. 11.  3.  8.  0.  0. 14.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0
 14  1 11  0 23 11  3  3  8 11  0  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 17. 29.  8.  4. 10.  0.  4.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11] -> size -> 47 
adversary victory points: 5
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.  0. 11.  3.  8.  0.  0. 14.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14
  1 11  0 23 11  3  3  8 11  0  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 23. 30. 17. 29.  8.  4. 10.  0.  4.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11] -> size -> 47 
adversary victory points: 5
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.  0. 11.  3.  8.  0.  0. 14.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14
  1 11  0 23 11  3  3  8 11  0  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 23. 30. 17. 29.  8.  4. 10.  0.  4.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11] -> size -> 47 
adversary victory points: 5
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.  0. 11.  3.  8.  0.  0. 14.  8.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14
  1 11  0 23 11  3  3  8 11  0  0  0  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 23. 30. 17. 29.  8.  4. 10.  0.  3.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11] -> size -> 47 
adversary victory points: 5
player victory points: 11 





Player: 0 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.43466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 17. 29.  8.  4. 10.  0.  3.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [ 0.  0. 23.  8.  3.] 
adversary cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.  0. 11.  3.  8.  0.  0. 14.  8.  8. 15.  3.] 
adversary owned cards: [ 3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14
  1 11  0 23 11  3  3  8 11  0  0  0  8] -> size -> 37 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -60 

action type: buy - action -1
Learning step: -3.3051230907440186
desired expected reward: -1.8982563018798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-12.812707]
 [-10.731253]
 [-10.713464]
 [-13.698919]
 [-10.434659]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 23. 30. 17. 29.  8.  4. 10.  0.  3.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [ 0.  0. 23.  8.  3.] 
adversary cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.  0. 11.  3.  8.  0.  0. 14.  8.  8. 15.  3.] 
adversary owned cards: [ 3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14
  1 11  0 23 11  3  3  8 11  0  0  0  8] -> size -> 37 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -60 

action type: take_action - action -1.0
Learning step: -2.736030340194702
desired expected reward: -13.170690536499023



buy possibilites: [-1] 
expected returns: [[-9.533717]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 23. 30. 17. 29.  8.  4. 10.  0.  3.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [ 0.  0. 23.  8.  3.] 
adversary cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.  0. 11.  3.  8.  0.  0. 14.  8.  8. 15.  3.] 
adversary owned cards: [ 3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14
  1 11  0 23 11  3  3  8 11  0  0  0  8] -> size -> 37 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5. -60.   0.   0.   0. -30.   0.   0.   0. -13.   0.   0.
   0.   0.] 
sum of rewards: -103.0 

action type: buy - action 0.0
Learning step: -4.723873615264893
desired expected reward: -17.536582946777344






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 23.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 23.  8.  3.] 
cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.  0. 11.  3.  8.  0.  0. 14.  8.  8. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14
  1 11  0 23 11  3  3  8 11  0  0  0  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 17. 29.  8.  4. 10.  0.  3.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [6. 1. 3. 0. 6.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.  0.  0.  3.  3.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0] -> size -> 48 
adversary victory points: 5
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 23.] 
cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.  0. 11.  3.  8.  0.  0. 14.  8.  8. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 17. 29.  8.  4. 10.  0.  3.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [6. 1. 3. 0. 6.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.  0.  0.  3.  3.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0] -> size -> 48 
adversary victory points: 5
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 23.] 
cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.  0. 11.  3.  8.  0.  0. 14.  8.  8. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 23. 30. 17. 29.  8.  4. 10.  0.  3.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [6. 1. 3. 0. 6.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.  0.  0.  3.  3.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0] -> size -> 48 
adversary victory points: 5
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 23.] 
cards in discard: [ 8.  0. 14.  1.  3.  0. 11.  0.  1.  3.  3.  0.  0.  0.  3.  1. 11.  3.
  0.  0. 11.  3.  8.  0.  0. 14.  8.  8. 15.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 23. 30. 17. 29.  8.  4. 10.  0.  3.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [6. 1. 3. 0. 6.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.  0.  0.  3.  3.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0] -> size -> 48 
adversary victory points: 5
player victory points: 10 





Player: 0 
cards in hand: [6. 1. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-19.628407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 3. 0. 6.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.  0.  0.  3.  3.  3.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 29.  8.  4. 10.  0.  3.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [ 8.  0.  0. 11.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0] -> size -> 37 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1
Learning step: -2.4649531841278076
desired expected reward: -11.99867057800293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[-22.66329 ]
 [-24.293253]
 [-20.122555]
 [-16.300148]
 [-25.317135]
 [-20.77793 ]
 [-19.628412]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 3. 0. 6.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.  0.  0.  3.  3.  3.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 23. 30. 17. 29.  8.  4. 10.  0.  3.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [ 8.  0.  0. 11.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0] -> size -> 37 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: take_action - action -1.0
Learning step: -1.9777494668960571
desired expected reward: -21.606155395507812



buy possibilites: [-1] 
expected returns: [[-4.91538]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 3. 0. 6.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.  0.  0.  3.  3.  3.
  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 23. 30. 17. 29.  8.  4. 10.  0.  2.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [ 8.  0.  0. 11.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0] -> size -> 37 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5. -50.   0.   0.   0.   0.   0.   0.   0. -14.   0.   0.
   2.   0.] 
sum of rewards: -62.0 

action type: buy - action 8.0
Learning step: -1.9447393417358398
desired expected reward: -27.26187515258789






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0. 11.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11.  4.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 29.  8.  4. 10.  0.  2.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [ 6.  6. 15. 15.  3.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.  0.  0.  3.  3.  3.
  0.  8.  6.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8] -> size -> 49 
adversary victory points: 5
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 4.] 
cards in discard: [16.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 29.  8.  4.  9.  0.  2.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [ 6.  6. 15. 15.  3.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.  0.  0.  3.  3.  3.
  0.  8.  6.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8] -> size -> 49 
adversary victory points: 5
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 4.] 
cards in discard: [16.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0 16] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 23. 30. 17. 29.  8.  4.  9.  0.  2.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [ 6.  6. 15. 15.  3.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.  0.  0.  3.  3.  3.
  0.  8.  6.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8] -> size -> 49 
adversary victory points: 5
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 4.] 
cards in discard: [16.  8.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0 16  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 29.  8.  4.  9.  0.  1.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [ 6.  6. 15. 15.  3.] 
adversary cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.  0.  0.  3.  3.  3.
  0.  8.  6.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8] -> size -> 49 
adversary victory points: 5
player victory points: 10 





Player: 0 
cards in hand: [ 6.  6. 15. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[-16.382544]
 [-15.08038 ]
 [-15.08038 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 15. 15.  3.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.  0.  0.  3.  3.  3.
  0.  8.  6.  1.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 29.  8.  4.  9.  0.  1.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4.] 
adversary owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0 16  8] -> size -> 39 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1
Learning step: -2.601562023162842
desired expected reward: -7.516942024230957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-16.332785]
 [-16.825048]
 [-16.382544]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 15. 15.  3.] 
cards in discard: [ 1. 11. 25.  3.  3. 11.  8. 29. 10. 11.  6.  3. 14.  0. 15.  3. 29. 29.
 14. 15.  1. 10.  0.  0. 11. 11. 14.  1.  3.  0.  0.  0.  0.  3.  3.  3.
  0.  8.  6.  1.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8] -> size -> 49 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 23. 30. 17. 29.  8.  4.  9.  0.  1.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4.] 
adversary owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0 16  8] -> size -> 39 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: take_action - action -1.0
Learning step: -2.0516998767852783
desired expected reward: -18.43424415588379



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [16.  8. 11.  8.  0.  0.  4.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0 16  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 29.  8.  4.  9.  0.  1.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [ 0.  1.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8] -> size -> 49 
adversary victory points: 5
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [16.  8. 11.  8.  0.  0.  4.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0 16  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 23. 30. 17. 29.  8.  4.  9.  0.  1.  9.  7.  5.  9.  7. 10.  5.] 
adversary cards in hand: [ 0.  1.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8] -> size -> 49 
adversary victory points: 5
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0 16  8 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 29.  8.  4.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 0.  1.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8] -> size -> 49 
adversary victory points: 5
player victory points: 10 





Player: 0 
cards in hand: [ 0.  1.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[-5.3585854]
 [-6.803921 ]
 [-6.803921 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 29.  8.  4.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 3.  1.  0.  8. 15.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0 16  8 10] -> size -> 40 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1.0
Learning step: -1.8192497491836548
desired expected reward: -18.201793670654297



action possibilites: [-1] 
expected returns: [[25.89277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 11.] 
cards in discard: [6.] 
cards in deck: 44 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 29.  8.  3.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 3.  1.  0.  8. 15.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0 16  8 10] -> size -> 40 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[  -5    0    4  -60    0    0   20    0    0    0    0  -15    0 -300
    0    0] 
sum of rewards: -356 

action type: gain_card_n - action 3
Learning step: -16.84416961669922
desired expected reward: -24.309053421020508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.24704 ]
 [22.436703]
 [21.045162]
 [10.426463]
 [19.956993]
 [20.67608 ]
 [20.318537]
 [14.206155]
 [19.934244]
 [17.937872]
 [24.219841]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 11.] 
cards in discard: [6.] 
cards in deck: 44 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6] -> size -> 50 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 23. 30. 17. 29.  8.  3.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 3.  1.  0.  8. 15.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0 16  8 10] -> size -> 40 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action -1
Learning step: -2.895486831665039
desired expected reward: 22.997283935546875



buy possibilites: [-1] 
expected returns: [[3.6654341]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 11.] 
cards in discard: [6. 6.] 
cards in deck: 44 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6] -> size -> 51 
action values: 0 
buys: 0 
player value: 4 
card supply: [12. 23. 30. 17. 29.  8.  2.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 3.  1.  0.  8. 15.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0 16  8 10] -> size -> 40 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.  -70.    0.    0.   20.    0.    0.    0.    0.  -16.
    0. -300.    0.    0.] 
sum of rewards: -368.0 

action type: buy - action 6.0
Learning step: -18.660484313964844
desired expected reward: -11.801351547241211






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 3.  1.  0.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  8. 15.] 
cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 15 11  8  3  0  0  0 14  3  4  0  0  3  3  1  0  1  8  8  0 14  1
 11  0 23 11  3  3  8 11  0  0  0  8  0 16  8 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 29.  8.  2.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 3. 10. 11. 14. 11.] 
adversary cards in discard: [ 6.  6. 11.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6] -> size -> 51 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  8  3  0  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23
 11  3  3  8 11  0  0  0  8  0 16  8 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 29.  8.  2.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 3. 10. 11. 14. 11.] 
adversary cards in discard: [ 6.  6. 11.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6] -> size -> 51 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  8  3  0  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23
 11  3  3  8 11  0  0  0  8  0 16  8 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 23. 30. 17. 29.  8.  2.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 3. 10. 11. 14. 11.] 
adversary cards in discard: [ 6.  6. 11.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6] -> size -> 51 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  8  3  0  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23
 11  3  3  8 11  0  0  0  8  0 16  8 10  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 23. 30. 17. 29.  8.  2.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 3. 10. 11. 14. 11.] 
adversary cards in discard: [ 6.  6. 11.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6] -> size -> 51 
adversary victory points: 3
player victory points: 9 





Player: 0 
cards in hand: [ 3. 10. 11. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 14. 11.] 
expected returns: [[-16.457973]
 [-14.074843]
 [-15.485041]
 [-10.951615]
 [-15.485041]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 14. 11.] 
cards in discard: [ 6.  6. 11.  0.  1.  0. 11.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 17. 29.  8.  2.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0 11  8  3  0  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23
 11  3  3  8 11  0  0  0  8  0 16  8 10  0] -> size -> 38 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -62 

action type: buy - action -1
Learning step: -3.595097780227661
desired expected reward: 0.07033634185791016



action possibilites: [-1] 
expected returns: [[-45.513535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 11.] 
cards in discard: [ 6.  6. 11.  0.  1.  0. 11.] 
cards in deck: 39 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 23. 30. 17. 29.  8.  2.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [11.  0.  3.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0 11  8  3  0  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23
 11  3  3  8 11  0  0  0  8  0 16  8 10  0] -> size -> 38 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action 14.0
Learning step: -2.5764739513397217
desired expected reward: -13.528087615966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-49.747414]
 [-45.88661 ]
 [-44.62055 ]
 [-51.620686]
 [-46.120903]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11. 11.] 
cards in discard: [ 6.  6. 11.  0.  1.  0. 11.] 
cards in deck: 39 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 23. 30. 17. 29.  8.  2.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [11.  0.  3.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0 11  8  3  0  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23
 11  3  3  8 11  0  0  0  8  0 16  8 10  0] -> size -> 38 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1
Learning step: -0.8833389282226562
desired expected reward: -46.396873474121094



buy possibilites: [-1] 
expected returns: [[-18.94126]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11. 11.] 
cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6.] 
cards in deck: 39 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6] -> size -> 52 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 23. 30. 17. 29.  8.  1.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [11.  0.  3.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0 11  8  3  0  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23
 11  3  3  8 11  0  0  0  8  0 16  8 10  0] -> size -> 38 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -70.    0.    0.   20.    0.    0.    0.    0.  -17.
    0. -300.    0.    0.] 
sum of rewards: -370.0 

action type: buy - action 6.0
Learning step: -16.69515037536621
desired expected reward: -61.31568908691406






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.] 
cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  8  3  0  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23
 11  3  3  8 11  0  0  0  8  0 16  8 10  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 17. 29.  8.  1.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6] -> size -> 52 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.] 
cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  8  3  0  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23
 11  3  3  8 11  0  0  0  8  0 16  8 10  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 23. 30. 17. 29.  8.  1.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6] -> size -> 52 
adversary victory points: 2
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [8. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[ -9.905393]
 [-11.801501]
 [-11.801501]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 17. 29.  8.  1.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [8. 1. 8. 0. 0.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.
 11.  0.  3.] 
adversary owned cards: [ 0 11  8  3  0  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23
 11  3  3  8 11  0  0  0  8  0 16  8 10  0] -> size -> 38 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1
Learning step: -2.949171543121338
desired expected reward: -21.890430450439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -9.889226]
 [ -7.463181]
 [-11.732769]
 [-11.8015  ]
 [ -9.905393]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 23. 30. 17. 29.  8.  1.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [8. 1. 8. 0. 0.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.
 11.  0.  3.] 
adversary owned cards: [ 0 11  8  3  0  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23
 11  3  3  8 11  0  0  0  8  0 16  8 10  0] -> size -> 38 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -3.3724663257598877
desired expected reward: -13.277859687805176



buy possibilites: [-1] 
expected returns: [[-14.172241]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6  3] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 16. 29.  8.  1.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [8. 1. 8. 0. 0.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.
 11.  0.  3.] 
adversary owned cards: [ 0 11  8  3  0  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23
 11  3  3  8 11  0  0  0  8  0 16  8 10  0] -> size -> 38 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0   0   0   0   0   0 -18   0   0   8   0] 
sum of rewards: -72 

action type: buy - action 3.0
Learning step: -3.5457165241241455
desired expected reward: -11.00889778137207






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [8. 1. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 8. 0. 0.] 
cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.
 11.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  8  3  0  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23
 11  3  3  8 11  0  0  0  8  0 16  8 10  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 16. 29.  8.  1.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 3.  3.  1.  3. 15.] 
adversary cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.  3.  8.  3.  0.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6  3] -> size -> 53 
adversary victory points: 3
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8.] 
cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.
 11.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8  3  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23 11  3
  3  8 11  0  0  0  8  0 16  8 10  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 16. 29.  8.  1.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 3.  3.  1.  3. 15.] 
adversary cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.  3.  8.  3.  0.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6  3] -> size -> 53 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8.] 
cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.
 11.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8  3  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23 11  3
  3  8 11  0  0  0  8  0 16  8 10  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 23. 30. 16. 29.  8.  1.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 3.  3.  1.  3. 15.] 
adversary cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.  3.  8.  3.  0.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6  3] -> size -> 53 
adversary victory points: 3
player victory points: 9 





Player: 0 
cards in hand: [ 3.  3.  1.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[ 1.6654928]
 [-4.575091 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1.  3. 15.] 
cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.  3.  8.  3.  0.  0.
  8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6  3] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 16. 29.  8.  1.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 0.  3.  8. 11. 23.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.
 11.  0.  3.  8.  1.  8.] 
adversary owned cards: [11  8  3  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23 11  3
  3  8 11  0  0  0  8  0 16  8 10  0] -> size -> 36 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -62 

action type: buy - action -1
Learning step: -2.4115848541259766
desired expected reward: -16.583826065063477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -3.7316484 ]
 [  0.83112216]
 [-21.655159  ]
 [ -0.69357824]
 [  1.6654928 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1.  3. 15.] 
cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.  3.  8.  3.  0.  0.
  8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6  3] -> size -> 53 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 23. 30. 16. 29.  8.  1.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 0.  3.  8. 11. 23.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.
 11.  0.  3.  8.  1.  8.] 
adversary owned cards: [11  8  3  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23 11  3
  3  8 11  0  0  0  8  0 16  8 10  0] -> size -> 36 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -62 

action type: take_action - action -1.0
Learning step: -3.263760805130005
desired expected reward: -1.5982637405395508



buy possibilites: [-1] 
expected returns: [[-4.8779755]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1.  3. 15.] 
cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.  3.  8.  3.  0.  0.
  8.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6  3  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 23. 30. 16. 29.  8.  1.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 0.  3.  8. 11. 23.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.
 11.  0.  3.  8.  1.  8.] 
adversary owned cards: [11  8  3  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23 11  3
  3  8 11  0  0  0  8  0 16  8 10  0] -> size -> 36 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -60.   0.   0.   0. -30.   0.   0.   0. -19.   0.   0.
   0.   0.] 
sum of rewards: -111.0 

action type: buy - action 0.0
Learning step: -5.473172187805176
desired expected reward: -9.204826354980469






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  8. 11. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 23.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 11. 23.] 
cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.
 11.  0.  3.  8.  1.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23 11  3
  3  8 11  0  0  0  8  0 16  8 10  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 23. 30. 16. 29.  8.  1.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [15.  0.  0.  6. 25.] 
adversary cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.  3.  8.  3.  0.  0.
  8.  0.  3.  3.  1.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6  3  0] -> size -> 54 
adversary victory points: 3
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 23.] 
cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.
 11.  0.  3.  8.  1.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  8  3  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23 11  3
  3  8 11  0  0  0  8  0 16  8 10  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 23. 30. 15. 29.  8.  1.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [15.  0.  0.  6. 25.] 
adversary cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.  3.  8.  3.  0.  0.
  8.  0.  3.  3.  1.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6  3  0] -> size -> 54 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8. 23.] 
cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.
 11.  0.  3.  8.  1.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  8  3  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23 11  3
  3  8 11  0  0  0  8  0 16  8 10  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 23. 30. 15. 29.  8.  1.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [15.  0.  0.  6. 25.] 
adversary cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.  3.  8.  3.  0.  0.
  8.  0.  3.  3.  1.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6  3  0] -> size -> 54 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8. 23.] 
cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.
 11.  0.  3.  8.  1.  8.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  8  3  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23 11  3
  3  8 11  0  0  0  8  0 16  8 10  0  3  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 23. 30. 15. 29.  8.  1.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [15.  0.  0.  6. 25.] 
adversary cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.  3.  8.  3.  0.  0.
  8.  0.  3.  3.  1.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6  3  0] -> size -> 54 
adversary victory points: 3
player victory points: 10 





Player: 0 
cards in hand: [15.  0.  0.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[-10.500133 ]
 [ -8.37104  ]
 [-13.7479925]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  6. 25.] 
cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.  3.  8.  3.  0.  0.
  8.  0.  3.  3.  1.  3. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6  3  0] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 15. 29.  8.  1.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 0. 11.  1.  0. 14.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.
 11.  0.  3.  8.  1.  8.  3.  0. 11.  0.  3.  8. 23.] 
adversary owned cards: [11  8  3  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23 11  3
  3  8 11  0  0  0  8  0 16  8 10  0  3  0] -> size -> 38 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -72 

action type: buy - action -1
Learning step: -3.5906929969787598
desired expected reward: -8.468667984008789



action possibilites: [-1] 
expected returns: [[-0.6520026]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  6. 15.  3.] 
cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.  3.  8.  3.  0.  0.
  8.  0.  3.  3.  1.  3. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6  3  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 15. 29.  8.  0.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 0. 11.  1.  0. 14.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.
 11.  0.  3.  8.  1.  8.  3.  0. 11.  0.  3.  8. 23.  6.] 
adversary owned cards: [11  8  3  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23 11  3
  3  8 11  0  0  0  8  0 16  8 10  0  3  0  6] -> size -> 39 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action 25.0
Learning step: -1.9272702932357788
desired expected reward: -15.675262451171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-2.2732573 ]
 [-0.32764673]
 [-2.0574534 ]
 [-0.6520028 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  6. 15.  3.] 
cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.  3.  8.  3.  0.  0.
  8.  0.  3.  3.  1.  3. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6  3  0] -> size -> 54 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 23. 30. 15. 29.  8.  0.  9.  0.  1.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 0. 11.  1.  0. 14.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.
 11.  0.  3.  8.  1.  8.  3.  0. 11.  0.  3.  8. 23.  6.] 
adversary owned cards: [11  8  3  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23 11  3
  3  8 11  0  0  0  8  0 16  8 10  0  3  0  6] -> size -> 39 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1
Learning step: -2.5932531356811523
desired expected reward: -3.245255708694458



Player 1 won the game! 



Player 0 bought cards:
Copper: 6 
Silver: 2 
Gold: 0 
Estate: 8 
Duchy: 0 
Province: 0 
Curse: 5 

Remodel: 0 
Workshop: 6 
Chapel: 3 
Witch: 1 
Poacher: 2 
Militia: 2 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 3 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15.  0.  0.  6. 15.  3.] 
cards in discard: [ 6.  6. 11.  0.  1.  0. 11.  6. 14.  3. 10. 11. 11.  3.  8.  3.  0.  0.
  8.  0.  3.  3.  1.  3. 15.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11  3 15  6  3  0  1  6 11 29 10 14 10  0 11  0 15
  3 29 29  3 14  1  0  3  6  1 14  6  3 25 15  3  6 11 11  1  8 15 11  0
  8  6  6  6  3  0  8] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 15. 29.  8.  0.  9.  0.  0.  9.  7.  5.  9.  6. 10.  5.] 
adversary cards in hand: [ 0. 11.  1.  0. 14.] 
adversary cards in discard: [16.  8. 11.  8.  0.  0.  4. 10.  0.  3.  0.  3.  0.  0.  8.  0.  0.  3.
 11.  0.  3.  8.  1.  8.  3.  0. 11.  0.  3.  8. 23.  6.] 
adversary owned cards: [11  8  3  0  0 14  3  4  0  0  3  3  0  1  8  8  0 14  1 11  0 23 11  3
  3  8 11  0  0  0  8  0 16  8 10  0  3  0  6] -> size -> 39 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5 -500    3  -70    0    0   20    0    0    0    0  -20    0    0
    4    0] 
sum of rewards: -568 

action type: buy - action 8.0
Learning step: -28.297128677368164
desired expected reward: -30.35457992553711



