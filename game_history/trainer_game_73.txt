 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[312.8437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -1  -60    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -566 

action type: buy - action -1
Learning step: -27.561756134033203
desired expected reward: -42.3266487121582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[287.58008]
 [300.0746 ]
 [294.35422]
 [262.0518 ]
 [307.1644 ]
 [296.39423]
 [293.40817]
 [312.57544]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.214664459228516
desired expected reward: 305.47015380859375



buy possibilites: [-1] 
expected returns: [[299.17325]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -7.436313152313232
desired expected reward: 286.91790771484375






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 3. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[310.66943]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -7.994600772857666
desired expected reward: 291.17864990234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[285.55405]
 [300.2187 ]
 [293.28583]
 [257.3251 ]
 [291.98386]
 [307.32117]
 [295.83884]
 [297.1579 ]
 [270.22684]
 [291.48477]
 [285.28134]
 [311.51324]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -9.09824275970459
desired expected reward: 302.6378479003906



buy possibilites: [-1] 
expected returns: [[283.60776]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  3.  3.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 31 

action type: buy - action 14.0
Learning step: -5.580167293548584
desired expected reward: 264.64666748046875






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[289.08847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [3. 0. 8. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 3] -> size -> 13 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -8.24492359161377
desired expected reward: 275.3628234863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[262.35245]
 [274.91553]
 [268.5077 ]
 [234.20012]
 [267.94785]
 [280.51678]
 [271.55478]
 [272.63242]
 [247.86288]
 [267.26685]
 [261.78204]
 [283.3679 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [3. 0. 8. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 3] -> size -> 13 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -8.97537899017334
desired expected reward: 279.26751708984375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [3. 0. 8. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  3.  0.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [3. 0. 8. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  3.  0.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [3. 0. 8. 0. 3. 3. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 3 8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 27. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  3.  0.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 0. 14.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[289.27997]
 [248.14856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  3.  0.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 3 8] -> size -> 14 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -8.699858665466309
desired expected reward: 274.66796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[263.66617]
 [277.66373]
 [270.79648]
 [235.73625]
 [285.42014]
 [273.31146]
 [269.4468 ]
 [290.40784]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.  0.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 27. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 3 8] -> size -> 14 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -8.85979175567627
desired expected reward: 279.2002258300781



buy possibilites: [-1] 
expected returns: [[310.09412]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.  0.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 27. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 3 8] -> size -> 14 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -41.0 

action type: buy - action 0.0
Learning step: -8.25619125366211
desired expected reward: 255.40997314453125






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 8. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 3 8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0] -> size -> 13 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0] -> size -> 13 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 27. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0] -> size -> 13 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 3 3 8 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0] -> size -> 13 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[309.45627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 3 8 0] -> size -> 12 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -9.109689712524414
desired expected reward: 300.98443603515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[278.39658]
 [285.48965]
 [250.12384]
 [287.93585]
 [302.8648 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 3 8 0] -> size -> 12 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -9.661643028259277
desired expected reward: 299.00579833984375



buy possibilites: [-1] 
expected returns: [[278.02472]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  9. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 3 8 0] -> size -> 12 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -322.0 

action type: buy - action 6.0
Learning step: -22.350635528564453
desired expected reward: 227.773193359375






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 3 8 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  9. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [6. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6] -> size -> 14 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 3 8 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  9. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [6. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6] -> size -> 14 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[318.54587]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6. 3. 0. 0. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  9. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 3 8 0] -> size -> 12 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -7.84467077255249
desired expected reward: 270.1800537109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[283.58557]
 [299.32758]
 [292.51193]
 [252.61852]
 [290.54376]
 [307.62024]
 [294.33762]
 [295.93298]
 [267.40863]
 [290.5173 ]
 [283.88528]
 [313.07416]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6. 3. 0. 0. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 27. 30.  8.  9. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 3 8 0] -> size -> 12 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -10.494585990905762
desired expected reward: 307.5749816894531



buy possibilites: [-1] 
expected returns: [[275.89594]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6. 3. 0. 0. 3. 3. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 30. 30. 27. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 3 8 0] -> size -> 12 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -333.0 

action type: buy - action 6.0
Learning step: -22.7034969329834
desired expected reward: 229.9149932861328






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 3 8 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  3.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6] -> size -> 15 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 3 8 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 27. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  3.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6] -> size -> 15 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  3.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[259.4307 ]
 [222.78697]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 3 8 0] -> size -> 12 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -10.024115562438965
desired expected reward: 265.871826171875



action possibilites: [-1] 
expected returns: [[229.72287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 3 8 0] -> size -> 12 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action 14.0
Learning step: -6.614327430725098
desired expected reward: 216.04750061035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[199.92233]
 [214.21112]
 [207.73167]
 [171.20782]
 [206.224  ]
 [221.52617]
 [209.74411]
 [211.0499 ]
 [185.0316 ]
 [205.90497]
 [199.8112 ]
 [226.25064]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 27. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 3 8 0] -> size -> 12 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1
Learning step: -7.526159763336182
desired expected reward: 222.19671630859375



buy possibilites: [-1] 
expected returns: [[230.6422]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 3 8 0] -> size -> 12 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -8.5 

action type: buy - action 11.0
Learning step: -6.311858654022217
desired expected reward: 215.21429443359375






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [0. 0. 3. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 3 8 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [11. 14.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11] -> size -> 16 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [0. 0. 3. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 3 8 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [11. 14.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11] -> size -> 16 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [0. 0. 3. 3. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 3 8 0 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [11. 14.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11] -> size -> 16 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[237.04024]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [11. 14.  6.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 3 8 0 0] -> size -> 13 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -7.850067138671875
desired expected reward: 222.79212951660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[221.03818]
 [232.69966]
 [225.40279]
 [196.16519]
 [226.00182]
 [236.65855]
 [230.06696]
 [230.6138 ]
 [207.04526]
 [224.3029 ]
 [219.24309]
 [237.59491]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [11. 14.  6.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 27. 30.  8.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 3 8 0 0] -> size -> 13 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -8.461122512817383
desired expected reward: 228.51856994628906



buy possibilites: [-1] 
expected returns: [[195.82353]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [11. 14.  6.  3.  0.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  8.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 3 8 0 0] -> size -> 13 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -1 

action type: buy - action 16.0
Learning step: -6.94406270980835
desired expected reward: 219.05776977539062






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 3 8 0 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  8.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [11. 14.  6.  3.  0.  0. 16.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16] -> size -> 17 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 3 3 3 3 8 0 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  8.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [11. 14.  6.  3.  0.  0. 16.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16] -> size -> 17 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 3 3 3 3 8 0 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  8.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [11. 14.  6.  3.  0.  0. 16.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16] -> size -> 17 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 3 3 3 3 8 0 0 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  8.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [11. 14.  6.  3.  0.  0. 16.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16] -> size -> 17 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[236.32266]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [11. 14.  6.  3.  0.  0. 16.  0.  0.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [0 0 0 3 3 3 3 3 8 0 0 0] -> size -> 12 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -6.152418613433838
desired expected reward: 189.67111206054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[211.60129]
 [217.84517]
 [189.20451]
 [219.1995 ]
 [234.72005]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [11. 14.  6.  3.  0.  0. 16.  0.  0.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 30.  8.  8.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [0 0 0 3 3 3 3 3 8 0 0 0] -> size -> 12 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -8.576154708862305
desired expected reward: 226.47976684570312



buy possibilites: [-1] 
expected returns: [[204.32104]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [11. 14.  6.  3.  0.  0. 16.  0.  0.  0.  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  8.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [0 0 0 3 3 3 3 3 8 0 0 0] -> size -> 12 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -14 

action type: buy - action 3.0
Learning step: -6.995034694671631
desired expected reward: 210.85011291503906






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 3 3 8 0 0 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  8.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3] -> size -> 18 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 3 3 8 0 0 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 26. 30.  8.  8.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3] -> size -> 18 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [0. 8. 3. 0. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3] -> size -> 18 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 3.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[207.48036]
 [204.48253]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -6.665431976318359
desired expected reward: 197.65560913085938



action possibilites: [-1] 
expected returns: [[212.29999]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: gain_card_n - action 0
Learning step: -6.116095066070557
desired expected reward: 179.7407989501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[186.66151]
 [192.65555]
 [162.40083]
 [195.24115]
 [207.94713]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 26. 30.  8.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1
Learning step: -6.462851047515869
desired expected reward: 205.83714294433594



buy possibilites: [-1] 
expected returns: [[228.90881]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [0. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  8.  9.  9.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 6 

action type: buy - action 8.0
Learning step: -4.311608791351318
desired expected reward: 190.9295196533203






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  8.  9.  9.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 14.] 
adversary cards in discard: [ 0.  8. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8] -> size -> 20 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 26. 30.  8.  8.  9.  9.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 14.] 
adversary cards in discard: [ 0.  8. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8] -> size -> 20 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[201.32793]
 [167.91704]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 14.] 
cards in discard: [ 0.  8. 11.  3.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  8.  9.  9.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 8. 3. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -8.4027681350708
desired expected reward: 220.50604248046875



action possibilites: [-1] 
expected returns: [[238.75916]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  8. 11.  3.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 26. 30.  8.  8.  9.  9.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 8. 3.] 
adversary owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action 14.0
Learning step: -2.6666200160980225
desired expected reward: 156.10739135742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[225.54369]
 [239.36763]
 [231.7752 ]
 [205.49496]
 [193.2515 ]
 [231.62352]
 [245.13739]
 [235.92273]
 [257.36432]
 [236.82942]
 [208.80011]
 [217.67517]
 [230.57385]
 [201.24129]
 [224.5898 ]
 [247.83276]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  8. 11.  3.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 30. 30. 26. 30.  8.  8.  9.  9.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 8. 3.] 
adversary owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1
Learning step: -6.928906440734863
desired expected reward: 231.8302459716797






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [3. 3. 0. 0. 3. 8. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  8.  9.  9.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  8. 11.  3.  0.  3.  0. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8] -> size -> 20 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [3. 3. 0. 0. 3. 8. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 26. 30.  8.  8.  9.  9.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  8. 11.  3.  0.  3.  0. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8] -> size -> 20 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [3. 3. 0. 0. 3. 8. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 26. 30.  8.  8.  9.  9.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  8. 11.  3.  0.  3.  0. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8] -> size -> 20 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[214.92387]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [ 0.  8. 11.  3.  0.  3.  0. 14.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  8.  9.  9.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8 0] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -8.638136863708496
desired expected reward: 239.19461059570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[196.84999]
 [208.13487]
 [203.13925]
 [174.28654]
 [213.78838]
 [204.49646]
 [201.56873]
 [217.34999]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [ 0.  8. 11.  3.  0.  3.  0. 14.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 26. 30.  8.  8.  9.  9.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8 0] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -7.330337047576904
desired expected reward: 208.38079833984375



buy possibilites: [-1] 
expected returns: [[209.4922]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [ 0.  8. 11.  3.  0.  3.  0. 14.  0.  0.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 30. 30. 26. 30.  8.  7.  9.  9.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8 0] -> size -> 14 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -333.0 

action type: buy - action 6.0
Learning step: -20.650754928588867
desired expected reward: 153.63580322265625






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  7.  9.  9.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14. 11.  6.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6] -> size -> 21 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 26. 30.  8.  7.  9.  9.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14. 11.  6.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6] -> size -> 21 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8 0 8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 26. 30.  8.  7.  9.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14. 11.  6.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6] -> size -> 21 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [14. 11.  6.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 16.] 
expected returns: [[173.046  ]
 [146.57057]
 [171.52432]
 [162.00153]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  6.  3. 16.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  7.  9.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 8.] 
adversary cards in discard: [8. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8 0 8] -> size -> 15 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -8.48388671875
desired expected reward: 201.00831604003906



action possibilites: [-1] 
expected returns: [[180.21753]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  3. 16.] 
cards in discard: [15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  7.  9.  9.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 8.] 
adversary cards in discard: [8. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8 0 8] -> size -> 15 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 3 

action type: gain_card_n - action 10
Learning step: -3.773426055908203
desired expected reward: 155.79298400878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[163.60762]
 [140.36232]
 [182.42119]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  3. 16.] 
cards in discard: [15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  7.  9.  9.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 8.] 
adversary cards in discard: [8. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8 0 8] -> size -> 15 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1
Learning step: -6.012868404388428
desired expected reward: 174.2046661376953



buy possibilites: [-1] 
expected returns: [[153.1819]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  3. 16.] 
cards in discard: [15.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  7.  9.  9.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 8.] 
adversary cards in discard: [8. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8 0 8] -> size -> 15 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action 0.0
Learning step: -6.883790016174316
desired expected reward: 156.72386169433594






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 8.] 
cards in discard: [8. 0. 3. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 3 3 8 0 0 0 8 0 8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  7.  9.  9.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [15.  0. 11. 14.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0] -> size -> 23 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [8. 0. 3. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 3 3 3 3 3 8 0 0 0 8 0 8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  7.  9.  9.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [15.  0. 11. 14.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0] -> size -> 23 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [8. 0. 3. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 3 3 3 3 3 8 0 0 0 8 0 8] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  7.  9.  9.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [15.  0. 11. 14.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0] -> size -> 23 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[138.29355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [15.  0. 11. 14.  6.  3. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  7.  9.  9.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 3 3 8 0 0 0 8 0 8] -> size -> 14 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -6.274334907531738
desired expected reward: 146.90756225585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[118.17297]
 [123.46982]
 [ 97.12706]
 [125.26639]
 [135.29521]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [15.  0. 11. 14.  6.  3. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 26. 30.  8.  7.  9.  9.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 3 3 8 0 0 0 8 0 8] -> size -> 14 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -5.696863174438477
desired expected reward: 129.18136596679688



buy possibilites: [-1] 
expected returns: [[125.1198]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [15.  0. 11. 14.  6.  3. 16.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 3 3 8 0 0 0 8 0 8] -> size -> 14 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -344.0 

action type: buy - action 6.0
Learning step: -19.241159439086914
desired expected reward: 77.88590240478516






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 3 3 8 0 0 0 8 0 8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [15.  0. 11. 14.  6.  3. 16.  6.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6] -> size -> 24 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 3 8 0 0 0 8 0 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [15.  0. 11. 14.  6.  3. 16.  6.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6] -> size -> 24 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 3 8 0 0 0 8 0 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [15.  0. 11. 14.  6.  3. 16.  6.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6] -> size -> 24 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 3 8 0 0 0 8 0 8 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [15.  0. 11. 14.  6.  3. 16.  6.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6] -> size -> 24 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[127.7392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [15.  0. 11. 14.  6.  3. 16.  6.  0.  3.  6.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 3.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [3 3 3 3 3 8 0 0 0 8 0 8 0] -> size -> 13 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -5.68628454208374
desired expected reward: 119.43350982666016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[110.93968 ]
 [120.90941 ]
 [116.64308 ]
 [ 91.125015]
 [115.36102 ]
 [126.38693 ]
 [117.659424]
 [118.64241 ]
 [100.680374]
 [115.373535]
 [111.10919 ]
 [130.24005 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [15.  0. 11. 14.  6.  3. 16.  6.  0.  3.  6.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 3.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [3 3 3 3 3 8 0 0 0 8 0 8 0] -> size -> 13 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -5.776586055755615
desired expected reward: 117.32141876220703



buy possibilites: [-1] 
expected returns: [[101.47331]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [15.  0. 11. 14.  6.  3. 16.  6.  0.  3.  6.  0.  3. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 0. 8. 3.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [3 3 3 3 3 8 0 0 0 8 0 8 0] -> size -> 13 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -12 

action type: buy - action 15.0
Learning step: -3.7172698974609375
desired expected reward: 107.39193725585938






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 3.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 0 0 0 8 0 8 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 6. 8.] 
adversary cards in discard: [15.  0. 11. 14.  6.  3. 16.  6.  0.  3.  6.  0.  3. 15.  0.  0.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15] -> size -> 25 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 8 0 0 8 0 8 0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 6. 8.] 
adversary cards in discard: [15.  0. 11. 14.  6.  3. 16.  6.  0.  3.  6.  0.  3. 15.  0.  0.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15] -> size -> 25 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 8 0 0 8 0 8 0] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 6. 8.] 
adversary cards in discard: [15.  0. 11. 14.  6.  3. 16.  6.  0.  3.  6.  0.  3. 15.  0.  0.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15] -> size -> 25 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0. 8. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 8 0 0 8 0 8 0 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 6. 8.] 
adversary cards in discard: [15.  0. 11. 14.  6.  3. 16.  6.  0.  3.  6.  0.  3. 15.  0.  0.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15] -> size -> 25 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[123.128174]
 [116.0629  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 8.] 
cards in discard: [15.  0. 11. 14.  6.  3. 16.  6.  0.  3.  6.  0.  3. 15.  0.  0.  0.  3.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 3 8 0 0 8 0 8 0 0] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -3.584705352783203
desired expected reward: 97.88861083984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[105.020676]
 [115.851074]
 [109.32999 ]
 [ 85.57507 ]
 [119.698   ]
 [112.852615]
 [107.74559 ]
 [120.24521 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 8.] 
cards in discard: [15.  0. 11. 14.  6.  3. 16.  6.  0.  3.  6.  0.  3. 15.  0.  0.  0.  3.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 3 8 0 0 8 0 8 0 0] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -4.882380962371826
desired expected reward: 118.0589370727539



buy possibilites: [-1] 
expected returns: [[94.99156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 8.] 
cards in discard: [15.  0. 11. 14.  6.  3. 16.  6.  0.  3.  6.  0.  3. 15.  0.  0.  0.  3.
  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 3 8 0 0 8 0 8 0 0] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -6 

action type: buy - action 10.0
Learning step: -3.549968719482422
desired expected reward: 104.19560241699219






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 8 0 0 8 0 8 0 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 6. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15 10] -> size -> 26 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 8 0 0 8 0 8 0 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 6. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15 10] -> size -> 26 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  0  0  8  0  8  0  0 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 6. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15 10] -> size -> 26 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [0. 6. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[143.09009]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 3. 8. 8.] 
adversary cards in discard: [10.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 3  3  3  8  0  0  8  0  8  0  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -2.8164987564086914
desired expected reward: 92.17506408691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[118.999115]
 [125.86615 ]
 [ 96.803406]
 [127.14078 ]
 [141.58139 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 3. 8. 8.] 
adversary cards in discard: [10.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 3  3  3  8  0  0  8  0  8  0  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -5.415567874908447
desired expected reward: 133.8323974609375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 8. 8.] 
cards in discard: [10.  0.  0.  0.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  0  0  8  0  8  0  0 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 14.  0.] 
adversary cards in discard: [0. 6. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15 10] -> size -> 26 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 8. 8.] 
cards in discard: [10.  0.  0.  0.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  0  0  8  0  8  0  0 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 14.  0.] 
adversary cards in discard: [0. 6. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15 10] -> size -> 26 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 8. 8.] 
cards in discard: [10.  0.  0.  0.  8.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  0  0  8  0  8  0  0 10  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 14.  0.] 
adversary cards in discard: [0. 6. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15 10] -> size -> 26 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[237.57346]
 [200.98495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 14.  0.] 
cards in discard: [0. 6. 3. 0. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8  0  0  8  0  8  0  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -3.4155890941619873
desired expected reward: 138.16583251953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[211.30202]
 [224.53638]
 [218.74832]
 [184.3892 ]
 [231.28723]
 [220.19234]
 [216.91891]
 [235.8313 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 14.  0.] 
cards in discard: [0. 6. 3. 0. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 26. 30.  8.  6.  9.  9.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8  0  0  8  0  8  0  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -8.013014793395996
desired expected reward: 226.30389404296875



buy possibilites: [-1] 
expected returns: [[151.06885]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 14.  0.] 
cards in discard: [ 0.  6.  3.  0.  3. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  6.  9.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8  0  0  8  0  8  0  0 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -6 

action type: buy - action 11.0
Learning step: -8.465313911437988
desired expected reward: 222.82192993164062






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  0  0  8  0  8  0  0 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  6.  9.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  8. 15. 15.  0.] 
adversary cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15 10 11] -> size -> 27 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  0  0  8  0  8  0  0 10  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 26. 30.  8.  6.  9.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  8. 15. 15.  0.] 
adversary cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15 10 11] -> size -> 27 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  0  0  8  0  8  0  0 10  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 30. 30. 26. 30.  8.  6.  9.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  8. 15. 15.  0.] 
adversary cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15 10 11] -> size -> 27 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 6.  8. 15. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 15.] 
expected returns: [[99.96344]
 [88.63585]
 [79.96124]
 [79.96124]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 15. 15.  0.] 
cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  6  6 11 16  3  0  8  6 15  0  6
 15 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 26. 30.  8.  6.  9.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  0.  8.  3. 10.] 
adversary cards in discard: [0. 3. 0. 3. 8. 0.] 
adversary owned cards: [ 3  3  3  8  0  0  8  0  8  0  0 10  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -6.8075714111328125
desired expected reward: 144.2612762451172



action possibilites: [-1] 
expected returns: [[126.47031]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 26. 30.  8.  6.  9.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  0.  8.  3. 10.] 
adversary cards in discard: [0. 3. 0. 3. 8. 0.] 
adversary owned cards: [ 3  3  3  8  0  0  8  0  8  0  0 10  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: trash_cards_n_from_hand - action 8
Learning step: -1.1507385969161987
desired expected reward: 85.77566528320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[110.33159 ]
 [ 84.932236]
 [133.3137  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 30. 30. 26. 30.  8.  6.  9.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  0.  8.  3. 10.] 
adversary cards in discard: [0. 3. 0. 3. 8. 0.] 
adversary owned cards: [ 3  3  3  8  0  0  8  0  8  0  0 10  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -3.5090959072113037
desired expected reward: 122.96121215820312



buy possibilites: [-1] 
expected returns: [[110.858246]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 26. 30.  8.  6.  9.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  0.  8.  3. 10.] 
adversary cards in discard: [0. 3. 0. 3. 8. 0.] 
adversary owned cards: [ 3  3  3  8  0  0  8  0  8  0  0 10  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action 0.0
Learning step: -4.172269344329834
desired expected reward: 106.15931701660156






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8.  3. 10.] 
cards in discard: [0. 3. 0. 3. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  0  0  8  0  8  0  0 10  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 26. 30.  8.  6.  9.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [0. 3. 0. 3. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  0  8  0  8  0  0 10  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 26. 30.  8.  6.  9.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [0. 3. 0. 3. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  0  8  0  8  0  0 10  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 30. 30. 26. 30.  8.  6.  9.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [11.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[95.94922 ]
 [93.931244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.  0.  8. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 26. 30.  8.  6.  9.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0  8  0  8  0  0 10  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -3.583833694458008
desired expected reward: 107.2744140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[76.585556]
 [86.065475]
 [81.33563 ]
 [58.889793]
 [90.6183  ]
 [82.990036]
 [79.70157 ]
 [92.82219 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.  0.  8. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 30. 30. 26. 30.  8.  6.  9.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0  8  0  8  0  0 10  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -3.0614078044891357
desired expected reward: 91.6743392944336



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  8  0  8  0  0 10  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 26. 30.  8.  6.  9.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  6. 16.  0. 10.] 
adversary cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.  0.  8. 15. 11.  3.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  0  8  0  8  0  0 10  0  0] -> size -> 11 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 26. 30.  8.  6.  9.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  6. 16.  0. 10.] 
adversary cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.  0.  8. 15. 11.  3.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  0  8  0  8  0  0 10  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 30. 30. 26. 30.  8.  6.  9.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  6. 16.  0. 10.] 
adversary cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.  0.  8. 15. 11.  3.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  0  8  0  8  0  0 10  0  0 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 26. 30.  8.  6.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  6. 16.  0. 10.] 
adversary cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.  0.  8. 15. 11.  3.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 6.  6. 16.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
expected returns: [[129.81416]
 [114.68956]
 [114.04231]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 16.  0. 10.] 
cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.  0.  8. 15. 11.  3.  0.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 26. 30.  8.  6.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [16. 10.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 3  3  0  8  0  8  0  0 10  0  0 16] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -2.1366190910339355
desired expected reward: 90.6855697631836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[103.19571 ]
 [ 81.88618 ]
 [120.708145]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 16.  0. 10.] 
cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.  0.  8. 15. 11.  3.  0.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 30. 30. 26. 30.  8.  6.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [16. 10.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 3  3  0  8  0  8  0  0 10  0  0 16] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -3.9392197132110596
desired expected reward: 117.7150650024414



buy possibilites: [-1] 
expected returns: [[83.45969]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 16.  0. 10.] 
cards in discard: [ 0.  6.  3.  0.  3. 11.  3.  0.  0. 14.  0.  0.  8. 15. 11.  3.  0.  0.
  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 30. 30. 26. 30.  8.  6.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [16. 10.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 3  3  0  8  0  8  0  0 10  0  0 16] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -33.0 

action type: buy - action 0.0
Learning step: -4.931942939758301
desired expected reward: 98.26376342773438






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 3.] 
cards in discard: [16. 10.  0.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  8  0  8  0  0 10  0  0 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 26. 30.  8.  6.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 3.] 
cards in discard: [16. 10.  0.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  8  0  8  0  0 10  0  0 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 30. 30. 26. 30.  8.  6.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 10.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[119.42562]
 [105.07492]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 26. 30.  8.  6.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  8. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0  8  0  8  0  0 10  0  0 16] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -1.8816848993301392
desired expected reward: 81.5780029296875



action possibilites: [-1.] 
expected returns: [[136.66724]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 26. 30.  8.  6.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  8. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0  8  0  8  0  0 10  0  0 16] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 18 

action type: take_action - action 10.0
Learning step: -1.109578013420105
desired expected reward: 100.58223724365234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[118.15923]
 [129.3915 ]
 [124.73271]
 [ 94.75156]
 [135.60823]
 [126.06807]
 [123.89588]
 [140.48943]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 30. 30. 26. 30.  8.  6.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  8. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0  8  0  8  0  0 10  0  0 16] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -3.1902172565460205
desired expected reward: 133.47702026367188



buy possibilites: [-1] 
expected returns: [[143.45978]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 30. 30. 26. 30.  8.  6.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  8. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0  8  0  8  0  0 10  0  0 16] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.   0.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -13.0 

action type: buy - action 0.0
Learning step: -3.3301169872283936
desired expected reward: 114.8291244506836






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  8  0  8  0  0 10  0  0 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 26. 30.  8.  6.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6. 15.  0.  8.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0] -> size -> 27 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  0  8  0  8  0  0 10  0  0 16] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 26. 30.  8.  6.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6. 15.  0.  8.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0] -> size -> 27 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 26. 30.  8.  6.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6. 15.  0.  8.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0] -> size -> 27 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 30. 30. 26. 30.  8.  6.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6. 15.  0.  8.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0] -> size -> 27 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 25. 30.  8.  6.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6. 15.  0.  8.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0] -> size -> 27 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 0.  6. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[208.1591 ]
 [184.23364]
 [191.26921]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  0.  8.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 25. 30.  8.  6.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -3.076472520828247
desired expected reward: 140.38330078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[184.83748]
 [191.38628]
 [162.44563]
 [192.26892]
 [208.86314]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  0.  8.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 30. 30. 25. 30.  8.  6.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -6.0256218910217285
desired expected reward: 196.07049560546875



buy possibilites: [-1] 
expected returns: [[125.45929]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  0.  8.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 30. 30. 25. 30.  8.  5.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3] -> size -> 11 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -314.0 

action type: buy - action 6.0
Learning step: -20.999448776245117
desired expected reward: 141.44618225097656






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [ 3. 10.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 25. 30.  8.  5.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [14.  0.  3.  6.  0.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [ 3. 10.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 30. 30. 25. 30.  8.  5.  8.  8.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [14.  0.  3.  6.  0.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [ 3. 10.  8.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 25. 30.  8.  5.  8.  7.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [14.  0.  3.  6.  0.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [14.  0.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[148.16354]
 [118.85397]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  6.  0.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 25. 30.  8.  5.  8.  7.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -4.027504920959473
desired expected reward: 121.4317855834961



action possibilites: [-1] 
expected returns: [[111.946526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 30. 30. 25. 30.  8.  5.  8.  7.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 11. 16.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action 14.0
Learning step: -2.9780795574188232
desired expected reward: 112.95944213867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[102.066   ]
 [110.96161 ]
 [106.14867 ]
 [ 86.25565 ]
 [105.91321 ]
 [114.18088 ]
 [108.46432 ]
 [108.75502 ]
 [ 92.79066 ]
 [104.7783  ]
 [100.759415]
 [114.94352 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 30. 30. 25. 30.  8.  5.  8.  7.  5. 10. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 11. 16.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -2.942255973815918
desired expected reward: 109.0042724609375



buy possibilites: [-1] 
expected returns: [[144.21979]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 25. 30.  8.  5.  8.  7.  5. 10. 10.  9. 10.  8. 10.  7.] 
adversary cards in hand: [ 3. 11. 16.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 38 

action type: buy - action 15.0
Learning step: 0.10697364807128906
desired expected reward: 100.86639404296875






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 3. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 16.] 
cards in discard: [0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 25. 30.  8.  5.  8.  7.  5. 10. 10.  9. 10.  8. 10.  7.] 
adversary cards in hand: [11.  3.  6.  0. 16.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8. 15. 14.  0.  3.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15] -> size -> 29 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.] 
cards in discard: [ 0.  8. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 25. 30.  8.  5.  8.  7.  5. 10. 10.  8. 10.  8. 10.  7.] 
adversary cards in hand: [11.  3.  6.  0. 16.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8. 15. 14.  0.  3.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15] -> size -> 29 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.] 
cards in discard: [ 0.  8. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 30. 30. 25. 30.  8.  5.  8.  7.  5. 10. 10.  8. 10.  8. 10.  7.] 
adversary cards in hand: [11.  3.  6.  0. 16.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8. 15. 14.  0.  3.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15] -> size -> 29 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.] 
cards in discard: [ 0.  8. 14.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 25. 30.  8.  5.  8.  7.  5. 10. 10.  8. 10.  8. 10.  7.] 
adversary cards in hand: [11.  3.  6.  0. 16.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8. 15. 14.  0.  3.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15] -> size -> 29 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [11.  3.  6.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[71.41522 ]
 [69.10478 ]
 [58.491234]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  6.  0. 16.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8. 15. 14.  0.  3.  6.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 25. 30.  8.  5.  8.  7.  5. 10. 10.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 0.  8. 14.  0. 11.  3. 16.] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -6.418385982513428
desired expected reward: 137.80140686035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[53.385384]
 [37.28387 ]
 [71.56821 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  6.  0. 16.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8. 15. 14.  0.  3.  6.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 30. 30. 25. 30.  8.  5.  8.  7.  5. 10. 10.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 0.  8. 14.  0. 11.  3. 16.] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -3.0539157390594482
desired expected reward: 68.36131286621094



buy possibilites: [-1] 
expected returns: [[79.63204]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  6.  0. 16.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8. 15. 14.  0.  3.  6.
  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 30. 30. 25. 30.  8.  5.  8.  7.  5. 10. 10.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 0.  8. 14.  0. 11.  3. 16.] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -44.0 

action type: buy - action 0.0
Learning step: -2.9587666988372803
desired expected reward: 50.42662048339844






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [ 0.  8. 14.  0. 11.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 25. 30.  8.  5.  8.  7.  5. 10. 10.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8. 15. 14.  0.  3.  6.
  0.  0. 11.  3.  6.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15  0] -> size -> 30 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [ 0.  8. 14.  0. 11.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 30. 30. 25. 30.  8.  5.  8.  7.  5. 10. 10.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8. 15. 14.  0.  3.  6.
  0.  0. 11.  3.  6.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15  0] -> size -> 30 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [ 0.  8. 14.  0. 11.  3. 16.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 30. 30. 25. 30.  8.  5.  8.  7.  4. 10. 10.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8. 15. 14.  0.  3.  6.
  0.  0. 11.  3.  6.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15  0] -> size -> 30 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[47.119682]
 [42.670708]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8. 15. 14.  0.  3.  6.
  0.  0. 11.  3.  6.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 25. 30.  8.  5.  8.  7.  4. 10. 10.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0. 11.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0  8] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -3.671452045440674
desired expected reward: 75.96058654785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.57395 ]
 [35.028114]
 [29.265482]
 [ 2.604259]
 [41.48488 ]
 [31.007559]
 [27.457455]
 [46.06688 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8. 15. 14.  0.  3.  6.
  0.  0. 11.  3.  6.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 30. 30. 25. 30.  8.  5.  8.  7.  4. 10. 10.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0. 11.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0  8] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -2.3936121463775635
desired expected reward: 44.72609329223633



buy possibilites: [-1] 
expected returns: [[77.269554]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  0.  6.  0.  6. 15.  0.  8. 15. 14.  0.  3.  6.
  0.  0. 11.  3.  6.  0. 16. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15  0 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 25. 30.  8.  5.  8.  7.  4. 10. 10.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 0. 11.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0  8] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 4 

action type: buy - action 10.0
Learning step: 0.5656914710998535
desired expected reward: 28.02315902709961






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 25. 30.  8.  5.  8.  7.  4. 10. 10.  8. 10.  7. 10.  7.] 
adversary cards in hand: [15.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15  0 10] -> size -> 31 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 30. 30. 25. 30.  8.  5.  8.  7.  4. 10. 10.  8. 10.  7. 10.  7.] 
adversary cards in hand: [15.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15  0 10] -> size -> 31 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3. 10.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0  8  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 25. 30.  8.  5.  8.  7.  3. 10. 10.  8. 10.  7. 10.  7.] 
adversary cards in hand: [15.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15  0 10] -> size -> 31 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [15.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[49.298927]
 [33.246063]
 [45.476738]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11
  0  0  0  6 15  0 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 25. 30.  8.  5.  8.  7.  3. 10. 10.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 8. 14. 16.  8.  0.] 
adversary cards in discard: [ 8.  0. 11.  0.  3. 10.] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0  8  8] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -3.668597936630249
desired expected reward: 73.60095977783203



action possibilites: [-1] 
expected returns: [[46.20752]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11  0
  0  0  6 15  0 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 30. 30. 25. 30.  8.  5.  8.  7.  3. 10. 10.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 8. 14. 16.  8.  0.] 
adversary cards in discard: [ 8.  0. 11.  0.  3. 10.] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0  8  8] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action 15.0
Learning step: -0.1717788726091385
desired expected reward: 30.057180404663086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[40.764908]
 [47.90471 ]
 [43.421516]
 [31.253988]
 [25.797707]
 [43.90043 ]
 [49.298958]
 [45.909386]
 [56.513054]
 [46.00412 ]
 [31.67293 ]
 [36.23964 ]
 [41.931908]
 [29.005108]
 [38.684547]
 [49.012245]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11  0
  0  0  6 15  0 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 30. 30. 25. 30.  8.  5.  8.  7.  3. 10. 10.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 8. 14. 16.  8.  0.] 
adversary cards in discard: [ 8.  0. 11.  0.  3. 10.] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0  8  8] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -1.0859694480895996
desired expected reward: 45.121551513671875



buy possibilites: [-1] 
expected returns: [[97.186295]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [23.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11  0
  0  0  6 15  0 10 23] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 25. 30.  8.  5.  8.  7.  3. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 8. 14. 16.  8.  0.] 
adversary cards in discard: [ 8.  0. 11.  0.  3. 10.] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0  8  8] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0  50   0] 
sum of rewards: 56 

action type: buy - action 23.0
Learning step: 3.174708127975464
desired expected reward: 39.414371490478516






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 8. 14. 16.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 16.  8.  0.] 
cards in discard: [ 8.  0. 11.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11 14  0  8  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 25. 30.  8.  5.  8.  7.  3. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [23. 15. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11  0
  0  0  6 15  0 10 23] -> size -> 31 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0.] 
cards in discard: [ 8.  0. 11.  0.  3. 10.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11  0  8  8  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 25. 30.  8.  5.  8.  7.  3. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [23. 15. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11  0
  0  0  6 15  0 10 23] -> size -> 31 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0.] 
cards in discard: [ 8.  0. 11.  0.  3. 10.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11  0  8  8  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 29. 30. 25. 30.  8.  5.  8.  7.  3. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [23. 15. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11  0
  0  0  6 15  0 10 23] -> size -> 31 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [6. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[49.813705]
 [38.5822  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [23. 15. 11.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  0  6 11 16  3  0  8  6  0  6 15 10 11  0
  0  0  6 15  0 10 23] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 25. 30.  8.  5.  8.  7.  3. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 8.  0. 11.  0.  3. 10.  1. 16.  8.  8.  0.] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11  0  8  8  1] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -4.6264519691467285
desired expected reward: 92.55984497070312



action possibilites: [-1] 
expected returns: [[62.5699]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [23. 15. 11.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 25. 30.  8.  5.  8.  7.  3. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 8.  0. 11.  0.  3. 10.  1. 16.  8.  8.  0.] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11  0  8  8  1] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: trash_cards_n_from_hand - action 6
Learning step: 1.4244097471237183
desired expected reward: 18.09267234802246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[56.668938]
 [45.22393 ]
 [66.95711 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [23. 15. 11.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 29. 30. 25. 30.  8.  5.  8.  7.  3. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 8.  0. 11.  0.  3. 10.  1. 16.  8.  8.  0.] 
adversary owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11  0  8  8  1] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -1.0120807886123657
desired expected reward: 61.55781936645508






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [ 8.  0. 11.  0.  3. 10.  1. 16.  8.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  8  0  0 10  0  0 16  3 11  0  8  8  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 25. 30.  8.  5.  8.  7.  3. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [10.  3.  0.  0.  6.] 
adversary cards in discard: [23. 15. 11.  0.  0.  8.] 
adversary owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23] -> size -> 27 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8.  0. 11.  0.  3. 10.  1. 16.  8.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0 10  0  0 16  3 11  0  8  8  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 25. 30.  8.  5.  8.  7.  3. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [10.  3.  0.  0.  6.] 
adversary cards in discard: [23. 15. 11.  0.  0.  8.] 
adversary owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23] -> size -> 27 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  0. 11.  0.  3. 10.  1. 16.  8.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0 10  0  0 16  3 11  0  8  8  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 29. 30. 25. 30.  8.  5.  8.  7.  3. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [10.  3.  0.  0.  6.] 
adversary cards in discard: [23. 15. 11.  0.  0.  8.] 
adversary owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23] -> size -> 27 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  0. 11.  0.  3. 10.  1. 16.  8.  8.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0 10  0  0 16  3 11  0  8  8  1  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 24. 30.  8.  5.  8.  7.  3. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [10.  3.  0.  0.  6.] 
adversary cards in discard: [23. 15. 11.  0.  0.  8.] 
adversary owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23] -> size -> 27 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [10.  3.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[25.475348]
 [18.19395 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  6.] 
cards in discard: [23. 15. 11.  0.  0.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 24. 30.  8.  5.  8.  7.  3. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [3. 3. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0 10  0  0 16  3 11  0  8  8  1  3] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -3.0244734287261963
desired expected reward: 63.93260955810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.946001 ]
 [20.771467 ]
 [ 7.7359495]
 [21.664059 ]
 [27.32952  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  6.] 
cards in discard: [23. 15. 11.  0.  0.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 29. 30. 24. 30.  8.  5.  8.  7.  3. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [3. 3. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0 10  0  0 16  3 11  0  8  8  1  3] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -0.9547508358955383
desired expected reward: 23.73110580444336



buy possibilites: [-1] 
expected returns: [[37.851646]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  6.] 
cards in discard: [23. 15. 11.  0.  0.  8.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 24. 30.  8.  5.  8.  7.  2. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [3. 3. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0 10  0  0 16  3 11  0  8  8  1  3] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 5 

action type: buy - action 8.0
Learning step: 0.018459511920809746
desired expected reward: 21.682510375976562






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [3. 3. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0 10  0  0 16  3 11  0  8  8  1  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 24. 30.  8.  5.  8.  7.  2. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [16. 14. 10.  3.  0.] 
adversary cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23  8] -> size -> 28 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0 10  0  0 16  3 11  0  8  8  1  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 29. 30. 24. 30.  8.  5.  8.  7.  2. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [16. 14. 10.  3.  0.] 
adversary cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23  8] -> size -> 28 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0. 8.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0 10  0  0 16  3 11  0  8  8  1  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 29. 30. 24. 30.  8.  5.  8.  7.  2. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [16. 14. 10.  3.  0.] 
adversary cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23  8] -> size -> 28 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [16. 14. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14. 10.] 
expected returns: [[51.06897 ]
 [41.239075]
 [29.166922]
 [40.3043  ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 14. 10.  3.  0.] 
cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 24. 30.  8.  5.  8.  7.  2. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [1. 8. 0. 8. 0.] 
adversary cards in discard: [0. 3. 3. 8. 0. 8.] 
adversary owned cards: [ 8  8  0  0 10  0  0 16  3 11  0  8  8  1  3  0] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -1.1584051847457886
desired expected reward: 36.693241119384766



action possibilites: [-1] 
expected returns: [[36.495792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  3.  0.] 
cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 29. 30. 24. 30.  8.  5.  8.  7.  2. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [1. 8. 8.] 
adversary cards in discard: [0. 3. 3. 8. 0. 8. 0. 0.] 
adversary owned cards: [ 8  8  0  0 10  0  0 16  3 11  0  8  8  1  3  0] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action 14.0
Learning step: 0.29983559250831604
desired expected reward: 28.66008758544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.970646]
 [33.03851 ]
 [29.243504]
 [11.819147]
 [36.305733]
 [30.48278 ]
 [27.873064]
 [37.996517]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 10.  3.  0.] 
cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 29. 30. 24. 30.  8.  5.  8.  7.  2. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [1. 8. 8.] 
adversary cards in discard: [0. 3. 3. 8. 0. 8. 0. 0.] 
adversary owned cards: [ 8  8  0  0 10  0  0 16  3 11  0  8  8  1  3  0] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -0.3230157792568207
desired expected reward: 36.17277526855469






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [1. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 8.] 
cards in discard: [0. 3. 3. 8. 0. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0 10  0  0 16  3 11  0  8  8  1  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 24. 30.  8.  5.  8.  7.  2. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 6.  3. 15.  3.  0.] 
adversary cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6. 14. 16. 10.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23  8] -> size -> 28 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [0. 3. 3. 8. 0. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 24. 30.  8.  5.  8.  7.  2. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 6.  3. 15.  3.  0.] 
adversary cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6. 14. 16. 10.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23  8] -> size -> 28 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [0. 3. 3. 8. 0. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 29. 30. 24. 30.  8.  5.  8.  7.  2. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 6.  3. 15.  3.  0.] 
adversary cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6. 14. 16. 10.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23  8] -> size -> 28 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [0. 3. 3. 8. 0. 8. 0. 0. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 24. 30.  8.  5.  8.  7.  1. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 6.  3. 15.  3.  0.] 
adversary cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6. 14. 16. 10.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23  8] -> size -> 28 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 6.  3. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[44.260956]
 [36.554058]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 15.  3.  0.] 
cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6. 14. 16. 10.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15
  0 10 23  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 24. 30.  8.  5.  8.  7.  1. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  0. 16. 11. 10.] 
adversary cards in discard: [0. 3. 3. 8. 0. 8. 0. 0. 8. 8. 1.] 
adversary owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -1.140642523765564
desired expected reward: 36.85586929321289



action possibilites: [-1] 
expected returns: [[20.702227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3.] 
cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6. 14. 16. 10.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0
 10 23  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 29. 30. 24. 30.  8.  5.  8.  7.  1. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  0. 16. 11. 10.] 
adversary cards in discard: [0. 3. 3. 8. 0. 8. 0. 0. 8. 8. 1.] 
adversary owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action 15.0
Learning step: -0.5119024515151978
desired expected reward: 36.04214859008789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[11.172552 ]
 [15.906261 ]
 [13.77585  ]
 [ 1.7941256]
 [18.129974 ]
 [14.34149  ]
 [13.011364 ]
 [19.358368 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3.] 
cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6. 14. 16. 10.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0
 10 23  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 29. 30. 24. 30.  8.  5.  8.  7.  1. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  0. 16. 11. 10.] 
adversary cards in discard: [0. 3. 3. 8. 0. 8. 0. 0. 8. 8. 1.] 
adversary owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: 0.11722622066736221
desired expected reward: 20.8194522857666



buy possibilites: [-1] 
expected returns: [[25.191204]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3.] 
cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6. 14. 16. 10.  3.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0
 10 23  8 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 24. 30.  8.  5.  8.  6.  1. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  0. 16. 11. 10.] 
adversary cards in discard: [0. 3. 3. 8. 0. 8. 0. 0. 8. 8. 1.] 
adversary owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 35 

action type: buy - action 11.0
Learning step: 1.4103032350540161
desired expected reward: 19.540279388427734






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 16. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16. 11. 10.] 
cards in discard: [0. 3. 3. 8. 0. 8. 0. 0. 8. 8. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 24. 30.  8.  5.  8.  6.  1. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [11.  0.  0.  6.  0.] 
adversary cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6. 14. 16. 10.  3.  0. 11.
 15.  6.  3.  3.] 
adversary owned cards: [ 0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0
 10 23  8 11] -> size -> 28 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16. 11. 10.] 
cards in discard: [0. 3. 3. 8. 0. 8. 0. 0. 8. 8. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 29. 30. 24. 30.  8.  5.  8.  6.  1. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [11.  0.  0.  6.  0.] 
adversary cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6. 14. 16. 10.  3.  0. 11.
 15.  6.  3.  3.] 
adversary owned cards: [ 0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0
 10 23  8 11] -> size -> 28 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16. 11. 10.] 
cards in discard: [0. 3. 3. 8. 0. 8. 0. 0. 8. 8. 1. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 23. 30.  8.  5.  8.  6.  1. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [11.  0.  0.  6.  0.] 
adversary cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6. 14. 16. 10.  3.  0. 11.
 15.  6.  3.  3.] 
adversary owned cards: [ 0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0
 10 23  8 11] -> size -> 28 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[15.966106]
 [13.274822]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  6.  0.] 
cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6. 14. 16. 10.  3.  0. 11.
 15.  6.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0
 10 23  8 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 23. 30.  8.  5.  8.  6.  1. 10. 10.  8.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  0.  8. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8  3] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -1.5805948972702026
desired expected reward: 23.61060905456543



action possibilites: [-1] 
expected returns: [[11.316303]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6. 14. 16. 10.  3.  0. 11.
 15.  6.  3.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0
 10 23  8 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 23. 30.  8.  5.  8.  6.  1. 10. 10.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  8. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8  3] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 16 

action type: gain_card_n - action 9
Learning step: 0.38523608446121216
desired expected reward: 13.77285099029541





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 6.54993  ]
 [ 7.704226 ]
 [ 7.781792 ]
 [ 4.632672 ]
 [ 8.905342 ]
 [ 7.0462346]
 [ 7.5568852]
 [10.159693 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [23. 15. 11.  0.  0.  8.  8. 10.  3.  0.  0.  6. 14. 16. 10.  3.  0. 11.
 15.  6.  3.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0
 10 23  8 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 29. 30. 23. 30.  8.  5.  8.  6.  1. 10. 10.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  8. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8  3] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -0.046108294278383255
desired expected reward: 11.270195007324219






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 23. 30.  8.  5.  8.  6.  1. 10. 10.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 23. 16.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0
 10 23  8 11 10] -> size -> 29 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8  3] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 23. 30.  8.  5.  8.  6.  1. 10. 10.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 23. 16.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0
 10 23  8 11 10] -> size -> 29 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 29. 30. 23. 30.  8.  5.  8.  6.  1. 10. 10.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 23. 16.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0
 10 23  8 11 10] -> size -> 29 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 8.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 29. 30. 23. 30.  8.  5.  8.  6.  1. 10. 10.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 23. 16.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0
 10 23  8 11 10] -> size -> 29 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0. 23. 16.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 16.] 
expected returns: [[-4.2653503]
 [-7.6526275]
 [-5.4362483]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23. 16.  3.  3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0
 10 23  8 11 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 23. 30.  8.  5.  8.  6.  1. 10. 10.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  1.  0.  3. 16.] 
adversary cards in discard: [ 0. 10.  0.  0.  8.  3.  8.] 
adversary owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8  3  0] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -1.2912806272506714
desired expected reward: 8.868413925170898



action possibilites: [-1] 
expected returns: [[12.321285]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  3.] 
cards in discard: [8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 23. 30.  8.  5.  8.  6.  0. 10. 10.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  1.  0.  3. 16.] 
adversary cards in discard: [ 0. 10.  0.  0.  8.  3.  8.] 
adversary owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8  3  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: 0 

action type: gain_card_n - action 6
Learning step: 0.4770776927471161
desired expected reward: -3.5198986530303955





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -2.4314027]
 [-22.120995 ]
 [ 14.151463 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  3.] 
cards in discard: [8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 30. 23. 30.  8.  5.  8.  6.  0. 10. 10.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  1.  0.  3. 16.] 
adversary cards in discard: [ 0. 10.  0.  0.  8.  3.  8.] 
adversary owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8  3  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -0.8940059542655945
desired expected reward: 11.427279472351074



buy possibilites: [-1] 
expected returns: [[12.943279]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  3.] 
cards in discard: [8. 6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 29. 30. 23. 30.  8.  4.  8.  6.  0. 10. 10.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  1.  0.  3. 16.] 
adversary cards in discard: [ 0. 10.  0.  0.  8.  3.  8.] 
adversary owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8  3  0] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -315.0 

action type: buy - action 6.0
Learning step: -14.3527250289917
desired expected reward: -36.4737434387207






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 3.  1.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  3. 16.] 
cards in discard: [ 0. 10.  0.  0.  8.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  1  3  0  8  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 23. 30.  8.  4.  8.  6.  0. 10. 10.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 11. 11.  0.  6.] 
adversary cards in discard: [ 8.  6. 16.  0. 23.  3.] 
adversary owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6] -> size -> 30 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [ 0. 10.  0.  0.  8.  3.  8. 22.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 23. 30.  8.  4.  8.  6.  0. 10. 10.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 11. 11.  0.  6.] 
adversary cards in discard: [ 8.  6. 16.  0. 23.  3.] 
adversary owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6] -> size -> 30 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 0. 10.  0.  0.  8.  3.  8. 22.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 30. 23. 30.  8.  4.  8.  6.  0. 10. 10.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 11. 11.  0.  6.] 
adversary cards in discard: [ 8.  6. 16.  0. 23.  3.] 
adversary owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6] -> size -> 30 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [ 0. 11. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[10.068691]
 [ 9.794033]
 [ 9.794033]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  6.] 
cards in discard: [ 8.  6. 16.  0. 23.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 23. 30.  8.  4.  8.  6.  0. 10. 10.  8.  9.  6.  9.  7.] 
adversary cards in hand: [0. 8. 0. 8. 0.] 
adversary cards in discard: [ 0. 10.  0.  0.  8.  3.  8. 22. 16.  3.  0.  3.] 
adversary owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -2.173511505126953
desired expected reward: 10.769767761230469



action possibilites: [-1] 
expected returns: [[-28.165154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  6.] 
cards in discard: [ 8.  6. 16.  0. 23.  3. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 23. 30.  8.  4.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [0. 8. 0. 8. 0.] 
adversary cards in discard: [ 0. 10.  0.  0.  8.  3.  8. 22. 16.  3.  0.  3.] 
adversary owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -6 

action type: gain_card_n - action 8
Learning step: -1.3333171606063843
desired expected reward: 6.6587090492248535





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-31.185162]
 [-30.636993]
 [-33.448116]
 [-28.392216]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  6.] 
cards in discard: [ 8.  6. 16.  0. 23.  3. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 29. 30. 23. 30.  8.  4.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [0. 8. 0. 8. 0.] 
adversary cards in discard: [ 0. 10.  0.  0.  8.  3.  8. 22. 16.  3.  0.  3.] 
adversary owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: -0.037334442138671875
desired expected reward: -28.20248794555664






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8. 0.] 
cards in discard: [ 0. 10.  0.  0.  8.  3.  8. 22. 16.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 23. 30.  8.  4.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  3. 10.] 
adversary cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.] 
adversary owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6 10] -> size -> 31 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [ 0. 10.  0.  0.  8.  3.  8. 22. 16.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 23. 30.  8.  4.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  3. 10.] 
adversary cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.] 
adversary owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6 10] -> size -> 31 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 0. 10.  0.  0.  8.  3.  8. 22. 16.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 29. 30. 23. 30.  8.  4.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  3. 10.] 
adversary cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.] 
adversary owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6 10] -> size -> 31 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 0. 10.  0.  0.  8.  3.  8. 22. 16.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 29. 30. 23. 30.  8.  4.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  3. 10.] 
adversary cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.] 
adversary owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6 10] -> size -> 31 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 15.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[-7.8774824]
 [-7.5489664]
 [-7.633374 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  3. 10.] 
cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 23. 30.  8.  4.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [22.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22  0] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -0.5033373236656189
desired expected reward: -28.895553588867188



action possibilites: [-1. 15. 10.] 
expected returns: [[-13.427341]
 [-11.790254]
 [-12.194537]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  3. 10.] 
cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6 10] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 23. 30.  8.  4.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [22.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22  0] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: -0.6489197015762329
desired expected reward: -8.282295227050781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-12.002173 ]
 [-12.105021 ]
 [ -7.5612297]
 [-13.874674 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  3. 10.] 
cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 29. 30. 23. 30.  8.  4.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [22.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22  0] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -0.33479878306388855
desired expected reward: -13.762137413024902



buy possibilites: [-1] 
expected returns: [[-4.6765943]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  3. 10.] 
cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6 10  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 29. 30. 23. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [22.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22  0] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -326.0 

action type: buy - action 6.0
Learning step: -16.027162551879883
desired expected reward: -23.588390350341797






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [22.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 23. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [11.  8.  0.  8.  3.] 
adversary cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.  6. 10.  0.  0. 15.  3.
 10.] 
adversary owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6 10  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 29. 30. 23. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [11.  8.  0.  8.  3.] 
adversary cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.  6. 10.  0.  0. 15.  3.
 10.] 
adversary owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6 10  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  3.  0.  0. 11.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [11.  8.  0.  8.  3.] 
adversary cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.  6. 10.  0.  0. 15.  3.
 10.] 
adversary owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6 10  6] -> size -> 32 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [11.  8.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
expected returns: [[3.4947944 ]
 [2.369409  ]
 [0.76027966]
 [0.76027966]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  8.  3.] 
cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.  6. 10.  0.  0. 15.  3.
 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 14  0 11 16  3  0  8  6  0  6 15 10 11  0  0  0  6 15  0 10
 23  8 11 10  8  6 10  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [3. 8. 0. 8. 3.] 
adversary cards in discard: [ 3. 22.  3.  0.  0. 11.] 
adversary owned cards: [ 8  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -2.524624824523926
desired expected reward: -7.201219081878662



action possibilites: [-1] 
expected returns: [[-4.930501]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.] 
cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.  6. 10.  0.  0. 15.  3.
 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [3. 8. 0. 8. 3.] 
adversary cards in discard: [ 3. 22.  3.  0.  0. 11.] 
adversary owned cards: [ 8  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: trash_cards_n_from_hand - action 9
Learning step: -1.9488540887832642
desired expected reward: -1.190499186515808





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-7.162222 ]
 [-8.831568 ]
 [-4.7220764]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.] 
cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.  6. 10.  0.  0. 15.  3.
 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [3. 8. 0. 8. 3.] 
adversary cards in discard: [ 3. 22.  3.  0.  0. 11.] 
adversary owned cards: [ 8  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -1.7088358402252197
desired expected reward: -6.639336585998535



buy possibilites: [-1] 
expected returns: [[5.5591364]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.] 
cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.  6. 10.  0.  0. 15.  3.
 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [3. 8. 0. 8. 3.] 
adversary cards in discard: [ 3. 22.  3.  0.  0. 11.] 
adversary owned cards: [ 8  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action 0.0
Learning step: -2.8168089389801025
desired expected reward: -9.979022026062012






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 8. 3.] 
cards in discard: [ 3. 22.  3.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 10  0  0 16  3 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  6.  3.  6. 10.] 
adversary cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.  6. 10.  0.  0. 15.  3.
 10.  0.  8. 11.  3.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0] -> size -> 31 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3.] 
cards in discard: [ 3. 22.  3.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  6.  3.  6. 10.] 
adversary cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.  6. 10.  0.  0. 15.  3.
 10.  0.  8. 11.  3.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0] -> size -> 31 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3.] 
cards in discard: [ 3. 22.  3.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  6.  3.  6. 10.] 
adversary cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.  6. 10.  0.  0. 15.  3.
 10.  0.  8. 11.  3.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0] -> size -> 31 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 0.  6.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[ 9.570358 ]
 [-0.8582585]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  6. 10.] 
cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.  6. 10.  0.  0. 15.  3.
 10.  0.  8. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 8.  0.  8.  0. 16.] 
adversary cards in discard: [ 3. 22.  3.  0.  0. 11.  8.  0.  8.  3.] 
adversary owned cards: [ 8  0 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -2.479926347732544
desired expected reward: 3.079210042953491



action possibilites: [-1. 15.] 
expected returns: [[-1.158932]
 [-9.913176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  6. 15.] 
cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.  6. 10.  0.  0. 15.  3.
 10.  0.  8. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 8.  0.  8.  0. 16.] 
adversary cards in discard: [ 3. 22.  3.  0.  0. 11.  8.  0.  8.  3.] 
adversary owned cards: [ 8  0 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action 10.0
Learning step: -1.3816324472427368
desired expected reward: -2.239884376525879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-11.910973  ]
 [-15.305541  ]
 [ -0.28355598]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  6. 15.] 
cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.  6. 10.  0.  0. 15.  3.
 10.  0.  8. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 8.  0.  8.  0. 16.] 
adversary cards in discard: [ 3. 22.  3.  0.  0. 11.  8.  0.  8.  3.] 
adversary owned cards: [ 8  0 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -1.4482711553573608
desired expected reward: -2.60719895362854



buy possibilites: [-1] 
expected returns: [[-10.626748]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  6. 15.] 
cards in discard: [ 8.  6. 16.  0. 23.  3. 10. 11.  0. 11.  0.  6.  6. 10.  0.  0. 15.  3.
 10.  0.  8. 11.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 8.  0.  8.  0. 16.] 
adversary cards in discard: [ 3. 22.  3.  0.  0. 11.  8.  0.  8.  3.] 
adversary owned cards: [ 8  0 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -56.0 

action type: buy - action 0.0
Learning step: -2.435455799102783
desired expected reward: -14.346427917480469






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  8.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8.  0. 16.] 
cards in discard: [ 3. 22.  3.  0.  0. 11.  8.  0.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 6. 15.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.] 
cards in discard: [ 3. 22.  3.  0.  0. 11.  8.  0.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 6. 15.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 16.] 
cards in discard: [ 3. 22.  3.  0.  0. 11.  8.  0.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 6. 15.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 6. 15.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
expected returns: [[18.186592]
 [13.924093]
 [11.179072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 17 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -1.4591789245605469
desired expected reward: -12.08592700958252





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[12.210648 ]
 [13.400219 ]
 [ 6.4762163]
 [17.275026 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 17 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -2.893711805343628
desired expected reward: 14.53412914276123



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [16.  8.  6. 15. 11.] 
adversary cards in discard: [ 6. 15.  0.  0. 14.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [16.  8.  6. 15. 11.] 
adversary cards in discard: [ 6. 15.  0.  0. 14.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  5.  9.  7.] 
adversary cards in hand: [16.  8.  6. 15. 11.] 
adversary cards in discard: [ 6. 15.  0.  0. 14.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [16.  8.  6. 15. 11.] 
adversary cards in discard: [ 6. 15.  0.  0. 14.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [16.  8.  6. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 15. 11.] 
expected returns: [[-6.3844395]
 [-6.3231306]
 [-6.537291 ]
 [-6.0834017]
 [-6.175111 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  6. 15. 11.] 
cards in discard: [ 6. 15.  0.  0. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [8. 8. 0. 3. 0.] 
adversary cards in discard: [10. 10.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 8 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3 10] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -3.299971342086792
desired expected reward: 13.975050926208496



action possibilites: [-1] 
expected returns: [[3.4209182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  6. 15.] 
cards in discard: [ 6. 15.  0.  0. 14.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [8. 8. 0. 3. 0.] 
adversary cards in discard: [10. 10.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 8 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3 10] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: gain_card_n - action 0
Learning step: -2.4178225994110107
desired expected reward: -8.521957397460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.25716853]
 [-1.1841524 ]
 [ 3.302778  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  6. 15.] 
cards in discard: [ 6. 15.  0.  0. 14.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [8. 8. 0. 3. 0.] 
adversary cards in discard: [10. 10.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 8 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3 10] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -1.4570749998092651
desired expected reward: 1.9638432264328003



buy possibilites: [-1] 
expected returns: [[9.918925]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  6. 15.] 
cards in discard: [ 6. 15.  0.  0. 14.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [8. 8. 0. 3. 0.] 
adversary cards in discard: [10. 10.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 8 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3 10] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action 0.0
Learning step: -2.5639660358428955
desired expected reward: -2.8211286067962646






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [8. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 3. 0.] 
cards in discard: [10. 10.  0.  3.  0.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  0  0 16 11  0  8  8  3  0  8  3  0 22  0  3 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [6. 3. 0. 3. 3.] 
adversary cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0  0  0] -> size -> 34 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [10. 10.  0.  3.  0.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [6. 3. 0. 3. 3.] 
adversary cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0  0  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [10. 10.  0.  3.  0.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [6. 3. 0. 3. 3.] 
adversary cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0  0  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [6. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-15.075434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 3.] 
cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 3.  0. 16. 22.  8.] 
adversary cards in discard: [10. 10.  0.  3.  0.  0. 11.  8.  8.  0.] 
adversary owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -2.635143518447876
desired expected reward: 7.283782005310059





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-16.248985]
 [-14.919673]
 [-15.152916]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 3.] 
cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 3.  0. 16. 22.  8.] 
adversary cards in discard: [10. 10.  0.  3.  0.  0. 11.  8.  8.  0.] 
adversary owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -1.3936381340026855
desired expected reward: -16.469072341918945



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 16. 22.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 22.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16. 22.  8.] 
cards in discard: [10. 10.  0.  3.  0.  0. 11.  8.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 8. 10. 10.  0.  6.] 
adversary cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0  0  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  8.  8.] 
cards in discard: [10. 10.  0.  3.  0.  0. 11.  8.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 8. 10. 10.  0.  6.] 
adversary cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0  0  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  8.  8.] 
cards in discard: [10. 10.  0.  3.  0.  0. 11.  8.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 8. 10. 10.  0.  6.] 
adversary cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0  0  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  8.  8.] 
cards in discard: [10. 10.  0.  3.  0.  0. 11.  8.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 8. 10. 10.  0.  6.] 
adversary cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0  0  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 8. 10. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
expected returns: [[-4.537747 ]
 [-6.449811 ]
 [-5.8040895]
 [-5.8040895]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.  0.  6.] 
cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [10.  8.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10  0] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -1.169451117515564
desired expected reward: -16.32236671447754



action possibilites: [-1.  8. 10.] 
expected returns: [[-3.3224797]
 [-4.9894934]
 [-5.380212 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  6.  0.] 
cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 10 11  0  0  0  6 15  0 10 23  8
 11 10  8  6 10  6  0  0  0  0] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [10.  8.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10  0] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: -0.5624827742576599
desired expected reward: -6.3665642738342285



action possibilites: [-1.] 
expected returns: [[3.1693084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [10.  8.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10  0] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: trash_cards_n_from_hand - action 2
Learning step: 0.5960538387298584
desired expected reward: -5.898834228515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-3.347369 ]
 [-2.3806286]
 [-2.9424477]
 [ 2.0789974]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 29. 30. 22. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [10.  8.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10  0] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1.0
Learning step: 0.004471492953598499
desired expected reward: 3.1737799644470215



buy possibilites: [-1] 
expected returns: [[-11.272053]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 21. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [10.  8.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10  0] -> size -> 17 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  40   0   0   0   0   0   0   0   8   0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 1.015410304069519
desired expected reward: -1.3652158975601196






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [10.  8.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 21. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [10.  0. 23. 11. 10.] 
adversary cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.  3.
 10.  8.  0.  6.  0.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3] -> size -> 34 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 21. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [10.  0. 23. 11. 10.] 
adversary cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.  3.
 10.  8.  0.  6.  0.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3] -> size -> 34 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 29. 30. 21. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [10.  0. 23. 11. 10.] 
adversary cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.  3.
 10.  8.  0.  6.  0.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3] -> size -> 34 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 8. 0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 29. 30. 21. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [10.  0. 23. 11. 10.] 
adversary cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.  3.
 10.  8.  0.  6.  0.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3] -> size -> 34 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [10.  0. 23. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23. 11. 10.] 
expected returns: [[14.260141]
 [ 9.123567]
 [ 5.845481]
 [12.945717]
 [ 9.123567]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 23. 11. 10.] 
cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.  3.
 10.  8.  0.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 21. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0. 16. 11.  0.  8.] 
adversary cards in discard: [ 0. 10.  8.  0.  3.  8.  0.] 
adversary owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -0.45553943514823914
desired expected reward: -11.727592468261719



action possibilites: [-1. 23. 11. 10.] 
expected returns: [[25.767647]
 [19.927792]
 [29.480282]
 [25.0049  ]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23. 11. 10.  0.] 
cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.  3.
 10.  8.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 21. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0. 16. 11.  0.  8.] 
adversary cards in discard: [ 0. 10.  8.  0.  3.  8.  0.] 
adversary owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -4 

action type: take_action - action 10.0
Learning step: -0.07879429310560226
desired expected reward: 8.767738342285156



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[25.532057]
 [24.963497]
 [21.629505]
 [24.963497]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0. 11.] 
cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.  3.
 10.  8.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3] -> size -> 34 
action values: 2 
buys: 1 
player value: 1 
card supply: [ 5. 29. 30. 21. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0. 16. 11.  0.  8.] 
adversary cards in discard: [ 0. 10.  8.  0.  3.  8.  0.] 
adversary owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action 23.0
Learning step: 0.29973849654197693
desired expected reward: 20.227523803710938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[24.951635]
 [28.264826]
 [25.765646]
 [17.416325]
 [29.255169]
 [25.773472]
 [29.39587 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  0. 11.] 
cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.  3.
 10.  8.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3] -> size -> 34 
action values: 0 
buys: 2 
player value: 3 
card supply: [ 5. 29. 30. 21. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0. 16. 11.  0.  8.] 
adversary cards in discard: [ 0. 10.  8.  0.  3.  8.  0.] 
adversary owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.054627325385808945
desired expected reward: 25.5866756439209



buy possibilites: [ 0.  6. -1.] 
expected returns: [[-14.87072 ]
 [-10.759227]
 [-17.649256]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  0. 11.] 
cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.  3.
 10.  8.  0.  6.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 29. 30. 20. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0. 16. 11.  0.  8.] 
adversary cards in discard: [ 0. 10.  8.  0.  3.  8.  0.] 
adversary owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  40   0   0   0   0   0   0   0   4   0] 
sum of rewards: 30 

action type: buy - action 3.0
Learning step: -0.11286153644323349
desired expected reward: 25.652761459350586



buy possibilites: [-1] 
expected returns: [[2.3532007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  0. 11.] 
cards in discard: [ 6. 15.  0.  0. 14.  0.  0. 11. 16.  8.  6. 15.  6.  3.  0.  3.  3.  3.
 10.  8.  0.  6.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 29. 30. 20. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0. 16. 11.  0.  8.] 
adversary cards in discard: [ 0. 10.  8.  0.  3.  8.  0.] 
adversary owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -10.   0.   0.  40. -30.   0.   0.   0.  -1.   0.   0.
   0.   0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0.5464827418327332
desired expected reward: -14.324231147766113






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 0. 16. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 11.  0.  8.] 
cards in discard: [ 0. 10.  8.  0.  3.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  0 16 11  0  8  8  0  8  3  0 22  0  3 10  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 20. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3  3  0] -> size -> 36 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 10.  8.  0.  3.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  0  8  8  0  8  3  0 22  0  3 10  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 20. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3  3  0] -> size -> 36 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 10.  8.  0.  3.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  0  8  8  0  8  3  0 22  0  3 10  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 29. 30. 20. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3  3  0] -> size -> 36 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 10.  8.  0.  3.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  0  8  8  0  8  3  0 22  0  3 10  0  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 29. 30. 20. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3  3  0] -> size -> 36 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [3. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-2.8811054]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 20. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 3.  8. 10.  0. 22.] 
adversary cards in discard: [ 0. 10.  8.  0.  3.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 8 10  0  8  8  0  8  3  0 22  0  3 10  0  0  0] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -0.8973763585090637
desired expected reward: 1.455824375152588





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 0.09926772]
 [-1.6087859 ]
 [ 4.4001713 ]
 [-1.4616952 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3  3  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 29. 30. 20. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 3.  8. 10.  0. 22.] 
adversary cards in discard: [ 0. 10.  8.  0.  3.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 8 10  0  8  8  0  8  3  0 22  0  3 10  0  0  0] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -0.5147997736930847
desired expected reward: -4.057746887207031



buy possibilites: [-1] 
expected returns: [[-7.9764595]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3  3  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 19. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 3.  8. 10.  0. 22.] 
adversary cards in discard: [ 0. 10.  8.  0.  3.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 8 10  0  8  8  0  8  3  0 22  0  3 10  0  0  0] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0 -2  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: 0.050969477742910385
desired expected reward: -1.5578265190124512






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 10.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 22.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  0. 22.] 
cards in discard: [ 0. 10.  8.  0.  3.  8.  0.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  0  8  8  0  8  3  0 22  0  3 10  0  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 19. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 6. 15.  0. 10. 10.] 
adversary cards in discard: [3. 3. 0. 3. 0. 6.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3  3  0  3] -> size -> 37 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 22.  0.] 
cards in discard: [ 0. 10.  8.  0.  3.  8.  0.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 10  0  8  8  0  8  3  0 22  0  3 10  0  0  0] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 19. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 6. 15.  0. 10. 10.] 
adversary cards in discard: [3. 3. 0. 3. 0. 6.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3  3  0  3] -> size -> 37 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 22.  0.] 
cards in discard: [ 0. 10.  8.  0.  3.  8.  0.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 10  0  8  8  0  8  3  0 22  0  3 10  0  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 29. 30. 19. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 6. 15.  0. 10. 10.] 
adversary cards in discard: [3. 3. 0. 3. 0. 6.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3  3  0  3] -> size -> 37 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 22.  0.] 
cards in discard: [ 0. 10.  8.  0.  3.  8.  0.  0.  8.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 10  0  8  8  0  8  3  0 22  0  3 10  0  0  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 18. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 6. 15.  0. 10. 10.] 
adversary cards in discard: [3. 3. 0. 3. 0. 6.] 
adversary owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3  3  0  3] -> size -> 37 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 6. 15.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10.] 
expected returns: [[19.88765 ]
 [14.185215]
 [15.73283 ]
 [15.73283 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0. 10. 10.] 
cards in discard: [3. 3. 0. 3. 0. 6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3  3  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 18. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  8. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0  8  8  0  8  3  0 22  0  3 10  0  0  0  3] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: 0.11749015003442764
desired expected reward: -7.858969211578369



action possibilites: [-1. 15. 10. 15.] 
expected returns: [[29.628883]
 [23.136173]
 [25.20982 ]
 [23.136173]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0. 10. 15.] 
cards in discard: [3. 3. 0. 3. 0. 6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3  3  0  3] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 18. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  8. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0  8  8  0  8  3  0 22  0  3 10  0  0  0  3] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action 10.0
Learning step: 0.1321239471435547
desired expected reward: 15.864957809448242



action possibilites: [-1. 15. 15. 11.] 
expected returns: [[ 1.6998298 ]
 [-0.30158854]
 [-0.30158854]
 [ 1.1285946 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0. 15. 11.] 
cards in discard: [3. 3. 0. 3. 0. 6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 3  3  3 14  0 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11
 10  8  6 10  6  0  0  0  0  3  3  0  3] -> size -> 37 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 18. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  8. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0  8  8  0  8  3  0 22  0  3 10  0  0  0  3] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 27 

action type: take_action - action 10.0
Learning step: 0.10202989727258682
desired expected reward: 25.311857223510742



action possibilites: [-1. 15. 11.] 
expected returns: [[ -8.825779]
 [ -9.901823]
 [-10.05447 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15. 11.] 
cards in discard: [3. 3. 0. 3. 0. 6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 10. 15.] 
owned cards: [ 3  3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10
  8  6 10  6  0  0  0  0  3  3  0  3] -> size -> 36 
action values: 2 
buys: 0 
player value: 3 
card supply: [ 3. 29. 30. 18. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  8. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0  8  8  0  8  3  0 22  0  3 10  0  0  0  3] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 47 

action type: take_action - action 15.0
Learning step: 2.149216651916504
desired expected reward: 1.847630262374878





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[-10.794957]
 [-10.897208]
 [ -9.566089]
 [-10.529254]
 [ -9.920629]
 [ -9.690085]
 [ -8.560532]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15. 11.] 
cards in discard: [3. 3. 0. 3. 0. 6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 10. 15.] 
owned cards: [ 3  3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10
  8  6 10  6  0  0  0  0  3  3  0  3] -> size -> 36 
action values: 2 
buys: 1 
player value: 3 
card supply: [ 3. 29. 30. 18. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  8. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0  8  8  0  8  3  0 22  0  3 10  0  0  0  3] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 47 

action type: take_action - action -1.0
Learning step: 2.566426992416382
desired expected reward: -6.259349822998047



buy possibilites: [-1] 
expected returns: [[-13.82486]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15. 11.] 
cards in discard: [3. 3. 0. 3. 0. 6. 1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 10. 15.] 
owned cards: [ 3  3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10
  8  6 10  6  0  0  0  0  3  3  0  3  1] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 18. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  8. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  0  8  8  0  8  3  0 22  0  3 10  0  0  0  3] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  60   0   0   0   0  -2   0   0  18   0] 
sum of rewards: 63 

action type: buy - action 1.0
Learning step: 3.383800983428955
desired expected reward: -7.5134053230285645






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 22.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  0  8  8  0  8  3  0 22  0  3 10  0  0  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 18. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  3. 14.  0.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.] 
adversary owned cards: [ 3  3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10
  8  6 10  6  0  0  0  0  3  3  0  3  1] -> size -> 37 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 18. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  3. 14.  0.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.] 
adversary owned cards: [ 3  3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10
  8  6 10  6  0  0  0  0  3  3  0  3  1] -> size -> 37 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 28. 30. 18. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  3. 14.  0.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.] 
adversary owned cards: [ 3  3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10
  8  6 10  6  0  0  0  0  3  3  0  3  1] -> size -> 37 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 18. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  3. 14.  0.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.] 
adversary owned cards: [ 3  3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10
  8  6 10  6  0  0  0  0  3  3  0  3  1] -> size -> 37 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
expected returns: [[-5.2069364]
 [-7.0492163]
 [-8.029758 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 14.  0.] 
cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10
  8  6 10  6  0  0  0  0  3  3  0  3  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 18. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 8.  3.  8.  3. 10.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -0.110895536839962
desired expected reward: -13.935754776000977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-8.439618 ]
 [-7.66123  ]
 [-8.906692 ]
 [-5.8025846]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 14.  0.] 
cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10
  8  6 10  6  0  0  0  0  3  3  0  3  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 28. 30. 18. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 8.  3.  8.  3. 10.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -0.5629531741142273
desired expected reward: -5.769887924194336



buy possibilites: [-1] 
expected returns: [[-4.1565027]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 14.  0.] 
cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10
  8  6 10  6  0  0  0  0  3  3  0  3  1  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 17. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 8.  3.  8.  3. 10.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0 -3  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: 0.456808865070343
desired expected reward: -7.5497941970825195






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8.  3. 10.] 
cards in discard: [0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 17. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [23.  8.  0.  0.  0.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.] 
adversary owned cards: [ 3  3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10
  8  6 10  6  0  0  0  0  3  3  0  3  1  3] -> size -> 38 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  8.  3. 10.] 
cards in discard: [0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0] -> size -> 14 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 2. 28. 30. 17. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [23.  8.  0.  0.  0.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.] 
adversary owned cards: [ 3  3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10
  8  6 10  6  0  0  0  0  3  3  0  3  1  3] -> size -> 38 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  8.  3. 10.] 
cards in discard: [0. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 17. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [23.  8.  0.  0.  0.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.] 
adversary owned cards: [ 3  3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10
  8  6 10  6  0  0  0  0  3  3  0  3  1  3] -> size -> 38 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [23.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
expected returns: [[-7.5650053]
 [-2.8409884]
 [-5.2945204]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.  0.  0.  0.] 
cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10
  8  6 10  6  0  0  0  0  3  3  0  3  1  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 17. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [ 0.  8.  0.  8.  3.  8.  3. 10.] 
adversary owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -0.009919834323227406
desired expected reward: -4.166422367095947



action possibilites: [-1.  8.] 
expected returns: [[-3.470892]
 [-4.177314]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10
  8  6 10  6  0  0  0  0  3  3  0  3  1  3] -> size -> 38 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 1. 28. 30. 17. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [ 0.  8.  0.  8.  3.  8.  3. 10.] 
adversary owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action 23.0
Learning step: 0.9560085535049438
desired expected reward: -1.8849810361862183



action possibilites: [-1] 
expected returns: [[-17.227734]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 28. 30. 17. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [ 0.  8.  0.  8.  3.  8.  3. 10.] 
adversary owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 27 

action type: trash_cards_n_from_hand - action 1
Learning step: 1.1640325784683228
desired expected reward: -2.8690977096557617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-13.650649]
 [-14.832004]
 [-14.893384]
 [ -8.612657]
 [-14.314456]
 [-15.000224]
 [-14.071464]
 [-10.690153]
 [-14.021875]
 [-13.349453]
 [-15.438622]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3] -> size -> 37 
action values: 0 
buys: 2 
player value: 4 
card supply: [ 1. 28. 30. 17. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [ 0.  8.  0.  8.  3.  8.  3. 10.] 
adversary owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: 1.9068880081176758
desired expected reward: -15.320845603942871



buy possibilites: [ 1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[ 5.4704227 ]
 [ 3.4302049 ]
 [-3.4200723 ]
 [ 4.0588675 ]
 [ 6.5922546 ]
 [ 5.5004997 ]
 [-0.48095727]
 [ 3.9750643 ]
 [ 2.9500217 ]
 [ 6.405345  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 28. 30. 17. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [ 0.  8.  0.  8.  3.  8.  3. 10.] 
adversary owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  40 -30   0   0   0  -3   0   0   0   0] 
sum of rewards: -6 

action type: buy - action 0.0
Learning step: 0.4601286053657532
desired expected reward: -13.190535545349121



buy possibilites: [-1] 
expected returns: [[20.75259]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 27. 30. 17. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [ 0.  8.  0.  8.  3.  8.  3. 10.] 
adversary owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -10.    0.    0.   40.    0.    0.    0.    0.   -4.
   0.    0.    4.5   0. ] 
sum of rewards: 27.5 

action type: buy - action 1.0
Learning step: 1.5684125423431396
desired expected reward: 7.038827896118164






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  8.] 
cards in discard: [ 0.  8.  0.  8.  3.  8.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 17. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  8. 11.  6.  0.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.  0.  1. 23.  8.  0.  0.  0.] 
adversary owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1] -> size -> 39 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [ 0.  8.  0.  8.  3.  8.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0  0] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 17. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  8. 11.  6.  0.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.  0.  1. 23.  8.  0.  0.  0.] 
adversary owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1] -> size -> 39 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [ 0.  8.  0.  8.  3.  8.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 27. 30. 17. 30.  8.  3.  8.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  8. 11.  6.  0.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.  0.  1. 23.  8.  0.  0.  0.] 
adversary owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1] -> size -> 39 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [ 0.  8.  0.  8.  3.  8.  3. 10. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0  0 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 17. 30.  8.  3.  7.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  8. 11.  6.  0.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.  0.  1. 23.  8.  0.  0.  0.] 
adversary owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1] -> size -> 39 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0.  8. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[ 3.9141684]
 [-2.6503708]
 [ 2.4928594]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  6.  0.] 
cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.  0.  1. 23.  8.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 17. 30.  8.  3.  7.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0  0 16] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -1.659444808959961
desired expected reward: 19.0931453704834



action possibilites: [-1] 
expected returns: [[1.2608604]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0.] 
cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.  0.  1. 23.  8.  0.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 17. 30.  8.  2.  7.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0  0 16] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -20    0    0   20    0    0    0    0   -5    0 -300
    0    0] 
sum of rewards: -309 

action type: gain_card_n - action 2
Learning step: -15.16019344329834
desired expected reward: -20.38896942138672





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[-7.470023 ]
 [-9.009815 ]
 [ 1.2608595]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0.] 
cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.  0.  1. 23.  8.  0.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 27. 30. 17. 30.  8.  2.  7.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0  0 16] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -0.3771618902683258
desired expected reward: 0.883698582649231



buy possibilites: [-1] 
expected returns: [[-15.789929]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0.] 
cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.  0.  1. 23.  8.  0.  0.  0.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 16. 30.  8.  2.  7.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0  0 16] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0  -6   0   0   8   0] 
sum of rewards: 9 

action type: buy - action 3.0
Learning step: 0.46822795271873474
desired expected reward: -7.001799583435059






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  8  8  3  0  3 10  0  0  0  3  0  0 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 16. 30.  8.  2.  7.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 3.  0. 11.  0.  6.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.  0.  1. 23.  8.  0.  0.  0.  6.  3. 11.  0.  8.  6.  0.] 
adversary owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3] -> size -> 41 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 16. 30.  8.  2.  7.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 3.  0. 11.  0.  6.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.  0.  1. 23.  8.  0.  0.  0.  6.  3. 11.  0.  8.  6.  0.] 
adversary owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3] -> size -> 41 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 27. 30. 16. 30.  8.  2.  7.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 3.  0. 11.  0.  6.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.  0.  1. 23.  8.  0.  0.  0.  6.  3. 11.  0.  8.  6.  0.] 
adversary owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3] -> size -> 41 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-16.3356  ]
 [-16.746437]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  6.] 
cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.  0.  1. 23.  8.  0.  0.  0.  6.  3. 11.  0.  8.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 16. 30.  8.  2.  7.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 3.  3. 16. 10. 10.] 
adversary cards in discard: [8. 8. 3.] 
adversary owned cards: [ 8 10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -0.232675701379776
desired expected reward: -16.022605895996094



action possibilites: [-1] 
expected returns: [[-26.491709]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6.] 
cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.  0.  1. 23.  8.  0.  0.  0.  6.  3. 11.  0.  8.  6.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 16. 30.  8.  1.  7.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 3.  3. 16. 10. 10.] 
adversary cards in discard: [8. 8. 3.] 
adversary owned cards: [ 8 10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -20    0    0   20    0    0    0    0   -7    0 -300
    0    0] 
sum of rewards: -311 

action type: gain_card_n - action 2
Learning step: -15.300518989562988
desired expected reward: -32.06017303466797





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[-26.644   ]
 [-20.388288]
 [-26.491709]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6.] 
cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.  0.  1. 23.  8.  0.  0.  0.  6.  3. 11.  0.  8.  6.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 27. 30. 16. 30.  8.  1.  7.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 3.  3. 16. 10. 10.] 
adversary cards in discard: [8. 8. 3.] 
adversary owned cards: [ 8 10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: 0.5731707811355591
desired expected reward: -25.918537139892578



buy possibilites: [-1] 
expected returns: [[-15.533512]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6.] 
cards in discard: [ 3.  3.  0.  3.  0.  6.  1. 10. 10. 15.  6. 15. 11.  3.  0. 10.  3. 14.
  0.  0.  1. 23.  8.  0.  0.  0.  6.  3. 11.  0.  8.  6.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 15. 30.  8.  1.  7.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 3.  3. 16. 10. 10.] 
adversary cards in discard: [8. 8. 3.] 
adversary owned cards: [ 8 10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0  -8   0   0   8   0] 
sum of rewards: 7 

action type: buy - action 3.0
Learning step: 1.3326963186264038
desired expected reward: -25.311309814453125






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 16. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16. 10. 10.] 
cards in discard: [8. 8. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 15. 30.  8.  1.  7.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 3.  0.  3.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6  3] -> size -> 43 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16. 10.  0.] 
cards in discard: [8. 8. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 15. 30.  8.  1.  7.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 3.  0.  3.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6  3] -> size -> 43 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16.  0.  0.] 
cards in discard: [8. 8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 8 10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 14 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 15. 30.  8.  1.  7.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 3.  0.  3.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6  3] -> size -> 43 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.  0.  0.] 
cards in discard: [8. 8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 8 10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 27. 30. 15. 30.  8.  1.  7.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 3.  0.  3.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6  3] -> size -> 43 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0.  3.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[-8.214186 ]
 [-7.5330477]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  6. 16.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8
  6 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 15. 30.  8.  1.  7.  6.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -0.0474431999027729
desired expected reward: -15.580955505371094



action possibilites: [-1] 
expected returns: [[7.6500034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6.] 
cards in discard: [11.] 
cards in deck: 38 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8  6
 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6  3 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 15. 30.  8.  1.  7.  5.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0  -8   0   0   9   0] 
sum of rewards: -3 

action type: gain_card_n - action 4
Learning step: 0.476549357175827
desired expected reward: -8.611936569213867





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[-14.249699]
 [  5.093149]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [11.] 
cards in deck: 38 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8  6
 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6  3 11] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 27. 30. 15. 30.  8.  1.  7.  5.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -0.6854755282402039
desired expected reward: 6.9645280838012695






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 15. 30.  8.  1.  7.  5.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [11.  0.  3.  3.  0.] 
adversary cards in discard: [11. 16.  0.  3.  6.] 
adversary owned cards: [ 3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8  6
 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6  3 11] -> size -> 43 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 15. 30.  8.  1.  7.  5.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [11.  0.  3.  3.  0.] 
adversary cards in discard: [11. 16.  0.  3.  6.] 
adversary owned cards: [ 3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8  6
 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6  3 11] -> size -> 43 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 27. 30. 15. 30.  8.  1.  7.  5.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [11.  0.  3.  3.  0.] 
adversary cards in discard: [11. 16.  0.  3.  6.] 
adversary owned cards: [ 3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8  6
 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6  3 11] -> size -> 43 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-9.011585]
 [-8.636173]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  3.  0.] 
cards in discard: [11. 16.  0.  3.  6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8  6
 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6  3 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 15. 30.  8.  1.  7.  5.  0. 10. 10.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 8. 16.  3.  0.  0.] 
adversary cards in discard: [8. 3. 0. 0.] 
adversary owned cards: [10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -1.6531933546066284
desired expected reward: 3.439939498901367



action possibilites: [-1] 
expected returns: [[-8.62949]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [11. 16.  0.  3.  6. 10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8  6
 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6  3 11 10] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 15. 30.  8.  1.  7.  5.  0. 10. 10.  8.  9.  3.  9.  7.] 
adversary cards in hand: [ 8. 16.  3.  0.  0.] 
adversary cards in discard: [8. 3. 0. 0.] 
adversary owned cards: [10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0  -9   0   0   9   0] 
sum of rewards: -4 

action type: gain_card_n - action 7
Learning step: -0.03783848509192467
desired expected reward: -7.164339065551758





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[-8.208311]
 [-5.957482]
 [-8.880633]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [11. 16.  0.  3.  6. 10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8  6
 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6  3 11 10] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 27. 30. 15. 30.  8.  1.  7.  5.  0. 10. 10.  8.  9.  3.  9.  7.] 
adversary cards in hand: [ 8. 16.  3.  0.  0.] 
adversary cards in discard: [8. 3. 0. 0.] 
adversary owned cards: [10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: 0.058632709085941315
desired expected reward: -8.570857048034668



buy possibilites: [-1] 
expected returns: [[-13.2765465]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [11. 16.  0.  3.  6. 10.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8  6
 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6  3 11 10  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 14. 30.  8.  1.  7.  5.  0. 10. 10.  8.  9.  3.  9.  7.] 
adversary cards in hand: [ 8. 16.  3.  0.  0.] 
adversary cards in discard: [8. 3. 0. 0.] 
adversary owned cards: [10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0 -10   0   0   8   0] 
sum of rewards: 5 

action type: buy - action 3.0
Learning step: 0.36169320344924927
desired expected reward: -7.846615791320801






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 8. 16.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  3.  0.  0.] 
cards in discard: [8. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  8  3  3 10  0  0  3  0  0 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 14. 30.  8.  1.  7.  5.  0. 10. 10.  8.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [11. 16.  0.  3.  6. 10.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8  6
 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6  3 11 10  3] -> size -> 45 
adversary victory points: 2
player victory points: 3 


Game is draw!



Player 0 bought cards:
Copper: 11 
Silver: 2 
Gold: 0 
Estate: 9 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 1 
Workshop: 3 
Chapel: 2 
Witch: 0 
Poacher: 0 
Militia: 1 
Market: 1 
Village: 2 
Library: 0 
Moneylender: 2 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3.  3. 15.  0.  0.] 
cards in discard: [11. 16.  0.  3.  6. 10.  3. 11.  0.  3.  3.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 11 16  3  0  6  0  6 15 11  0  0  0  6 15  0 10 23  8 11 10  8  6
 10  6  0  0  0  0  3  3  0  3  1  3  0  1  6  3  6  3 11 10  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 14. 30.  8.  0.  7.  5.  0. 10. 10.  8.  9.  3.  9.  7.] 
adversary cards in hand: [8. 3. 0.] 
adversary cards in discard: [8. 3. 0. 0. 6.] 
adversary owned cards: [10  8  8  8  3  3 10  0  3  0  0 16  6] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: 0.5138273239135742
desired expected reward: -12.76271915435791



