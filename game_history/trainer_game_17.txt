 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[320.19275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    7  -10    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -508 

action type: buy - action -1
Learning step: -31.86834716796875
desired expected reward: 97.49861145019531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[305.12302]
 [307.17288]
 [307.63986]
 [304.73264]
 [304.67218]
 [307.81256]
 [310.99826]
 [308.3133 ]
 [313.32083]
 [312.6332 ]
 [308.06155]
 [309.8134 ]
 [308.78036]
 [307.56082]
 [310.31058]
 [319.8915 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.142143249511719
desired expected reward: 312.3385009765625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[347.13748]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.235669136047363
desired expected reward: 311.6558532714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[325.05118]
 [328.57236]
 [324.4272 ]
 [329.51355]
 [344.96732]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.026078224182129
desired expected reward: 339.2586669921875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[309.83493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -10.347928047180176
desired expected reward: 334.6193542480469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[295.6594 ]
 [297.67044]
 [298.12146]
 [295.21472]
 [301.43762]
 [298.7799 ]
 [299.23093]
 [310.53568]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.838857650756836
desired expected reward: 302.2916564941406



buy possibilites: [-1] 
expected returns: [[292.93863]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -7.764953136444092
desired expected reward: 290.3564758300781






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[329.03806]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -6.761205196380615
desired expected reward: 286.17742919921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[312.67905]
 [315.19995]
 [315.76755]
 [312.12204]
 [315.97995]
 [319.9248 ]
 [316.5897 ]
 [322.0221 ]
 [316.27484]
 [317.15735]
 [319.04227]
 [331.34045]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.82740306854248
desired expected reward: 321.6493225097656



buy possibilites: [-1] 
expected returns: [[345.2679]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0.  3.  0.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 41 

action type: buy - action 14.0
Learning step: -5.995213985443115
desired expected reward: 310.2796325683594






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[323.00772]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -9.47789192199707
desired expected reward: 335.7900085449219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[303.3984 ]
 [305.61282]
 [306.11633]
 [302.97626]
 [302.9109 ]
 [306.30057]
 [309.77338]
 [306.83722]
 [312.39035]
 [311.61374]
 [306.56403]
 [308.4601 ]
 [307.34067]
 [306.02737]
 [308.99673]
 [319.38187]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.844210624694824
desired expected reward: 317.1781921386719



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 25.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[329.9395]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [ 0. 25.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: -8.079137802124023
desired expected reward: 311.302734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[311.42133]
 [310.86105]
 [329.9694 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [ 0. 25.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.85301399230957
desired expected reward: 321.8116760253906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [ 0. 25.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [ 0. 25.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [ 0. 25.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[326.74554]
 [309.98465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: -8.812939643859863
desired expected reward: 321.1564025878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[310.25977]
 [312.56918]
 [313.10205]
 [309.7548 ]
 [316.92133]
 [313.84988]
 [314.38266]
 [328.17685]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.750656127929688
desired expected reward: 318.82904052734375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[300.00925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  0.  3. 14.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [25.  3.  0.  3.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: -9.175993919372559
desired expected reward: 319.0008850097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[283.37286]
 [285.1402 ]
 [285.51645]
 [282.97247]
 [285.66617]
 [288.40244]
 [286.0932 ]
 [289.8666 ]
 [285.85175]
 [286.46945]
 [287.78476]
 [296.66232]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  0.  3. 14.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [25.  3.  0.  3.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.003878593444824
desired expected reward: 291.57843017578125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [25.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  3.  0.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 8. 3.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6] -> size -> 13 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 8. 3.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6] -> size -> 13 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 8. 3.] 
cards in discard: [29.  0.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6] -> size -> 13 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[283.07983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    3    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -302 

action type: buy - action -1.0
Learning step: -23.54815673828125
desired expected reward: 273.1141357421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[266.9862 ]
 [269.06622]
 [269.5263 ]
 [266.52103]
 [273.2753 ]
 [270.21066]
 [270.67078]
 [284.50208]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 29. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.090947151184082
desired expected reward: 275.68499755859375



buy possibilites: [-1] 
expected returns: [[333.4767]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [6. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 1.0
Learning step: -5.15008544921875
desired expected reward: 263.9161376953125






Player: 1 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  0.] 
adversary cards in discard: [6. 1. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  0.] 
adversary cards in discard: [6. 1. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  0.] 
adversary cards in discard: [6. 1. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[280.3923 ]
 [265.17535]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14.  0.] 
cards in discard: [6. 1. 0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0.  0.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -10.58159351348877
desired expected reward: 322.8951110839844



action possibilites: [-1] 
expected returns: [[287.43393]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [6. 1. 0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action 14.0
Learning step: -5.893867015838623
desired expected reward: 259.3287353515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[267.16873]
 [269.90683]
 [270.52194]
 [266.64355]
 [266.5599 ]
 [270.75204]
 [275.0397 ]
 [271.41733]
 [278.27716]
 [277.31192]
 [271.06717]
 [273.40924]
 [272.0324 ]
 [270.40192]
 [274.07452]
 [287.43668]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [6. 1. 0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -7.233378887176514
desired expected reward: 280.2005615234375



buy possibilites: [-1] 
expected returns: [[289.98563]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [6. 1. 0. 0. 0. 3. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 31.0 

action type: buy - action 3.0
Learning step: -5.451419353485107
desired expected reward: 265.07049560546875






Player: 1 
cards in hand: [29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.] 
cards in discard: [10.  0.  8.  0.  0.  0. 25.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.] 
cards in discard: [10.  0.  8.  0.  0.  0. 25.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.] 
cards in discard: [10.  0.  8.  0.  0.  0. 25.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[275.84955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0. 25.  0.  3. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -8.327162742614746
desired expected reward: 281.6584777832031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[254.83952]
 [257.14993]
 [257.66602]
 [254.39587]
 [254.32532]
 [257.85843]
 [261.47202]
 [258.41977]
 [264.20056]
 [263.3871 ]
 [258.12244]
 [260.09723]
 [258.93588]
 [257.56107]
 [260.65857]
 [271.91357]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 27. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0. 25.  0.  3. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -7.951784610748291
desired expected reward: 268.5868225097656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10.  0.  8.  0.  0.  0. 25.  0.  3. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 1. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10.  0.  8.  0.  0.  0. 25.  0.  3. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 27. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 1. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10.  0.  8.  0.  0.  0. 25.  0.  3. 29.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 1. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[291.20065]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 1. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -7.03570032119751
desired expected reward: 264.87786865234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[275.1921 ]
 [277.99585]
 [278.64188]
 [274.5747 ]
 [283.3301 ]
 [279.57013]
 [280.21616]
 [295.74765]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 1. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 27. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.31783676147461
desired expected reward: 285.458984375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  3.  6.  0.  3.] 
adversary cards in discard: [0. 1. 0. 3. 0. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 27. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  3.  6.  0.  3.] 
adversary cards in discard: [0. 1. 0. 3. 0. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [14.  3.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[276.0638 ]
 [263.14145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  6.  0.  3.] 
cards in discard: [0. 1. 0. 3. 0. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -8.766379356384277
desired expected reward: 286.9812316894531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[260.63968]
 [260.15002]
 [276.4357 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  6.  0.  3.] 
cards in discard: [0. 1. 0. 3. 0. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 27. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -7.71521520614624
desired expected reward: 266.67803955078125



buy possibilites: [-1] 
expected returns: [[270.78427]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  6.  0.  3.] 
cards in discard: [0. 1. 0. 3. 0. 0. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -31.0 

action type: buy - action 0.0
Learning step: -8.489336967468262
desired expected reward: 252.1503143310547






Player: 1 
cards in hand: [ 0.  0.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 10.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 27. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  0.  3.  3.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  9. 10.  9.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[285.70865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  9. 10.  9.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  1. 29.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 11. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -7.216573238372803
desired expected reward: 263.56768798828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[260.4722 ]
 [263.16284]
 [263.77243]
 [259.95633]
 [259.87628]
 [264.00192]
 [268.235  ]
 [264.6658 ]
 [271.3855 ]
 [270.46945]
 [264.32065]
 [266.61642]
 [265.27533]
 [263.65674]
 [267.28027]
 [279.49857]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 27. 30.  8.  9. 10.  9.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  1. 29.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 11. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -7.925403118133545
desired expected reward: 271.1177062988281



buy possibilites: [-1] 
expected returns: [[304.1179]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  9. 10.  9.  9.  9.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  1. 29.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 11. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 7.0 

action type: buy - action 14.0
Learning step: -6.023380279541016
desired expected reward: 258.2972717285156






Player: 1 
cards in hand: [ 0.  1. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.  0.  0.] 
cards in discard: [ 0.  0.  3.  3.  0. 11. 10.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  9. 10.  9.  9.  9.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 14.  3.  0.  0.] 
adversary cards in discard: [14.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14] -> size -> 17 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29.  0.  0.] 
cards in discard: [ 0.  0.  3.  3.  0. 11. 10.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 27. 30.  8.  9. 10.  9.  9.  9.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 14.  3.  0.  0.] 
adversary cards in discard: [14.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14] -> size -> 17 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29.  0.  0.] 
cards in discard: [ 0.  0.  3.  3.  0. 11. 10.  8.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 27. 30.  8.  9. 10.  9.  9.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 14.  3.  0.  0.] 
adversary cards in discard: [14.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14] -> size -> 17 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3. 14.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[292.3519 ]
 [275.40433]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  3.  0.  0.] 
cards in discard: [14.  0.  0.  0.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  9. 10.  9.  9.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  3.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10] -> size -> 21 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -8.884799003601074
desired expected reward: 295.23309326171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[271.55484]
 [274.89914]
 [270.95215]
 [275.80356]
 [291.915  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  3.  0.  0.] 
cards in discard: [14.  0.  0.  0.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 27. 30.  8.  9. 10.  9.  9.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  3.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10] -> size -> 21 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.164070129394531
desired expected reward: 280.8742980957031



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  3.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  9. 10.  9.  9.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [14.  0.  0.  0.  3.  1.  3. 14.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14] -> size -> 17 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  8. 10.  9.  9.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [14.  0.  0.  0.  3.  1.  3. 14.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6] -> size -> 18 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 27. 30.  8.  8. 10.  9.  9.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [14.  0.  0.  0.  3.  1.  3. 14.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6] -> size -> 18 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  3.  0. 10.] 
cards in discard: [11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  8. 10.  8.  9.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [14.  0.  0.  0.  3.  1.  3. 14.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6] -> size -> 18 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[260.3611]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [14.  0.  0.  0.  3.  1.  3. 14.  3.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  8. 10.  8.  9.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  8.  0. 11.] 
adversary cards in discard: [11. 25.  1.  3.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    3  -10    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -312 

action type: buy - action -1.0
Learning step: -24.365575790405273
desired expected reward: 267.5494384765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[242.68715]
 [245.57155]
 [242.17577]
 [246.42998]
 [261.4758 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [14.  0.  0.  0.  3.  1.  3. 14.  3.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 27. 30.  8.  8. 10.  8.  9.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  8.  0. 11.] 
adversary cards in discard: [11. 25.  1.  3.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.886244297027588
desired expected reward: 251.23265075683594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  0. 11.] 
cards in discard: [11. 25.  1.  3.  0.  3.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  8. 10.  8.  9.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 6. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8.  0. 11.] 
cards in discard: [11. 25.  1.  3.  0.  3.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 27. 30.  8.  8. 10.  8.  9.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 6. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8.  0. 11.] 
cards in discard: [11. 25.  1.  3.  0.  3.  0. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  8. 10.  8.  8.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 6. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [6. 6. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[188.71758]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  8. 10.  8.  8.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [11. 25.  1.  3.  0.  3.  0. 10.  8.  3.  0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -9.457108497619629
desired expected reward: 252.01869201660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[179.822  ]
 [181.70778]
 [182.1017 ]
 [179.36458]
 [185.05353]
 [182.69008]
 [183.08401]
 [193.34492]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 27. 30.  8.  8. 10.  8.  8.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [11. 25.  1.  3.  0.  3.  0. 10.  8.  3.  0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -5.7739787101745605
desired expected reward: 181.63409423828125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [11. 25.  1.  3.  0.  3.  0. 10.  8.  3.  0.  8.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  8. 10.  8.  8.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [6. 6. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [11. 25.  1.  3.  0.  3.  0. 10.  8.  3.  0.  8.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 27. 30.  8.  8. 10.  8.  8.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [6. 6. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [11. 25.  1.  3.  0.  3.  0. 10.  8.  3.  0.  8.  0. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  8.  8.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [6. 6. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[296.69476]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6. 6. 3. 1. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  8.  8.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -3.6586272716522217
desired expected reward: 189.686279296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[277.51645]
 [280.12958]
 [280.71643]
 [276.93365]
 [280.93546]
 [285.17398]
 [281.56744]
 [287.59448]
 [281.2359 ]
 [282.15436]
 [284.13882]
 [298.47806]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6. 6. 3. 1. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  8.  8.  9.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.80865478515625
desired expected reward: 284.90771484375



buy possibilites: [-1] 
expected returns: [[235.5548]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6.  6.  3.  1.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  8.  8.  9.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -7.5 

action type: buy - action 10.0
Learning step: -9.182733535766602
desired expected reward: 272.9715881347656






Player: 1 
cards in hand: [11.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  8.  8.  9.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0.  3.] 
adversary cards in discard: [ 6.  6.  3.  1.  0. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  8.  8.  9.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0.  3.] 
adversary cards in discard: [ 6.  6.  3.  1.  0. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  8.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  0.  3.] 
adversary cards in discard: [ 6.  6.  3.  1.  0. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  8.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  0.  3.] 
adversary cards in discard: [ 6.  6.  3.  1.  0. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [15. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  7.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  0.  3.] 
adversary cards in discard: [ 6.  6.  3.  1.  0. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[244.37262]
 [228.20523]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0.  3.] 
cards in discard: [ 6.  6.  3.  1.  0. 10.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  7.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 10.] 
adversary cards in discard: [15. 11. 10. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -7.035008430480957
desired expected reward: 228.51979064941406



action possibilites: [-1] 
expected returns: [[285.36746]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 6.  6.  3.  1.  0. 10.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  7.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action 14.0
Learning step: -4.5193305015563965
desired expected reward: 222.2826385498047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[263.55408]
 [266.52148]
 [267.20612]
 [262.89954]
 [267.468  ]
 [272.1762 ]
 [268.2006 ]
 [274.70422]
 [267.83005]
 [268.88522]
 [271.10165]
 [286.02695]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 6.  6.  3.  1.  0. 10.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  7.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -7.684999942779541
desired expected reward: 277.6824645996094



buy possibilites: [-1] 
expected returns: [[240.37666]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 6.  6.  3.  1.  0. 10.  0.  0.  0.  0.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 27. 30.  8.  8. 10.  7.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 12.5 

action type: buy - action 1.0
Learning step: -7.292601108551025
desired expected reward: 259.2289123535156






Player: 1 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 30.  8.  8. 10.  7.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 27. 30.  8.  8. 10.  7.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 27. 30.  8.  8. 10.  7.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[204.37933]
 [189.60423]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 30.  8.  8. 10.  7.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  1. 29.] 
adversary cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -8.204639434814453
desired expected reward: 232.17202758789062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[188.69249]
 [191.13557]
 [191.69073]
 [188.1513 ]
 [195.74359]
 [192.50037]
 [193.05553]
 [207.01575]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 27. 30.  8.  8. 10.  7.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  1. 29.] 
adversary cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -6.270891189575195
desired expected reward: 196.12367248535156



buy possibilites: [-1] 
expected returns: [[222.62173]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.  3.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  1. 29.] 
adversary cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -10.0 

action type: buy - action 8.0
Learning step: -5.116029262542725
desired expected reward: 187.38433837890625






Player: 1 
cards in hand: [ 0.  0.  0.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  1. 29.] 
cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 1. 3.] 
adversary cards in discard: [ 8.  0.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  1. 29.] 
cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 27. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 1. 3.] 
adversary cards in discard: [ 8.  0.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8] -> size -> 21 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  1. 29.] 
cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.  0.  3.  0.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11  0  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 1. 3.] 
adversary cards in discard: [ 8.  0.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8] -> size -> 21 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[220.13205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1. 3.] 
cards in discard: [ 8.  0.  0. 14.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  3.  8.] 
adversary cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.  0.  3.  0.  0.  1.  0.  0.  0.
  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11  0  1] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -6.788712978363037
desired expected reward: 215.83302307128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[201.11447]
 [203.76024]
 [204.37975]
 [200.53423]
 [208.81648]
 [205.27618]
 [205.89569]
 [220.70795]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 3.] 
cards in discard: [ 8.  0.  0. 14.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  3.  8.] 
adversary cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.  0.  3.  0.  0.  1.  0.  0.  0.
  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11  0  1] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -6.839744567871094
desired expected reward: 212.8212890625



buy possibilites: [-1] 
expected returns: [[209.3602]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 3.] 
cards in discard: [ 8.  0.  0. 14.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 26. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  3.  8.] 
adversary cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.  0.  3.  0.  0.  1.  0.  0.  0.
  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11  0  1] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -42.0 

action type: buy - action 0.0
Learning step: -7.445120334625244
desired expected reward: 193.66937255859375






Player: 1 
cards in hand: [ 8.  3. 25.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 25.  3.  8.] 
cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.  0.  3.  0.  0.  1.  0.  0.  0.
  1. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0 25  8  0 29  0 10  3  1 11 10 11  8  0
 15 11  0  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 14.  0.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 14.  0.  3.  0.  3.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.  0.  3.  0.  0.  1.  0.  0.  0.
  1. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 14.  0.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 14.  0.  3.  0.  3.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.  0.  3.  0.  0.  1.  0.  0.  0.
  1. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 26. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 14.  0.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 14.  0.  3.  0.  3.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15. 11. 10. 11.  0.  0.  0.  0. 11. 10.  0.  3.  0.  0.  1.  0.  0.  0.
  1. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 14.  0.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 14.  0.  3.  0.  3.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 1. 14.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[257.2682 ]
 [244.13547]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  0.  6.  0.] 
cards in discard: [ 8.  0.  0. 14.  0.  3.  0.  3.  0.  3.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -4.381009101867676
desired expected reward: 204.97918701171875



action possibilites: [-1] 
expected returns: [[226.5914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 0.] 
cards in discard: [ 8.  0.  0. 14.  0.  3.  0.  3.  0.  3.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action 14.0
Learning step: -5.708468914031982
desired expected reward: 238.42703247070312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[210.47458]
 [212.18701]
 [210.68951]
 [212.5706 ]
 [210.14432]
 [210.09407]
 [212.71408]
 [215.40431]
 [213.1397 ]
 [217.42891]
 [216.82053]
 [212.91495]
 [214.37036]
 [213.52328]
 [212.4893 ]
 [214.79597]
 [224.08595]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 0.] 
cards in discard: [ 8.  0.  0. 14.  0.  3.  0.  3.  0.  3.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 26. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -5.04736852645874
desired expected reward: 221.54403686523438






Player: 1 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [8. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  0. 10.] 
adversary cards in discard: [ 8.  0.  0. 14.  0.  3.  0.  3.  0.  3.  1.  3. 14.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [8. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  0. 10.] 
adversary cards in discard: [ 8.  0.  0. 14.  0.  3.  0.  3.  0.  3.  1.  3. 14.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [8. 0. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  0. 10.] 
adversary cards in discard: [ 8.  0.  0. 14.  0.  3.  0.  3.  0.  3.  1.  3. 14.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[218.03659]
 [206.40279]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6.  0. 10.] 
cards in discard: [ 8.  0.  0. 14.  0.  3.  0.  3.  0.  3.  1.  3. 14.  1.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 10.  3.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -5.988420009613037
desired expected reward: 218.09754943847656



action possibilites: [-1.] 
expected returns: [[245.71704]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 10.  3.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 29 

action type: take_action - action 10.0
Learning step: -3.341506242752075
desired expected reward: 203.061279296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[230.18526]
 [232.92444]
 [233.55696]
 [229.58191]
 [238.12875]
 [234.47668]
 [235.10922]
 [251.41583]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 27. 30.  8.  8. 10.  7.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 10.  3.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -5.472431182861328
desired expected reward: 240.24461364746094



buy possibilites: [-1] 
expected returns: [[176.53514]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 30.  8.  8. 10.  6.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 10.  3.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 46 

action type: buy - action 11.0
Learning step: -5.634395122528076
desired expected reward: 232.4943084716797






Player: 1 
cards in hand: [ 0.  0.  1. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 10.  3.] 
cards in discard: [8. 0. 0. 0. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 30.  8.  8. 10.  6.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 14.  3.] 
adversary cards in discard: [11. 10.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11] -> size -> 23 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [8. 0. 0. 0. 0. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 30.  8.  8. 10.  6.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 14.  3.] 
adversary cards in discard: [11. 10.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11] -> size -> 23 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [8. 0. 0. 0. 0. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 26. 30. 27. 30.  8.  8. 10.  6.  7.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 14.  3.] 
adversary cards in discard: [11. 10.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11] -> size -> 23 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 8.  0.  0.  0.  0.  3. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 27. 30.  8.  8. 10.  6.  7.  9.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 14.  3.] 
adversary cards in discard: [11. 10.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11] -> size -> 23 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  1. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[151.6846 ]
 [140.61542]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 14.  3.] 
cards in discard: [11. 10.  3.  0.  6.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 30.  8.  8. 10.  6.  7.  9.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3. 14. 10.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -5.146659851074219
desired expected reward: 171.38848876953125



action possibilites: [-1] 
expected returns: [[170.89293]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3.] 
cards in discard: [11. 10.  3.  0.  6.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 27. 30.  8.  8. 10.  6.  7.  9.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3. 14. 10.  0.  0.  1.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action 14.0
Learning step: -1.6807323694229126
desired expected reward: 136.8357391357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[155.56664]
 [157.4447 ]
 [157.87395]
 [155.20662]
 [155.15103]
 [158.03824]
 [161.25099]
 [158.50322]
 [163.8676 ]
 [163.08058]
 [158.26353]
 [159.93727]
 [158.93246]
 [157.79855]
 [160.47618]
 [171.50984]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3.] 
cards in discard: [11. 10.  3.  0.  6.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 26. 30. 27. 30.  8.  8. 10.  6.  7.  9.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3. 14. 10.  0.  0.  1.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -3.470508337020874
desired expected reward: 167.42242431640625



buy possibilites: [-1] 
expected returns: [[149.71718]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3.] 
cards in discard: [11. 10.  3.  0.  6.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 26. 30. 26. 30.  8.  8. 10.  6.  7.  9.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3. 14. 10.  0.  0.  1.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14] -> size -> 27 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 20.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 41.0 

action type: buy - action 3.0
Learning step: -2.4341118335723877
desired expected reward: 155.4398651123047






Player: 1 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  0.  0.  0.  0.  3. 14. 10.  0.  0.  1.  3.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8.  8. 10.  6.  7.  9.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [11. 10.  3.  0.  6.  0.  0.  3. 14.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3] -> size -> 24 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  0.  0.  0.  0.  3. 14. 10.  0.  0.  1.  3.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 26. 30.  8.  8. 10.  6.  7.  9.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [11. 10.  3.  0.  6.  0.  0.  3. 14.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3] -> size -> 24 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  0.  0.  0.  0.  3. 14. 10.  0.  0.  1.  3.  0.  0. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8.  8. 10.  6.  7.  9.  9.  7. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [11. 10.  3.  0.  6.  0.  0.  3. 14.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3] -> size -> 24 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[174.78143]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [11. 10.  3.  0.  6.  0.  0.  3. 14.  0.  3.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8.  8. 10.  6.  7.  9.  9.  7. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0. 11. 15. 29.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3. 14. 10.  0.  0.  1.  3.  0.  0. 11. 10.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10] -> size -> 28 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: -2.6032769680023193
desired expected reward: 147.11390686035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[165.49261]
 [167.74828]
 [168.26964]
 [165.06252]
 [164.99669]
 [168.45807]
 [172.02658]
 [169.02063]
 [174.69962]
 [173.89249]
 [168.7348 ]
 [170.65686]
 [169.54198]
 [168.17226]
 [171.21947]
 [182.29915]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [11. 10.  3.  0.  6.  0.  0.  3. 14.  0.  3.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 26. 30. 26. 30.  8.  8. 10.  6.  7.  9.  9.  7. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0. 11. 15. 29.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3. 14. 10.  0.  0.  1.  3.  0.  0. 11. 10.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10] -> size -> 28 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -3.8772358894348145
desired expected reward: 170.90419006347656



buy possibilites: [-1] 
expected returns: [[174.49698]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [11. 10.  3.  0.  6.  0.  0.  3. 14.  0.  3.  1.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 26. 30. 26. 30.  8.  8. 10.  6.  6.  9.  9.  7. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0. 11. 15. 29.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3. 14. 10.  0.  0.  1.  3.  0.  0. 11. 10.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10] -> size -> 28 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 21.0 

action type: buy - action 8.0
Learning step: -3.4748504161834717
desired expected reward: 165.54579162597656






Player: 1 
cards in hand: [10.  0. 11. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 15. 29.] 
cards in discard: [ 8.  0.  0.  0.  0.  3. 14. 10.  0.  0.  1.  3.  0.  0. 11. 10.  0.  0.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8.  8. 10.  6.  6.  9.  9.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  0. 14.] 
adversary cards in discard: [11. 10.  3.  0.  6.  0.  0.  3. 14.  0.  3.  1.  3.  8.  0.  0.  3.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8] -> size -> 25 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1. 10. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 15.  1.] 
cards in discard: [ 8.  0.  0.  0.  0.  3. 14. 10.  0.  0.  1.  3.  0.  0. 11. 10.  0.  0.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 26. 30.  8.  8. 10.  6.  6.  9.  9.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  0. 14.] 
adversary cards in discard: [11. 10.  3.  0.  6.  0.  0.  3. 14.  0.  3.  1.  3.  8.  0.  0.  3.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8] -> size -> 25 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15.  1.] 
cards in discard: [ 8.  0.  0.  0.  0.  3. 14. 10.  0.  0.  1.  3.  0.  0. 11. 10.  0.  0.
  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 25. 30.  8.  8. 10.  6.  6.  9.  9.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  0. 14.] 
adversary cards in discard: [11. 10.  3.  0.  6.  0.  0.  3. 14.  0.  3.  1.  3.  8.  0.  0.  3.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8] -> size -> 25 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 15.  1.] 
cards in discard: [ 8.  0.  0.  0.  0.  3. 14. 10.  0.  0.  1.  3.  0.  0. 11. 10.  0.  0.
  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 26. 30. 25. 30.  8.  8. 10.  6.  6.  9.  9.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  0. 14.] 
adversary cards in discard: [11. 10.  3.  0.  6.  0.  0.  3. 14.  0.  3.  1.  3.  8.  0.  0.  3.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8] -> size -> 25 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 15.  1.] 
cards in discard: [ 8.  0.  0.  0.  0.  3. 14. 10.  0.  0.  1.  3.  0.  0. 11. 10.  0.  0.
  0.  3. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10  3 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  8. 10.  6.  6.  9.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  8.  0. 14.] 
adversary cards in discard: [11. 10.  3.  0.  6.  0.  0.  3. 14.  0.  3.  1.  3.  8.  0.  0.  3.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8] -> size -> 25 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  8.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[187.71991]
 [176.93263]
 [176.68544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8.  0. 14.] 
cards in discard: [11. 10.  3.  0.  6.  0.  0.  3. 14.  0.  3.  1.  3.  8.  0.  0.  3.  0.
  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  8. 10.  6.  6.  9.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [11.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10  3 15] -> size -> 30 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -4.163625240325928
desired expected reward: 170.33335876464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[170.01662]
 [172.26137]
 [169.60423]
 [172.87787]
 [183.62088]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  8.  0. 14.] 
cards in discard: [11. 10.  3.  0.  6.  0.  0.  3. 14.  0.  3.  1.  3.  8.  0.  0.  3.  0.
  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 25. 30.  8.  8. 10.  6.  6.  9.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [11.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10  3 15] -> size -> 30 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -4.9582977294921875
desired expected reward: 182.76162719726562



buy possibilites: [-1] 
expected returns: [[178.62439]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  8.  0. 14.] 
cards in discard: [11. 10.  3.  0.  6.  0.  0.  3. 14.  0.  3.  1.  3.  8.  0.  0.  3.  0.
  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 26. 30. 25. 30.  8.  8. 10.  6.  6.  9.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [11.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10  3 15] -> size -> 30 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -21.0 

action type: buy - action 0.0
Learning step: -5.531783103942871
desired expected reward: 164.48484802246094






Player: 1 
cards in hand: [11.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10  3 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  8. 10.  6.  6.  9.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 1. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10  3 15 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 1. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10  3 15 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 1. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [29. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10  3 15 29 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  5. 10.  8.] 
adversary cards in hand: [3. 1. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [3. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[98.295044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 1.  0. 15.  0.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10  3 15 29 10] -> size -> 32 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -6.2873735427856445
desired expected reward: 172.33702087402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 83.58988 ]
 [ 86.03164 ]
 [ 86.59659 ]
 [ 83.05149 ]
 [ 86.80987 ]
 [ 90.67936 ]
 [ 87.42074 ]
 [ 92.71451 ]
 [ 87.113884]
 [ 87.98569 ]
 [ 89.80755 ]
 [101.85221 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 26. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 1.  0. 15.  0.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10  3 15 29 10] -> size -> 32 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -2.3378689289093018
desired expected reward: 95.1664047241211



buy possibilites: [-1] 
expected returns: [[235.88211]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 1.  0. 15.  0.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10  3 15 29 10] -> size -> 32 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.  10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 13.5 

action type: buy - action 1.0
Learning step: 1.6807655096054077
desired expected reward: 87.71240234375






Player: 1 
cards in hand: [ 1.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15.  0.  0.] 
cards in discard: [29. 10. 11.  0.  0.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1
  0  0 14 10  3 15 29 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  3. 14.  0.  0.] 
adversary cards in discard: [1. 3. 1. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1] -> size -> 27 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [29. 10. 11.  0.  0.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 25. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  3. 14.  0.  0.] 
adversary cards in discard: [1. 3. 1. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1] -> size -> 27 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [29. 10. 11.  0.  0.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 7 
card supply: [19. 25. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  3. 14.  0.  0.] 
adversary cards in discard: [1. 3. 1. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1] -> size -> 27 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [29. 10. 11.  0.  0.  0. 11. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 4 
card supply: [19. 25. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  4. 10.  8.] 
adversary cards in hand: [ 3.  3. 14.  0.  0.] 
adversary cards in discard: [1. 3. 1. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1] -> size -> 27 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[194.9255]
 [183.2121]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 14.  0.  0.] 
cards in discard: [1. 3. 1. 0. 0. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  4. 10.  8.] 
adversary cards in hand: [29. 10.  3.  0.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10] -> size -> 32 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.048841953277588
desired expected reward: 228.83326721191406



action possibilites: [-1] 
expected returns: [[246.956]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [1. 3. 1. 0. 0. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 25. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  4. 10.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10] -> size -> 32 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action 14.0
Learning step: -2.154095411300659
desired expected reward: 181.05799865722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[233.81906]
 [235.45355]
 [235.81807]
 [233.45433]
 [235.95776]
 [238.52744]
 [236.36688]
 [239.88206]
 [236.1503 ]
 [236.73141]
 [237.94633]
 [246.88573]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [1. 3. 1. 0. 0. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 25. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  4. 10.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10] -> size -> 32 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1
Learning step: -5.4918742179870605
desired expected reward: 241.46412658691406



buy possibilites: [-1] 
expected returns: [[184.55469]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 1.  3.  1.  0.  0.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10] -> size -> 32 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 61 

action type: buy - action 15.0
Learning step: -4.694835662841797
desired expected reward: 233.25148010253906






Player: 1 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [11. 14.  8.  8.  0.] 
adversary cards in discard: [ 1.  3.  1.  0.  0.  3. 15. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15] -> size -> 28 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [11. 14.  8.  8.  0.] 
adversary cards in discard: [ 1.  3.  1.  0.  0.  3. 15. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15] -> size -> 28 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 25. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [11. 14.  8.  8.  0.] 
adversary cards in discard: [ 1.  3.  1.  0.  0.  3. 15. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15] -> size -> 28 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11. 14.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.  8.  8.] 
expected returns: [[121.47697]
 [111.98   ]
 [109.00526]
 [109.26306]
 [109.26306]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  8.  8.  0.] 
cards in discard: [ 1.  3.  1.  0.  0.  3. 15. 14.  3.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [14. 15.  3.  3.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0] -> size -> 33 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -6.187985420227051
desired expected reward: 178.36669921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[105.160835]
 [104.71061 ]
 [120.47676 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  8.  8.  0.] 
cards in discard: [ 1.  3.  1.  0.  0.  3. 15. 14.  3.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 25. 30. 25. 30.  8.  8. 10.  6.  6.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [14. 15.  3.  3.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0] -> size -> 33 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -3.073324203491211
desired expected reward: 118.40362548828125



buy possibilites: [-1] 
expected returns: [[75.92698]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  8.  8.  0.] 
cards in discard: [ 1.  3.  1.  0.  0.  3. 15. 14.  3.  3.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 25. 30. 25. 30.  8.  7. 10.  6.  6.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [14. 15.  3.  3.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -302.0 

action type: buy - action 6.0
Learning step: -18.597421646118164
desired expected reward: 86.1131820678711






Player: 1 
cards in hand: [14. 15.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 15.  3.  3.  0.] 
cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.  0.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  7. 10.  6.  6.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [10.  1.  0.  0.  0.] 
adversary cards in discard: [ 1.  3.  1.  0.  0.  3. 15. 14.  3.  3.  0.  0.  6. 11. 14.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15  6] -> size -> 29 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 15.  3.  3.  0.] 
cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.  0.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 25. 30. 25. 30.  8.  7. 10.  6.  6.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [10.  1.  0.  0.  0.] 
adversary cards in discard: [ 1.  3.  1.  0.  0.  3. 15. 14.  3.  3.  0.  0.  6. 11. 14.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15  6] -> size -> 29 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [10.  1.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[151.64996]
 [144.97171]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  0.  0.] 
cards in discard: [ 1.  3.  1.  0.  0.  3. 15. 14.  3.  3.  0.  0.  6. 11. 14.  8.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  7. 10.  6.  6.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 10. 11.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.  0.  3.  0.  0.
 14. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -0.5358566641807556
desired expected reward: 75.39112091064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[147.76328]
 [148.96301]
 [149.22226]
 [147.52869]
 [147.4928 ]
 [149.31833]
 [151.19176]
 [149.61903]
 [152.60133]
 [152.17616]
 [149.45312]
 [150.46594]
 [149.8783 ]
 [149.15247]
 [150.76662]
 [156.55652]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.  0.  0.] 
cards in discard: [ 1.  3.  1.  0.  0.  3. 15. 14.  3.  3.  0.  0.  6. 11. 14.  8.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 25. 30. 25. 30.  8.  7. 10.  6.  6.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 10. 11.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.  0.  3.  0.  0.
 14. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -4.259281158447266
desired expected reward: 147.3907012939453



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 11.] 
cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.  0.  3.  0.  0.
 14. 15.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  7. 10.  6.  6.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [ 1.  3.  1.  0.  0.  3. 15. 14.  3.  3.  0.  0.  6. 11. 14.  8.  8.  0.
 10.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15  6] -> size -> 29 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.  0.  3.  0.  0.
 14. 15.  3.  3.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  7. 10.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [ 1.  3.  1.  0.  0.  3. 15. 14.  3.  3.  0.  0.  6. 11. 14.  8.  8.  0.
 10.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15  6] -> size -> 29 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.  0.  3.  0.  0.
 14. 15.  3.  3.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 25. 30. 25. 30.  8.  7. 10.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [ 1.  3.  1.  0.  0.  3. 15. 14.  3.  3.  0.  0.  6. 11. 14.  8.  8.  0.
 10.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15  6] -> size -> 29 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[136.3913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [ 1.  3.  1.  0.  0.  3. 15. 14.  3.  3.  0.  0.  6. 11. 14.  8.  8.  0.
 10.  1.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  7. 10.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0.  1.  8.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.  0.  3.  0.  0.
 14. 15.  3.  3.  0.  8. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0  8] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -4.859023571014404
desired expected reward: 151.69752502441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[120.8646 ]
 [122.98908]
 [120.48237]
 [123.57083]
 [134.18787]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [ 1.  3.  1.  0.  0.  3. 15. 14.  3.  3.  0.  0.  6. 11. 14.  8.  8.  0.
 10.  1.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 25. 30. 25. 30.  8.  7. 10.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0.  1.  8.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.  0.  3.  0.  0.
 14. 15.  3.  3.  0.  8. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0  8] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -4.051391124725342
desired expected reward: 132.33990478515625



buy possibilites: [-1] 
expected returns: [[66.71611]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [ 1.  3.  1.  0.  0.  3. 15. 14.  3.  3.  0.  0.  6. 11. 14.  8.  8.  0.
 10.  1.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15  6  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 24. 30.  8.  7. 10.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0.  1.  8.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.  0.  3.  0.  0.
 14. 15.  3.  3.  0.  8. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0  8] -> size -> 34 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 17 

action type: buy - action 3.0
Learning step: -3.798341751098633
desired expected reward: 119.19074249267578






Player: 1 
cards in hand: [10.  0.  1.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.  8.  0.] 
cards in discard: [29. 10. 11.  0.  0.  0. 11. 10. 15.  1.  0.  0. 29. 10.  0.  3.  0.  0.
 14. 15.  3.  3.  0.  8. 11.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 24. 30.  8.  7. 10.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15  6  3] -> size -> 30 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8.  0. 29.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0  8] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 24. 30.  8.  7. 10.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15  6  3] -> size -> 30 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0  8] -> size -> 34 
action values: 2 
buys: 0 
player value: 1 
card supply: [18. 25. 30. 24. 30.  8.  7. 10.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15  6  3] -> size -> 30 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 6 
card supply: [18. 25. 30. 24. 30.  8.  7. 10.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15  6  3] -> size -> 30 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 0. 0.] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0  8  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 4 
card supply: [18. 25. 30. 23. 30.  8.  7. 10.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15  6  3] -> size -> 30 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[25.080765]
 [20.70629 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3
  8  0  1 15  6  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 23. 30.  8.  7. 10.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 3. 15. 10.  0.  0.] 
adversary cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0  8  3] -> size -> 35 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -2.855308771133423
desired expected reward: 63.860801696777344



action possibilites: [-1] 
expected returns: [[135.03175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 25. 30. 23. 30.  8.  7. 10.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 3. 15. 10.  0.  0.] 
adversary cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0  8  3] -> size -> 35 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action 15.0
Learning step: 2.952899694442749
desired expected reward: 23.659189224243164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[121.2599  ]
 [123.18331 ]
 [123.63415 ]
 [120.839096]
 [123.797806]
 [126.875175]
 [124.288704]
 [128.47894 ]
 [124.04401 ]
 [124.739525]
 [126.179665]
 [135.63185 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 25. 30. 23. 30.  8.  7. 10.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 3. 15. 10.  0.  0.] 
adversary cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0  8  3] -> size -> 35 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -2.910463333129883
desired expected reward: 132.1212921142578






Player: 1 
cards in hand: [ 3. 15. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10.  0.  0.] 
cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0
  0 14 10  3 15 29 10 10  0  8  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 23. 30.  8.  7. 10.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [0. 3. 0. 8. 3.] 
adversary cards in discard: [15.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.] 
cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 25. 30. 23. 30.  8.  7. 10.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [0. 3. 0. 8. 3.] 
adversary cards in discard: [15.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.] 
cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 25. 30. 23. 30.  8.  7. 10.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [0. 3. 0. 8. 3.] 
adversary cards in discard: [15.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.] 
cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 23. 30.  8.  7.  9.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [0. 3. 0. 8. 3.] 
adversary cards in discard: [15.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[116.62683 ]
 [110.404655]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 3.] 
cards in discard: [15.  6.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 23. 30.  8.  7.  9.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 10. 29.] 
adversary cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16] -> size -> 35 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -4.255595684051514
desired expected reward: 131.3762664794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[111.177284]
 [112.42902 ]
 [110.95586 ]
 [112.780396]
 [118.93707 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 3.] 
cards in discard: [15.  6.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 25. 30. 23. 30.  8.  7.  9.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 10. 29.] 
adversary cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16] -> size -> 35 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -3.293102741241455
desired expected reward: 113.3337173461914



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 29.] 
cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 23. 30.  8.  7.  9.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0.  0.  0.  6.] 
adversary cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 29.] 
cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 25. 30. 23. 30.  8.  7.  9.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0.  0.  0.  6.] 
adversary cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 29.] 
cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 23. 30.  8.  7.  9.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0.  0.  0.  6.] 
adversary cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[161.27786]
 [151.56512]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  6.] 
cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 23. 30.  8.  7.  9.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [14. 11.  0.  3.  0.] 
adversary cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.  0.  0.  0. 10.
 29.] 
adversary owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1] -> size -> 36 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -2.4431939125061035
desired expected reward: 116.4938735961914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[150.7674 ]
 [152.48743]
 [152.88559]
 [150.38841]
 [155.75339]
 [153.46178]
 [153.85994]
 [163.5727 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  6.] 
cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 24. 30. 23. 30.  8.  7.  9.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [14. 11.  0.  3.  0.] 
adversary cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.  0.  0.  0. 10.
 29.] 
adversary owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1] -> size -> 36 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -4.579253196716309
desired expected reward: 156.69862365722656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  0.  3.  0.] 
cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.  0.  0.  0. 10.
 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 23. 30.  8.  7.  9.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 14.  1.  6.  3.] 
adversary cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3. 10.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  0.  3.  0.] 
cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.  0.  0.  0. 10.
 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 24. 30. 23. 30.  8.  7.  9.  6.  5.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 14.  1.  6.  3.] 
adversary cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3. 10.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  0.  3.  0.] 
cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.  0.  0.  0. 10.
 29.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 23. 30.  8.  7.  9.  6.  4.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 14.  1.  6.  3.] 
adversary cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3. 10.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  1.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[104.46804 ]
 [ 95.264496]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.  6.  3.] 
cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3. 10.  0.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 23. 30.  8.  7.  9.  6.  4.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 1. 10.  0. 11.  3.] 
adversary cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.  0.  0.  0. 10.
 29.  8. 14. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8] -> size -> 37 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -5.949259281158447
desired expected reward: 157.62342834472656



action possibilites: [-1] 
expected returns: [[125.09517]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 3.] 
cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3. 10.  0.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 24. 30. 23. 30.  8.  7.  9.  6.  4.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 1. 10.  3.] 
adversary cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.  0.  0.  0. 10.
 29.  8. 14. 11.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8] -> size -> 37 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action 14.0
Learning step: -0.9985832571983337
desired expected reward: 94.26590728759766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[113.065346]
 [114.96518 ]
 [115.40718 ]
 [112.70907 ]
 [112.65443 ]
 [115.57215 ]
 [118.64196 ]
 [116.05632 ]
 [121.36797 ]
 [120.54094 ]
 [115.81765 ]
 [117.45229 ]
 [116.50104 ]
 [115.33349 ]
 [117.947014]
 [129.24713 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 3.] 
cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3. 10.  0.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 24. 30. 23. 30.  8.  7.  9.  6.  4.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 1. 10.  3.] 
adversary cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.  0.  0.  0. 10.
 29.  8. 14. 11.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8] -> size -> 37 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -2.5848350524902344
desired expected reward: 122.51033020019531



buy possibilites: [-1] 
expected returns: [[105.17358]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 3.] 
cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3. 10.  0.  0.  0.  6. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 24. 30. 23. 30.  8.  7.  9.  5.  4.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 1. 10.  3.] 
adversary cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.  0.  0.  0. 10.
 29.  8. 14. 11.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8] -> size -> 37 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 23.5 

action type: buy - action 11.0
Learning step: -2.395164966583252
desired expected reward: 116.24678039550781






Player: 1 
cards in hand: [ 1. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.] 
cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.  0.  0.  0. 10.
 29.  8. 14. 11.  0.  3.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 23. 30.  8.  7.  9.  5.  4.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 8. 11.  3.  3. 14.] 
adversary cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3. 10.  0.  0.  0.  6. 11. 14.  0.  1.
  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11] -> size -> 30 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.] 
cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.  0.  0.  0. 10.
 29.  8. 14. 11.  0.  3.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 24. 30. 23. 30.  8.  7.  9.  5.  4.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 8. 11.  3.  3. 14.] 
adversary cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3. 10.  0.  0.  0.  6. 11. 14.  0.  1.
  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11] -> size -> 30 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.] 
cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.  0.  0.  0. 10.
 29.  8. 14. 11.  0.  3.  0.  0. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 24. 30. 23. 30.  8.  7.  9.  5.  4.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 8. 11.  3.  3. 14.] 
adversary cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3. 10.  0.  0.  0.  6. 11. 14.  0.  1.
  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11] -> size -> 30 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  3.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 14.] 
expected returns: [[123.79413 ]
 [117.856865]
 [119.196884]
 [117.71502 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  3. 14.] 
cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3. 10.  0.  0.  0.  6. 11. 14.  0.  1.
  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 23. 30.  8.  7.  9.  5.  4.  9.  8.  7. 10.  4. 10.  7.] 
adversary cards in hand: [11.  0.  8. 10. 15.] 
adversary cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.  0.  0.  0. 10.
 29.  8. 14. 11.  0.  3.  0.  0. 11.  0.  1. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -2.587533712387085
desired expected reward: 102.58604431152344



action possibilites: [-1] 
expected returns: [[90.103004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3. 14.] 
cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3. 10.  0.  0.  0.  6. 11. 14.  0.  1.
  6.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 23. 30.  8.  7.  9.  5.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [11.  0.  8. 10. 15.] 
adversary cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.  0.  0.  0. 10.
 29.  8. 14. 11.  0.  3.  0.  0. 11.  0.  1. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 35 

action type: gain_card_n - action 10
Learning step: -2.1265628337860107
desired expected reward: 115.9510498046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[75.98719]
 [75.62397]
 [90.37797]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  3. 14.] 
cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3. 10.  0.  0.  0.  6. 11. 14.  0.  1.
  6.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 24. 30. 23. 30.  8.  7.  9.  5.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [11.  0.  8. 10. 15.] 
adversary cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.  0.  0.  0. 10.
 29.  8. 14. 11.  0.  3.  0.  0. 11.  0.  1. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -1.67186439037323
desired expected reward: 88.43113708496094






Player: 1 
cards in hand: [11.  0.  8. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 10. 15.] 
cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.  0.  0.  0. 10.
 29.  8. 14. 11.  0.  3.  0.  0. 11.  0.  1. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 23. 30.  8.  7.  9.  5.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [0. 0. 3. 1. 1.] 
adversary cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3. 10.  0.  0.  0.  6. 11. 14.  0.  1.
  6.  3. 15. 11.  8.  3.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8. 10. 15.] 
cards in discard: [ 3. 10. 29.  0.  1.  8.  0.  0. 16. 15.  3. 10.  0.  1.  0.  0.  0. 10.
 29.  8. 14. 11.  0.  3.  0.  0. 11.  0.  1. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 24. 30. 23. 30.  8.  7.  9.  5.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [0. 0. 3. 1. 1.] 
adversary cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3. 10.  0.  0.  0.  6. 11. 14.  0.  1.
  6.  3. 15. 11.  8.  3.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[163.65279]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 1.] 
cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3. 10.  0.  0.  0.  6. 11. 14.  0.  1.
  6.  3. 15. 11.  8.  3.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 23. 30.  8.  7.  9.  5.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -0.8867111206054688
desired expected reward: 89.49126434326172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[148.07417]
 [149.59999]
 [148.27075]
 [149.9474 ]
 [147.78036]
 [147.73462]
 [150.06906]
 [152.76631]
 [150.45837]
 [154.94868]
 [154.28781]
 [150.26059]
 [151.63243]
 [150.80574]
 [149.87125]
 [152.10544]
 [161.36053]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 1.] 
cards in discard: [15.  6.  0.  3.  0.  3.  0.  8.  3. 10.  0.  0.  0.  6. 11. 14.  0.  1.
  6.  3. 15. 11.  8.  3.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 6 
card supply: [17. 24. 30. 23. 30.  8.  7.  9.  5.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -4.759523868560791
desired expected reward: 158.8932647705078



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 23. 30.  8.  7.  9.  5.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [3. 1. 3. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 24. 30. 23. 30.  8.  7.  9.  5.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [3. 1. 3. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [3. 1. 3. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [3. 1. 3. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[40.281353]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 1. 6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 8.  0. 10.  0. 10.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0 11] -> size -> 39 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -7.211694240570068
desired expected reward: 154.14878845214844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[33.49013 ]
 [34.04146 ]
 [34.17092 ]
 [33.366367]
 [34.216557]
 [35.147144]
 [34.368874]
 [35.630962]
 [34.287704]
 [34.498333]
 [34.936512]
 [37.792713]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 1. 6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 8.  0. 10.  0. 10.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0 11] -> size -> 39 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -1.2621358633041382
desired expected reward: 39.01921844482422



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0. 10.] 
cards in discard: [11. 29.  0.  0.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [15.  0.  3.  3.  8.] 
adversary cards in discard: [3. 1. 3. 1. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  0. 10.] 
cards in discard: [11. 29.  0.  0.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [15.  0.  3.  3.  8.] 
adversary cards in discard: [3. 1. 3. 1. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  0. 10.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [15.  0.  3.  3.  8.] 
adversary cards in discard: [3. 1. 3. 1. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [15.  0.  3.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[152.32817]
 [146.32454]
 [145.33696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  3.  8.] 
cards in discard: [3. 1. 3. 1. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [14.  1.  0.  8.  0.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 40 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: 1.420770287513733
desired expected reward: 39.213478088378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[143.19725]
 [142.97972]
 [151.70493]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  3.  8.] 
cards in discard: [3. 1. 3. 1. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [14.  1.  0.  8.  0.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 40 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -4.341869831085205
desired expected reward: 147.98629760742188



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  1.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  0.  8.  0.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0  0 29  0 10  3  1 11 10 11  8  0 15 11  0  1  0  0
 14 10  3 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  3.  3. 14.  3.] 
adversary cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  3.  3. 14.  3.] 
adversary cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  3.  3. 14.  3.] 
adversary cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[102.01455]
 [ 92.08176]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 14.  3.] 
cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [29.  0.  0.  0. 16.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -5.416711807250977
desired expected reward: 146.28819274902344



action possibilites: [-1] 
expected returns: [[138.46193]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3.] 
cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [29.  0. 16.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action 14.0
Learning step: -0.5386943817138672
desired expected reward: 91.54305267333984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[129.59929]
 [131.02919]
 [131.35527]
 [129.28001]
 [133.79239]
 [131.85362]
 [132.18483]
 [140.41916]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3.] 
cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [29.  0. 16.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -2.937056303024292
desired expected reward: 135.52487182617188






Player: 1 
cards in hand: [29.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 16.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [14.  8.  0.  0. 10.] 
adversary cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8. 14.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 16.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [14.  8.  0.  0. 10.] 
adversary cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8. 14.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [14.  8.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10.] 
expected returns: [[99.76217 ]
 [91.96429 ]
 [92.131615]
 [92.43038 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  0.  0. 10.] 
cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8. 14.  0.  3.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 10. 11. 11. 11.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -4.914291858673096
desired expected reward: 135.50485229492188



action possibilites: [-1] 
expected returns: [[87.76337]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10.] 
cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8. 14.  0.  3.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 10. 11.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action 14.0
Learning step: -1.6735385656356812
desired expected reward: 90.2907485961914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[71.82484 ]
 [73.006516]
 [73.27718 ]
 [71.561806]
 [73.37242 ]
 [75.28659 ]
 [73.676155]
 [76.49789 ]
 [73.52406 ]
 [73.946815]
 [74.823685]
 [82.724686]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 10.] 
cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8. 14.  0.  3.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 10. 11.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -1.7046536207199097
desired expected reward: 86.0587158203125



buy possibilites: [-1] 
expected returns: [[85.48665]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 10.] 
cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8. 14.  0.  3.  3.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  5.] 
adversary cards in hand: [ 3. 10. 11.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 51 

action type: buy - action 15.0
Learning step: 0.8208656311035156
desired expected reward: 73.87254333496094






Player: 1 
cards in hand: [ 3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  5.] 
adversary cards in hand: [ 1.  0. 15.  0.  0.] 
adversary cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8. 14.  0.  3.  3.  3. 15. 14.  8.
  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15 15] -> size -> 32 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  5.] 
adversary cards in hand: [ 1.  0. 15.  0.  0.] 
adversary cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8. 14.  0.  3.  3.  3. 15. 14.  8.
  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15 15] -> size -> 32 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[68.23247]
 [64.04532]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15.  0.  0.] 
cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8. 14.  0.  3.  3.  3. 15. 14.  8.
  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8
  0  1 15  6  3 11 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  5.] 
adversary cards in hand: [1. 1. 3. 8. 0.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -2.821474075317383
desired expected reward: 82.66517639160156



action possibilites: [-1] 
expected returns: [[112.921165]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8. 14.  0.  3.  3.  3. 15. 14.  8.
  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  5.] 
adversary cards in hand: [1. 1. 3. 8. 0.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action 15.0
Learning step: 0.2884601652622223
desired expected reward: 64.33377838134766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[101.10916 ]
 [102.527245]
 [101.28807 ]
 [102.8452  ]
 [100.8336  ]
 [100.79096 ]
 [102.95853 ]
 [105.20152 ]
 [103.32645 ]
 [106.871994]
 [106.36475 ]
 [103.137146]
 [104.3264  ]
 [103.644394]
 [102.76927 ]
 [104.6943  ]
 [111.61252 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8. 14.  0.  3.  3.  3. 15. 14.  8.
  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 7 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  8.  7. 10.  4. 10.  5.] 
adversary cards in hand: [1. 1. 3. 8. 0.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -2.3058502674102783
desired expected reward: 110.61531829833984



buy possibilites: [-1] 
expected returns: [[126.484695]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8. 14.  0.  3.  3.  3. 15. 14.  8.
  0.  0. 10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  7.  7. 10.  4. 10.  5.] 
adversary cards in hand: [1. 1. 3. 8. 0.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 27.0 

action type: buy - action 29.0
Learning step: -1.1223324537277222
desired expected reward: 105.24242401123047






Player: 1 
cards in hand: [1. 1. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3. 8. 0.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.  3. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  7.  7. 10.  4. 10.  5.] 
adversary cards in hand: [11.  0.  0.  6. 11.] 
adversary cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8. 14.  0.  3.  3.  3. 15. 14.  8.
  0.  0. 10. 29. 15.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29] -> size -> 32 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 8. 0.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.  3. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  7.  7. 10.  4. 10.  5.] 
adversary cards in hand: [11.  0.  0.  6. 11.] 
adversary cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8. 14.  0.  3.  3.  3. 15. 14.  8.
  0.  0. 10. 29. 15.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29] -> size -> 32 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 8. 0.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.  3. 10. 11. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  7.  7. 10.  3. 10.  5.] 
adversary cards in hand: [11.  0.  0.  6. 11.] 
adversary cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8. 14.  0.  3.  3.  3. 15. 14.  8.
  0.  0. 10. 29. 15.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29] -> size -> 32 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[70.27223]
 [65.89701]
 [65.89701]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  6. 11.] 
cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8. 14.  0.  3.  3.  3. 15. 14.  8.
  0.  0. 10. 29. 15.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  7.  7. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 10.  3. 10.  0.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.  3. 10. 11. 10.  1.  1.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -4.8382110595703125
desired expected reward: 121.646484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[59.927814]
 [60.812336]
 [59.760963]
 [61.05391 ]
 [66.528   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  6. 11.] 
cards in discard: [ 3.  1.  3.  1.  6. 15.  0.  3.  3.  8. 14.  0.  3.  3.  3. 15. 14.  8.
  0.  0. 10. 29. 15.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  7.  7. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 10.  3. 10.  0.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.  3. 10. 11. 10.  1.  1.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10] -> size -> 38 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -2.1426751613616943
desired expected reward: 68.12955474853516



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 10.  0.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.  3. 10. 11. 10.  1.  1.  3.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  7.  7. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 11.  1.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29] -> size -> 32 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0. 15.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.  3. 10. 11. 10.  1.  1.  3.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  7.  7. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 11.  1.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29] -> size -> 32 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0. 15.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.  3. 10. 11. 10.  1.  1.  3.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  7.  7. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 11.  1.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29] -> size -> 32 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0. 15.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  8.  0. 10.  0. 10.  8.  0.  0.  0. 29.  0.
 16. 11. 11.  3. 10. 11. 10.  1.  1.  3.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  7.  7. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 11.  1.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29] -> size -> 32 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  1.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[60.09251 ]
 [56.190704]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  1.  3.  6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 23. 30.  8.  7.  9.  4.  4.  9.  7.  7. 10.  3. 10.  5.] 
adversary cards in hand: [11.  0. 11.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10  0] -> size -> 39 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -2.0544850826263428
desired expected reward: 64.47352600097656



action possibilites: [-1] 
expected returns: [[86.05769]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 6.] 
cards in discard: [8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 23. 30.  8.  7.  9.  4.  3.  9.  7.  7. 10.  3. 10.  5.] 
adversary cards in hand: [11.  0. 11.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10  0] -> size -> 39 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 23 

action type: gain_card_n - action 6
Learning step: 0.40437719225883484
desired expected reward: 54.04279327392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[77.79813 ]
 [79.13572 ]
 [79.442   ]
 [77.499954]
 [81.69095 ]
 [79.89721 ]
 [80.20449 ]
 [89.10262 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 6.] 
cards in discard: [8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 24. 30. 23. 30.  8.  7.  9.  4.  3.  9.  7.  7. 10.  3. 10.  5.] 
adversary cards in hand: [11.  0. 11.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10  0] -> size -> 39 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -1.4796046018600464
desired expected reward: 84.57808685302734



buy possibilites: [-1] 
expected returns: [[131.10945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 6.] 
cards in discard: [8. 8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 24. 30. 23. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  5.] 
adversary cards in hand: [11.  0. 11.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10  0] -> size -> 39 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 21.0 

action type: buy - action 8.0
Learning step: 0.0051021575927734375
desired expected reward: 79.90231323242188






Player: 1 
cards in hand: [11.  0. 11.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  3. 15.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 23. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  5.] 
adversary cards in hand: [29. 14.  1. 15.  6.] 
adversary cards in discard: [ 8.  8. 11.  0.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8  8] -> size -> 34 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  3. 15.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 24. 30. 23. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  5.] 
adversary cards in hand: [29. 14.  1. 15.  6.] 
adversary cards in discard: [ 8.  8. 11.  0.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8  8] -> size -> 34 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [29. 14.  1. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 15.] 
expected returns: [[73.133995]
 [69.60989 ]
 [67.99103 ]
 [68.685486]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 14.  1. 15.  6.] 
cards in discard: [ 8.  8. 11.  0.  1.  3.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 23. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  5.] 
adversary cards in hand: [ 8.  0.  0.  0. 15.] 
adversary cards in discard: [11.  0. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10  0] -> size -> 39 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -5.010658264160156
desired expected reward: 126.09879302978516



action possibilites: [-1. 14. 15.] 
expected returns: [[100.37806 ]
 [ 95.058876]
 [ 96.01631 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1. 15.  6.  0.] 
cards in discard: [ 8.  8. 11.  0.  1.  3.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 24. 30. 23. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  5.] 
adversary cards in hand: [ 8.  0.  0.  0. 15.] 
adversary cards in discard: [11.  0. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10  0] -> size -> 39 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 20 

action type: take_action - action 29.0
Learning step: -0.27188608050346375
desired expected reward: 69.3380126953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 95.85021 ]
 [ 96.68991 ]
 [ 96.87715 ]
 [ 95.661285]
 [ 96.94601 ]
 [ 98.3109  ]
 [ 97.16441 ]
 [ 99.03913 ]
 [ 97.05176 ]
 [ 97.35347 ]
 [ 97.999405]
 [102.31052 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1. 15.  6.  0.] 
cards in discard: [ 8.  8. 11.  0.  1.  3.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 24. 30. 23. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  5.] 
adversary cards in hand: [ 8.  0.  0.  0. 15.] 
adversary cards in discard: [11.  0. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10  0] -> size -> 39 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -1.8396834135055542
desired expected reward: 98.53836822509766



buy possibilites: [-1] 
expected returns: [[57.88568]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1. 15.  6.  0.] 
cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8  8 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 23. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [ 8.  0.  0.  0. 15.] 
adversary cards in discard: [11.  0. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10  0] -> size -> 39 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 51 

action type: buy - action 15.0
Learning step: -1.0705711841583252
desired expected reward: 96.92882537841797






Player: 1 
cards in hand: [ 8.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 15.] 
cards in discard: [11.  0. 11.  3. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 15 11  0  1  0  0 10  3
 15 29 10 10  0  8  3 16  1  8  0 11  0 10  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 23. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8  8 15] -> size -> 35 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0. 11.  3. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 11  0  1  0  0 10  3 15
 29 10 10  0  8  3 16  1  8  0 11  0 10  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 23. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8  8 15] -> size -> 35 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0. 11.  3. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 11  0  1  0  0 10  3 15
 29 10 10  0  8  3 16  1  8  0 11  0 10  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 24. 30. 23. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8  8 15] -> size -> 35 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0. 11.  3. 15.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 11  0  1  0  0 10  3 15
 29 10 10  0  8  3 16  1  8  0 11  0 10  0  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 23. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8  8 15] -> size -> 35 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.586021]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8  8 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 23. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [29. 11. 16.  0.  0.] 
adversary cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 11  0  1  0  0 10  3 15
 29 10 10  0  8  3 16  1  8  0 11  0 10  0  1] -> size -> 39 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -2.301098585128784
desired expected reward: 55.5845832824707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.516912]
 [22.417671]
 [21.37621 ]
 [22.738228]
 [29.280876]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8  8 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 23. 30. 23. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [29. 11. 16.  0.  0.] 
adversary cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 11  0  1  0  0 10  3 15
 29 10 10  0  8  3 16  1  8  0 11  0 10  0  1] -> size -> 39 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -0.910395085811615
desired expected reward: 27.675626754760742



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29. 11. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 16.  0.  0.] 
cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 11 10 11  8  0 11  0  1  0  0 10  3 15
 29 10 10  0  8  3 16  1  8  0 11  0 10  0  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 23. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [6. 8. 1. 0. 0.] 
adversary cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8  8 15] -> size -> 35 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.] 
cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 22. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [6. 8. 1. 0. 0.] 
adversary cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8  8 15] -> size -> 35 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.] 
cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 23. 30. 22. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [6. 8. 1. 0. 0.] 
adversary cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8  8 15] -> size -> 35 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [6. 8. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[41.485954]
 [37.10305 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 1. 0. 0.] 
cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 14  6  1  3  0 14  6 10  1  8  0 11  3  8  0
  1 15  6  3 11 15 15 29  8  8 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 22. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [ 8. 10.  0. 10. 11.] 
adversary cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3] -> size -> 39 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -1.1144945621490479
desired expected reward: 28.166362762451172



action possibilites: [-1] 
expected returns: [[75.79173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 22. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [ 8. 10.  0. 10. 11.] 
adversary cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3] -> size -> 39 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: trash_cards_n_from_hand - action 10
Learning step: 0.9057052731513977
desired expected reward: 36.89787673950195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[64.115685]
 [63.851624]
 [73.46849 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 23. 30. 22. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [ 8. 10.  0. 10. 11.] 
adversary cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3] -> size -> 39 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action -1
Learning step: -1.2343193292617798
desired expected reward: 74.55741119384766



buy possibilites: [-1] 
expected returns: [[51.581573]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 22. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [ 8. 10.  0. 10. 11.] 
adversary cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3] -> size -> 39 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[ -5   0   5   0   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action 0.0
Learning step: -2.545198917388916
desired expected reward: 61.57048416137695






Player: 1 
cards in hand: [ 8. 10.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 10. 11.] 
cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 22. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [14. 10.  3.  8.  3.] 
adversary cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0] -> size -> 32 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1.  8. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 11.  0.] 
cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 22. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [14. 10.  3.  8.  3.] 
adversary cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0] -> size -> 32 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10. 11.  0.] 
cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 23. 30. 22. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [14. 10.  3.  8.  3.] 
adversary cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0] -> size -> 32 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [14. 10.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.  8.] 
expected returns: [[32.952362]
 [31.8973  ]
 [31.961014]
 [31.925835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  3.  8.  3.] 
cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 22. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3] -> size -> 39 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1
Learning step: -1.849529504776001
desired expected reward: 49.7320442199707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.404163]
 [30.361286]
 [31.71083 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  3.  8.  3.] 
cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 23. 30. 22. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3] -> size -> 39 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: -0.9478151202201843
desired expected reward: 32.004547119140625



buy possibilites: [-1] 
expected returns: [[41.6512]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  3.  8.  3.] 
cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.  0.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 22. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3] -> size -> 39 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[ -5   0   5   0   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: buy - action 0.0
Learning step: -2.0830562114715576
desired expected reward: 28.321107864379883






Player: 1 
cards in hand: [10.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 22. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [ 0. 15. 11.  3. 15.] 
adversary cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.  0.  8.  0. 14. 10.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0] -> size -> 33 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 22. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [ 0. 15. 11.  3. 15.] 
adversary cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.  0.  8.  0. 14. 10.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0] -> size -> 33 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 23. 30. 22. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [ 0. 15. 11.  3. 15.] 
adversary cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.  0.  8.  0. 14. 10.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0] -> size -> 33 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 23. 30. 21. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [ 0. 15. 11.  3. 15.] 
adversary cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.  0.  8.  0. 14. 10.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0] -> size -> 33 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 0. 15. 11.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 15.] 
expected returns: [[4.559869 ]
 [3.8184328]
 [3.8740392]
 [3.8184328]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11.  3. 15.] 
cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.  0.  8.  0. 14. 10.  3.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 21. 30.  8.  7.  9.  4.  2.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [10.  1.  8.  0.  1.] 
adversary cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.  3. 10.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3] -> size -> 40 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1
Learning step: -2.488346576690674
desired expected reward: 39.1628532409668



action possibilites: [-1] 
expected returns: [[22.337177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3. 15.] 
cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.  0.  8.  0. 14. 10.  3.  8.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 21. 30.  8.  7.  9.  4.  1.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [10.  1.  8.  0.  1.] 
adversary cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.  3. 10.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3] -> size -> 40 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: 14 

action type: gain_card_n - action 6
Learning step: 1.0330421924591064
desired expected reward: 4.423929214477539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.663422]
 [16.497837]
 [22.07422 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3. 15.] 
cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.  0.  8.  0. 14. 10.  3.  8.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 23. 30. 21. 30.  8.  7.  9.  4.  1.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [10.  1.  8.  0.  1.] 
adversary cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.  3. 10.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3] -> size -> 40 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 10 

action type: take_action - action -1
Learning step: -0.17681923508644104
desired expected reward: 22.160358428955078



buy possibilites: [-1] 
expected returns: [[64.40535]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3. 15.] 
cards in discard: [ 8.  8. 11.  0.  1.  3.  6. 15. 29. 14.  1. 15.  6.  0.  0.  3.  0.  3.
  3.  0.  8.  0. 14. 10.  3.  8.  3.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 23. 30. 21. 30.  8.  6.  9.  4.  1.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [10.  1.  8.  0.  1.] 
adversary cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.  3. 10.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3] -> size -> 40 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -301.0 

action type: buy - action 6.0
Learning step: -14.42577075958252
desired expected reward: 2.072068214416504






Player: 1 
cards in hand: [10.  1.  8.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  8.  0.  1.] 
cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.  3. 10.  0. 10.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 21. 30.  8.  6.  9.  4.  1.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [ 3. 29. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6] -> size -> 35 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 1. 3.] 
cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.  3. 10.  0. 10.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 21. 30.  8.  6.  9.  4.  1.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [ 3. 29. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6] -> size -> 35 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 1. 3.] 
cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.  3. 10.  0. 10.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 23. 30. 21. 30.  8.  6.  9.  4.  1.  9.  7.  7. 10.  3. 10.  4.] 
adversary cards in hand: [ 3. 29. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6] -> size -> 35 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 1. 3.] 
cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.  3. 10.  0. 10.  0.  0.  3. 23.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 21. 30.  8.  6.  9.  4.  1.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [ 3. 29. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6] -> size -> 35 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
expected returns: [[64.44219]
 [61.07231]
 [59.40679]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 21. 30.  8.  6.  9.  4.  1.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.  3. 10.  0. 10.  0.  0.  3. 23. 10.  1.  8.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23] -> size -> 41 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -2.863640546798706
desired expected reward: 61.541709899902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[58.687035]
 [59.742985]
 [58.493103]
 [60.046806]
 [65.21201 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 23. 30. 21. 30.  8.  6.  9.  4.  1.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.  3. 10.  0. 10.  0.  0.  3. 23. 10.  1.  8.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23] -> size -> 41 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -2.9366042613983154
desired expected reward: 62.66401290893555



buy possibilites: [-1] 
expected returns: [[64.13792]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 14.  0.  0.] 
cards in discard: [3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 20. 30.  8.  6.  9.  4.  1.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.  3. 10.  0. 10.  0.  0.  3. 23. 10.  1.  8.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23] -> size -> 41 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0  -1   0   0   8   0] 
sum of rewards: -3 

action type: buy - action 3.0
Learning step: -1.6940460205078125
desired expected reward: 58.0489387512207






Player: 1 
cards in hand: [29.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  3.] 
cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.  3. 10.  0. 10.  0.  0.  3. 23. 10.  1.  8.  0.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 20. 30.  8.  6.  9.  4.  1.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [1. 0. 3. 0. 8.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3] -> size -> 36 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  3.] 
cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.  3. 10.  0. 10.  0.  0.  3. 23. 10.  1.  8.  0.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 23. 30. 20. 30.  8.  6.  9.  4.  1.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [1. 0. 3. 0. 8.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3] -> size -> 36 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  3.] 
cards in discard: [11.  0. 11.  3. 15.  1.  8.  0.  0.  0.  3. 16. 29.  0.  0. 10.  8.  0.
 10. 11.  0.  3. 10.  0. 10.  0.  0.  3. 23. 10.  1.  8.  0.  1.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 23. 30. 20. 30.  8.  6.  9.  4.  0.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [1. 0. 3. 0. 8.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3] -> size -> 36 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [1. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[49.51806 ]
 [43.583973]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 8.] 
cards in discard: [ 3.  3. 29. 14.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 20. 30.  8.  6.  9.  4.  0.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [10.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8] -> size -> 42 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1
Learning step: -2.638617753982544
desired expected reward: 61.499298095703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[42.5568  ]
 [43.574306]
 [43.80713 ]
 [42.329678]
 [43.885525]
 [45.510498]
 [46.34032 ]
 [44.023956]
 [44.391518]
 [45.142937]
 [50.09276 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 8.] 
cards in discard: [ 3.  3. 29. 14.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 23. 30. 20. 30.  8.  6.  9.  4.  0.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [10.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8] -> size -> 42 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1.0
Learning step: -1.9322643280029297
desired expected reward: 47.585784912109375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 20. 30.  8.  6.  9.  4.  0.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [ 6. 15.  3.  6. 14.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3] -> size -> 36 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 20. 30.  8.  6.  9.  4.  0.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [ 6. 15.  3.  6. 14.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3] -> size -> 36 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 23. 30. 20. 30.  8.  6.  9.  4.  0.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [ 6. 15.  3.  6. 14.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3] -> size -> 36 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10.  0.] 
cards in discard: [3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 30.  8.  6.  9.  4.  0.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [ 6. 15.  3.  6. 14.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3] -> size -> 36 
adversary victory points: 5
player victory points: 7 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 6. 15.  3.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
expected returns: [[57.364586]
 [51.60439 ]
 [50.312073]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  3.  6. 14.] 
cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 30.  8.  6.  9.  4.  0.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [ 3. 16.  1. 11.  1.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3] -> size -> 43 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action -1.0
Learning step: -2.2799739837646484
desired expected reward: 47.812782287597656



action possibilites: [-1] 
expected returns: [[54.95954]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  6. 14.] 
cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 30.  8.  6.  9.  4.  0.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [ 3. 16.  1. 11.  1.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3] -> size -> 43 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action 15.0
Learning step: -1.3436294794082642
desired expected reward: 50.2607536315918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[42.863777]
 [42.542946]
 [53.70275 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  6. 14.] 
cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 23. 30. 19. 30.  8.  6.  9.  4.  0.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [ 3. 16.  1. 11.  1.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3] -> size -> 43 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action -1
Learning step: -1.6530516147613525
desired expected reward: 53.306488037109375



buy possibilites: [-1] 
expected returns: [[78.49623]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  6. 14.] 
cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 30.  8.  5.  9.  4.  0.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [ 3. 16.  1. 11.  1.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3] -> size -> 43 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[  -5    0    4  -30    0    0   20    0    0    0    0   -2    0 -300
    0    0] 
sum of rewards: -313 

action type: buy - action 6.0
Learning step: -16.010982513427734
desired expected reward: 26.531959533691406






Player: 1 
cards in hand: [ 3. 16.  1. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  1. 11.  1.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 30.  8.  5.  9.  4.  0.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [8. 3. 1. 0. 6.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3  6] -> size -> 37 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  1.  1.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 30.  8.  4.  9.  4.  0.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [8. 3. 1. 0. 6.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3  6] -> size -> 37 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  1.  1.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 23. 30. 19. 30.  8.  4.  9.  4.  0.  9.  7.  7.  9.  3. 10.  4.] 
adversary cards in hand: [8. 3. 1. 0. 6.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3  6] -> size -> 37 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  1.  1.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 30.  8.  4.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [8. 3. 1. 0. 6.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.] 
adversary owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3  6] -> size -> 37 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [8. 3. 1. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[26.31295 ]
 [19.339066]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 1. 0. 6.] 
cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 14  3  0 14  6 10  1  8  0 11  3  8  0  1 15  6  3
 11 15 15 29  8  8 15  0  0  8  6  3  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 30.  8.  4.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 0. 15. 10.  0.  3.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15] -> size -> 45 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -4.436687469482422
desired expected reward: 74.05953979492188



action possibilites: [-1] 
expected returns: [[74.63699]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29
  8  8 15  0  0  8  6  3  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 30.  8.  4.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 0. 15. 10.  0.  3.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15] -> size -> 45 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: trash_cards_n_from_hand - action 14
Learning step: 0.6244063377380371
desired expected reward: 20.72292709350586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[63.773537]
 [63.490776]
 [73.1828  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29
  8  8 15  0  0  8  6  3  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 23. 30. 19. 30.  8.  4.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 0. 15. 10.  0.  3.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15] -> size -> 45 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action -1
Learning step: -2.2336888313293457
desired expected reward: 72.40330505371094



buy possibilites: [-1] 
expected returns: [[62.666252]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29
  8  8 15  0  0  8  6  3  6  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 30.  8.  3.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 0. 15. 10.  0.  3.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15] -> size -> 45 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5    0    3  -30    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -312 

action type: buy - action 6.0
Learning step: -17.36454963684082
desired expected reward: 46.12623596191406






Player: 1 
cards in hand: [ 0. 15. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10.  0.  3.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 30.  8.  3.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 0.  3.  8. 11.  3.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.] 
adversary owned cards: [ 0  0  3  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29
  8  8 15  0  0  8  6  3  6  6] -> size -> 34 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10.  0.  3.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 23. 30. 19. 30.  8.  3.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 0.  3.  8. 11.  3.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.] 
adversary owned cards: [ 0  0  3  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29
  8  8 15  0  0  8  6  3  6  6] -> size -> 34 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  8. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[40.731762]
 [34.86325 ]
 [36.061493]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 11.  3.] 
cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29
  8  8 15  0  0  8  6  3  6  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 30.  8.  3.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 1.  0. 23. 11.  8.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15] -> size -> 45 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -3.871166944503784
desired expected reward: 58.79508590698242



action possibilites: [-1] 
expected returns: [[88.96359]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.] 
cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 30.  8.  3.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 1.  0. 23. 11.  8.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15] -> size -> 45 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.7385208010673523
desired expected reward: 32.88447189331055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[80.95042 ]
 [80.72384 ]
 [88.372894]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.] 
cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 23. 30. 19. 30.  8.  3.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 1.  0. 23. 11.  8.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15] -> size -> 45 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1
Learning step: -3.687471389770508
desired expected reward: 85.276123046875






Player: 1 
cards in hand: [ 1.  0. 23. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 23. 11.  8.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 30.  8.  3.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 8.  0. 15. 10. 15.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.  8.  0. 11.  3.] 
adversary owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6] -> size -> 33 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 23.  8.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 19. 30.  8.  3.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 8.  0. 15. 10. 15.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.  8.  0. 11.  3.] 
adversary owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6] -> size -> 33 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 23.  8.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 23. 30. 19. 30.  8.  3.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 8.  0. 15. 10. 15.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.  8.  0. 11.  3.] 
adversary owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6] -> size -> 33 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 23.  8.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 23. 30. 19. 30.  8.  3.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 8.  0. 15. 10. 15.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.  8.  0. 11.  3.] 
adversary owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6] -> size -> 33 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 15. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10. 15.] 
expected returns: [[15.246672]
 [11.625033]
 [12.173119]
 [11.752519]
 [12.173119]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15. 10. 15.] 
cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.  8.  0. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 19. 30.  8.  3.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0] -> size -> 47 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -6.266610622406006
desired expected reward: 82.10628509521484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.703725]
 [10.584732]
 [15.567645]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15. 10. 15.] 
cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.  8.  0. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 23. 30. 19. 30.  8.  3.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0] -> size -> 47 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -2.61281418800354
desired expected reward: 12.633854866027832



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 19. 30.  8.  3.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 8. 15.  3. 11.  0.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.  8.  0. 11.  3.  8.  0. 15. 10. 15.] 
adversary owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6] -> size -> 33 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0] -> size -> 47 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 19. 30.  8.  3.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 8. 15.  3. 11.  0.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.  8.  0. 11.  3.  8.  0. 15. 10. 15.] 
adversary owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6] -> size -> 33 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 23. 30. 19. 30.  8.  3.  9.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 8. 15.  3. 11.  0.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.  8.  0. 11.  3.  8.  0. 15. 10. 15.] 
adversary owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6] -> size -> 33 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 19. 30.  8.  3.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 8. 15.  3. 11.  0.] 
adversary cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.  8.  0. 11.  3.  8.  0. 15. 10. 15.] 
adversary owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6] -> size -> 33 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 8. 15.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 11.] 
expected returns: [[41.80294 ]
 [35.82465 ]
 [36.81392 ]
 [37.184814]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  3. 11.  0.] 
cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.  8.  0. 11.  3.  8.  0. 15. 10. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 19. 30.  8.  3.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16] -> size -> 48 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -2.0480642318725586
desired expected reward: 13.519582748413086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[34.69712 ]
 [34.468853]
 [42.290737]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  3. 11.  0.] 
cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.  8.  0. 11.  3.  8.  0. 15. 10. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 23. 30. 19. 30.  8.  3.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16] -> size -> 48 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -3.3680596351623535
desired expected reward: 38.43486785888672



buy possibilites: [-1] 
expected returns: [[-0.72223055]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  3. 11.  0.] 
cards in discard: [ 3.  3. 29. 14.  0.  0.  1.  0.  3.  0.  8.  6. 15.  6.  3.  6. 14.  6.
  8.  8.  0. 11.  3.  8.  0. 15. 10. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 23. 30. 19. 30.  8.  3.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16] -> size -> 48 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -73.0 

action type: buy - action 0.0
Learning step: -5.4011054039001465
desired expected reward: 29.296003341674805






Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29
 10 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 23. 30. 19. 30.  8.  3.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [15.  0.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6  0] -> size -> 34 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29 10
 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 23. 30. 19. 30.  8.  3.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [15.  0.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6  0] -> size -> 34 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29 10
 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 23. 30. 19. 30.  8.  3.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [15.  0.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6  0] -> size -> 34 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29 10
 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 23. 30. 19. 30.  8.  3.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [15.  0.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6  0] -> size -> 34 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [15.  0.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 29.] 
expected returns: [[33.93511 ]
 [30.39716 ]
 [29.720854]
 [31.224237]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8. 29.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 19. 30.  8.  3.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 0.  8. 10. 29.  3.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.  0.  8.  0.
  0.  0.] 
adversary owned cards: [ 0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29 10
 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0] -> size -> 48 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1
Learning step: -1.3907952308654785
desired expected reward: -2.113025665283203



action possibilites: [-1.  8.  8.] 
expected returns: [[27.783697]
 [24.829687]
 [24.829687]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8.] 
cards in discard: [15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3 14  3  0 14 10  8  0 11  3  8  0  1 15  6  3 11 15 15 29  8
  8 15  0  0  8  6  3  6  6  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 23. 30. 19. 30.  8.  3.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 0.  8. 10. 29.  3.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.  0.  8.  0.
  0.  0.] 
adversary owned cards: [ 0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29 10
 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0] -> size -> 48 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: discard_n_cards - action 2
Learning step: -1.9904632568359375
desired expected reward: 26.71244239807129



action possibilites: [-1] 
expected returns: [[3.5846033]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 23. 30. 19. 30.  8.  3.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 0.  8. 10. 29.  3.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.  0.  8.  0.
  0.  0.] 
adversary owned cards: [ 0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29 10
 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0] -> size -> 48 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: trash_cards_n_from_hand - action 4
Learning step: -1.2074534893035889
desired expected reward: 21.5546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[5.4117446]
 [5.4555707]
 [4.684673 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 23. 30. 19. 30.  8.  3.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 0.  8. 10. 29.  3.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.  0.  8.  0.
  0.  0.] 
adversary owned cards: [ 0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29 10
 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0] -> size -> 48 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -0.2106790840625763
desired expected reward: 3.3739242553710938



buy possibilites: [-1] 
expected returns: [[39.514526]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 0.  8. 10. 29.  3.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.  0.  8.  0.
  0.  0.] 
adversary owned cards: [ 0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29 10
 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0] -> size -> 48 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -50.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -314.0 

action type: buy - action 6.0
Learning step: -15.083702087402344
desired expected reward: -9.628133773803711






Player: 1 
cards in hand: [ 0.  8. 10. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 29.  3.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.  0.  8.  0.
  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29 10
 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [15. 11. 11.  3.  6.] 
adversary cards in discard: [15.  6. 29.  8.] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6] -> size -> 32 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 29.  3.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.  0.  8.  0.
  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29 10
 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [15. 11. 11.  3.  6.] 
adversary cards in discard: [15.  6. 29.  8.] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6] -> size -> 32 
adversary victory points: 1
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [15. 11. 11.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 11.] 
expected returns: [[-1.0981646]
 [-1.0981646]
 [-1.0981646]
 [-1.0981646]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 11.  3.  6.] 
cards in discard: [15.  6. 29.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 8.  3.  0. 29. 11.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.  0.  8.  0.
  0.  0.  0.  8. 10. 29.  3.] 
adversary owned cards: [ 0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29 10
 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0] -> size -> 48 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -4.700435161590576
desired expected reward: 34.814090728759766



action possibilites: [-1] 
expected returns: [[-1.0988503]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  3.  6.] 
cards in discard: [15.  6. 29.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 8.  3.  0. 29. 11.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.  0.  8.  0.
  0.  0.  0.  8. 10. 29.  3.] 
adversary owned cards: [ 0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29 10
 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0] -> size -> 48 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: gain_card_n - action 0
Learning step: -3.1698005199432373
desired expected reward: -4.267965316772461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.1870527 ]
 [-0.14957616]
 [-1.0988503 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  3.  6.] 
cards in discard: [15.  6. 29.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 8.  3.  0. 29. 11.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.  0.  8.  0.
  0.  0.  0.  8. 10. 29.  3.] 
adversary owned cards: [ 0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29 10
 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0] -> size -> 48 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1
Learning step: -1.6535090208053589
desired expected reward: -2.752359390258789



buy possibilites: [-1] 
expected returns: [[43.376446]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  3.  6.] 
cards in discard: [15.  6. 29.  8.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 8.  3.  0. 29. 11.] 
adversary cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.  0.  8.  0.
  0.  0.  0.  8. 10. 29.  3.] 
adversary owned cards: [ 0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29 10
 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0] -> size -> 48 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action 0.0
Learning step: -2.214677095413208
desired expected reward: -2.401735544204712






Player: 1 
cards in hand: [ 8.  3.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 29. 11.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.  0.  8.  0.
  0.  0.  0.  8. 10. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0  0 29  0 10  3 10 11  8  0 11  0  1  0  0 10  3 15 29 10
 10  0  8  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 3.  0.  8. 14.  6.] 
adversary cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6.] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.  0.  8.  0.
  0.  0.  0.  8. 10. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8
  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 3.  0.  8. 14.  6.] 
adversary cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6.] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.  0.  8.  0.
  0.  0.  0.  8. 10. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8
  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 3.  0.  8. 14.  6.] 
adversary cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6.] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3. 10.  3.  3.  0. 10.  0.  6. 15. 11.  3. 16.  1.  1.  0. 15. 10.  0.
  3.  0.  0. 11.  1.  0. 23.  8. 16. 10.  0.  0.  0.  0. 10.  0.  8.  0.
  0.  0.  0.  8. 10. 29.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8
  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [ 3.  0.  8. 14.  6.] 
adversary cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6.] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  8. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[29.08417 ]
 [25.105917]
 [25.019203]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 14.  6.] 
cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [16.  0.  8.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8
  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0] -> size -> 46 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -4.255885124206543
desired expected reward: 39.12055969238281



action possibilites: [-1] 
expected returns: [[71.388565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 6.] 
cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [0. 3. 8.] 
adversary cards in discard: [16.  8.] 
adversary owned cards: [ 0  3  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8
  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0] -> size -> 46 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action 14.0
Learning step: -1.3447173833847046
desired expected reward: 23.674484252929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[63.39551 ]
 [64.02382 ]
 [64.16263 ]
 [63.25392 ]
 [65.20565 ]
 [64.51676 ]
 [68.002144]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 6.] 
cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  3. 10.  3.] 
adversary cards in hand: [0. 3. 8.] 
adversary cards in discard: [16.  8.] 
adversary owned cards: [ 0  3  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8
  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0] -> size -> 46 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1
Learning step: -3.7911899089813232
desired expected reward: 67.59737396240234



buy possibilites: [-1] 
expected returns: [[26.581472]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 6.] 
cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  2. 10.  3.] 
adversary cards in hand: [0. 3. 8.] 
adversary cards in discard: [16.  8.] 
adversary owned cards: [ 0  3  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8
  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0] -> size -> 46 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -16 

action type: buy - action 10.0
Learning step: -3.427755117416382
desired expected reward: 61.08900833129883






Player: 1 
cards in hand: [0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8.] 
cards in discard: [16.  8.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8
  3 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  2. 10.  3.] 
adversary cards in hand: [14.  0.  6.  0.  3.] 
adversary cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6.] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10] -> size -> 35 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [16.  8.] 
cards in deck: 41 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3
 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  2. 10.  3.] 
adversary cards in hand: [14.  0.  6.  0.  3.] 
adversary cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6.] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10] -> size -> 35 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [16.  8.] 
cards in deck: 41 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3
 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  2. 10.  3.] 
adversary cards in hand: [14.  0.  6.  0.  3.] 
adversary cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6.] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10] -> size -> 35 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [14.  0.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[15.085247]
 [14.437705]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  6.  0.  3.] 
cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  2. 10.  3.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [16.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3
 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0] -> size -> 45 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -3.194662094116211
desired expected reward: 23.386810302734375



action possibilites: [-1] 
expected returns: [[34.197075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  2. 10.  3.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3
 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0] -> size -> 45 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action 14.0
Learning step: -1.1524509191513062
desired expected reward: 13.285250663757324





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[24.267906]
 [24.771263]
 [24.953512]
 [24.160587]
 [25.012856]
 [26.26752 ]
 [26.901894]
 [25.12408 ]
 [25.408285]
 [25.983309]
 [29.900618]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  7.  9.  2. 10.  3.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3
 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0] -> size -> 45 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -2.301969528198242
desired expected reward: 31.895105361938477



buy possibilites: [-1] 
expected returns: [[13.950503]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  6.  9.  2. 10.  3.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3
 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0] -> size -> 45 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0  -1   0   0  32   0] 
sum of rewards: 7 

action type: buy - action 14.0
Learning step: -0.5923174023628235
desired expected reward: 24.531757354736328






Player: 1 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [16.  8.  8.  0.  3. 10.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3
 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  6.  9.  2. 10.  3.] 
adversary cards in hand: [ 0.  3.  1.  0. 15.] 
adversary cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6. 14.
 14.  0.  6.  0.  3.] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14] -> size -> 36 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [16.  8.  8.  0.  3. 10.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3
 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  6.  9.  2. 10.  3.] 
adversary cards in hand: [ 0.  3.  1.  0. 15.] 
adversary cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6. 14.
 14.  0.  6.  0.  3.] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14] -> size -> 36 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3
 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  6.  9.  2. 10.  3.] 
adversary cards in hand: [ 0.  3.  1.  0. 15.] 
adversary cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6. 14.
 14.  0.  6.  0.  3.] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14] -> size -> 36 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  1.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[13.056788]
 [ 9.978372]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1.  0. 15.] 
cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6. 14.
 14.  0.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  6.  9.  2. 10.  3.] 
adversary cards in hand: [ 0.  0. 15.  1.  6.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3
 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0] -> size -> 46 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -2.6275477409362793
desired expected reward: 11.322956085205078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[7.705697 ]
 [7.873435 ]
 [7.9057226]
 [7.666114 ]
 [7.9178715]
 [8.1764555]
 [8.311607 ]
 [7.934952 ]
 [7.9942045]
 [8.117204 ]
 [9.717821 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  0. 15.] 
cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6. 14.
 14.  0.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  6.  9.  2. 10.  3.] 
adversary cards in hand: [ 0.  0. 15.  1.  6.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3
 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0] -> size -> 46 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -2.6588940620422363
desired expected reward: 10.397903442382812



buy possibilites: [-1] 
expected returns: [[14.812463]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  0. 15.] 
cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6. 14.
 14.  0.  6.  0.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [ 0.  0. 15.  1.  6.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3
 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0] -> size -> 46 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0  -2   0   0  32   0] 
sum of rewards: -14 

action type: buy - action 15.0
Learning step: -0.7725798487663269
desired expected reward: 7.344624042510986






Player: 1 
cards in hand: [ 0.  0. 15.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  1.  6.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3
 16  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [ 0. 10.  3. 15.  6.] 
adversary cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6. 14.
 14.  0.  6.  0.  3. 15.  0.  3.  1.  0. 15.] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14 15] -> size -> 37 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16
  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [ 0. 10.  3. 15.  6.] 
adversary cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6. 14.
 14.  0.  6.  0.  3. 15.  0.  3.  1.  0. 15.] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14 15] -> size -> 37 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16
  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 5. 23. 30. 19. 30.  8.  2.  8.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [ 0. 10.  3. 15.  6.] 
adversary cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6. 14.
 14.  0.  6.  0.  3. 15.  0.  3.  1.  0. 15.] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14 15] -> size -> 37 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16.] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16
  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 23. 30. 19. 30.  8.  2.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [ 0. 10.  3. 15.  6.] 
adversary cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6. 14.
 14.  0.  6.  0.  3. 15.  0.  3.  1.  0. 15.] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14 15] -> size -> 37 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[-1.0988503]
 [-1.0988503]
 [-1.0988503]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 15.  6.] 
cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6. 14.
 14.  0.  6.  0.  3. 15.  0.  3.  1.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 19. 30.  8.  2.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [11.  0.  3.  3. 10.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16
  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16] -> size -> 46 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -2.9653472900390625
desired expected reward: 11.847115516662598



action possibilites: [-1. 15.] 
expected returns: [[-1.0988503]
 [-1.0988503]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  6.  3.] 
cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6. 14.
 14.  0.  6.  0.  3. 15.  0.  3.  1.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14 15] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 19. 30.  8.  2.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [11.  0.  3.  3. 10.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16
  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16] -> size -> 46 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action 10.0
Learning step: -1.1697815656661987
desired expected reward: -2.268631935119629





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-1.0988503]
 [-1.0988503]
 [-1.0982282]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  6.  3.] 
cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6. 14.
 14.  0.  6.  0.  3. 15.  0.  3.  1.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 23. 30. 19. 30.  8.  2.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [11.  0.  3.  3. 10.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16
  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16] -> size -> 46 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -1.169774055480957
desired expected reward: -2.2686243057250977



buy possibilites: [-1] 
expected returns: [[5.6136937]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  6.  3.] 
cards in discard: [15.  6. 29.  8.  0.  0. 11. 15. 11.  3.  6. 10. 14.  3.  0.  8.  6. 14.
 14.  0.  6.  0.  3. 15.  0.  3.  1.  0. 15.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14 15  6] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 23. 30. 19. 30.  8.  1.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [11.  0.  3.  3. 10.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16
  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16] -> size -> 46 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -50.    0.    0.   20.    0.    0.    0.    0.   -3.
    0. -300.    0.    0.] 
sum of rewards: -338.0 

action type: buy - action 6.0
Learning step: -16.718652725219727
desired expected reward: -17.819459915161133






Player: 1 
cards in hand: [11.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  3. 10.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16
  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 19. 30.  8.  1.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [15.  1. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14 15  6] -> size -> 38 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16
  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 19. 30.  8.  1.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [15.  1. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14 15  6] -> size -> 38 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16
  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 23. 30. 19. 30.  8.  1.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [15.  1. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14 15  6] -> size -> 38 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [15.  1. 10.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.  8.] 
expected returns: [[40.05404 ]
 [36.388916]
 [35.832954]
 [35.6597  ]
 [35.6597  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 10.  8.  8.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  3  0 14 10  0 11  3  8  0  1 15  6  3 11 15 15 29  8  8 15  0
  0  8  6  3  6  6  0  6  0  0 10 14 15  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 19. 30.  8.  1.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [10.  3. 16. 23.  0.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16
  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0] -> size -> 47 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -2.1810364723205566
desired expected reward: 3.432657241821289



action possibilites: [-1] 
expected returns: [[4.9730945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 19. 30.  8.  1.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [10.  3. 16. 23.  0.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16
  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0] -> size -> 47 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: trash_cards_n_from_hand - action 8
Learning step: -3.387009382247925
desired expected reward: 31.59107208251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[1.9415593]
 [2.312342 ]
 [1.876396 ]
 [6.1039295]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 23. 30. 19. 30.  8.  1.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [10.  3. 16. 23.  0.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16
  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0] -> size -> 47 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -1.9084059000015259
desired expected reward: 3.0646886825561523



buy possibilites: [-1] 
expected returns: [[16.125553]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [10.  3. 16. 23.  0.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16
  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0] -> size -> 47 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -60.    0.    0.   20.    0.    0.    0.    0.   -2.
    0. -300.    0.    0.] 
sum of rewards: -348.0 

action type: buy - action 6.0
Learning step: -17.13099479675293
desired expected reward: -15.254602432250977






Player: 1 
cards in hand: [10.  3. 16. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 23.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 16. 23.  0.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16
  1  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [14.  3.  6.  0.  0.] 
adversary cards in discard: [6. 8. 1. 8.] 
adversary owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6] -> size -> 37 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 23.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16  1
  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [14.  3.  6.  0.  0.] 
adversary cards in discard: [6. 8. 1. 8.] 
adversary owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6] -> size -> 37 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 23.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16  1
  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [14.  3.  6.  0.  0.] 
adversary cards in discard: [6. 8. 1. 8.] 
adversary owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6] -> size -> 37 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [14.  3.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[0.42887902]
 [0.5830483 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  6.  0.  0.] 
cards in discard: [6. 8. 1. 8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [ 0.  8. 10.  0. 15.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.] 
adversary owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16  1
  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0] -> size -> 47 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -4.094351291656494
desired expected reward: 12.03120231628418



action possibilites: [-1] 
expected returns: [[14.163533]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [6. 8. 1. 8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [ 8.  0. 15.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.] 
adversary owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16  1
  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0] -> size -> 47 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action 14.0
Learning step: -2.0104730129241943
desired expected reward: -1.4274239540100098





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[13.437008]
 [13.354873]
 [13.328125]
 [13.320373]
 [13.176628]
 [13.107477]
 [13.302704]
 [13.270366]
 [13.208964]
 [13.25081 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [6. 8. 1. 8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  2.] 
adversary cards in hand: [ 8.  0. 15.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.] 
adversary owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16  1
  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0] -> size -> 47 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -2.7083375453948975
desired expected reward: 11.455195426940918



buy possibilites: [-1] 
expected returns: [[13.76079]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [ 6.  8.  1.  8. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [ 8.  0. 15.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.] 
adversary owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16  1
  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0] -> size -> 47 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0  -3   0   0  32   0] 
sum of rewards: -17 

action type: buy - action 15.0
Learning step: -1.2008304595947266
desired expected reward: 12.008134841918945






Player: 1 
cards in hand: [ 8.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 15 29 10 10  0  8  3 16  1
  8  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [ 8.  3.  6. 29.  3.] 
adversary cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.] 
adversary owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15] -> size -> 38 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [ 8.  3.  6. 29.  3.] 
adversary cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.] 
adversary owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15] -> size -> 38 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [ 8.  3.  6. 29.  3.] 
adversary cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.] 
adversary owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15] -> size -> 38 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [ 8.  3.  6. 29.  3.] 
adversary cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.] 
adversary owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15] -> size -> 38 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 8.  3.  6. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[14.75153 ]
 [11.832848]
 [12.831116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  6. 29.  3.] 
cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [ 8.  1.  0.  1. 29.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0  0] -> size -> 47 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -3.6810719966888428
desired expected reward: 10.079717636108398





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[10.482599]
 [14.11834 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  6. 29.  3.] 
cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15] -> size -> 38 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 2. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [ 8.  1.  0.  1. 29.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0  0] -> size -> 47 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -3.7480227947235107
desired expected reward: 11.003503799438477



buy possibilites: [-1] 
expected returns: [[31.012642]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  6. 29.  3.] 
cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [ 8.  1.  0.  1. 29.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0  0] -> size -> 47 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0 -30   0   0   0  -4   0   0   0   0] 
sum of rewards: -100 

action type: buy - action 0.0
Learning step: -4.826345443725586
desired expected reward: 5.656249046325684






Player: 1 
cards in hand: [ 8.  1.  0.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  0.  1. 29.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.  0.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [ 6. 14.  3. 11.  6.] 
adversary cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.  0.  8.  3.  6. 29.  3.] 
adversary owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15  0] -> size -> 39 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.  0.  8.  0.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [ 6. 14.  3. 11.  6.] 
adversary cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.  0.  8.  3.  6. 29.  3.] 
adversary owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15  0] -> size -> 39 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.  0.  8.  0.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [ 6. 14.  3. 11.  6.] 
adversary cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.  0.  8.  3.  6. 29.  3.] 
adversary owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15  0] -> size -> 39 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [ 6. 14.  3. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[29.14738 ]
 [25.46936 ]
 [26.354319]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  3. 11.  6.] 
cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.  0.  8.  3.  6. 29.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.  0.  8.  0.  1.  0. 29.  8.  1.
  0.] 
adversary owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0  0] -> size -> 47 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -4.2281694412231445
desired expected reward: 26.784473419189453



action possibilites: [-1] 
expected returns: [[27.694592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11.  6.] 
cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.  0.  8.  3.  6. 29.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.  0.  8.  0.  1.  0. 29.  8.  1.
  0.  0. 10.] 
adversary owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0  0] -> size -> 47 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action 14.0
Learning step: -2.9503395557403564
desired expected reward: 22.51901626586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[28.914297]
 [29.057884]
 [30.167566]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 11.  6.] 
cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.  0.  8.  3.  6. 29.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.  0.  8.  0.  1.  0. 29.  8.  1.
  0.  0. 10.] 
adversary owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0  0] -> size -> 47 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -3.0181386470794678
desired expected reward: 24.67645263671875






Player: 1 
cards in hand: [10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.  0.  8.  0.  1.  0. 29.  8.  1.
  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [14.  3.  6. 15.  0.] 
adversary cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.  0.  8.  3.  6. 29.  3. 14.  6.
  3. 11.  6.] 
adversary owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15  0] -> size -> 39 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.  0.  8.  0.  1.  0. 29.  8.  1.
  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0  0] -> size -> 47 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [14.  3.  6. 15.  0.] 
adversary cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.  0.  8.  3.  6. 29.  3. 14.  6.
  3. 11.  6.] 
adversary owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15  0] -> size -> 39 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.  0.  8.  0.  1.  0. 29.  8.  1.
  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 23. 30. 19. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [14.  3.  6. 15.  0.] 
adversary cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.  0.  8.  3.  6. 29.  3. 14.  6.
  3. 11.  6.] 
adversary owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15  0] -> size -> 39 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [16.  8.  8.  0.  3. 10.  0.  0.  0.  3. 16. 15.  0.  1.  6.  0. 11.  0.
  3.  3. 10.  0. 16. 10.  3. 23.  0. 10.  0.  8.  0.  1.  0. 29.  8.  1.
  0.  0. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0  0  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 18. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [14.  3.  6. 15.  0.] 
adversary cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.  0.  8.  3.  6. 29.  3. 14.  6.
  3. 11.  6.] 
adversary owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15  0] -> size -> 39 
adversary victory points: -1
player victory points: 6 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [14.  3.  6. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
expected returns: [[54.964222]
 [52.714214]
 [53.127327]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  6. 15.  0.] 
cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.  0.  8.  3.  6. 29.  3. 14.  6.
  3. 11.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 18. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0  0  3] -> size -> 48 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1.0
Learning step: -3.807952880859375
desired expected reward: 20.663711547851562





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[52.467587]
 [55.29548 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  6. 15.  0.] 
cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.  0.  8.  3.  6. 29.  3. 14.  6.
  3. 11.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 23. 30. 18. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0  0  3] -> size -> 48 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -5.325926303863525
desired expected reward: 49.6382942199707



Player 1 won the game! 



Player 0 bought cards:
Copper: 9 
Silver: 3 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 0 
Workshop: 2 
Chapel: 3 
Witch: 0 
Poacher: 1 
Militia: 3 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 5 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [14.  3.  6. 15.  0.] 
cards in discard: [ 6.  8.  1.  8. 15. 14.  3.  6.  0.  0.  0.  8.  3.  6. 29.  3. 14.  6.
  3. 11.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  3  0 14  0 11  3  8  0  1  6  3 11 15 15 29  8  8 15  0  0  8
  6  3  6  6  0  6  0  0 10 14 15  6  6 15  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 18. 30.  8.  0.  7.  4.  0.  9.  7.  6.  9.  2. 10.  1.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  3 10  8  0 11  0  1  0  0 10  3 29 10 10  0  8  3 16  1  8
  0 11  0 10  0  1  3  3 23  8  3  6 15  0  0 16  0  0  0 16  0  0  0  3] -> size -> 48 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[  -5 -500   -1  -70    0    0    0  -30    0    0    0   -5    0    0
    0    0] 
sum of rewards: -611 

action type: buy - action 0.0
Learning step: -33.17338180541992
desired expected reward: 19.294200897216797



