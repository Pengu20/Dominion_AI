 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.348625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0   20    0    0    0    0  -21    0    0
    9    0] 
sum of rewards: -497 

action type: gain_card_n - action 4
Learning step: -15.50546932220459
desired expected reward: 4.343518257141113





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.619928]
 [21.491169]
 [21.03036 ]
 [19.469505]
 [22.733477]
 [22.323044]
 [21.862236]
 [22.539253]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6038321852684021
desired expected reward: 22.137666702270508



buy possibilites: [-1] 
expected returns: [[22.588694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -0.5225100517272949
desired expected reward: 21.800533294677734






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.33649]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5695911049842834
desired expected reward: 22.019102096557617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.192093]
 [24.063334]
 [23.602526]
 [22.041672]
 [23.60925 ]
 [25.305641]
 [24.895206]
 [25.486298]
 [23.7371  ]
 [24.434402]
 [24.608337]
 [25.111416]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6307595372200012
desired expected reward: 23.947301864624023



buy possibilites: [-1] 
expected returns: [[24.977869]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 3. 0. 0. 0. 3. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 6] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.548981666564941
desired expected reward: 12.492688179016113






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 6] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 6] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1. 0. 0. 0. 0. 3. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 6] -> size -> 12 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.845362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6353954076766968
desired expected reward: 24.34247398376465





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.269753]
 [24.140993]
 [23.680185]
 [22.119333]
 [23.686909]
 [25.383303]
 [24.972868]
 [25.56396 ]
 [23.814758]
 [24.512064]
 [24.685997]
 [25.189077]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.646718442440033
desired expected reward: 24.49048614501953



buy possibilites: [-1] 
expected returns: [[27.605173]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.3329355716705322
desired expected reward: 25.896894454956055






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 8. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 8. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 0. 8. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29] -> size -> 13 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[28.158941]
 [27.942736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6818309426307678
desired expected reward: 26.923341751098633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.405602]
 [26.816034]
 [25.255182]
 [28.108715]
 [28.324924]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.713103175163269
desired expected reward: 27.59473419189453



buy possibilites: [-1] 
expected returns: [[28.620619]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.4139646291732788
desired expected reward: 26.40207290649414






Player: 1 
cards in hand: [0. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [10.  0.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [10.  0.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3] -> size -> 14 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[25.104483]
 [24.888275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  1. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7433788776397705
desired expected reward: 27.877239227294922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.413244]
 [24.284481]
 [23.823675]
 [22.262823]
 [25.526793]
 [25.116356]
 [24.655552]
 [25.332565]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  1. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6526795625686646
desired expected reward: 24.69472312927246



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  1. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 10.  8.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 8. 0. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.10554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0. 8. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  3.  1.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6553159356117249
desired expected reward: 24.6772518157959





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.485254]
 [23.356493]
 [22.895689]
 [21.334835]
 [24.598806]
 [24.18837 ]
 [23.727566]
 [24.404577]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0. 8. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  3.  1.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6296044588088989
desired expected reward: 23.62383460998535



buy possibilites: [-1] 
expected returns: [[26.08872]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0. 8. 0. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  3.  1.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.5363667011260986
desired expected reward: 21.948888778686523






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  3.  1.  8.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  3.  1.  8.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  3.  1.  8.  0.  3.  4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0] -> size -> 15 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[21.707935]
 [22.092049]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7003166079521179
desired expected reward: 25.388402938842773



action possibilites: [-1.] 
expected returns: [[26.705399]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.06195453554391861
desired expected reward: 22.343692779541016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.250717]
 [26.09347 ]
 [25.643284]
 [24.136452]
 [25.651035]
 [27.293486]
 [26.90092 ]
 [27.464125]
 [25.770866]
 [26.450733]
 [26.61362 ]
 [27.080011]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.07344325631856918
desired expected reward: 26.631956100463867



buy possibilites: [-1] 
expected returns: [[26.990173]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 1.0
Learning step: 0.08559270948171616
desired expected reward: 26.179061889648438






Player: 1 
cards in hand: [0. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 29.  0.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1] -> size -> 16 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 29.  0.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1] -> size -> 16 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 29.  0.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1] -> size -> 16 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.774828]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1. 29.  0.  0.  3.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [4. 0. 3. 0. 0.] 
adversary cards in discard: [15.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4 15] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7089866399765015
desired expected reward: 26.281187057495117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.184477]
 [23.027225]
 [22.577044]
 [21.07021 ]
 [22.584795]
 [24.227247]
 [23.83468 ]
 [24.397882]
 [22.704626]
 [23.384493]
 [23.54738 ]
 [24.01377 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1. 29.  0.  0.  3.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [4. 0. 3. 0. 0.] 
adversary cards in discard: [15.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4 15] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6208152770996094
desired expected reward: 23.257137298583984



buy possibilites: [-1] 
expected returns: [[23.556284]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1. 29.  0.  0.  3.  6.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [4. 0. 3. 0. 0.] 
adversary cards in discard: [15.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4 15] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 1.0
Learning step: -0.45847588777542114
desired expected reward: 22.568754196166992






Player: 1 
cards in hand: [4. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 3. 0. 0.] 
cards in discard: [15.  0.  1.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 3. 0. 0.] 
cards in discard: [15.  0.  1.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 3. 0. 0.] 
cards in discard: [15.  0.  1.  0.  0.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4 15  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[24.065935]
 [23.886847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 10.] 
adversary cards in discard: [15.  0.  1.  0.  0.  3.  1.  4.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4 15  1] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6030920743942261
desired expected reward: 22.95319175720215





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[22.706852]
 [23.09942 ]
 [21.592587]
 [24.357056]
 [24.536146]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 10.] 
adversary cards in discard: [15.  0.  1.  0.  0.  3.  1.  4.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4 15  1] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6298136711120605
desired expected reward: 23.593860626220703



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 10.] 
cards in discard: [15.  0.  1.  0.  0.  3.  1.  4.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4 15  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 1. 0. 0. 6.] 
adversary cards in discard: [0. 0. 3. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  0  4 15  1] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 1. 0. 0. 6.] 
adversary cards in discard: [0. 0. 3. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 10  0  4 15  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 1. 0. 0. 6.] 
adversary cards in discard: [0. 0. 3. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 10  0  4 15  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 1. 0. 0. 6.] 
adversary cards in discard: [0. 0. 3. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [3. 1. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.483992]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 6.] 
cards in discard: [0. 0. 3. 8. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 3. 0. 3. 0.] 
adversary cards in discard: [10.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 10  0  4 15  1] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6275960803031921
desired expected reward: 23.908552169799805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.330313]
 [24.173069]
 [23.722881]
 [22.21605 ]
 [23.730633]
 [25.373083]
 [24.980516]
 [25.543722]
 [23.850464]
 [24.530333]
 [24.693218]
 [25.15961 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 6.] 
cards in discard: [0. 0. 3. 8. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 3. 0. 3. 0.] 
adversary cards in discard: [10.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 10  0  4 15  1] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6309834718704224
desired expected reward: 23.98695182800293



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [1. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 3. 0.] 
cards in discard: [10.  8.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 10  0  4 15  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  1.  0. 29.] 
adversary cards in discard: [0. 0. 3. 8. 3. 3. 1. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 0.] 
cards in discard: [10.  8.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 10  0  4 15  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  1.  0. 29.] 
adversary cards in discard: [0. 0. 3. 8. 3. 3. 1. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 0.] 
cards in discard: [10.  8.  3.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 10  0  4 15  1  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  1.  0. 29.] 
adversary cards in discard: [0. 0. 3. 8. 3. 3. 1. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[24.349533]
 [24.733646]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1.  0. 29.] 
cards in discard: [0. 0. 3. 8. 3. 3. 1. 0. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  4.  0. 15.  0.] 
adversary cards in discard: [10.  8.  3.  0.  1.  1.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 10  0  4 15  1  1] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.645369827747345
desired expected reward: 24.514238357543945



action possibilites: [-1.] 
expected returns: [[27.367662]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [0. 0. 3. 8. 3. 3. 1. 0. 0. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  4.  0. 15.  0.] 
adversary cards in discard: [10.  8.  3.  0.  1.  1.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 10  0  4 15  1  1] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.008444423787295818
desired expected reward: 24.85171890258789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[26.034172]
 [26.876925]
 [25.583984]
 [26.426739]
 [25.354307]
 [24.919907]
 [26.434488]
 [28.076944]
 [27.684374]
 [28.927446]
 [28.247581]
 [26.554323]
 [26.147192]
 [27.23419 ]
 [25.304438]
 [27.397078]
 [27.863466]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [0. 0. 3. 8. 3. 3. 1. 0. 0. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 25. 30. 29. 29.  8.  9. 10. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  4.  0. 15.  0.] 
adversary cards in discard: [10.  8.  3.  0.  1.  1.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 10  0  4 15  1  1] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.08542533963918686
desired expected reward: 27.282238006591797



buy possibilites: [-1] 
expected returns: [[35.124516]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [ 0.  0.  3.  8.  3.  3.  1.  0.  0.  6. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 29. 29.  8.  9. 10. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  4.  0. 15.  0.] 
adversary cards in discard: [10.  8.  3.  0.  1.  1.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 10  0  4 15  1  1] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 27.5 

action type: buy - action 25.0
Learning step: 0.3259839713573456
desired expected reward: 29.253429412841797






Player: 1 
cards in hand: [ 0.  4.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4.  0. 15.  0.] 
cards in discard: [10.  8.  3.  0.  1.  1.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 10  0  4 15  1  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  9. 10. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25] -> size -> 18 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0.] 
cards in discard: [10.  8.  3.  0.  1.  1.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 10  0  4 15  1  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 25. 30. 29. 29.  8.  9. 10. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25] -> size -> 18 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0.] 
cards in discard: [10.  8.  3.  0.  1.  1.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 10  0  4 15  1  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 25. 30. 29. 29.  8.  9. 10. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25] -> size -> 18 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0.] 
cards in discard: [10.  8.  3.  0.  1.  1.  3.  0.  3.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 10  0  4 15  1  1 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 29. 29.  8.  9. 10. 10.  8.  9.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 25.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25] -> size -> 18 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[27.7296  ]
 [28.793583]
 [27.550508]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  8.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  9. 10. 10.  8.  9.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 4. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 10  0  4 15  1  1 15] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.9062063694000244
desired expected reward: 34.21830749511719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.95375 ]
 [26.791805]
 [26.340998]
 [24.845192]
 [27.982227]
 [27.594978]
 [27.144173]
 [27.750814]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25.  8.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 30. 29. 29.  8.  9. 10. 10.  8.  9.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 4. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 10  0  4 15  1  1 15] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6973996162414551
desired expected reward: 27.012149810791016



buy possibilites: [-1] 
expected returns: [[30.830387]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25.  8.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  9. 10. 10.  8.  9.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 0. 4. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 10  0  4 15  1  1 15] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: -0.10060621052980423
desired expected reward: 27.043567657470703






Player: 1 
cards in hand: [3. 0. 0. 4. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 4. 1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 10  0  4 15  1  1 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  9. 10. 10.  8.  9.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [10.  0.  0. 25.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10] -> size -> 19 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 4. 1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 10  0  4 15  1  1 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 25. 30. 29. 29.  8.  9. 10. 10.  8.  9.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [10.  0.  0. 25.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10] -> size -> 19 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 4. 1.] 
cards in discard: [16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 10  0  4 15  1  1 15 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  9.  9. 10.  8.  9.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [10.  0.  0. 25.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10] -> size -> 19 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[29.449837]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [10.  0.  0. 25.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  9.  9. 10.  8.  9.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 1. 15.  0. 10.  0.] 
adversary cards in discard: [16.  3.  0.  0.  4.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 10  0  4 15  1  1 15 16] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7645005583763123
desired expected reward: 30.065887451171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[28.06712 ]
 [28.905172]
 [28.454369]
 [27.388582]
 [26.958559]
 [28.463297]
 [30.095592]
 [29.708345]
 [30.942574]
 [30.264034]
 [28.579002]
 [28.172005]
 [29.257542]
 [27.333956]
 [29.417055]
 [29.864182]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [10.  0.  0. 25.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 25. 30. 29. 29.  8.  9.  9. 10.  8.  9.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 1. 15.  0. 10.  0.] 
adversary cards in discard: [16.  3.  0.  0.  4.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 10  0  4 15  1  1 15 16] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7294266819953918
desired expected reward: 28.833526611328125



buy possibilites: [-1] 
expected returns: [[26.537653]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [10.  0.  0. 25.  8.  0. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  9.  9. 10.  8.  8.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 1. 15.  0. 10.  0.] 
adversary cards in discard: [16.  3.  0.  0.  4.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 10  0  4 15  1  1 15 16] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 45 

action type: buy - action 25.0
Learning step: 0.7003680467605591
desired expected reward: 31.6429443359375






Player: 1 
cards in hand: [ 1. 15.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0. 10.  0.] 
cards in discard: [16.  3.  0.  0.  4.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 10  0  4 15  1  1 15 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  9.  9. 10.  8.  8.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [1. 3. 6. 0. 3.] 
adversary cards in discard: [10.  0.  0. 25.  8.  0. 25.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.] 
cards in discard: [16.  3.  0.  0.  4.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1  8 10  0  4 15  1  1 15 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 25. 30. 29. 29.  8.  9.  9. 10.  8.  8.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [1. 3. 6. 0. 3.] 
adversary cards in discard: [10.  0.  0. 25.  8.  0. 25.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.] 
cards in discard: [16.  3.  0.  0.  4.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1  8 10  0  4 15  1  1 15 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 25. 30. 29. 29.  8.  9.  9. 10.  8.  8.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [1. 3. 6. 0. 3.] 
adversary cards in discard: [10.  0.  0. 25.  8.  0. 25.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.] 
cards in discard: [16.  3.  0.  0.  4.  1.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1  8 10  0  4 15  1  1 15 16  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 25. 30. 29. 29.  8.  9.  9. 10.  7.  8.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [1. 3. 6. 0. 3.] 
adversary cards in discard: [10.  0.  0. 25.  8.  0. 25.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [1. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.393948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 6. 0. 3.] 
cards in discard: [10.  0.  0. 25.  8.  0. 25.  0.  0.  0.  1.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  9.  9. 10.  7.  8.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  1.  0.  3. 15.] 
adversary cards in discard: [16.  3.  0.  0.  4.  1.  8. 15.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  8 10  0  4 15  1  1 15 16  8] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6156255006790161
desired expected reward: 25.922027587890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.805286]
 [30.643335]
 [30.192532]
 [28.703674]
 [31.833757]
 [31.446514]
 [30.995707]
 [31.602343]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 0. 3.] 
cards in discard: [10.  0.  0. 25.  8.  0. 25.  0.  0.  0.  1.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 30. 29. 29.  8.  9.  9. 10.  7.  8.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  1.  0.  3. 15.] 
adversary cards in discard: [16.  3.  0.  0.  4.  1.  8. 15.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  8 10  0  4 15  1  1 15 16  8] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7699620127677917
desired expected reward: 30.70661163330078



buy possibilites: [-1] 
expected returns: [[29.14984]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 0. 3.] 
cards in discard: [10.  0.  0. 25.  8.  0. 25.  0.  0.  0.  1.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 25. 30. 29. 29.  8.  8.  9. 10.  7.  8.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  1.  0.  3. 15.] 
adversary cards in discard: [16.  3.  0.  0.  4.  1.  8. 15.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  8 10  0  4 15  1  1 15 16  8] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.705036163330078
desired expected reward: 18.998638153076172






Player: 1 
cards in hand: [ 3.  1.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  3. 15.] 
cards in discard: [16.  3.  0.  0.  4.  1.  8. 15.  1. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  8 10  0  4 15  1  1 15 16  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  8.  9. 10.  7.  8.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6] -> size -> 21 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3.] 
cards in discard: [16.  3.  0.  0.  4.  1.  8. 15.  1. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3  1  8 10  0  4 15  1  1 15 16  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 25. 30. 29. 29.  8.  8.  9. 10.  7.  8.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6] -> size -> 21 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3.] 
cards in discard: [16.  3.  0.  0.  4.  1.  8. 15.  1. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3  1  8 10  0  4 15  1  1 15 16  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 25. 30. 29. 29.  8.  8.  9. 10.  7.  8.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6] -> size -> 21 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3.] 
cards in discard: [16.  3.  0.  0.  4.  1.  8. 15.  1. 10.  0. 23.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3  1  8 10  0  4 15  1  1 15 16  8 23] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  8.  9. 10.  7.  8.  9. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6] -> size -> 21 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[30.432684]
 [30.832539]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  8.  9. 10.  7.  8.  9. 10.  9.  8. 10.  8.] 
adversary cards in hand: [16.  3.  4.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  1  8 10  0  4 15  1  1 15 16  8 23] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7012530565261841
desired expected reward: 28.448585510253906



action possibilites: [-1.] 
expected returns: [[36.607357]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 29. 29.  8.  8.  9. 10.  7.  8.  9. 10.  9.  8. 10.  8.] 
adversary cards in hand: [16.  3.  4.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  1  8 10  0  4 15  1  1 15 16  8 23] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.09397000819444656
desired expected reward: 30.85093879699707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[35.189533]
 [36.027588]
 [35.576786]
 [34.080975]
 [35.585712]
 [37.218002]
 [36.83076 ]
 [37.38645 ]
 [35.701416]
 [36.379955]
 [36.53947 ]
 [36.98659 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 25. 30. 29. 29.  8.  8.  9. 10.  7.  8.  9. 10.  9.  8. 10.  8.] 
adversary cards in hand: [16.  3.  4.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  1  8 10  0  4 15  1  1 15 16  8 23] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.2662568688392639
desired expected reward: 36.34109878540039



buy possibilites: [-1] 
expected returns: [[40.200153]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  8.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [16.  3.  4.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  1  8 10  0  4 15  1  1 15 16  8 23] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: 0.7105081677436829
desired expected reward: 38.096954345703125






Player: 1 
cards in hand: [16.  3.  4.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  4.  1.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  8 10  0  4 15  1  1 15 16  8 23] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  8.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  6.  0. 10.  0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29] -> size -> 22 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  8.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  6.  0. 10.  0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29] -> size -> 22 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  8.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  6.  0. 10.  0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29] -> size -> 22 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[30.460066]
 [29.853428]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 10.  0.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  8.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [15.  3.  3.  0.  1.] 
adversary cards in discard: [ 8. 16.  3.] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.0376464128494263
desired expected reward: 39.162506103515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.259113]
 [30.097164]
 [29.64636 ]
 [28.15055 ]
 [31.287584]
 [30.900337]
 [30.449532]
 [31.056173]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 10.  0.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 30. 29. 29.  8.  8.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [15.  3.  3.  0.  1.] 
adversary cards in discard: [ 8. 16.  3.] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7482814192771912
desired expected reward: 29.8142032623291



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15.  3.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.  0.  1.] 
cards in discard: [ 8. 16.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8.  8.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  0. 25.  1.  1.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.  0.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29] -> size -> 22 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  3.  0.  1.] 
cards in discard: [ 8. 16.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 30. 29. 29.  8.  8.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  0. 25.  1.  1.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.  0.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29] -> size -> 22 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  3.  0.  1.] 
cards in discard: [ 8. 16.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 28. 29.  8.  8.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  0. 25.  1.  1.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.  0.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29] -> size -> 22 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 25.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[34.537365]
 [35.615757]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 25.  1.  1.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0.  0.  6.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 29.  8.  8.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [10. 15.  0.  8. 23.] 
adversary cards in discard: [ 8. 16.  3.  3. 15.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7113454937934875
desired expected reward: 30.344825744628906



action possibilites: [-1] 
expected returns: [[29.71722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  1.  1. 25.  8.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0.  0.  6.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [10. 15.  0.  8. 23.] 
adversary cards in discard: [ 8. 16.  3.  3. 15.  3.  3.  0.  1.  6.] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.3028305768966675
desired expected reward: 35.39896774291992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[28.530424]
 [29.358894]
 [28.909101]
 [27.857323]
 [27.434372]
 [28.920715]
 [30.530832]
 [30.152159]
 [31.370913]
 [30.697811]
 [29.029263]
 [28.626286]
 [29.702368]
 [27.797813]
 [29.857733]
 [30.27994 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1.  1. 25.  8.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0.  0.  6.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 25. 30. 28. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [10. 15.  0.  8. 23.] 
adversary cards in discard: [ 8. 16.  3.  3. 15.  3.  3.  0.  1.  6.] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.12938329577445984
desired expected reward: 29.58783721923828



buy possibilites: [-1] 
expected returns: [[30.738007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1.  1. 25.  8.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0.  0.  6.  0. 10.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 25. 30. 27. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [10. 15.  0.  8. 23.] 
adversary cards in discard: [ 8. 16.  3.  3. 15.  3.  3.  0.  1.  6.] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: -0.03452401980757713
desired expected reward: 28.87457847595215






Player: 1 
cards in hand: [10. 15.  0.  8. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  8. 23.] 
cards in discard: [ 8. 16.  3.  3. 15.  3.  3.  0.  1.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 10. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  8.  0.] 
cards in discard: [ 8. 16.  3.  3. 15.  3.  3.  0.  1.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6] -> size -> 17 
action values: 1 
buys: 1 
player value: 1 
card supply: [28. 25. 30. 27. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0.  8.  0.] 
cards in discard: [ 8. 16.  3.  3. 15.  3.  3.  0.  1.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6] -> size -> 17 
action values: 0 
buys: 2 
player value: 3 
card supply: [28. 25. 30. 27. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0.  8.  0.] 
cards in discard: [ 8. 16.  3.  3. 15.  3.  3.  0.  1.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 25. 30. 26. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3] -> size -> 23 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[34.306274]
 [34.17849 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 16.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7116379737854004
desired expected reward: 30.026369094848633



action possibilites: [-1] 
expected returns: [[35.003723]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 16.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 8
Learning step: -0.2061367630958557
desired expected reward: 33.91638946533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.43759 ]
 [32.341537]
 [35.187103]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 25. 30. 26. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 16.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.2435133308172226
desired expected reward: 34.76020812988281






Player: 1 
cards in hand: [ 0.  3.  0. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 16.  1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [25.  0.  6. 29.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3] -> size -> 20 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 16.  1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 25. 30. 26. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  8.] 
adversary cards in hand: [25.  0.  6. 29.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3] -> size -> 20 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 16.  1.] 
cards in discard: [15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  7.] 
adversary cards in hand: [25.  0.  6. 29.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3] -> size -> 20 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [25.  0.  6. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[29.162931]
 [30.253902]
 [29.5808  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  6. 29.  0.] 
cards in discard: [8. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  6. 10. 23. 15.] 
adversary cards in discard: [15.  0.  3.  0. 16.  1.] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.8920634984970093
desired expected reward: 34.295040130615234



action possibilites: [-1. 25.] 
expected returns: [[32.376457]
 [33.46743 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  6.  0.  1.] 
cards in discard: [8. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 26. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  6. 10. 23. 15.] 
adversary cards in discard: [15.  0.  3.  0. 16.  1.] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.09294953942298889
desired expected reward: 29.566234588623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[30.775633]
 [31.604097]
 [31.154306]
 [30.10253 ]
 [29.679575]
 [31.165915]
 [32.77604 ]
 [32.39736 ]
 [33.616116]
 [32.943012]
 [31.274466]
 [30.87149 ]
 [31.947569]
 [30.043022]
 [32.102936]
 [32.525146]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  6.  0.  1.] 
cards in discard: [8. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 25. 30. 26. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  6. 10. 23. 15.] 
adversary cards in discard: [15.  0.  3.  0. 16.  1.] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.18558579683303833
desired expected reward: 32.19087219238281



buy possibilites: [-1] 
expected returns: [[39.410656]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  6.  0.  1.] 
cards in discard: [8. 3. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 25. 30. 25. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  6. 10. 23. 15.] 
adversary cards in discard: [15.  0.  3.  0. 16.  1.] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: -0.01081735547631979
desired expected reward: 31.143491744995117






Player: 1 
cards in hand: [ 8.  6. 10. 23. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 23. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 10. 23. 15.] 
cards in discard: [15.  0.  3.  0. 16.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 25. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  1. 29.  0.  0.] 
adversary cards in discard: [ 8.  3.  3. 29. 25.  0.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 10. 23. 15.] 
cards in discard: [15.  0.  3.  0. 16.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15] -> size -> 19 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 25. 30. 25. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  1. 29.  0.  0.] 
adversary cards in discard: [ 8.  3.  3. 29. 25.  0.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3] -> size -> 21 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 10. 23. 15.] 
cards in discard: [15.  0.  3.  0. 16.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  1. 29.  0.  0.] 
adversary cards in discard: [ 8.  3.  3. 29. 25.  0.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3] -> size -> 21 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[29.783009]
 [30.194311]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.  0.  0.] 
cards in discard: [ 8.  3.  3. 29. 25.  0.  6.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  7.] 
adversary cards in hand: [0. 3. 1. 8. 3.] 
adversary cards in discard: [15.  0.  3.  0. 16.  1.  0.  8.  6. 10. 23. 15.] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.0161515474319458
desired expected reward: 38.39450454711914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[28.528803]
 [29.3443  ]
 [28.90155 ]
 [27.866217]
 [27.449896]
 [28.912964]
 [30.497898]
 [30.125147]
 [31.324806]
 [30.662222]
 [29.019817]
 [28.62313 ]
 [29.6824  ]
 [27.807636]
 [29.835314]
 [30.250916]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29.  0.  0.] 
cards in discard: [ 8.  3.  3. 29. 25.  0.  6.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 25. 30. 25. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  8. 10.  7.] 
adversary cards in hand: [0. 3. 1. 8. 3.] 
adversary cards in discard: [15.  0.  3.  0. 16.  1.  0.  8.  6. 10. 23. 15.] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.734014630317688
desired expected reward: 29.130455017089844



buy possibilites: [-1] 
expected returns: [[27.74067]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29.  0.  0.] 
cards in discard: [ 8.  3.  3. 29. 25.  0.  6.  0.  1. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 25. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  7. 10.  7.] 
adversary cards in hand: [0. 3. 1. 8. 3.] 
adversary cards in discard: [15.  0.  3.  0. 16.  1.  0.  8.  6. 10. 23. 15.] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 10.0
Learning step: -0.614194929599762
desired expected reward: 29.068204879760742






Player: 1 
cards in hand: [0. 3. 1. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 8. 3.] 
cards in discard: [15.  0.  3.  0. 16.  1.  0.  8.  6. 10. 23. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 3. 10.  0.  6. 25.] 
adversary cards in discard: [ 8.  3.  3. 29. 25.  0.  6.  0.  1. 10.  0.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 8. 3.] 
cards in discard: [15.  0.  3.  0. 16.  1.  0.  8.  6. 10. 23. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 30. 25. 29.  8.  7.  9. 10.  7.  8.  8. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 3. 10.  0.  6. 25.] 
adversary cards in discard: [ 8.  3.  3. 29. 25.  0.  6.  0.  1. 10.  0.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10] -> size -> 22 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 8. 3.] 
cards in discard: [15.  0.  3.  0. 16.  1.  0.  8.  6. 10. 23. 15. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  7.  9.  9.  7.  8.  8. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 3. 10.  0.  6. 25.] 
adversary cards in discard: [ 8.  3.  3. 29. 25.  0.  6.  0.  1. 10.  0.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10] -> size -> 22 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[26.735287]
 [26.157711]
 [27.82626 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  6. 25.] 
cards in discard: [ 8.  3.  3. 29. 25.  0.  6.  0.  1. 10.  0.  1. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  7.  9.  9.  7.  8.  8. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  8. 15.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6977603435516357
desired expected reward: 27.042909622192383



action possibilites: [-1] 
expected returns: [[31.49032]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  6.  3.  3.] 
cards in discard: [ 8.  3.  3. 29. 25.  0.  6.  0.  1. 10.  0.  1. 29.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  6.  9.  9.  7.  8.  8. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  8. 15.  3.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.05416986346244812
desired expected reward: 27.773103713989258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.875391]
 [28.779335]
 [31.624905]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  6.  3.  3.] 
cards in discard: [ 8.  3.  3. 29. 25.  0.  6.  0.  1. 10.  0.  1. 29.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 25. 30. 25. 29.  8.  6.  9.  9.  7.  8.  8. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  8. 15.  3.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.1755143105983734
desired expected reward: 31.31480598449707






Player: 1 
cards in hand: [ 0.  8. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15.  3.  3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  6.  9.  9.  7.  8.  8. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 6.  0. 29.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 25. 30. 25. 29.  8.  6.  9.  9.  7.  8.  8. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 6.  0. 29.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 30. 25. 29.  8.  6.  9.  9.  7.  8.  8. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 6.  0. 29.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [6. 1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 25. 29.  8.  6.  9.  9.  7.  8.  8. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 6.  0. 29.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[32.72321 ]
 [33.158733]
 [32.16491 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 29.  0. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 25. 29.  8.  6.  9.  9.  7.  8.  8. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [ 6.  1. 15.  8.  3.  3.] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7478489279747009
desired expected reward: 30.688264846801758



action possibilites: [-1. 10.] 
expected returns: [[32.756115]
 [32.197815]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 24. 30. 25. 29.  8.  6.  9.  9.  7.  8.  8. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [ 6.  1. 15.  8.  3.  3.] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.20622459053993225
desired expected reward: 33.054405212402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[31.132658]
 [31.958916]
 [31.50753 ]
 [30.040163]
 [31.521193]
 [33.12273 ]
 [32.747864]
 [33.290302]
 [31.62413 ]
 [32.296474]
 [32.450386]
 [32.85478 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 24. 30. 25. 29.  8.  6.  9.  9.  7.  8.  8. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [ 6.  1. 15.  8.  3.  3.] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.19359087944030762
desired expected reward: 32.562522888183594



buy possibilites: [-1] 
expected returns: [[41.392155]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 10.  0.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 25. 29.  8.  6.  9.  9.  7.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [ 6.  1. 15.  8.  3.  3.] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: 0.8459085822105408
desired expected reward: 34.13621139526367






Player: 1 
cards in hand: [ 0. 10.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0.  0.] 
cards in discard: [ 6.  1. 15.  8.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 25. 29.  8.  6.  9.  9.  7.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  3.  3.  0. 25.] 
adversary cards in discard: [29. 29.  6.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 6.] 
cards in discard: [ 6.  1. 15.  8.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 25. 29.  8.  6.  9.  9.  7.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  3.  3.  0. 25.] 
adversary cards in discard: [29. 29.  6.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 6.] 
cards in discard: [ 6.  1. 15.  8.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 24. 30. 25. 29.  8.  6.  9.  9.  7.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  3.  3.  0. 25.] 
adversary cards in discard: [29. 29.  6.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 6.] 
cards in discard: [ 6.  1. 15.  8.  3.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 24. 30. 25. 29.  8.  6.  9.  9.  7.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  3.  3.  0. 25.] 
adversary cards in discard: [29. 29.  6.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[30.761305]
 [31.869175]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 25.] 
cards in discard: [29. 29.  6.  0.  0. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 25. 29.  8.  6.  9.  9.  7.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  1.  3.  3. 23.] 
adversary cards in discard: [ 6.  1. 15.  8.  3.  3.  0. 10.  0.  8.  0.  0.  6.] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.0611720085144043
desired expected reward: 40.33098220825195



action possibilites: [-1] 
expected returns: [[30.701456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 29. 10.] 
cards in discard: [29. 29.  6.  0.  0. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 25. 29.  8.  5.  9.  9.  7.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  1.  3.  3. 23.] 
adversary cards in discard: [ 6.  1. 15.  8.  3.  3.  0. 10.  0.  8.  0.  0.  6.  6.] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.18547925353050232
desired expected reward: 31.742671966552734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.194185]
 [28.101685]
 [30.916298]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  0. 29. 10.] 
cards in discard: [29. 29.  6.  0.  0. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 24. 30. 25. 29.  8.  5.  9.  9.  7.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  1.  3.  3. 23.] 
adversary cards in discard: [ 6.  1. 15.  8.  3.  3.  0. 10.  0.  8.  0.  0.  6.  6.] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.15912534296512604
desired expected reward: 30.542329788208008






Player: 1 
cards in hand: [ 3.  1.  3.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  3.  3. 23.] 
cards in discard: [ 6.  1. 15.  8.  3.  3.  0. 10.  0.  8.  0.  0.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 25. 29.  8.  5.  9.  9.  7.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 6.  0.  3.  1. 25.] 
adversary cards in discard: [29. 29.  6.  0.  0. 10.  0. 25.  3.  3.  3.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  3.  3. 23.] 
cards in discard: [ 6.  1. 15.  8.  3.  3.  0. 10.  0.  8.  0.  0.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 24. 30. 25. 29.  8.  5.  9.  9.  7.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 6.  0.  3.  1. 25.] 
adversary cards in discard: [29. 29.  6.  0.  0. 10.  0. 25.  3.  3.  3.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  3.  3. 23.] 
cards in discard: [ 6.  1. 15.  8.  3.  3.  0. 10.  0.  8.  0.  0.  6.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 24. 29.  8.  5.  9.  9.  7.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 6.  0.  3.  1. 25.] 
adversary cards in discard: [29. 29.  6.  0.  0. 10.  0. 25.  3.  3.  3.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  3.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[34.39519 ]
 [35.503063]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  1. 25.] 
cards in discard: [29. 29.  6.  0.  0. 10.  0. 25.  3.  3.  3.  0. 29. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 24. 29.  8.  5.  9.  9.  7.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [15. 15. 11. 16.  1.] 
adversary cards in discard: [ 6.  1. 15.  8.  3.  3.  0. 10.  0.  8.  0.  0.  6.  6.  3.  3.  1.  3.
  3. 23.] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7093597650527954
desired expected reward: 30.20693588256836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[32.848522]
 [33.674774]
 [33.223392]
 [31.756023]
 [34.838593]
 [34.463722]
 [34.012337]
 [34.570637]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  1. 25.] 
cards in discard: [29. 29.  6.  0.  0. 10.  0. 25.  3.  3.  3.  0. 29. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 24. 30. 24. 29.  8.  5.  9.  9.  7.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [15. 15. 11. 16.  1.] 
adversary cards in discard: [ 6.  1. 15.  8.  3.  3.  0. 10.  0.  8.  0.  0.  6.  6.  3.  3.  1.  3.
  3. 23.] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.825837254524231
desired expected reward: 33.56935501098633



buy possibilites: [-1] 
expected returns: [[33.565445]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  1. 25.] 
cards in discard: [29. 29.  6.  0.  0. 10.  0. 25.  3.  3.  3.  0. 29. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 24. 29.  8.  5.  9.  9.  6.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [15. 15. 11. 16.  1.] 
adversary cards in discard: [ 6.  1. 15.  8.  3.  3.  0. 10.  0.  8.  0.  0.  6.  6.  3.  3.  1.  3.
  3. 23.] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -0.7714744806289673
desired expected reward: 33.6922492980957






Player: 1 
cards in hand: [15. 15. 11. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 11. 16.  1.] 
cards in discard: [ 6.  1. 15.  8.  3.  3.  0. 10.  0.  8.  0.  0.  6.  6.  3.  3.  1.  3.
  3. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 24. 29.  8.  5.  9.  9.  6.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [6. 8. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 16.  1.] 
cards in discard: [ 6.  1. 15.  8.  3.  3.  0. 10.  0.  8.  0.  0.  6.  6.  3.  3.  1.  3.
  3. 23.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 24. 29.  8.  5.  9.  9.  6.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [6. 8. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 16.  1.] 
cards in discard: [ 6.  1. 15.  8.  3.  3.  0. 10.  0.  8.  0.  0.  6.  6.  3.  3.  1.  3.
  3. 23.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 24. 30. 24. 29.  8.  5.  9.  9.  6.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [6. 8. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 16.  1.] 
cards in discard: [ 6.  1. 15.  8.  3.  3.  0. 10.  0.  8.  0.  0.  6.  6.  3.  3.  1.  3.
  3. 23.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 23. 29.  8.  5.  9.  9.  6.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [6. 8. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [6. 8. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[34.199345]
 [34.092426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 23. 29.  8.  5.  9.  9.  6.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  3.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3  0  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7976973652839661
desired expected reward: 32.76774597167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[32.562332]
 [33.388584]
 [32.937202]
 [31.469833]
 [34.5524  ]
 [34.177532]
 [33.726147]
 [34.284447]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 23. 29.  8.  5.  9.  9.  6.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  3.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3  0  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8247436285018921
desired expected reward: 33.4338264465332



buy possibilites: [-1] 
expected returns: [[41.553753]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 1. 0.] 
cards in discard: [11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 23. 29.  8.  5.  9.  8.  6.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  3.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3  0  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.2102576047182083
desired expected reward: 34.34214401245117






Player: 1 
cards in hand: [ 3.  3.  3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  8. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 23. 29.  8.  5.  9.  8.  6.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [29.  6.  1.  3. 29.] 
adversary cards in discard: [11.  6.  8.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 8.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3  0  3  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  5.  9.  8.  6.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [29.  6.  1.  3. 29.] 
adversary cards in discard: [11.  6.  8.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 8.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3  0  3  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  5.  9.  8.  6.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [29.  6.  1.  3. 29.] 
adversary cards in discard: [11.  6.  8.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [29.  6.  1.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[32.666134]
 [33.101665]
 [33.101665]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  1.  3. 29.] 
cards in discard: [11.  6.  8.  3.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  5.  9.  8.  6.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [15.  0. 10.  6. 16.] 
adversary cards in discard: [ 1. 11.  3.  3.  3.  8.] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3  0  3  1] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.050264596939087
desired expected reward: 40.50348663330078



action possibilites: [-1. 29. 10.] 
expected returns: [[35.820614]
 [36.25613 ]
 [35.26231 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  3. 29. 10.] 
cards in discard: [11.  6.  8.  3.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 23. 29.  8.  5.  9.  8.  6.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [15.  0. 10.  6. 16.] 
adversary cards in discard: [ 1. 11.  3.  3.  3.  8.] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3  0  3  1] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.16636252403259277
desired expected reward: 32.93529510498047



action possibilites: [-1. 29. 25.] 
expected returns: [[37.71542 ]
 [38.170177]
 [38.842335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  3. 29. 25.] 
cards in discard: [11.  6.  8.  3.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11] -> size -> 25 
action values: 2 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 23. 29.  8.  5.  9.  8.  6.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [15.  0. 10.  6. 16.] 
adversary cards in discard: [ 1. 11.  3.  3.  3.  8.] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3  0  3  1] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0.39560428261756897
desired expected reward: 35.65791320800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[36.03382 ]
 [36.857826]
 [36.404984]
 [34.944454]
 [38.01419 ]
 [37.64303 ]
 [37.190186]
 [37.7266  ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  3. 29. 25.] 
cards in discard: [11.  6.  8.  3.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 30. 23. 29.  8.  5.  9.  8.  6.  8.  7. 10.  9.  7. 10.  7.] 
adversary cards in hand: [15.  0. 10.  6. 16.] 
adversary cards in discard: [ 1. 11.  3.  3.  3.  8.] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3  0  3  1] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.3079230785369873
desired expected reward: 38.02334213256836



buy possibilites: [-1] 
expected returns: [[35.107014]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  3. 29. 25.] 
cards in discard: [11.  6.  8.  3.  1.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  5.  9.  8.  6.  8.  7. 10.  9.  6. 10.  7.] 
adversary cards in hand: [15.  0. 10.  6. 16.] 
adversary cards in discard: [ 1. 11.  3.  3.  3.  8.] 
adversary owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3  0  3  1] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 18  0] 
sum of rewards: 53 

action type: buy - action 10.0
Learning step: 0.8429180979728699
desired expected reward: 38.03310012817383






Player: 1 
cards in hand: [15.  0. 10.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 16.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10.  6. 16.] 
cards in discard: [ 1. 11.  3.  3.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6
  3  0  3  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  5.  9.  8.  6.  8.  7. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 25.  3.  0.  3.] 
adversary cards in discard: [11.  6.  8.  3.  1.  0. 10. 29. 10.  6.  1.  3. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10] -> size -> 26 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 16.] 
cards in discard: [ 1. 11.  3.  3.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 23. 30. 23. 29.  8.  5.  9.  8.  6.  8.  7. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 25.  3.  0.  3.] 
adversary cards in discard: [11.  6.  8.  3.  1.  0. 10. 29. 10.  6.  1.  3. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10] -> size -> 26 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 16.] 
cards in discard: [ 1. 11.  3.  3.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 30. 23. 29.  8.  5.  9.  8.  6.  8.  7. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 25.  3.  0.  3.] 
adversary cards in discard: [11.  6.  8.  3.  1.  0. 10. 29. 10.  6.  1.  3. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10] -> size -> 26 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 16.] 
cards in discard: [ 1. 11.  3.  3.  3.  8. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  5.  9.  7.  6.  8.  7. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 25.  3.  0.  3.] 
adversary cards in discard: [11.  6.  8.  3.  1.  0. 10. 29. 10.  6.  1.  3. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10] -> size -> 26 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[35.174618]
 [36.301525]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0.  3.] 
cards in discard: [11.  6.  8.  3.  1.  0. 10. 29. 10.  6.  1.  3. 29. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  5.  9.  7.  6.  8.  7. 10.  9.  6. 10.  7.] 
adversary cards in hand: [15.  3.  6. 23.  1.] 
adversary cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8267773389816284
desired expected reward: 34.280235290527344



action possibilites: [-1] 
expected returns: [[32.821392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3.  0. 29.] 
cards in discard: [11.  6.  8.  3.  1.  0. 10. 29. 10.  6.  1.  3. 29. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  4.  9.  7.  6.  8.  7. 10.  9.  6. 10.  7.] 
adversary cards in hand: [15.  3.  6. 23.  1.] 
adversary cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.29442110657691956
desired expected reward: 36.007102966308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[31.488209]
 [32.2836  ]
 [31.846481]
 [30.436663]
 [33.399815]
 [33.041534]
 [32.60442 ]
 [33.12218 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3.  0. 29.] 
cards in discard: [11.  6.  8.  3.  1.  0. 10. 29. 10.  6.  1.  3. 29. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 30. 23. 29.  8.  4.  9.  7.  6.  8.  7. 10.  9.  6. 10.  7.] 
adversary cards in hand: [15.  3.  6. 23.  1.] 
adversary cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.193368062376976
desired expected reward: 32.62802505493164



buy possibilites: [-1] 
expected returns: [[29.226036]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3.  0. 29.] 
cards in discard: [11.  6.  8.  3.  1.  0. 10. 29. 10.  6.  1.  3. 29. 25.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  6.  8.  7. 10.  9.  6. 10.  7.] 
adversary cards in hand: [15.  3.  6. 23.  1.] 
adversary cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6] -> size -> 29 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: -0.13852106034755707
desired expected reward: 31.70796012878418






Player: 1 
cards in hand: [15.  3.  6. 23.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 23.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  6. 23.  1.] 
cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  6.  8.  7. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  0. 10.  0.  3.] 
adversary cards in discard: [11.  6.  8.  3.  1.  0. 10. 29. 10.  6.  1.  3. 29. 25.  3. 25.  0.  3.
  0.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 23.  1.] 
cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  6.  8.  7. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  0. 10.  0.  3.] 
adversary cards in discard: [11.  6.  8.  3.  1.  0. 10. 29. 10.  6.  1.  3. 29. 25.  3. 25.  0.  3.
  0.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 23.  1.] 
cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  6.  8.  7. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  0. 10.  0.  3.] 
adversary cards in discard: [11.  6.  8.  3.  1.  0. 10. 29. 10.  6.  1.  3. 29. 25.  3. 25.  0.  3.
  0.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 23.  1.] 
cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  5.  8.  7. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  0. 10.  0.  3.] 
adversary cards in discard: [11.  6.  8.  3.  1.  0. 10. 29. 10.  6.  1.  3. 29. 25.  3. 25.  0.  3.
  0.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[36.45023 ]
 [36.366665]
 [35.913815]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0.  3.] 
cards in discard: [11.  6.  8.  3.  1.  0. 10. 29. 10.  6.  1.  3. 29. 25.  3. 25.  0.  3.
  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  5.  8.  7. 10.  9.  6. 10.  7.] 
adversary cards in hand: [0. 1. 0. 1. 3.] 
adversary cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.  8. 15.  3.  6. 23.  1.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8] -> size -> 30 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6457895636558533
desired expected reward: 28.580245971679688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[34.85932 ]
 [35.230488]
 [33.76996 ]
 [36.468536]
 [36.55211 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  0.  3.] 
cards in discard: [11.  6.  8.  3.  1.  0. 10. 29. 10.  6.  1.  3. 29. 25.  3. 25.  0.  3.
  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  5.  8.  7. 10.  9.  6. 10.  7.] 
adversary cards in hand: [0. 1. 0. 1. 3.] 
adversary cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.  8. 15.  3.  6. 23.  1.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8] -> size -> 30 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8695884346961975
desired expected reward: 35.58064651489258



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 1. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 1. 3.] 
cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.  8. 15.  3.  6. 23.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  5.  8.  7. 10.  9.  6. 10.  7.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 3.] 
cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.  8. 15.  3.  6. 23.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  5.  8.  7. 10.  9.  6. 10.  7.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 3.] 
cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.  8. 15.  3.  6. 23.  1.
 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  5.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[33.02872 ]
 [32.945145]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8
 11 10  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  5.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [3. 6. 8. 0. 0.] 
adversary cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.  8. 15.  3.  6. 23.  1.
 14.  0.  1.  0.  1.  3.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14] -> size -> 31 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.9000979661941528
desired expected reward: 35.652008056640625



action possibilites: [-1] 
expected returns: [[32.878464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  5.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [3. 6. 8. 0. 0.] 
adversary cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.  8. 15.  3.  6. 23.  1.
 14.  0.  1.  0.  1.  3.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.16467349231243134
desired expected reward: 31.831905364990234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.6234  ]
 [31.994562]
 [30.534035]
 [33.232613]
 [33.31618 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  5.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [3. 6. 8. 0. 0.] 
adversary cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.  8. 15.  3.  6. 23.  1.
 14.  0.  1.  0.  1.  3.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.196412593126297
desired expected reward: 32.68205261230469






Player: 1 
cards in hand: [3. 6. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 0. 0.] 
cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.  8. 15.  3.  6. 23.  1.
 14.  0.  1.  0.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  5.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3. 10. 10. 11.  8.] 
adversary cards in discard: [8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 0. 0.] 
cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.  8. 15.  3.  6. 23.  1.
 14.  0.  1.  0.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  5.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3. 10. 10. 11.  8.] 
adversary cards in discard: [8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 0. 0.] 
cards in discard: [ 1. 11.  3.  3.  3.  8. 11. 15. 10.  6. 16.  6.  8. 15.  3.  6. 23.  1.
 14.  0.  1.  0.  1.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  4.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3. 10. 10. 11.  8.] 
adversary cards in discard: [8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 10. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.  8.] 
expected returns: [[33.815746]
 [33.27933 ]
 [33.27933 ]
 [34.10334 ]
 [33.732178]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 11.  8.] 
cards in discard: [8. 0. 0. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  4.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [15.  3.  6.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8] -> size -> 32 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7952757477760315
desired expected reward: 32.520904541015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.276737]
 [31.18737 ]
 [33.96952 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10. 11.  8.] 
cards in discard: [8. 0. 0. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  4.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [15.  3.  6.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8] -> size -> 32 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8203222155570984
desired expected reward: 32.99542236328125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15.  3.  6.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  6.  3. 15.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  4.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  6.  1. 10. 29.] 
adversary cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  3. 15.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  4.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  6.  1. 10. 29.] 
adversary cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  3. 15.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 23. 30. 22. 29.  8.  4.  9.  7.  4.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  6.  1. 10. 29.] 
adversary cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  3. 15.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 22. 29.  8.  4.  9.  7.  4.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  6.  1. 10. 29.] 
adversary cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  1. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[28.916735]
 [28.380318]
 [29.37149 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  1. 10. 29.] 
cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 11.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 22. 29.  8.  4.  9.  7.  4.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 14.  1. 16.  0.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.8647333979606628
desired expected reward: 33.10478210449219



action possibilites: [-1. 10. 25.] 
expected returns: [[30.1848  ]
 [29.673931]
 [31.333656]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  1. 10. 25.] 
cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 11.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 23. 30. 22. 29.  8.  4.  9.  7.  4.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 14.  1. 16.  0.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.11017587780952454
desired expected reward: 29.26131248474121



action possibilites: [-1. 25. 29.] 
expected returns: [[30.943161]
 [32.073696]
 [31.411205]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  1. 25. 29.] 
cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 11.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3] -> size -> 26 
action values: 2 
buys: 0 
player value: 1 
card supply: [24. 23. 30. 22. 29.  8.  4.  9.  7.  4.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 14.  1. 16.  0.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0.49153539538383484
desired expected reward: 30.16546630859375



action possibilites: [-1. 29.] 
expected returns: [[35.655193]
 [36.13084 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  1. 29.  1.  0.] 
cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 11.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 10. 25.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 23. 30. 22. 29.  8.  3.  9.  7.  4.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 14.  1. 16.  0.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 25.0
Learning step: 1.0651651620864868
desired expected reward: 33.13886260986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[34.182693]
 [35.004208]
 [33.72837 ]
 [34.54989 ]
 [33.509487]
 [33.095882]
 [34.566578]
 [36.154285]
 [35.787083]
 [36.992485]
 [36.319283]
 [34.65956 ]
 [34.26057 ]
 [35.33276 ]
 [33.439053]
 [35.481075]
 [35.84363 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  1. 29.  1.  0.] 
cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 11.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 10. 25.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 23. 30. 22. 29.  8.  3.  9.  7.  4.  8.  7.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 14.  1. 16.  0.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0.950994074344635
desired expected reward: 36.60618591308594



buy possibilites: [-1] 
expected returns: [[35.022274]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  1. 29.  1.  0.] 
cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 11.  8. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 10. 25.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 23. 30. 22. 29.  8.  3.  9.  7.  4.  8.  7.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 14.  1. 16.  0.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 60.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 63.0 

action type: buy - action 14.0
Learning step: 1.2179471254348755
desired expected reward: 35.877506256103516






Player: 1 
cards in hand: [ 0. 14.  1. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1. 16.  0.] 
cards in discard: [ 0. 15.  3.  6.  3. 15.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 22. 29.  8.  3.  9.  7.  4.  8.  7.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  3.  0. 29.] 
adversary cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 11.  8. 14. 29. 10. 25.  3.  6.  1. 29.  1.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14] -> size -> 27 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1. 16.  0.] 
cards in discard: [ 0. 15.  3.  6.  3. 15.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 23. 30. 22. 29.  8.  3.  9.  7.  4.  8.  7.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  3.  0. 29.] 
adversary cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 11.  8. 14. 29. 10. 25.  3.  6.  1. 29.  1.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14] -> size -> 27 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1. 16.  0.] 
cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 23. 30. 21. 29.  8.  3.  9.  7.  4.  8.  7.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  3.  0. 29.] 
adversary cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 11.  8. 14. 29. 10. 25.  3.  6.  1. 29.  1.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14] -> size -> 27 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[32.01301 ]
 [32.488655]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 29.] 
cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 11.  8. 14. 29. 10. 25.  3.  6.  1. 29.  1.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 21. 29.  8.  3.  9.  7.  4.  8.  7.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  8.  8. 11.  8.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8615350127220154
desired expected reward: 34.16073989868164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[30.519382]
 [30.886578]
 [29.432571]
 [32.123775]
 [32.180325]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 29.] 
cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 11.  8. 14. 29. 10. 25.  3.  6.  1. 29.  1.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 23. 30. 21. 29.  8.  3.  9.  7.  4.  8.  7.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  8.  8. 11.  8.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.782171905040741
desired expected reward: 31.230836868286133



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  8.  8. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  8. 11.  8.] 
cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 21. 29.  8.  3.  9.  7.  4.  8.  7.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 1.  3.  6. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14] -> size -> 27 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8. 8.] 
cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 21. 29.  8.  3.  9.  7.  4.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 1.  3.  6. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14] -> size -> 27 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8. 8.] 
cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 23. 30. 21. 29.  8.  3.  9.  7.  4.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 1.  3.  6. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14] -> size -> 27 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8. 8.] 
cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 21. 29.  8.  3.  9.  7.  4.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 1.  3.  6. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14] -> size -> 27 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  6. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[26.768513]
 [27.917366]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  6. 25.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 21. 29.  8.  3.  9.  7.  4.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [11.  1.  3.  3. 23.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.8271024823188782
desired expected reward: 31.35321807861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.283766]
 [26.105282]
 [25.650965]
 [24.196957]
 [27.255356]
 [26.888159]
 [26.433842]
 [26.944706]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  6. 25.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 23. 30. 21. 29.  8.  3.  9.  7.  4.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [11.  1.  3.  3. 23.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6766221523284912
desired expected reward: 26.091890335083008



buy possibilites: [-1] 
expected returns: [[34.18391]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  6. 25.  0.] 
cards in discard: [11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 21. 29.  8.  3.  9.  6.  4.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [11.  1.  3.  3. 23.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.06872966885566711
desired expected reward: 27.186628341674805






Player: 1 
cards in hand: [11.  1.  3.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  3. 23.] 
cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 21. 29.  8.  3.  9.  6.  4.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 1. 25.  0.  0.  8.] 
adversary cards in discard: [11.  1.  3.  6. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11] -> size -> 28 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3. 23.] 
cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 21. 29.  8.  3.  8.  6.  4.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 1. 25.  0.  0.  8.] 
adversary cards in discard: [11.  1.  3.  6. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11] -> size -> 28 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  3. 23.] 
cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 23. 30. 21. 29.  8.  3.  8.  6.  4.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 1. 25.  0.  0.  8.] 
adversary cards in discard: [11.  1.  3.  6. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11] -> size -> 28 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  3. 23.] 
cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 20. 29.  8.  3.  8.  6.  4.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 1. 25.  0.  0.  8.] 
adversary cards in discard: [11.  1.  3.  6. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11] -> size -> 28 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 1. 25.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[31.599514]
 [32.74837 ]
 [31.542965]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0.  0.  8.] 
cards in discard: [11.  1.  3.  6. 25.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 20. 29.  8.  3.  8.  6.  4.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [3. 3. 3. 0. 1.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3. 11.  1.  3.  3. 23.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3] -> size -> 39 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8382513523101807
desired expected reward: 33.34565734863281



action possibilites: [-1] 
expected returns: [[36.17724]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  8.  0. 29.] 
cards in discard: [11.  1.  3.  6. 25.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 20. 29.  8.  2.  8.  6.  4.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [3. 3. 3. 0. 1.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3. 11.  1.  3.  3. 23.  6.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6] -> size -> 40 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.15259014070034027
desired expected reward: 32.59577941894531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[35.004185]
 [35.825706]
 [35.371384]
 [34.33098 ]
 [33.917377]
 [35.388073]
 [36.975777]
 [36.608578]
 [37.81398 ]
 [37.140774]
 [35.48105 ]
 [35.08206 ]
 [36.15426 ]
 [34.260548]
 [36.30257 ]
 [36.665123]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  8.  0. 29.] 
cards in discard: [11.  1.  3.  6. 25.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 23. 30. 20. 29.  8.  2.  8.  6.  4.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [3. 3. 3. 0. 1.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3. 11.  1.  3.  3. 23.  6.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6] -> size -> 40 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.25543853640556335
desired expected reward: 35.92179870605469



buy possibilites: [-1] 
expected returns: [[34.592365]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  8.  0. 29.] 
cards in discard: [11.  1.  3.  6. 25.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 23. 30. 19. 29.  8.  2.  8.  6.  4.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [3. 3. 3. 0. 1.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3. 11.  1.  3.  3. 23.  6.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6] -> size -> 40 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: -0.18792182207107544
desired expected reward: 35.18346405029297






Player: 1 
cards in hand: [3. 3. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 1.] 
cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3. 11.  1.  3.  3. 23.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 19. 29.  8.  2.  8.  6.  4.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [14. 29. 29. 10.  0.] 
adversary cards in discard: [11.  1.  3.  6. 25.  0.  3. 25.  1.  0.  0.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3] -> size -> 29 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 1.] 
cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3. 11.  1.  3.  3. 23.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 23. 30. 19. 29.  8.  2.  8.  6.  4.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [14. 29. 29. 10.  0.] 
adversary cards in discard: [11.  1.  3.  6. 25.  0.  3. 25.  1.  0.  0.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3] -> size -> 29 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 1.] 
cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3. 11.  1.  3.  3. 23.  6.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 19. 29.  8.  2.  8.  6.  3.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [14. 29. 29. 10.  0.] 
adversary cards in discard: [11.  1.  3.  6. 25.  0.  3. 25.  1.  0.  0.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3] -> size -> 29 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [14. 29. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29. 29. 10.] 
expected returns: [[24.805218]
 [23.621138]
 [25.28086 ]
 [25.28086 ]
 [24.294348]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 29. 29. 10.  0.] 
cards in discard: [11.  1.  3.  6. 25.  0.  3. 25.  1.  0.  0.  8.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 19. 29.  8.  2.  8.  6.  3.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [0. 6. 6. 8. 1.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3. 11.  1.  3.  3. 23.  6.  8.  3.  3.  3.  0.  1.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8] -> size -> 41 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.927566647529602
desired expected reward: 33.664798736572266



action possibilites: [-1. 14. 29. 10.] 
expected returns: [[30.75965 ]
 [29.575575]
 [31.235298]
 [30.248783]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 29. 10.  0.  3.] 
cards in discard: [11.  1.  3.  6. 25.  0.  3. 25.  1.  0.  0.  8.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 19. 29.  8.  2.  8.  6.  3.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [0. 6. 6. 8. 1.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3. 11.  1.  3.  3. 23.  6.  8.  3.  3.  3.  0.  1.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8] -> size -> 41 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.012988757342100143
desired expected reward: 25.293851852416992



action possibilites: [-1. 14. 10. 10.] 
expected returns: [[31.949917]
 [30.800093]
 [31.473577]
 [31.473577]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  0.  3. 10.] 
cards in discard: [11.  1.  3.  6. 25.  0.  3. 25.  1.  0.  0.  8.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 23. 30. 19. 29.  8.  2.  8.  6.  3.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [0. 6. 6. 8. 1.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3. 11.  1.  3.  3. 23.  6.  8.  3.  3.  3.  0.  1.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8] -> size -> 41 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0.4459196627140045
desired expected reward: 31.68121910095215



action possibilites: [-1. 14. 10.] 
expected returns: [[29.918938]
 [28.769114]
 [29.442598]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3. 10.  3.] 
cards in discard: [11.  1.  3.  6. 25.  0.  3. 25.  1.  0.  0.  8.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3] -> size -> 29 
action values: 2 
buys: 0 
player value: 2 
card supply: [23. 23. 30. 19. 29.  8.  2.  8.  6.  3.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [0. 6. 6. 8. 1.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3. 11.  1.  3.  3. 23.  6.  8.  3.  3.  3.  0.  1.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8] -> size -> 41 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 10.0
Learning step: 1.0153882503509521
desired expected reward: 32.48896408081055



action possibilites: [-1. 10.] 
expected returns: [[33.53095 ]
 [33.054607]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [11.  1.  3.  6. 25.  0.  3. 25.  1.  0.  0.  8.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 10. 14.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 4 
card supply: [23. 23. 30. 19. 29.  8.  2.  8.  6.  3.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [0. 8. 1.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3. 11.  1.  3.  3. 23.  6.  8.  3.  3.  3.  0.  1.  6.  6.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8] -> size -> 41 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 14.0
Learning step: 1.737000823020935
desired expected reward: 30.50611686706543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[31.905048]
 [32.720516]
 [32.265285]
 [31.231565]
 [30.823942]
 [32.28412 ]
 [33.86058 ]
 [33.500347]
 [34.694885]
 [34.0214  ]
 [32.371628]
 [31.970873]
 [33.045116]
 [31.155405]
 [33.1871  ]
 [33.521458]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [11.  1.  3.  6. 25.  0.  3. 25.  1.  0.  0.  8.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 10. 14.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 23. 30. 19. 29.  8.  2.  8.  6.  3.  8.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [0. 8. 1.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3. 11.  1.  3.  3. 23.  6.  8.  3.  3.  3.  0.  1.  6.  6.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8] -> size -> 41 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 1.5912742614746094
desired expected reward: 35.122222900390625



buy possibilites: [-1] 
expected returns: [[40.843857]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [11.  1.  3.  6. 25.  0.  3. 25.  1.  0.  0.  8.  0. 29. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 10. 14.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 19. 29.  8.  2.  8.  6.  3.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [0. 8. 1.] 
adversary cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3. 11.  1.  3.  3. 23.  6.  8.  3.  3.  3.  0.  1.  6.  6.] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8] -> size -> 41 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0 50  0] 
sum of rewards: 125 

action type: buy - action 25.0
Learning step: 3.1380138397216797
desired expected reward: 37.83290100097656






Player: 1 
cards in hand: [0. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1.] 
cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3. 11.  1.  3.  3. 23.  6.  8.  3.  3.  3.  0.  1.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 19. 29.  8.  2.  8.  6.  3.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  6.  8.  3.] 
adversary cards in discard: [11.  1.  3.  6. 25.  0.  3. 25.  1.  0.  0.  8.  0. 29. 25. 29. 29. 10.
 14.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25] -> size -> 30 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1.] 
cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3. 11.  1.  3.  3. 23.  6.  8.  3.  3.  3.  0.  1.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 23. 30. 19. 29.  8.  2.  8.  6.  3.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  6.  8.  3.] 
adversary cards in discard: [11.  1.  3.  6. 25.  0.  3. 25.  1.  0.  0.  8.  0. 29. 25. 29. 29. 10.
 14.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25] -> size -> 30 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1.] 
cards in discard: [ 0. 15.  3.  6.  3. 15.  6.  3.  0. 14.  1. 16.  0. 14.  0. 11.  6.  8.
  8.  8. 16.  3. 11.  1.  3.  3. 23.  6.  8.  3.  3.  3.  0.  1.  6.  6.
  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 19. 29.  8.  2.  8.  6.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  6.  8.  3.] 
adversary cards in discard: [11.  1.  3.  6. 25.  0.  3. 25.  1.  0.  0.  8.  0. 29. 25. 29. 29. 10.
 14.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25] -> size -> 30 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  6.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[31.495432]
 [31.83456 ]
 [31.474323]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  8.  3.] 
cards in discard: [11.  1.  3.  6. 25.  0.  3. 25.  1.  0.  0.  8.  0. 29. 25. 29. 29. 10.
 14.  0.  3. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 19. 29.  8.  2.  8.  6.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 16.  0. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8] -> size -> 42 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.0430110692977905
desired expected reward: 39.800846099853516



action possibilites: [-1] 
expected returns: [[36.302063]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 3.] 
cards in discard: [11.  1.  3.  6. 25.  0.  3. 25.  1.  0.  0.  8.  0. 29. 25. 29. 29. 10.
 14.  0.  3. 10.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 18. 29.  8.  2.  8.  6.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 16.  0. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8] -> size -> 42 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 2
Learning step: 0.06845775246620178
desired expected reward: 29.49225616455078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[34.68977 ]
 [33.608665]
 [36.306175]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 3.] 
cards in discard: [11.  1.  3.  6. 25.  0.  3. 25.  1.  0.  0.  8.  0. 29. 25. 29. 29. 10.
 14.  0.  3. 10.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 23. 30. 18. 29.  8.  2.  8.  6.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 16.  0. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8] -> size -> 42 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.26992595195770264
desired expected reward: 36.03213882446289






Player: 1 
cards in hand: [ 8. 16.  0. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0. 15. 10.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10  0 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3
  0  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 18. 29.  8.  2.  8.  6.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  3. 25.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3] -> size -> 31 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16. 10.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  8 10 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3  0
  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 23. 30. 18. 29.  8.  2.  8.  6.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  3. 25.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3] -> size -> 31 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16. 10.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  8 10 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3  0
  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 23. 30. 18. 29.  8.  2.  8.  6.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  3. 25.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3] -> size -> 31 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16. 10.] 
cards in discard: [1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  8 10 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3  0
  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 18. 29.  8.  2.  8.  6.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  3. 25.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3] -> size -> 31 
adversary victory points: 5
player victory points: 3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 25.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[28.791105]
 [29.964537]
 [28.32191 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25.  3. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 18. 29.  8.  2.  8.  6.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 6. 14.  3.  3. 11.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.] 
adversary owned cards: [ 3  3  3  8 10 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3  0
  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1] -> size -> 42 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.9324424266815186
desired expected reward: 35.37372970581055



action possibilites: [-1] 
expected returns: [[37.10611]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10.  6.  6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 18. 29.  8.  1.  8.  6.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 6. 14.  3.  3. 11.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.] 
adversary owned cards: [ 3  3  3  8 10 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3  0
  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6] -> size -> 43 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.05932193621993065
desired expected reward: 29.90521240234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.614315]
 [34.533207]
 [37.230717]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 10.  6.  6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 22. 30. 18. 29.  8.  1.  8.  6.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 6. 14.  3.  3. 11.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.] 
adversary owned cards: [ 3  3  3  8 10 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3  0
  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6] -> size -> 43 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.28433966636657715
desired expected reward: 36.82176971435547






Player: 1 
cards in hand: [ 6. 14.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  3.  3. 11.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3  0
  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 18. 29.  8.  1.  8.  6.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8. 10.  1.  0.] 
adversary cards in discard: [25.  3.  3.  3. 10.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3] -> size -> 31 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  3.  3. 11.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3  0
  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6] -> size -> 43 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 22. 30. 18. 29.  8.  1.  8.  6.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8. 10.  1.  0.] 
adversary cards in discard: [25.  3.  3.  3. 10.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3] -> size -> 31 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  3.  3. 11.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3  0
  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 18. 29.  8.  1.  8.  6.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8. 10.  1.  0.] 
adversary cards in discard: [25.  3.  3.  3. 10.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3] -> size -> 31 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[34.441963]
 [34.420856]
 [33.965622]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  1.  0.] 
cards in discard: [25.  3.  3.  3. 10.  6.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 18. 29.  8.  1.  8.  6.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [3. 0. 6. 8. 8.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.] 
adversary owned cards: [ 3  3  3  8 10 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3  0
  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0] -> size -> 44 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.9066737294197083
desired expected reward: 36.32404327392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[33.031216]
 [33.846684]
 [33.391453]
 [31.950108]
 [34.986748]
 [34.626514]
 [34.171284]
 [34.64762 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  1.  0.] 
cards in discard: [25.  3.  3.  3. 10.  6.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 22. 30. 18. 29.  8.  1.  8.  6.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [3. 0. 6. 8. 8.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.] 
adversary owned cards: [ 3  3  3  8 10 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3  0
  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0] -> size -> 44 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8256025314331055
desired expected reward: 33.61635971069336



buy possibilites: [-1] 
expected returns: [[32.187218]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  1.  0.] 
cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 18. 29.  8.  1.  8.  5.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [3. 0. 6. 8. 8.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.] 
adversary owned cards: [ 3  3  3  8 10 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3  0
  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0] -> size -> 44 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.3216366469860077
desired expected reward: 34.66511154174805






Player: 1 
cards in hand: [3. 0. 6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 8. 8.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8 10 15  1  1 15 16  8 23  3  6  3 15  0 11  6  1  0  6  3  0
  3  1 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 18. 29.  8.  1.  8.  5.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [10.  0. 14. 11.  0.] 
adversary cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11] -> size -> 32 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 18. 29.  8.  1.  8.  5.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [10.  0. 14. 11.  0.] 
adversary cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11] -> size -> 32 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 22. 30. 18. 29.  8.  1.  8.  5.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [10.  0. 14. 11.  0.] 
adversary cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11] -> size -> 32 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 18. 29.  8.  1.  8.  5.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [10.  0. 14. 11.  0.] 
adversary cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11] -> size -> 32 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [10.  0. 14. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 11.] 
expected returns: [[29.661148]
 [29.184807]
 [28.511322]
 [30.000277]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 14. 11.  0.] 
cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 18. 29.  8.  1.  8.  5.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  8.  8. 15.  6.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0] -> size -> 43 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8061650395393372
desired expected reward: 31.381052017211914



action possibilites: [-1] 
expected returns: [[27.937534]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 14.  0.] 
cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 18. 29.  8.  1.  8.  4.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  8.  8. 15.  6.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0] -> size -> 43 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 5
Learning step: 0.16172657907009125
desired expected reward: 28.54897689819336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.382252]
 [26.735708]
 [25.302046]
 [27.975471]
 [27.958473]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 14.  0.] 
cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 22. 30. 18. 29.  8.  1.  8.  4.  2.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  8.  8. 15.  6.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0] -> size -> 43 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.103662870824337
desired expected reward: 27.833871841430664



buy possibilites: [-1] 
expected returns: [[31.940365]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 14.  0.] 
cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0. 11.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 18. 29.  8.  1.  8.  4.  1.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  8.  8. 15.  6.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0] -> size -> 43 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.1861095428466797
desired expected reward: 28.161584854125977






Player: 1 
cards in hand: [ 0.  8.  8. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 15.  6.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 18. 29.  8.  1.  8.  4.  1.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [29. 29.  0.  0. 29.] 
adversary cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0. 11.  8. 11. 10.  0.
 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8] -> size -> 34 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8. 15.  6.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 22. 30. 18. 29.  8.  1.  8.  4.  1.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [29. 29.  0.  0. 29.] 
adversary cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0. 11.  8. 11. 10.  0.
 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8] -> size -> 34 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8. 15.  6.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 22. 30. 18. 29.  8.  1.  8.  4.  1.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [29. 29.  0.  0. 29.] 
adversary cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0. 11.  8. 11. 10.  0.
 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8] -> size -> 34 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [29. 29.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[25.1997  ]
 [25.709068]
 [25.709068]
 [25.709068]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0. 29.] 
cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0. 11.  8. 11. 10.  0.
 14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 18. 29.  8.  1.  8.  4.  1.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [16.  6.  3. 11. 23.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0] -> size -> 44 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8393354415893555
desired expected reward: 31.101028442382812



action possibilites: [-1. 29. 29.] 
expected returns: [[27.279308]
 [27.80707 ]
 [27.80707 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 29.  3.] 
cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0. 11.  8. 11. 10.  0.
 14.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 22. 30. 18. 29.  8.  1.  8.  4.  1.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [16.  6.  3. 11. 23.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0] -> size -> 44 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.030775565654039383
desired expected reward: 25.678293228149414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.644909]
 [26.456429]
 [25.998365]
 [24.564701]
 [27.591587]
 [27.23813 ]
 [26.780064]
 [27.221127]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 29.  3.] 
cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0. 11.  8. 11. 10.  0.
 14.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 22. 30. 18. 29.  8.  1.  8.  4.  1.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [16.  6.  3. 11. 23.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0] -> size -> 44 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.08836681395769119
desired expected reward: 27.190940856933594



buy possibilites: [-1] 
expected returns: [[22.014357]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 29.  3.] 
cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0. 11.  8. 11. 10.  0.
 14.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 22. 30. 18. 29.  8.  1.  8.  4.  1.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [16.  6.  3. 11. 23.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0] -> size -> 44 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: -0.0881965234875679
desired expected reward: 25.556713104248047






Player: 1 
cards in hand: [16.  6.  3. 11. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  3. 11. 23.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 18. 29.  8.  1.  8.  4.  1.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  3.  8. 25.] 
adversary cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0. 11.  8. 11. 10.  0.
 14.  0.  0. 29. 29.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0] -> size -> 35 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  3. 11. 23.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0] -> size -> 44 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 22. 30. 18. 29.  8.  1.  8.  4.  1.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  3.  8. 25.] 
adversary cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0. 11.  8. 11. 10.  0.
 14.  0.  0. 29. 29.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0] -> size -> 35 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  3. 11. 23.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 18. 29.  8.  1.  8.  4.  1.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  3.  8. 25.] 
adversary cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0. 11.  8. 11. 10.  0.
 14.  0.  0. 29. 29.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0] -> size -> 35 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[27.953917]
 [27.97092 ]
 [29.158165]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  8. 25.] 
cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0. 11.  8. 11. 10.  0.
 14.  0.  0. 29. 29.  0.  0. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 18. 29.  8.  1.  8.  4.  1.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 1.  0.  3. 15.  1.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0] -> size -> 45 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5109661221504211
desired expected reward: 21.50339126586914



action possibilites: [-1] 
expected returns: [[21.018465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  8.  1. 25.] 
cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0. 11.  8. 11. 10.  0.
 14.  0.  0. 29. 29.  0.  0. 29.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 18. 29.  8.  0.  8.  4.  1.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 1.  0.  3. 15.  1.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6] -> size -> 46 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.20405107736587524
desired expected reward: 28.954113006591797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[19.662764]
 [20.4541  ]
 [20.007435]
 [21.56103 ]
 [21.21636 ]
 [20.769691]
 [21.199764]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  8.  1. 25.] 
cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0. 11.  8. 11. 10.  0.
 14.  0.  0. 29. 29.  0.  0. 29.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 22. 30. 18. 29.  8.  0.  8.  4.  1.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 1.  0.  3. 15.  1.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6] -> size -> 46 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.03856956213712692
desired expected reward: 21.057035446166992



buy possibilites: [-1] 
expected returns: [[22.303347]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  8.  1. 25.] 
cards in discard: [25.  3.  3.  3. 10.  6.  6. 11.  3.  8. 10.  1.  0. 11.  8. 11. 10.  0.
 14.  0.  0. 29. 29.  0.  0. 29.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 22. 30. 18. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 1.  0.  3. 15.  1.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6] -> size -> 46 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -1.  0.  0.  2.  0.] 
sum of rewards: 16.0 

action type: buy - action 8.0
Learning step: 0.07769439369440079
desired expected reward: 21.294052124023438






Player: 1 
cards in hand: [ 1.  0.  3. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 15.  1.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 18. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 11.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0  8] -> size -> 36 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 15.  1.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 22. 30. 18. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 11.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0  8] -> size -> 36 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 15.  1.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 21. 30. 18. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 11.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0  8] -> size -> 36 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[29.269274]
 [29.639734]
 [29.639734]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  1. 11.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 18. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  1.  0. 14.  6.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.  1.  1.  0.  3. 15.  1.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1] -> size -> 47 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5089204907417297
desired expected reward: 21.79442596435547



action possibilites: [-1] 
expected returns: [[27.614212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 11.] 
cards in discard: [15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0  8 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 18. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  1.  0. 14.  6.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.  1.  1.  0.  3. 15.  1.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1] -> size -> 47 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -2  0  0 16  0] 
sum of rewards: 29 

action type: gain_card_n - action 8
Learning step: 0.2813608944416046
desired expected reward: 29.567638397216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[26.299667]
 [27.111189]
 [26.653124]
 [28.246346]
 [27.434826]
 [27.875885]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 11.] 
cards in discard: [15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0  8 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 21. 30. 18. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  1.  0. 14.  6.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.  1.  1.  0.  3. 15.  1.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1] -> size -> 47 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.09003959596157074
desired expected reward: 27.524171829223633



buy possibilites: [-1] 
expected returns: [[32.006577]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 11.] 
cards in discard: [15.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 21. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  1.  0. 14.  6.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.  1.  1.  0.  3. 15.  1.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1] -> size -> 47 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -3.  0.  0.  2.  0.] 
sum of rewards: 14.0 

action type: buy - action 3.0
Learning step: -0.03757907822728157
desired expected reward: 26.615550994873047






Player: 1 
cards in hand: [ 3.  1.  0. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 14.  6.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.  1.  1.  0.  3. 15.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  3.  8. 11. 25.] 
adversary cards in discard: [15.  3. 11.  0.  3.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 38 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 14.  6.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.  1.  1.  0.  3. 15.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 21. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  3.  8. 11. 25.] 
adversary cards in discard: [15.  3. 11.  0.  3.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 38 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 14.  6.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.  1.  1.  0.  3. 15.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  3.  8. 11. 25.] 
adversary cards in discard: [15.  3. 11.  0.  3.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 38 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  8. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 25.] 
expected returns: [[32.76297]
 [32.81613]
 [33.159  ]
 [33.98595]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 11. 25.] 
cards in discard: [15.  3. 11.  0.  3.  1. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11
 10  3 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [1. 3. 8. 3. 0.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.  1.  1.  0.  3. 15.  1.  1.
  3.  1.  0. 14.  6.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1] -> size -> 48 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7601062655448914
desired expected reward: 31.246469497680664



action possibilites: [-1] 
expected returns: [[32.563225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 25.] 
cards in discard: [15.  3. 11.  0.  3.  1. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10
  3 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [1. 3. 8. 3. 0.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.  1.  1.  0.  3. 15.  1.  1.
  3.  1.  0. 14.  6.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1] -> size -> 48 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.17056788504123688
desired expected reward: 31.91215705871582





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[31.268631]
 [32.79357 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 25.] 
cards in discard: [15.  3. 11.  0.  3.  1. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10
  3 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [1. 3. 8. 3. 0.] 
adversary cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.  1.  1.  0.  3. 15.  1.  1.
  3.  1.  0. 14.  6.] 
adversary owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1] -> size -> 48 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.1889689564704895
desired expected reward: 32.3742561340332






Player: 1 
cards in hand: [1. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 8. 3. 0.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.  1.  1.  0.  3. 15.  1.  1.
  3.  1.  0. 14.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 10 15  1  1 15 16  8 23  3  3 15  0 11  6  1  0  6  3  0  3  1
 11  6  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [ 0. 29. 29.  6.  3.] 
adversary cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.] 
adversary owned cards: [ 0  0  0  0  0  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10
  3 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 37 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.  1.  1.  0.  3. 15.  1.  1.
  3.  1.  0. 14.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 10 15  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6
  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [ 0. 29. 29.  6.  3.] 
adversary cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.] 
adversary owned cards: [ 0  0  0  0  0  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10
  3 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 37 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [ 1. 15.  8. 16. 10.  6.  0.  6. 14.  3.  3. 11.  0.  8.  0.  8.  0.  0.
  8.  8. 15.  6.  0. 16.  6.  3. 11. 23.  6.  1.  1.  0.  3. 15.  1.  1.
  3.  1.  0. 14.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 10 15  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6
  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [ 0. 29. 29.  6.  3.] 
adversary cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.] 
adversary owned cards: [ 0  0  0  0  0  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10
  3 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 37 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[38.739105]
 [39.288055]
 [39.288055]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  6.  3.] 
cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10
  3 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [ 8. 15.  8.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10 15  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6
  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1] -> size -> 46 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7228195667266846
desired expected reward: 32.07075119018555



action possibilites: [-1. 29.  8.] 
expected returns: [[32.464943]
 [33.013893]
 [32.518105]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.] 
cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  8  6 29  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10
  3 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [ 8. 15.  8.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10 15  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6
  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1] -> size -> 46 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 8
Learning step: -0.37004756927490234
desired expected reward: 38.42222595214844



action possibilites: [-1] 
expected returns: [[31.651426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [ 8. 15.  8.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10 15  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6
  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1] -> size -> 46 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 1
Learning step: 0.43284037709236145
desired expected reward: 32.082828521728516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[30.254673]
 [30.597544]
 [31.779615]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [ 8. 15.  8.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 10 15  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6
  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1] -> size -> 46 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.42656347155570984
desired expected reward: 32.0779914855957






Player: 1 
cards in hand: [ 8. 15.  8.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  8.  6.  3.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 10 15  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6
  8 14  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [25. 11.  6.  8.  3.] 
adversary cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [25. 11.  6.  8.  3.] 
adversary cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [25. 11.  6.  8.  3.] 
adversary cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [25. 11.  6.  8.  3.] 
adversary cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [25. 11.  6.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.  8.] 
expected returns: [[31.151077]
 [32.374058]
 [31.547113]
 [31.20424 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  6.  8.  3.] 
cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  6.] 
adversary cards in hand: [0. 1. 6. 6. 1.] 
adversary cards in discard: [0. 8. 6. 3.] 
adversary owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0] -> size -> 45 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7702222466468811
desired expected reward: 31.00939178466797



action possibilites: [-1] 
expected returns: [[27.132061]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.  8.  3.] 
cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  5.] 
adversary cards in hand: [0. 1. 6. 6. 1.] 
adversary cards in discard: [0. 8. 6. 3.] 
adversary owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0] -> size -> 45 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -2  0  0 16  0] 
sum of rewards: 29 

action type: gain_card_n - action 8
Learning step: 0.2187594175338745
desired expected reward: 31.423002243041992





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[25.662374]
 [27.175854]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.  8.  3.] 
cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  5.] 
adversary cards in hand: [0. 1. 6. 6. 1.] 
adversary cards in discard: [0. 8. 6. 3.] 
adversary owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0] -> size -> 45 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.08497197926044464
desired expected reward: 27.047088623046875






Player: 1 
cards in hand: [0. 1. 6. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 6. 1.] 
cards in discard: [0. 8. 6. 3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  5.] 
adversary cards in hand: [ 0.  0. 29. 10. 14.] 
adversary cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0. 15. 11.
 25.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3 15] -> size -> 37 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 6. 1.] 
cards in discard: [0. 8. 6. 3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6. 10.  5.] 
adversary cards in hand: [ 0.  0. 29. 10. 14.] 
adversary cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0. 15. 11.
 25.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3 15] -> size -> 37 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 6. 1.] 
cards in discard: [ 0.  8.  6.  3. 22.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  0. 29. 10. 14.] 
adversary cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0. 15. 11.
 25.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3 15] -> size -> 37 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 14.] 
expected returns: [[31.799086]
 [32.348034]
 [31.394566]
 [30.720535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 10. 14.] 
cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0. 15. 11.
 25.  6.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [14.  0.  0.  6.  3.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1.] 
adversary owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22] -> size -> 46 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6321941614151001
desired expected reward: 26.543663024902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[30.273546]
 [30.616417]
 [31.798489]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 10. 14.] 
cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0. 15. 11.
 25.  6.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [14.  0.  0.  6.  3.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1.] 
adversary owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22] -> size -> 46 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7776679992675781
desired expected reward: 31.02141761779785



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  0.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  6.  3.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0. 15. 11.
 25.  6.  8.  3.  0.  0. 29. 10. 14.] 
adversary owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3 15] -> size -> 37 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [10.  0.  3.] 
adversary cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0. 15. 11.
 25.  6.  8.  3.  0.  0. 29. 10. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3 15] -> size -> 37 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [10.  0.  3.] 
adversary cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0. 15. 11.
 25.  6.  8.  3.  0.  0. 29. 10. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3 15] -> size -> 37 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [10.  0.  3.] 
adversary cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0. 15. 11.
 25.  6.  8.  3.  0.  0. 29. 10. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3 15] -> size -> 37 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[19.787039]
 [19.430246]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.] 
cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0. 15. 11.
 25.  6.  8.  3.  0.  0. 29. 10. 14.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 8. 15.  3.  3.  1.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.] 
adversary owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15] -> size -> 47 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 3
Learning step: -0.3332204222679138
desired expected reward: 12.649640083312988



action possibilites: [-1. 25.] 
expected returns: [[20.627874]
 [21.805685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.] 
cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0. 15. 11.
 25.  6.  8.  3.  0.  0. 29. 10. 14.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3 15] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 8. 15.  3.  3.  1.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.] 
adversary owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15] -> size -> 47 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.09110555797815323
desired expected reward: 19.521350860595703





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.252752]
 [20.662941]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.] 
cards in discard: [15.  3. 11.  0.  3.  1. 11.  8.  3. 11. 25.  6.  3. 29.  8.  0. 15. 11.
 25.  6.  8.  3.  0.  0. 29. 10. 14.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 8. 15.  3.  3.  1.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.] 
adversary owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15] -> size -> 47 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.04220186173915863
desired expected reward: 20.670076370239258






Player: 1 
cards in hand: [ 8. 15.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  3.  3.  1.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 1.  8.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3 15] -> size -> 37 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  3.  3.  1.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 1.  8.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3 15] -> size -> 37 
adversary victory points: 5
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 1.  8.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[33.281605]
 [33.364597]
 [32.90573 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0. 10.  1.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  6  3  0  1  1 25 10 25  6 29  3  3 10 29  8 11 10  3
 14 11  3 25  3 11 11  8  0  8 15  3 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 3. 11.  6. 11.  1.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.] 
adversary owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15] -> size -> 47 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.421077162027359
desired expected reward: 20.241863250732422



action possibilites: [-1] 
expected returns: [[27.740507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 3. 11.  6. 11.  1.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.] 
adversary owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15] -> size -> 47 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 3
Learning step: -0.22286184132099152
desired expected reward: 31.915042877197266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[26.636232]
 [26.959076]
 [28.069925]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 3. 11.  6. 11.  1.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.] 
adversary owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15] -> size -> 47 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.09460572898387909
desired expected reward: 27.64590072631836



buy possibilites: [-1] 
expected returns: [[29.746103]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.] 
cards in discard: [0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 3. 11.  6. 11.  1.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.] 
adversary owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15] -> size -> 47 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -1.  0.  0.  0.  0.] 
sum of rewards: 14.0 

action type: buy - action 0.0
Learning step: -0.06675281375646591
desired expected reward: 26.569477081298828






Player: 1 
cards in hand: [ 3. 11.  6. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6. 11.  1.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 0. 10.  3. 25. 15.] 
adversary cards in discard: [ 0.  8. 10.  1.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  6. 11.  1.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 0. 10.  3. 25. 15.] 
adversary cards in discard: [ 0.  8. 10.  1.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 15.] 
expected returns: [[27.22029 ]
 [26.844412]
 [28.460907]
 [26.96398 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 25. 15.] 
cards in discard: [ 0.  8. 10.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 8. 14.  0. 16.  3.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.] 
adversary owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15] -> size -> 47 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7526870369911194
desired expected reward: 28.99341583251953



action possibilites: [-1] 
expected returns: [[31.994093]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 15.  8. 11.] 
cards in discard: [ 0.  8. 10.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 8. 14.  0. 16.  3.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.] 
adversary owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15] -> size -> 47 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.06788921356201172
desired expected reward: 28.393016815185547





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[30.67103 ]
 [32.156498]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 15.  8. 11.] 
cards in discard: [ 0.  8. 10.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 8. 14.  0. 16.  3.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.] 
adversary owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15] -> size -> 47 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.17841847240924835
desired expected reward: 31.815673828125






Player: 1 
cards in hand: [ 8. 14.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0. 16.  3.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14
  8  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 17. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 0.  6. 25. 10. 11.] 
adversary cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14  8
  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 16. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 0.  6. 25. 10. 11.] 
adversary cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  0.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14  8
  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 20. 30. 16. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 0.  6. 25. 10. 11.] 
adversary cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 25. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11.] 
expected returns: [[24.79117 ]
 [26.03179 ]
 [24.415297]
 [25.208662]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 25. 10. 11.] 
cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 16. 29.  8.  0.  8.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 0.  8.  0. 23.  6.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.] 
adversary owned cards: [10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14  8
  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3] -> size -> 47 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.8490896224975586
desired expected reward: 31.30740737915039



action possibilites: [-1] 
expected returns: [[31.84912]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 25. 10.] 
cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 16. 29.  8.  0.  7.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 0.  8.  0. 23.  6.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.] 
adversary owned cards: [10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14  8
  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3] -> size -> 47 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -2  0  0 16  0] 
sum of rewards: 29 

action type: gain_card_n - action 3
Learning step: 0.4952096939086914
desired expected reward: 24.135414123535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[30.387926]
 [31.873394]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 25. 10.] 
cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 20. 30. 16. 29.  8.  0.  7.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 0.  8.  0. 23.  6.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.] 
adversary owned cards: [10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14  8
  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3] -> size -> 47 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.17704187333583832
desired expected reward: 31.672077178955078






Player: 1 
cards in hand: [ 0.  8.  0. 23.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 23.  6.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  1  1 15 16  8 23  3  3 15 11  6  1  0  6  3  0  3  1 11  6  8 14  8
  0  6  3 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 16. 29.  8.  0.  7.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 0.  0.  0. 29. 11.] 
adversary cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16] -> size -> 37 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  0  6  3
 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 16. 29.  8.  0.  7.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 0.  0.  0. 29. 11.] 
adversary cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16] -> size -> 37 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  0  6  3
 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 20. 30. 16. 29.  8.  0.  7.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 0.  0.  0. 29. 11.] 
adversary cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16] -> size -> 37 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[20.965929]
 [21.544786]
 [21.40021 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 11.] 
cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 16. 29.  8.  0.  7.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [0. 6. 8. 1. 1.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.  8.  6.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  0  6  3
 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3] -> size -> 44 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.8772328495979309
desired expected reward: 30.837017059326172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[19.600716]
 [20.377218]
 [19.923737]
 [21.469307]
 [20.686184]
 [21.035025]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29. 11.] 
cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 20. 30. 16. 29.  8.  0.  7.  4.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [0. 6. 8. 1. 1.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.  8.  6.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  0  6  3
 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3] -> size -> 44 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5615631341934204
desired expected reward: 20.404361724853516



buy possibilites: [-1] 
expected returns: [[24.651]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29. 11.] 
cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [0. 6. 8. 1. 1.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.  8.  6.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  0  6  3
 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3] -> size -> 44 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -3  0  0 18  0] 
sum of rewards: 10 

action type: buy - action 11.0
Learning step: -0.08524371683597565
desired expected reward: 21.384063720703125






Player: 1 
cards in hand: [0. 6. 8. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 1. 1.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  0  6  3
 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 3.  3.  8. 11.  8.] 
adversary cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11] -> size -> 38 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 1. 1.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  0  6  3
 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  7.  7.  9.  6.  9.  4.] 
adversary cards in hand: [ 3.  3.  8. 11.  8.] 
adversary cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11] -> size -> 38 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 1. 1.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.  8.  6. 22.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  0  6  3
 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  7.  7.  9.  6.  8.  4.] 
adversary cards in hand: [ 3.  3.  8. 11.  8.] 
adversary cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11] -> size -> 38 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  8. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
expected returns: [[20.28913 ]
 [20.395933]
 [20.716585]
 [20.395933]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 11.  8.] 
cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  7.  7.  9.  6.  8.  4.] 
adversary cards in hand: [10.  3. 15.  0. 16.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.  8.  6. 22.  0.  6.
  8.  1.  1.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  0  6  3
 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22] -> size -> 45 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6742501854896545
desired expected reward: 23.976749420166016





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[18.937534]
 [20.357214]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  8. 11.  8.] 
cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11] -> size -> 38 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  7.  7.  9.  6.  8.  4.] 
adversary cards in hand: [10.  3. 15.  0. 16.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.  8.  6. 22.  0.  6.
  8.  1.  1.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  0  6  3
 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22] -> size -> 45 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5508858561515808
desired expected reward: 19.738245010375977



buy possibilites: [-1] 
expected returns: [[18.04623]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  8. 11.  8.] 
cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  7.  7.  9.  6.  8.  4.] 
adversary cards in hand: [10.  3. 15.  0. 16.] 
adversary cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.  8.  6. 22.  0.  6.
  8.  1.  1.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  0  6  3
 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22] -> size -> 45 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -4  0  0  0  0] 
sum of rewards: -9 

action type: buy - action 0.0
Learning step: -0.6486405730247498
desired expected reward: 18.288894653320312






Player: 1 
cards in hand: [10.  3. 15.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 15.  0. 16.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.  8.  6. 22.  0.  6.
  8.  1.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  0  6  3
 14  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  7.  7.  9.  6.  8.  4.] 
adversary cards in hand: [25.  3.  3.  3.  3.] 
adversary cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.  0.  3.  3.  8. 11.  8.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11  0] -> size -> 39 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 15.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.  8.  6. 22.  0.  6.
  8.  1.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  7.  7.  9.  6.  8.  4.] 
adversary cards in hand: [25.  3.  3.  3.  3.] 
adversary cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.  0.  3.  3.  8. 11.  8.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11  0] -> size -> 39 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 15.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.  8.  6. 22.  0.  6.
  8.  1.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  7.  7.  9.  6.  8.  4.] 
adversary cards in hand: [25.  3.  3.  3.  3.] 
adversary cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.  0.  3.  3.  8. 11.  8.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11  0] -> size -> 39 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 15.] 
cards in discard: [ 0.  8.  6.  3. 22.  0.  1.  6.  6.  1. 15. 14.  0.  0.  6.  3.  8. 15.
  3.  3.  1.  3. 11.  6. 11.  1.  3. 16.  8. 14.  0.  8.  6. 22.  0.  6.
  8.  1.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  7.  7.  9.  6.  8.  4.] 
adversary cards in hand: [25.  3.  3.  3.  3.] 
adversary cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.  0.  3.  3.  8. 11.  8.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11  0] -> size -> 39 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [25.  3.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[17.126272]
 [18.301493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  3.  3.  3.] 
cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.  0.  3.  3.  8. 11.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  7.  7.  9.  6.  8.  4.] 
adversary cards in hand: [3. 3. 1. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0] -> size -> 46 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5041571259498596
desired expected reward: 17.542072296142578





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.769455]
 [17.126272]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  3.  3.  3.] 
cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.  0.  3.  3.  8. 11.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11  0] -> size -> 39 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  7.  7.  9.  6.  8.  4.] 
adversary cards in hand: [3. 3. 1. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0] -> size -> 46 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.48966091871261597
desired expected reward: 16.636611938476562



buy possibilites: [-1] 
expected returns: [[18.436846]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  3.  3.  3.] 
cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.  0.  3.  3.  8. 11.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  7.  7.  9.  6.  8.  4.] 
adversary cards in hand: [3. 3. 1. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0] -> size -> 46 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -5  0  0  0  0] 
sum of rewards: -10 

action type: buy - action 0.0
Learning step: -0.5794967412948608
desired expected reward: 15.189957618713379






Player: 1 
cards in hand: [3. 3. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0. 1.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  7.  7.  9.  6.  8.  4.] 
adversary cards in hand: [29.  6.  0. 14. 15.] 
adversary cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.  0.  3.  3.  8. 11.  8.  0. 25.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11  0  0] -> size -> 40 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 1.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  7.  7.  9.  6.  8.  4.] 
adversary cards in hand: [29.  6.  0. 14. 15.] 
adversary cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.  0.  3.  3.  8. 11.  8.  0. 25.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11  0  0] -> size -> 40 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 1.] 
cards in discard: [29.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  6.  7.  9.  6.  8.  4.] 
adversary cards in hand: [29.  6.  0. 14. 15.] 
adversary cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.  0.  3.  3.  8. 11.  8.  0. 25.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11  0  0] -> size -> 40 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [29.  6.  0. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 15.] 
expected returns: [[17.945078]
 [18.494703]
 [16.977274]
 [17.720842]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  0. 14. 15.] 
cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.  0.  3.  3.  8. 11.  8.  0. 25.  3.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11
  3 25  3 11 11  8  0  8 15  3 15  0 16 11  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  6.  7.  9.  6.  8.  4.] 
adversary cards in hand: [6. 8. 0. 1. 6.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29] -> size -> 47 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5148769021034241
desired expected reward: 17.921968460083008



action possibilites: [-1] 
expected returns: [[22.613626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6. 14.] 
cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.  0.  3.  3.  8. 11.  8.  0. 25.  3.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3
 25  3 11 11  8  0  8 15  3 15  0 16 11  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  6.  7.  9.  6.  8.  4.] 
adversary cards in hand: [6. 8. 0. 1. 6.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29] -> size -> 47 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.1558178812265396
desired expected reward: 17.876657485961914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[21.221329]
 [21.977243]
 [21.535793]
 [23.032843]
 [22.27693 ]
 [22.613628]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6. 14.] 
cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.  0.  3.  3.  8. 11.  8.  0. 25.  3.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3
 25  3 11 11  8  0  8 15  3 15  0 16 11  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 20. 30. 16. 29.  8.  0.  7.  3.  0.  7.  6.  7.  9.  6.  8.  4.] 
adversary cards in hand: [6. 8. 0. 1. 6.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29] -> size -> 47 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.005681018810719252
desired expected reward: 22.619306564331055



buy possibilites: [-1] 
expected returns: [[21.835592]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6. 14.] 
cards in discard: [ 0.  8. 10.  1. 25.  0. 10.  3. 15.  8. 11. 16. 11.  0.  6. 25. 10. 11.
  0.  0.  0. 29. 11.  0.  3.  3.  8. 11.  8.  0. 25.  3.  3.  3.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3
 25  3 11 11  8  0  8 15  3 15  0 16 11  0  0  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 16. 29.  8.  0.  7.  3.  0.  7.  6.  7.  9.  6.  8.  4.] 
adversary cards in hand: [6. 8. 0. 1. 6.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29] -> size -> 47 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -5  0  0 18  0] 
sum of rewards: 28 

action type: buy - action 1.0
Learning step: 0.4099563658237457
desired expected reward: 22.38719940185547






Player: 1 
cards in hand: [6. 8. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 1. 6.] 
cards in discard: [29.  3.  3.  1.  0.  1.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 16. 29.  8.  0.  7.  3.  0.  7.  6.  7.  9.  6.  8.  4.] 
adversary cards in hand: [10.  0. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3
 25  3 11 11  8  0  8 15  3 15  0 16 11  0  0  1] -> size -> 40 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 1. 6.] 
cards in discard: [29.  3.  3.  1.  0.  1.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 19. 30. 16. 29.  8.  0.  7.  3.  0.  7.  6.  7.  9.  6.  8.  4.] 
adversary cards in hand: [10.  0. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3
 25  3 11 11  8  0  8 15  3 15  0 16 11  0  0  1] -> size -> 40 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 1. 6.] 
cards in discard: [29.  3.  3.  1.  0.  1. 11.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 16. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  6.  8.  4.] 
adversary cards in hand: [10.  0. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3
 25  3 11 11  8  0  8 15  3 15  0 16 11  0  0  1] -> size -> 40 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [10.  0. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[24.14313 ]
 [23.794287]
 [23.794287]
 [24.251629]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  8.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3
 25  3 11 11  8  0  8 15  3 15  0 16 11  0  0  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 16. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  6.  8.  4.] 
adversary cards in hand: [ 3. 11.  8.  6.  0.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11] -> size -> 48 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5525742769241333
desired expected reward: 21.283018112182617



action possibilites: [-1. 10.  8.] 
expected returns: [[25.14432 ]
 [24.795473]
 [25.252813]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3
 25  3 11 11  8  0  8 15  3 15  0 16 11  0  0  1] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 16. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  6.  8.  4.] 
adversary cards in hand: [ 3. 11.  8.  6.  0.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11] -> size -> 48 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.0002584648027550429
desired expected reward: 23.794029235839844



action possibilites: [-1. 10.] 
expected returns: [[20.369028]
 [20.0658  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11
 11  8  0  8 15  3 15  0 16 11  0  0  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 16. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  6.  8.  4.] 
adversary cards in hand: [ 3. 11.  8.  6.  0.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11] -> size -> 48 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 5
Learning step: 0.5592936873435974
desired expected reward: 24.002878189086914





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.191545]
 [20.516611]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11
 11  8  0  8 15  3 15  0 16 11  0  0  1] -> size -> 37 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 19. 30. 16. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  6.  8.  4.] 
adversary cards in hand: [ 3. 11.  8.  6.  0.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11] -> size -> 48 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.6487882733345032
desired expected reward: 21.0178165435791



buy possibilites: [-1] 
expected returns: [[20.165564]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11
 11  8  0  8 15  3 15  0 16 11  0  0  1  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 16. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  6.  8.  4.] 
adversary cards in hand: [ 3. 11.  8.  6.  0.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11] -> size -> 48 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -3  0  0  0  0] 
sum of rewards: 32 

action type: buy - action 0.0
Learning step: 0.5959921479225159
desired expected reward: 19.78753662109375






Player: 1 
cards in hand: [ 3. 11.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  6.  0.] 
cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 16. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  6.  8.  4.] 
adversary cards in hand: [ 0.  3.  8. 16.  0.] 
adversary cards in discard: [ 0. 10.  8. 10.] 
adversary owned cards: [ 8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11
 11  8  0  8 15  3 15  0 16 11  0  0  1  0] -> size -> 38 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 0.] 
cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11
 10] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 16. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [ 0.  3.  8. 16.  0.] 
adversary cards in discard: [ 0. 10.  8. 10.] 
adversary owned cards: [ 8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11
 11  8  0  8 15  3 15  0 16 11  0  0  1  0] -> size -> 38 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6. 0.] 
cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11
 10] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 19. 30. 16. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [ 0.  3.  8. 16.  0.] 
adversary cards in discard: [ 0. 10.  8. 10.] 
adversary owned cards: [ 8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11
 11  8  0  8 15  3 15  0 16 11  0  0  1  0] -> size -> 38 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  8. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[23.45453 ]
 [23.589823]
 [22.409039]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 16.  0.] 
cards in discard: [ 0. 10.  8. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  0  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11
 11  8  0  8 15  3 15  0 16 11  0  0  1  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 16. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [ 1.  8.  3.  8. 22.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11
 10] -> size -> 49 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5109587907791138
desired expected reward: 19.654603958129883



action possibilites: [-1] 
expected returns: [[21.210764]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [ 0. 10.  8. 10.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [ 1.  8.  3.  8. 22.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11
 10] -> size -> 49 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -3  0  0  4  0] 
sum of rewards: 16 

action type: gain_card_n - action 1
Learning step: 0.13299328088760376
desired expected reward: 19.1236515045166





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[20.119759]
 [21.444828]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [ 0. 10.  8. 10.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [ 1.  8.  3.  8. 22.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.] 
adversary owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11
 10] -> size -> 49 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.033282507210969925
desired expected reward: 21.244047164916992






Player: 1 
cards in hand: [ 1.  8.  3.  8. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  3.  8. 22.] 
cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [10  1  1 15 16  8  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14
  0 16  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11
 10] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [ 3. 15. 29. 11. 11.] 
adversary cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.] 
adversary owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3] -> size -> 38 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 22.] 
cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [ 3. 15. 29. 11. 11.] 
adversary cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.] 
adversary owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3] -> size -> 38 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22.] 
cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10] -> size -> 47 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [ 3. 15. 29. 11. 11.] 
adversary cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.] 
adversary owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3] -> size -> 38 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 3. 15. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 11. 11.] 
expected returns: [[26.688543]
 [26.47466 ]
 [27.279306]
 [27.14124 ]
 [27.14124 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 29. 11. 11.] 
cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [16.  6.  1.  8.  0.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.] 
adversary owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10] -> size -> 47 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5097202658653259
desired expected reward: 20.93510627746582



action possibilites: [-1. 15. 11.] 
expected returns: [[26.361237]
 [26.147356]
 [26.813932]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  3.] 
cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [16.  6.  1.  8.  0.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.] 
adversary owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10] -> size -> 47 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 6
Learning step: 0.000868949864525348
desired expected reward: 24.252315521240234





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[24.933187]
 [26.328657]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  3.] 
cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3] -> size -> 38 
action values: 1 
buys: 1 
player value: 1 
card supply: [11. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [16.  6.  1.  8.  0.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.] 
adversary owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10] -> size -> 47 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.07024721056222916
desired expected reward: 26.290990829467773






Player: 1 
cards in hand: [16.  6.  1.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  1.  8.  0.] 
cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [25.  6.  3. 29.  3.] 
adversary cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3.] 
adversary owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3] -> size -> 38 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  1.  8.  0.] 
cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [25.  6.  3. 29.  3.] 
adversary cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3.] 
adversary owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3] -> size -> 38 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  1.  8.  0.] 
cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [25.  6.  3. 29.  3.] 
adversary cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3.] 
adversary owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3] -> size -> 38 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [25.  6.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[28.06412 ]
 [29.310617]
 [28.644041]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.  3. 29.  3.] 
cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [14.  6.  0. 15. 22.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.  0. 16.  6.  1.  8.  0.] 
adversary owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10  0] -> size -> 48 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6374548673629761
desired expected reward: 25.69120216369629



action possibilites: [-1. 15.] 
expected returns: [[31.39773 ]
 [31.191278]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.] 
cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3. 25.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [14.  6.  0. 15. 22.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.  0. 16.  6.  1.  8.  0.] 
adversary owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10  0] -> size -> 48 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 2
Learning step: -0.009535102173686028
desired expected reward: 26.268604278564453



action possibilites: [-1] 
expected returns: [[26.153505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3. 25.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [14.  6.  0. 15. 22.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.  0. 16.  6.  1.  8.  0.] 
adversary owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10  0] -> size -> 48 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 15.0
Learning step: 0.3884645998477936
desired expected reward: 31.579742431640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[24.834085]
 [26.195341]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3. 25.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [14.  6.  0. 15. 22.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.  0. 16.  6.  1.  8.  0.] 
adversary owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10  0] -> size -> 48 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.5347286462783813
desired expected reward: 26.688234329223633



buy possibilites: [-1] 
expected returns: [[30.123423]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3. 25.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [14.  6.  0. 15. 22.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.  0. 16.  6.  1.  8.  0.] 
adversary owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10  0] -> size -> 48 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0. -4.  0.  0.  0.  0.] 
sum of rewards: 31.0 

action type: buy - action 0.0
Learning step: 0.5012733340263367
desired expected reward: 25.335359573364258






Player: 1 
cards in hand: [14.  6.  0. 15. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  0. 15. 22.] 
cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.  0. 16.  6.  1.  8.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [11. 25.  1.  0. 25.] 
adversary cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3. 25.  6.  0.
 29. 15.  3.  3.] 
adversary owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3  0] -> size -> 39 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0. 15. 22.] 
cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.  0. 16.  6.  1.  8.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [11. 25.  1.  0. 25.] 
adversary cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3. 25.  6.  0.
 29. 15.  3.  3.] 
adversary owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3  0] -> size -> 39 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0. 15. 22.] 
cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.  0. 16.  6.  1.  8.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10  0
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [11. 25.  1.  0. 25.] 
adversary cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3. 25.  6.  0.
 29. 15.  3.  3.] 
adversary owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3  0] -> size -> 39 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [11. 25.  1.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 25.] 
expected returns: [[30.859968]
 [31.329702]
 [32.125877]
 [32.125877]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  1.  0. 25.] 
cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3. 25.  6.  0.
 29. 15.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [16.  3.  1.  0. 11.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.  0. 16.  6.  1.  8.  0.  0. 14.  6.  0. 15. 22.] 
adversary owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10  0
  0] -> size -> 49 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.720711350440979
desired expected reward: 29.402711868286133



action possibilites: [-1] 
expected returns: [[28.656446]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0. 25.  8. 10.] 
cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3. 25.  6.  0.
 29. 15.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [16.  3.  1.  0. 11.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.  0. 16.  6.  1.  8.  0.  0. 14.  6.  0. 15. 22.] 
adversary owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10  0
  0] -> size -> 49 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.2128836214542389
desired expected reward: 31.912994384765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[27.297028]
 [28.062498]
 [27.609554]
 [29.12802 ]
 [28.362553]
 [28.658287]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0. 25.  8. 10.] 
cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3. 25.  6.  0.
 29. 15.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 19. 30. 15. 29.  8.  0.  7.  2.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [16.  3.  1.  0. 11.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.  0. 16.  6.  1.  8.  0.  0. 14.  6.  0. 15. 22.] 
adversary owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10  0
  0] -> size -> 49 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.11175939440727234
desired expected reward: 28.544687271118164



buy possibilites: [-1] 
expected returns: [[25.890173]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0. 25.  8. 10.] 
cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3. 25.  6.  0.
 29. 15.  3.  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3  0 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 19. 30. 15. 29.  8.  0.  7.  1.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [16.  3.  1.  0. 11.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.  0. 16.  6.  1.  8.  0.  0. 14.  6.  0. 15. 22.] 
adversary owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10  0
  0] -> size -> 49 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -5  0  0 18  0] 
sum of rewards: 28 

action type: buy - action 11.0
Learning step: 0.23800626397132874
desired expected reward: 29.366025924682617






Player: 1 
cards in hand: [16.  3.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  1.  0. 11.] 
cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.  0. 16.  6.  1.  8.  0.  0. 14.  6.  0. 15. 22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10  0
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 19. 30. 15. 29.  8.  0.  7.  1.  0.  7.  6.  7.  9.  5.  8.  4.] 
adversary cards in hand: [ 0.  0. 14. 11.  6.] 
adversary cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3. 25.  6.  0.
 29. 15.  3.  3. 11. 25. 11.  1.  0. 25.  8. 10.] 
adversary owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3  0 11] -> size -> 40 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  1.  0.] 
cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.  0. 16.  6.  1.  8.  0.  0. 14.  6.  0. 15. 22. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10  0
  0 29] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 19. 30. 15. 29.  8.  0.  7.  1.  0.  7.  5.  7.  9.  5.  8.  4.] 
adversary cards in hand: [ 0.  0. 14. 11.  6.] 
adversary cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3. 25.  6.  0.
 29. 15.  3.  3. 11. 25. 11.  1.  0. 25.  8. 10.] 
adversary owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3  0 11] -> size -> 40 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  1.  0.] 
cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.  0. 16.  6.  1.  8.  0.  0. 14.  6.  0. 15. 22. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10  0
  0 29] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 19. 30. 15. 29.  8.  0.  7.  1.  0.  7.  5.  7.  9.  5.  8.  4.] 
adversary cards in hand: [ 0.  0. 14. 11.  6.] 
adversary cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3. 25.  6.  0.
 29. 15.  3.  3. 11. 25. 11.  1.  0. 25.  8. 10.] 
adversary owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3  0 11] -> size -> 40 
adversary victory points: 6
player victory points: 0 


Player 0 won the game! 



Player 0 bought cards:
Copper: 7 
Silver: 3 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 2 

Remodel: 0 
Workshop: 5 
Chapel: 4 
Witch: 3 
Poacher: 3 
Militia: 1 
Market: 0 
Village: 3 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0.  0. 14. 11.  6.] 
cards in discard: [ 0. 10.  8. 10.  3. 16.  3.  8.  0.  3. 11. 29. 15. 11.  3. 25.  6.  0.
 29. 15.  3.  3. 11. 25. 11.  1.  0. 25.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  3  1 25 10 25  6 29  3  3 10 29  8 11 10  3 14 11  3 25  3 11 11
  8  0  8 15  3 15  0 16 11  0  0  1  0  3  0 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 19. 30. 15. 29.  8.  0.  7.  0.  0.  7.  5.  7.  9.  5.  8.  4.] 
adversary cards in hand: [16.  3.  1.  0.] 
adversary cards in discard: [29.  3.  3.  1.  0.  1. 11.  6.  8.  0.  1.  6. 10. 11.  3.  8.  6.  0.
  8.  3. 22.  0. 16.  6.  1.  8.  0.  0. 14.  6.  0. 15. 22. 29. 11.] 
adversary owned cards: [10  1 15 16  3  3 15 11  6  1  6  3  3  1 11  6  8 14  8  6  3 14  0 16
  3  6  8  8  1  6  0  0  0  0  6  1  1  0 22 15  3 22  0  0 29 11 10  0
  0 29 11] -> size -> 51 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5 500   0   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: buy - action -1
Learning step: 14.073294639587402
desired expected reward: 39.96346664428711



