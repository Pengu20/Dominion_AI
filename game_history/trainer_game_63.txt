 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[306.95416]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    1  -20    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -524 

action type: buy - action -1
Learning step: -25.815540313720703
desired expected reward: -33.504730224609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[283.19373]
 [295.92578]
 [291.72495]
 [258.67355]
 [288.80994]
 [304.31256]
 [292.5156 ]
 [294.8889 ]
 [270.8488 ]
 [289.5328 ]
 [285.14105]
 [310.96155]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.995368957519531
desired expected reward: 301.6724853515625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[338.45]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.9636969566345215
desired expected reward: 302.99786376953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[308.9523 ]
 [321.8612 ]
 [317.8176 ]
 [282.85245]
 [330.99954]
 [318.37384]
 [315.5785 ]
 [339.0126 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.907188415527344
desired expected reward: 331.6208190917969



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[345.23895]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.262228965759277
desired expected reward: 329.7503967285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[318.0758 ]
 [328.70667]
 [325.26627]
 [296.96622]
 [336.0002 ]
 [325.87598]
 [323.5101 ]
 [341.87555]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.996954917907715
desired expected reward: 336.1543273925781



buy possibilites: [-1] 
expected returns: [[282.36957]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 10.0
Learning step: -9.02219295501709
desired expected reward: 314.48797607421875






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[316.67188]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 16.] 
adversary cards in discard: [3. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -7.595822334289551
desired expected reward: 274.77374267578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[288.3006 ]
 [301.195  ]
 [297.31564]
 [263.56567]
 [294.0696 ]
 [309.95224]
 [297.61874]
 [299.8882 ]
 [275.8661 ]
 [294.9339 ]
 [290.31857]
 [317.38724]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 16.] 
adversary cards in discard: [3. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.663422584533691
desired expected reward: 306.8990783691406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  0. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 16.] 
cards in discard: [3. 0. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.] 
cards in discard: [3. 0. 3. 3. 0. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.] 
cards in discard: [3. 0. 3. 3. 0. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  6. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3  6 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[334.1667 ]
 [317.41064]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3  6 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.594550132751465
desired expected reward: 308.792724609375



action possibilites: [-1.] 
expected returns: [[335.84995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3  6 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action 10.0
Learning step: -7.391844272613525
desired expected reward: 309.5775146484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[303.96457]
 [316.9378 ]
 [312.58817]
 [278.24637]
 [325.2928 ]
 [313.48764]
 [310.3435 ]
 [331.80316]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3  6 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -8.755270004272461
desired expected reward: 327.09466552734375



buy possibilites: [-1] 
expected returns: [[340.1269]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3  6 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -12.0 

action type: buy - action 0.0
Learning step: -8.145373344421387
desired expected reward: 295.8191833496094






Player: 1 
cards in hand: [ 0. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3  6 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3  6 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3  6 10  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[350.6739]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  3. 16.  0.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3  6 10  8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.234686851501465
desired expected reward: 330.8922119140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[324.3226 ]
 [338.08615]
 [333.8944 ]
 [299.3346 ]
 [330.11673]
 [348.04285]
 [334.05957]
 [336.74936]
 [311.75418]
 [331.27045]
 [326.26892]
 [355.97305]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  3. 16.  0.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3  6 10  8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.991582870483398
desired expected reward: 339.8598937988281



buy possibilites: [-1] 
expected returns: [[345.34583]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  0.  0.  3.  0.  3. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  8.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  3. 16.  0.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3  6 10  8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 16.0
Learning step: -7.2355570793151855
desired expected reward: 322.8811950683594






Player: 1 
cards in hand: [11.  6.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3. 16.  0.] 
cards in discard: [ 8.  0. 10.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3  6 10  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  8.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.] 
cards in discard: [ 8.  0. 10.  0.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  8.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.] 
cards in discard: [ 8.  0. 10.  0.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  8.  8.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[295.63477]
 [275.2654 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  8.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  0.  6. 16. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -10.868205070495605
desired expected reward: 334.4776306152344



action possibilites: [-1.] 
expected returns: [[282.95633]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  8.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  0.  6. 16. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 19 

action type: take_action - action 10.0
Learning step: -5.792304992675781
desired expected reward: 256.3841552734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[258.64175]
 [271.8463 ]
 [267.17126]
 [232.36589]
 [279.70673]
 [268.3028 ]
 [264.7183 ]
 [285.64877]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8.  8.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  0.  6. 16. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -7.138969421386719
desired expected reward: 275.8173522949219



buy possibilites: [-1] 
expected returns: [[293.1496]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  8.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  0.  6. 16. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 36 

action type: buy - action 1.0
Learning step: -5.196448802947998
desired expected reward: 266.64984130859375






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8.  0. 10.  0.  3.  0.  6. 16. 11.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  8.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8.  0. 10.  0.  3.  0.  6. 16. 11.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  8.  8.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8.  0. 10.  0.  3.  0.  6. 16. 11.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  8.  8.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[300.58917]
 [285.89404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  0.] 
cards in discard: [ 1. 10.  3.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  8.  8.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.137853622436523
desired expected reward: 285.0117492675781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[286.15347]
 [295.39548]
 [291.6662 ]
 [267.28656]
 [290.08347]
 [300.93222]
 [293.17154]
 [294.7839 ]
 [276.5971 ]
 [290.29504]
 [287.18973]
 [304.97757]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  0.] 
cards in discard: [ 1. 10.  3.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  8.  8.  8.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.481390953063965
desired expected reward: 291.48236083984375



buy possibilites: [-1] 
expected returns: [[258.02115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  0.] 
cards in discard: [ 1. 10.  3.  0.  0.  3.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  8.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -8.853099822998047
desired expected reward: 284.31842041015625






Player: 1 
cards in hand: [ 0.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  8.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6 11  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8.  8.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [16.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
expected returns: [[274.91165]
 [256.78036]
 [256.96283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3. 11.  3.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6 11  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.011012554168701
desired expected reward: 251.0101318359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[249.0198 ]
 [256.17932]
 [226.63005]
 [257.30038]
 [272.29825]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  8.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3. 11.  3.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6 11  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.057312965393066
desired expected reward: 267.1236572265625



buy possibilites: [-1] 
expected returns: [[249.88597]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 10.  0.  3.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3. 11.  3.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6 11  0] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -21.35906982421875
desired expected reward: 205.27101135253906






Player: 1 
cards in hand: [11.  0.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 11.  3.] 
cards in discard: [ 0.  0.  0. 10.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6 11  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [ 6. 16.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6] -> size -> 16 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.] 
cards in discard: [ 0.  0.  0. 10.  0.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6 11  0  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [ 6. 16.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6] -> size -> 16 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.] 
cards in discard: [ 0.  0.  0. 10.  0.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6 11  0  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [ 6. 16.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6] -> size -> 16 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [1. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[260.79163]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 6. 16.  0. 10.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  0.  3.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.  0.  1. 11.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6 11  0  1] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -7.238519191741943
desired expected reward: 242.64744567871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[250.27847]
 [261.31018]
 [257.13397]
 [236.48422]
 [229.24323]
 [255.0316 ]
 [267.8967 ]
 [258.53284]
 [276.98706]
 [260.2598 ]
 [238.96889]
 [246.49582]
 [255.30827]
 [234.44777]
 [251.40306]
 [272.46747]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 6. 16.  0. 10.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 29. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  0.  3.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.  0.  1. 11.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6 11  0  1] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.926945686340332
desired expected reward: 254.55215454101562



buy possibilites: [-1] 
expected returns: [[210.35373]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 6. 16.  0. 10.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  0.  3.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.  0.  1. 11.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6 11  0  1] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 3.0
Learning step: -8.123740196228027
desired expected reward: 249.01023864746094






Player: 1 
cards in hand: [ 0. 16.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8.  0.  3.] 
cards in discard: [ 0.  0.  0. 10.  0.  0.  1. 11.  0.  3. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  3 10  8  6 11  0  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 16.  0. 10.  0.  3.  3.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 0.  0.  0. 10.  0.  0.  1. 11.  0.  3. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 10  8  6 11  0  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 16.  0. 10.  0.  3.  3.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0.  0.  0. 10.  0.  0.  1. 11.  0.  3. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 10  8  6 11  0  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 16.  0. 10.  0.  3.  3.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0.  0.  0. 10.  0.  0.  1. 11.  0.  3. 11.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 10  8  6 11  0  1  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 16.  0. 10.  0.  3.  3.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[263.7767 ]
 [248.18028]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [ 6. 16.  0. 10.  0.  3.  3.  1.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 10  8  6 11  0  1  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -4.95957612991333
desired expected reward: 205.39414978027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[233.50482]
 [245.16383]
 [241.18701]
 [210.43997]
 [252.65619]
 [242.02252]
 [238.97697]
 [257.89334]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [ 6. 16.  0. 10.  0.  3.  3.  1.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 28. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 10  8  6 11  0  1  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.439883708953857
desired expected reward: 249.6734619140625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 10  8  6 11  0  1  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 10  8  6 11  0  1  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  6.  3.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 10  8  6 11  0  1  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [8. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[233.77821]
 [218.42384]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 10. 11.  0.] 
adversary cards in discard: [ 0.  0. 11.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 10  8  6 11  0  1  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.926887512207031
desired expected reward: 249.96649169921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[205.84534]
 [216.93736]
 [213.1182 ]
 [191.55353]
 [184.29976]
 [210.75764]
 [223.76044]
 [213.93886]
 [232.50487]
 [215.75516]
 [194.66364]
 [202.56313]
 [211.08664]
 [190.1592 ]
 [207.0975 ]
 [228.95213]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 28. 30.  8.  7.  8.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 10. 11.  0.] 
adversary cards in discard: [ 0.  0. 11.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 10  8  6 11  0  1  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -6.789306640625
desired expected reward: 223.9699249267578



buy possibilites: [-1] 
expected returns: [[222.34743]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  7.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 10. 11.  0.] 
adversary cards in discard: [ 0.  0. 11.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 10  8  6 11  0  1  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 6.0 

action type: buy - action 14.0
Learning step: -3.9917263984680176
desired expected reward: 181.89913940429688






Player: 1 
cards in hand: [ 0.  8. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 11.  0.] 
cards in discard: [ 0.  0. 11.  0.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 10  8  6 11  0  1  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [14.  8.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14] -> size -> 18 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  0.  3.] 
cards in discard: [ 0.  0. 11.  0.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3 10  8  6 11  0  1  0  0] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [14.  8.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14] -> size -> 18 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0.  0. 11.  0.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [14.  8.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0.  0. 11.  0.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  7.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [14.  8.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0.  0. 11.  0.  6.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  7.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [14.  8.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[262.69263]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [14.  8.  1.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  7.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 11.  0.  6.  3.  3. 10.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -5.928072452545166
desired expected reward: 216.4193572998047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[245.78474]
 [249.50269]
 [228.95102]
 [252.07071]
 [258.34277]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [14.  8.  1.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 27. 30.  8.  7.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 11.  0.  6.  3.  3. 10.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.837716579437256
desired expected reward: 249.46446228027344



buy possibilites: [-1] 
expected returns: [[278.06927]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [14.  8.  1.  0.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 27. 30.  8.  6.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 11.  0.  6.  3.  3. 10.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -323.0 

action type: buy - action 6.0
Learning step: -21.340993881225586
desired expected reward: 207.6100311279297






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  0. 11.  0.  6.  3.  3. 10.  8.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  6.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 16. 10.  0.  0.] 
adversary cards in discard: [14.  8.  1.  0.  0.  0.  6.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6] -> size -> 19 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  0. 11.  0.  6.  3.  3. 10.  8.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 27. 30.  8.  6.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 16. 10.  0.  0.] 
adversary cards in discard: [14.  8.  1.  0.  0.  0.  6.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6] -> size -> 19 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  0. 11.  0.  6.  3.  3. 10.  8.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 26. 30.  8.  6.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 16. 10.  0.  0.] 
adversary cards in discard: [14.  8.  1.  0.  0.  0.  6.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6] -> size -> 19 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 6. 16. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
expected returns: [[210.89471]
 [196.45506]
 [196.47552]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16. 10.  0.  0.] 
cards in discard: [14.  8.  1.  0.  0.  0.  6.  3.  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  6.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -11.102188110351562
desired expected reward: 266.96710205078125



action possibilites: [-1] 
expected returns: [[190.72763]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.] 
cards in discard: [14.  8.  1.  0.  0.  0.  6.  3.  0.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  6.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: gain_card_n - action 0
Learning step: -8.849250793457031
desired expected reward: 210.96319580078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[172.85907]
 [153.7583 ]
 [194.22809]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.] 
cards in discard: [14.  8.  1.  0.  0.  0.  6.  3.  0.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 26. 30.  8.  6.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1
Learning step: -6.15097188949585
desired expected reward: 184.57666015625



buy possibilites: [-1] 
expected returns: [[211.43115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.] 
cards in discard: [14.  8.  1.  0.  0.  0.  6.  3.  0.  3.  0.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 26. 30.  8.  5.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -324.0 

action type: buy - action 6.0
Learning step: -19.130714416503906
desired expected reward: 134.62759399414062






Player: 1 
cards in hand: [ 3.  0. 10.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  5.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6] -> size -> 20 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 26. 30.  8.  5.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6] -> size -> 20 
adversary victory points: 1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[161.37396]
 [144.28809]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  5.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 3.  0. 10.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -9.38593578338623
desired expected reward: 202.0452117919922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[135.65933]
 [142.70892]
 [113.25686]
 [143.98766]
 [157.75168]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 26. 30.  8.  5.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 3.  0. 10.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -6.792275905609131
desired expected reward: 149.8452911376953



buy possibilites: [-1] 
expected returns: [[156.87497]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  0.  3.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 26. 30.  8.  5.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 3.  0. 10.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -74.0 

action type: buy - action 0.0
Learning step: -6.953279972076416
desired expected reward: 128.7060546875






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3.  0. 10.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  5.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  6.  3. 10.] 
adversary cards in discard: [ 0.  3.  0. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3.  0. 10.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 26. 30.  8.  5.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  6.  3. 10.] 
adversary cards in discard: [ 0.  3.  0. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3.  0. 10.  3.  1.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  5.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  6.  3. 10.] 
adversary cards in discard: [ 0.  3.  0. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  6.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[148.27696]
 [132.17255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6.  3. 10.] 
cards in discard: [ 0.  3.  0. 16.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  5.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 3.  0. 10.  3.  1.  1.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3  1] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -6.934083461761475
desired expected reward: 149.94088745117188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[128.25946]
 [111.60917]
 [149.73184]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6.  3. 10.] 
cards in discard: [ 0.  3.  0. 16.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8.  5.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 3.  0. 10.  3.  1.  1.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3  1] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -6.348092555999756
desired expected reward: 137.54153442382812



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [ 3.  0. 10.  3.  1.  1.  0.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  5.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  8.  1. 14.] 
adversary cards in discard: [ 0.  3.  0. 16.  0.  3.  6.  0.  6.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  0. 10.  3.  1.  1.  0.  0.  3.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  5.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  8.  1. 14.] 
adversary cards in discard: [ 0.  3.  0. 16.  0.  3.  6.  0.  6.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  0. 10.  3.  1.  1.  0.  0.  3.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 26. 30.  8.  5.  8.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  8.  1. 14.] 
adversary cards in discard: [ 0.  3.  0. 16.  0.  3.  6.  0.  6.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  0. 10.  3.  1.  1.  0.  0.  3.  3.  0.  1.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 26. 30.  8.  5.  8.  8.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  8.  1. 14.] 
adversary cards in discard: [ 0.  3.  0. 16.  0.  3.  6.  0.  6.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  8.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[166.57896]
 [155.67953]
 [136.33319]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8.  1. 14.] 
cards in discard: [ 0.  3.  0. 16.  0.  3.  6.  0.  6.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  5.  8.  8.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [ 3.  0. 10.  3.  1.  1.  0.  0.  3.  3.  0.  1.  8. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -6.263779163360596
desired expected reward: 143.4680938720703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[132.83308 ]
 [142.34935 ]
 [138.1578  ]
 [117.198074]
 [147.13629 ]
 [139.88153 ]
 [136.33824 ]
 [149.7069  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  8.  1. 14.] 
cards in discard: [ 0.  3.  0. 16.  0.  3.  6.  0.  6.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 26. 30.  8.  5.  8.  8.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [ 3.  0. 10.  3.  1.  1.  0.  0.  3.  3.  0.  1.  8. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -6.4659342765808105
desired expected reward: 142.4026336669922



buy possibilites: [-1] 
expected returns: [[118.72331]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  8.  1. 14.] 
cards in discard: [ 0.  3.  0. 16.  0.  3.  6.  0.  6.  3. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 26. 30.  8.  5.  8.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [ 3.  0. 10.  3.  1.  1.  0.  0.  3.  3.  0.  1.  8. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -42.0 

action type: buy - action 8.0
Learning step: -6.422800540924072
desired expected reward: 133.4586944580078






Player: 1 
cards in hand: [0. 0. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 3.] 
cards in discard: [ 3.  0. 10.  3.  1.  1.  0.  0.  3.  3.  0.  1.  8. 11.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  5.  8.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  3.  0. 16.  0.  3.  6.  0.  6.  3. 10.  8.  0.  6.  8.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 3.  0. 10.  3.  1.  1.  0.  0.  3.  3.  0.  1.  8. 11.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  5.  8.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  3.  0. 16.  0.  3.  6.  0.  6.  3. 10.  8.  0.  6.  8.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 3.  0. 10.  3.  1.  1.  0.  0.  3.  3.  0.  1.  8. 11.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  5.  8.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  3.  0. 16.  0.  3.  6.  0.  6.  3. 10.  8.  0.  6.  8.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[156.003]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  3.  0. 16.  0.  3.  6.  0.  6.  3. 10.  8.  0.  6.  8.  1. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  5.  8.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 1. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -4.126098155975342
desired expected reward: 114.59721374511719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[137.23831]
 [146.6237 ]
 [143.13092]
 [118.52172]
 [141.35771]
 [152.2814 ]
 [144.0715 ]
 [145.423  ]
 [127.42698]
 [141.41022]
 [137.92873]
 [156.55298]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  3.  0. 16.  0.  3.  6.  0.  6.  3. 10.  8.  0.  6.  8.  1. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 26. 30.  8.  5.  8.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 1. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -6.23030948638916
desired expected reward: 149.77268981933594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 1. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  5.  8.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 26. 30.  8.  5.  8.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 1.] 
cards in discard: [23.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  5.  8.  8.  6. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[147.64392]
 [132.12126]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  5.  8.  8.  6. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  8. 11.  0.] 
adversary cards in discard: [23.  3.  1.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -6.457150936126709
desired expected reward: 150.09580993652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[121.99626]
 [134.04007]
 [130.16469]
 [ 98.79885]
 [142.07571]
 [130.7763 ]
 [128.02136]
 [146.63828]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 26. 30.  8.  5.  8.  8.  6. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  8. 11.  0.] 
adversary cards in discard: [23.  3.  1.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -5.790772438049316
desired expected reward: 136.30429077148438



buy possibilites: [-1] 
expected returns: [[171.63733]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 25. 30.  8.  5.  8.  8.  6. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  8. 11.  0.] 
adversary cards in discard: [23.  3.  1.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -21.0 

action type: buy - action 3.0
Learning step: -3.6963956356048584
desired expected reward: 126.46830749511719






Player: 1 
cards in hand: [ 3.  0.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 11.  0.] 
cards in discard: [23.  3.  1.  0.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  5.  8.  8.  6. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 14. 16.  6.  0.] 
adversary cards in discard: [3. 0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8. 11.  0.] 
cards in discard: [23.  3.  1.  0.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 25. 30.  8.  5.  8.  8.  6. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 14. 16.  6.  0.] 
adversary cards in discard: [3. 0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 14. 16.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
expected returns: [[119.50426]
 [ 91.04137]
 [104.60533]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 16.  6.  0.] 
cards in discard: [3. 0. 8. 0. 3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  5.  8.  8.  6. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 1. 10.  0.  8.  0.] 
adversary cards in discard: [23.  3.  1.  0.  3.  1.  3.  0.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -7.286421298980713
desired expected reward: 164.3509063720703



action possibilites: [-1] 
expected returns: [[145.28366]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  0.] 
cards in discard: [3. 0. 8. 0. 3. 0. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  5.  8.  8.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 1. 10.  0.  8.  0.] 
adversary cards in discard: [23.  3.  1.  0.  3.  1.  3.  0.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: 1 

action type: gain_card_n - action 3
Learning step: -1.7010895013809204
desired expected reward: 98.69834899902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[129.73021]
 [110.46001]
 [150.65414]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0.] 
cards in discard: [3. 0. 8. 0. 3. 0. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 25. 30.  8.  5.  8.  8.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 1. 10.  0.  8.  0.] 
adversary cards in discard: [23.  3.  1.  0.  3.  1.  3.  0.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -4.35528564453125
desired expected reward: 140.92837524414062






Player: 1 
cards in hand: [ 1. 10.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  8.  0.] 
cards in discard: [23.  3.  1.  0.  3.  1.  3.  0.  8. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  5.  8.  8.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 6.] 
adversary cards in discard: [ 3.  0.  8.  0.  3.  0.  8. 16. 14.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3  8] -> size -> 23 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.  8.  0.] 
cards in discard: [23.  3.  1.  0.  3.  1.  3.  0.  8. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 25. 30.  8.  5.  8.  8.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 6.] 
adversary cards in discard: [ 3.  0.  8.  0.  3.  0.  8. 16. 14.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3  8] -> size -> 23 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.  8.  0.] 
cards in discard: [23.  3.  1.  0.  3.  1.  3.  0.  8. 11.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 25. 30.  8.  5.  8.  8.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 6.] 
adversary cards in discard: [ 3.  0.  8.  0.  3.  0.  8. 16. 14.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3  8] -> size -> 23 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [3. 8. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[104.61977]
 [ 95.94059]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 6.] 
cards in discard: [ 3.  0.  8.  0.  3.  0.  8. 16. 14.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 25. 30.  8.  5.  8.  8.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [23.  3.  1.  0.  3.  1.  3.  0.  8. 11.  0.  1.  1. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1] -> size -> 22 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -6.446750640869141
desired expected reward: 144.2073974609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 87.84026]
 [ 68.89902]
 [102.32437]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 6.] 
cards in discard: [ 3.  0.  8.  0.  3.  0.  8. 16. 14.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 25. 30.  8.  5.  8.  8.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [23.  3.  1.  0.  3.  1.  3.  0.  8. 11.  0.  1.  1. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1] -> size -> 22 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -4.231637001037598
desired expected reward: 98.26055908203125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [23.  3.  1.  0.  3.  1.  3.  0.  8. 11.  0.  1.  1. 10.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 25. 30.  8.  5.  8.  8.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [10.  0.  1.  0.  0.] 
adversary cards in discard: [ 3.  0.  8.  0.  3.  0.  8. 16. 14.  6.  0.  3.  8.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3  8] -> size -> 23 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [23.  3.  1.  0.  3.  1.  3.  0.  8. 11.  0.  1.  1. 10.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 30. 25. 30.  8.  5.  8.  8.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [10.  0.  1.  0.  0.] 
adversary cards in discard: [ 3.  0.  8.  0.  3.  0.  8. 16. 14.  6.  0.  3.  8.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3  8] -> size -> 23 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [23.  3.  1.  0.  3.  1.  3.  0.  8. 11.  0.  1.  1. 10.  0.  8.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  5.  8.  8.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [10.  0.  1.  0.  0.] 
adversary cards in discard: [ 3.  0.  8.  0.  3.  0.  8. 16. 14.  6.  0.  3.  8.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3  8] -> size -> 23 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [10.  0.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[62.98101]
 [49.83802]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.  0.  0.] 
cards in discard: [ 3.  0.  8.  0.  3.  0.  8. 16. 14.  6.  0.  3.  8.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  5.  8.  8.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3] -> size -> 23 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -5.455856800079346
desired expected reward: 96.86851501464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[49.02161 ]
 [56.20388 ]
 [53.68981 ]
 [39.68054 ]
 [35.024513]
 [52.189255]
 [60.634777]
 [54.282955]
 [66.516205]
 [55.411007]
 [41.74112 ]
 [46.825783]
 [52.408577]
 [38.767014]
 [49.783985]
 [63.96537 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  0.  0.] 
cards in discard: [ 3.  0.  8.  0.  3.  0.  8. 16. 14.  6.  0.  3.  8.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 25. 30. 24. 30.  8.  5.  8.  8.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3] -> size -> 23 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -3.5542473793029785
desired expected reward: 59.42677688598633



buy possibilites: [-1] 
expected returns: [[49.6491]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  0.  0.] 
cards in discard: [ 3.  0.  8.  0.  3.  0.  8. 16. 14.  6.  0.  3.  8.  3.  0.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3  8  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 5 
card supply: [24. 25. 30. 24. 30.  8.  4.  8.  8.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -344.0 

action type: buy - action 6.0
Learning step: -17.55794334411621
desired expected reward: 11.94302749633789






Player: 1 
cards in hand: [11.  3.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  4.  8.  8.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [3. 8. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3  8  6] -> size -> 24 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 25. 30. 24. 30.  8.  4.  8.  8.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [3. 8. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3  8  6] -> size -> 24 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  1.] 
cards in discard: [11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 24. 30.  8.  4.  8.  7.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [3. 8. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3  8  6] -> size -> 24 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [3. 8. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[62.216576]
 [53.134945]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0 16  1  8  6  3 14  6  0  6  0  8  3  8  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  4.  8.  7.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 1. 1. 1.] 
adversary cards in discard: [11. 11.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -3.4237968921661377
desired expected reward: 46.225303649902344



action possibilites: [-1] 
expected returns: [[49.64219]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  0 16  1  8  3 14  6  0  6  0  8  3  8  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  4.  8.  7.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 1. 1. 1.] 
adversary cards in discard: [11. 11.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: trash_cards_n_from_hand - action 7
Learning step: -2.343402862548828
desired expected reward: 42.8636360168457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[40.539505]
 [29.11035 ]
 [51.25393 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  0 16  1  8  3 14  6  0  6  0  8  3  8  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 24. 30.  8.  4.  8.  7.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 1. 1. 1.] 
adversary cards in discard: [11. 11.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -2.7067506313323975
desired expected reward: 46.93544006347656



buy possibilites: [-1] 
expected returns: [[78.00038]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 24. 30.  8.  3.  8.  7.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 1. 1. 1.] 
adversary cards in discard: [11. 11.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11] -> size -> 24 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -50.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -335.0 

action type: buy - action 6.0
Learning step: -16.450510025024414
desired expected reward: 12.659845352172852






Player: 1 
cards in hand: [8. 0. 1. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 1. 1.] 
cards in discard: [11. 11.  3.  0.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  3.  8.  7.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 14.  0.] 
adversary cards in discard: [6. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6] -> size -> 23 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 1. 1.] 
cards in discard: [11. 11.  3.  0.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 7 
card supply: [24. 25. 30. 24. 30.  8.  3.  8.  7.  5. 10. 10.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 14.  0.] 
adversary cards in discard: [6. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6] -> size -> 23 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 1. 1.] 
cards in discard: [11. 11.  3.  0.  0.  1. 22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11
 22] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 30. 24. 30.  8.  3.  8.  7.  5. 10. 10.  9.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  6.  0. 14.  0.] 
adversary cards in discard: [6. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6] -> size -> 23 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[52.280106]
 [36.598824]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 14.  0.] 
cards in discard: [6. 8. 0. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  3.  8.  7.  5. 10. 10.  9.  9.  8.  9. 10.] 
adversary cards in hand: [10.  3.  3.  0.  0.] 
adversary cards in discard: [11. 11.  3.  0.  0.  1. 22.  8.  0.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11
 22] -> size -> 25 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -5.616950511932373
desired expected reward: 72.38343048095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[43.450535]
 [50.130985]
 [46.438816]
 [33.054966]
 [53.22904 ]
 [48.52752 ]
 [45.310726]
 [55.439796]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 14.  0.] 
cards in discard: [6. 8. 0. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 24. 30.  8.  3.  8.  7.  5. 10. 10.  9.  9.  8.  9. 10.] 
adversary cards in hand: [10.  3.  3.  0.  0.] 
adversary cards in discard: [11. 11.  3.  0.  0.  1. 22.  8.  0.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11
 22] -> size -> 25 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -4.186153888702393
desired expected reward: 46.726890563964844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0.  0.] 
cards in discard: [11. 11.  3.  0.  0.  1. 22.  8.  0.  1.  1.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11
 22] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  3.  8.  7.  5. 10. 10.  9.  9.  8.  9. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  8.] 
adversary cards in discard: [ 6.  8.  0.  3.  0.  6.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6] -> size -> 23 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11. 11.  3.  0.  0.  1. 22.  8.  0.  1.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11
 22] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  3.  8.  7.  5. 10. 10.  9.  9.  8.  9. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  8.] 
adversary cards in discard: [ 6.  8.  0.  3.  0.  6.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6] -> size -> 23 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11. 11.  3.  0.  0.  1. 22.  8.  0.  1.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11
 22] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 24. 30.  8.  3.  8.  7.  5. 10. 10.  9.  9.  8.  9. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  8.] 
adversary cards in discard: [ 6.  8.  0.  3.  0.  6.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6] -> size -> 23 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11. 11.  3.  0.  0.  1. 22.  8.  0.  1.  1.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11
 22  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 23. 30.  8.  3.  8.  7.  5. 10. 10.  9.  9.  8.  9. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  8.] 
adversary cards in discard: [ 6.  8.  0.  3.  0.  6.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6] -> size -> 23 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[67.775764]
 [59.358707]
 [60.73598 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  8.] 
cards in discard: [ 6.  8.  0.  3.  0.  6.  0. 14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  3.  8.  7.  5. 10. 10.  9.  9.  8.  9. 10.] 
adversary cards in hand: [ 3.  8.  0.  6. 23.] 
adversary cards in discard: [11. 11.  3.  0.  0.  1. 22.  8.  0.  1.  1.  1.  3. 10.  3.  3.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11
 22  3] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: -4.597128391265869
desired expected reward: 50.8426513671875



action possibilites: [-1] 
expected returns: [[115.2364]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 6.  8.  0.  3.  0.  6.  0. 14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  3.  8.  7.  5. 10. 10.  9.  9.  8.  9. 10.] 
adversary cards in hand: [ 3.  8.  0.  6. 23.] 
adversary cards in discard: [11. 11.  3.  0.  0.  1. 22.  8.  0.  1.  1.  1.  3. 10.  3.  3.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11
 22  3] -> size -> 26 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: trash_cards_n_from_hand - action 8
Learning step: -3.2924370765686035
desired expected reward: 58.41267776489258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[100.805435]
 [105.08323 ]
 [ 85.53809 ]
 [106.53172 ]
 [114.33217 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6.  8.  0.  3.  0.  6.  0. 14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 30. 23. 30.  8.  3.  8.  7.  5. 10. 10.  9.  9.  8.  9. 10.] 
adversary cards in hand: [ 3.  8.  0.  6. 23.] 
adversary cards in discard: [11. 11.  3.  0.  0.  1. 22.  8.  0.  1.  1.  1.  3. 10.  3.  3.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11
 22  3] -> size -> 26 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1
Learning step: -6.182162284851074
desired expected reward: 109.05423736572266



buy possibilites: [-1] 
expected returns: [[76.30206]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6.  8.  0.  3.  0.  6.  0. 14.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 30. 23. 30.  8.  2.  8.  7.  5. 10. 10.  9.  9.  8.  9. 10.] 
adversary cards in hand: [ 3.  8.  0.  6. 23.] 
adversary cards in discard: [11. 11.  3.  0.  0.  1. 22.  8.  0.  1.  1.  1.  3. 10.  3.  3.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11
 22  3] -> size -> 26 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -80.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -367.0 

action type: buy - action 6.0
Learning step: -20.91010856628418
desired expected reward: 64.62798309326172






Player: 1 
cards in hand: [ 3.  8.  0.  6. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  6. 23.] 
cards in discard: [11. 11.  3.  0.  0.  1. 22.  8.  0.  1.  1.  1.  3. 10.  3.  3.  0.  0.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  6 11  0  1  0  0  3  3  1  1  8 23  1  3 11
 22  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  2.  8.  7.  5. 10. 10.  9.  9.  8.  9. 10.] 
adversary cards in hand: [16.  3.  6.  6.  3.] 
adversary cards in discard: [ 6.  8.  0.  3.  0.  6.  0. 14.  0.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11. 11.  3.  0.  0.  1. 22.  8.  0.  1.  1.  1.  3. 10.  3.  3.  0.  0.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  2.  8.  7.  5. 10. 10.  9.  9.  8.  9. 10.] 
adversary cards in hand: [16.  3.  6.  6.  3.] 
adversary cards in discard: [ 6.  8.  0.  3.  0.  6.  0. 14.  0.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11. 11.  3.  0.  0.  1. 22.  8.  0.  1.  1.  1.  3. 10.  3.  3.  0.  0.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  2.  8.  7.  5. 10. 10.  9.  9.  8.  9. 10.] 
adversary cards in hand: [16.  3.  6.  6.  3.] 
adversary cards in discard: [ 6.  8.  0.  3.  0.  6.  0. 14.  0.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11. 11.  3.  0.  0.  1. 22.  8.  0.  1.  1.  1.  3. 10.  3.  3.  0.  0.
  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  2.  8.  7.  5. 10. 10.  9.  9.  8.  9. 10.] 
adversary cards in hand: [16.  3.  6.  6.  3.] 
adversary cards in discard: [ 6.  8.  0.  3.  0.  6.  0. 14.  0.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [16.  3.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[130.1087 ]
 [111.92658]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  6.  6.  3.] 
cards in discard: [ 6.  8.  0.  3.  0.  6.  0. 14.  0.  6.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  2.  8.  7.  5. 10. 10.  9.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0] -> size -> 23 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -5.4358696937561035
desired expected reward: 70.86619567871094



action possibilites: [-1] 
expected returns: [[20.190228]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3.] 
cards in discard: [ 6.  8.  0.  3.  0.  6.  0. 14.  0.  6.  8.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  2.  8.  7.  5. 10.  9.  9.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0] -> size -> 23 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -62 

action type: gain_card_n - action 7
Learning step: -4.728816509246826
desired expected reward: 36.93311309814453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 9.12118 ]
 [ 3.204693]
 [22.59794 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [ 6.  8.  0.  3.  0.  6.  0. 14.  0.  6.  8.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  2.  8.  7.  5. 10.  9.  9.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0] -> size -> 23 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1
Learning step: -4.578977108001709
desired expected reward: 15.611249923706055






Player: 1 
cards in hand: [ 0.  0. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  2.  8.  7.  5. 10.  9.  9.  9.  8.  9. 10.] 
adversary cards in hand: [0. 8. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29] -> size -> 22 
adversary victory points: -3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  2.  7.  7.  5. 10.  9.  9.  9.  8.  9. 10.] 
adversary cards in hand: [0. 8. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29] -> size -> 22 
adversary victory points: -3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 23. 30.  8.  2.  7.  7.  5. 10.  9.  9.  9.  8.  9. 10.] 
adversary cards in hand: [0. 8. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29] -> size -> 22 
adversary victory points: -3
player victory points: 6 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[58.987347]
 [47.106403]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  2.  7.  7.  5. 10.  9.  9.  9.  8.  9. 10.] 
adversary cards in hand: [1. 3. 0. 3. 0.] 
adversary cards in discard: [16. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16] -> size -> 24 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: buy - action -1.0
Learning step: -4.890437602996826
desired expected reward: 17.707517623901367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[40.662296]
 [50.01181 ]
 [46.5497  ]
 [29.553469]
 [22.99939 ]
 [44.447094]
 [56.338165]
 [47.359676]
 [64.18455 ]
 [48.692333]
 [32.255356]
 [37.960625]
 [44.898693]
 [28.245623]
 [41.387268]
 [60.520454]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 25. 30. 23. 30.  8.  2.  7.  7.  5. 10.  9.  9.  9.  8.  9. 10.] 
adversary cards in hand: [1. 3. 0. 3. 0.] 
adversary cards in discard: [16. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16] -> size -> 24 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: take_action - action -1.0
Learning step: -6.569488525390625
desired expected reward: 48.986976623535156



buy possibilites: [-1] 
expected returns: [[51.960327]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 1.] 
cards in discard: [25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  2.  7.  7.  5.  9.  9.  9.  9.  8.  9. 10.] 
adversary cards in hand: [1. 3. 0. 3. 0.] 
adversary cards in discard: [16. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16] -> size -> 24 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: -48 

action type: buy - action 25.0
Learning step: -4.440121173858643
desired expected reward: 59.744449615478516






Player: 1 
cards in hand: [1. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 3. 0.] 
cards in discard: [16. 11.  0.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  2.  7.  7.  5.  9.  9.  9.  9.  8.  9. 10.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [25.  0.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25] -> size -> 23 
adversary victory points: -3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 0.] 
cards in discard: [16. 11.  0.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 25. 30. 23. 30.  8.  2.  7.  7.  5.  9.  9.  9.  9.  8.  9. 10.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [25.  0.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25] -> size -> 23 
adversary victory points: -3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 0.] 
cards in discard: [16. 11.  0.  0.  3.  3. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  2.  7.  7.  5.  9.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [25.  0.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25] -> size -> 23 
adversary victory points: -3
player victory points: 6 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[57.532524]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [25.  0.  8.  0.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  2.  7.  7.  5.  9.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [11.  8.  1. 22.  3.] 
adversary cards in discard: [16. 11.  0.  0.  3.  3. 14.  1.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14] -> size -> 25 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: buy - action -1
Learning step: -6.221140384674072
desired expected reward: 45.73918533325195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[49.534016]
 [54.247547]
 [52.20513 ]
 [40.825768]
 [57.54923 ]
 [52.96297 ]
 [51.421955]
 [60.638866]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [25.  0.  8.  0.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 25. 30. 23. 30.  8.  2.  7.  7.  5.  9.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [11.  8.  1. 22.  3.] 
adversary cards in discard: [16. 11.  0.  0.  3.  3. 14.  1.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14] -> size -> 25 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: take_action - action -1.0
Learning step: -6.506537914276123
desired expected reward: 50.24351119995117



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  8.  1. 22.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 22.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  1. 22.  3.] 
cards in discard: [16. 11.  0.  0.  3.  3. 14.  1.  3.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  2.  7.  7.  5.  9.  9.  8.  9.  8.  9. 10.] 
adversary cards in hand: [ 0. 16. 14.  3.  6.] 
adversary cards in discard: [25.  0.  8.  0.  0.  1.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25] -> size -> 23 
adversary victory points: -3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 22.  3.] 
cards in discard: [16. 11.  0.  0.  3.  3. 14.  1.  3.  0.  3.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  2.  7.  7.  5.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [ 0. 16. 14.  3.  6.] 
adversary cards in discard: [25.  0.  8.  0.  0.  1.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25] -> size -> 23 
adversary victory points: -3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 22.  3.] 
cards in discard: [16. 11.  0.  0.  3.  3. 14.  1.  3.  0.  3.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 23. 30.  8.  2.  7.  7.  5.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [ 0. 16. 14.  3.  6.] 
adversary cards in discard: [25.  0.  8.  0.  0.  1.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25] -> size -> 23 
adversary victory points: -3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 22.  3.] 
cards in discard: [16. 11.  0.  0.  3.  3. 14.  1.  3.  0.  3.  0. 15.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  2.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [ 0. 16. 14.  3.  6.] 
adversary cards in discard: [25.  0.  8.  0.  0.  1.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25] -> size -> 23 
adversary victory points: -3
player victory points: 6 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0. 16. 14.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
expected returns: [[52.03258 ]
 [44.0982  ]
 [38.489475]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 14.  3.  6.] 
cards in discard: [25.  0.  8.  0.  0.  1.  0.  0.  6.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  2.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [10.  0.  1.  0.  1.] 
adversary cards in discard: [16. 11.  0.  0.  3.  3. 14.  1.  3.  0.  3.  0. 15.  8. 11.  8.  1. 22.
  3.] 
adversary owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8] -> size -> 27 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: buy - action -1.0
Learning step: -6.8774638175964355
desired expected reward: 53.76139450073242



action possibilites: [-1] 
expected returns: [[55.779613]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  6.] 
cards in discard: [25.  0.  8.  0.  0.  1.  0.  0.  6.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 25. 30. 23. 30.  8.  2.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [10.  0.  1.] 
adversary cards in discard: [16. 11.  0.  0.  3.  3. 14.  1.  3.  0.  3.  0. 15.  8. 11.  8.  1. 22.
  3.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8] -> size -> 27 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action 14.0
Learning step: -4.569432735443115
desired expected reward: 33.92005157470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[43.189537]
 [48.37485 ]
 [46.9161  ]
 [32.05033 ]
 [52.12377 ]
 [46.923717]
 [46.00008 ]
 [55.08062 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  6.] 
cards in discard: [25.  0.  8.  0.  0.  1.  0.  0.  6.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 25. 30. 23. 30.  8.  2.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [10.  0.  1.] 
adversary cards in discard: [16. 11.  0.  0.  3.  3. 14.  1.  3.  0.  3.  0. 15.  8. 11.  8.  1. 22.
  3.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8] -> size -> 27 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1
Learning step: -5.591724872589111
desired expected reward: 50.187889099121094



buy possibilites: [-1] 
expected returns: [[7.094245]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  6.] 
cards in discard: [25.  0.  8.  0.  0.  1.  0.  0.  6.  0.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 25. 30. 23. 30.  8.  2.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [10.  0.  1.] 
adversary cards in discard: [16. 11.  0.  0.  3.  3. 14.  1.  3.  0.  3.  0. 15.  8. 11.  8.  1. 22.
  3.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8] -> size -> 27 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -90.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -108.0 

action type: buy - action 0.0
Learning step: -7.3998565673828125
desired expected reward: 35.78968048095703






Player: 1 
cards in hand: [10.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.] 
cards in discard: [16. 11.  0.  0.  3.  3. 14.  1.  3.  0.  3.  0. 15.  8. 11.  8.  1. 22.
  3.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 23. 30.  8.  2.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [29.  3.  6.  0.  6.] 
adversary cards in discard: [25.  0.  8.  0.  0.  1.  0.  0.  6.  0.  6.  0. 14.  0. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0] -> size -> 24 
adversary victory points: -3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.] 
cards in discard: [16. 11.  0.  0.  3.  3. 14.  1.  3.  0.  3.  0. 15.  8. 11.  8.  1. 22.
  3.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 30. 23. 30.  8.  2.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [29.  3.  6.  0.  6.] 
adversary cards in discard: [25.  0.  8.  0.  0.  1.  0.  0.  6.  0.  6.  0. 14.  0. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0] -> size -> 24 
adversary victory points: -3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.] 
cards in discard: [16. 11.  0.  0.  3.  3. 14.  1.  3.  0.  3.  0. 15.  8. 11.  8.  1. 22.
  3.  1.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 22. 30.  8.  2.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [29.  3.  6.  0.  6.] 
adversary cards in discard: [25.  0.  8.  0.  0.  1.  0.  0.  6.  0.  6.  0. 14.  0. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0] -> size -> 24 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [29.  3.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[52.709663]
 [42.96902 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  6.  0.  6.] 
cards in discard: [25.  0.  8.  0.  0.  1.  0.  0.  6.  0.  6.  0. 14.  0. 16.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  2.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [ 3. 14.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8  3] -> size -> 28 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1
Learning step: -4.647831439971924
desired expected reward: 2.446413516998291





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.319584]
 [25.967258]
 [52.89384 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  6.  0.  6.] 
cards in discard: [25.  0.  8.  0.  0.  1.  0.  0.  6.  0.  6.  0. 14.  0. 16.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 22. 30.  8.  2.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [ 3. 14.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8  3] -> size -> 28 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action -1.0
Learning step: -7.075421333312988
desired expected reward: 45.63423538208008



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 14.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  3.  8.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  2.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [ 6. 25.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0] -> size -> 24 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 25. 30. 22. 30.  8.  2.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [ 6. 25.  8.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0] -> size -> 24 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 30. 22. 30.  8.  2.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [ 6. 25.  8.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0] -> size -> 24 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0.] 
cards in discard: [3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8  3  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 21. 30.  8.  2.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [ 6. 25.  8.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0] -> size -> 24 
adversary victory points: -3
player victory points: 8 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 6. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[70.737   ]
 [73.883286]
 [66.17044 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25.  8.] 
cards in discard: [0. 8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 21. 30.  8.  2.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [ 8. 16.  1.  3. 11.] 
adversary cards in discard: [ 3. 14.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8  3  3] -> size -> 29 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: discard_down_to_3_cards - action 5
Learning step: -5.837061405181885
desired expected reward: 24.95758819580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[61.1748  ]
 [50.895733]
 [69.07438 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25.  8.] 
cards in discard: [0. 8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [22. 25. 30. 21. 30.  8.  2.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [ 8. 16.  1.  3. 11.] 
adversary cards in discard: [ 3. 14.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8  3  3] -> size -> 29 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: take_action - action -1.0
Learning step: -8.022195816040039
desired expected reward: 62.682044982910156



buy possibilites: [-1] 
expected returns: [[43.042145]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25.  8.] 
cards in discard: [0. 8. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 21. 30.  8.  1.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [ 8. 16.  1.  3. 11.] 
adversary cards in discard: [ 3. 14.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8  3  3] -> size -> 29 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -120    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -429 

action type: buy - action 6.0
Learning step: -22.59327507019043
desired expected reward: 19.641172409057617






Player: 1 
cards in hand: [ 8. 16.  1.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  1.  3. 11.] 
cards in discard: [ 3. 14.  3.  3.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16
 14 15  8  3  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 21. 30.  8.  1.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [ 0.  8.  6.  6. 25.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6] -> size -> 25 
adversary victory points: -4
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 11.] 
cards in discard: [ 3. 14.  3.  3.  8.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14
 15  8  3  3  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 21. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [ 0.  8.  6.  6. 25.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6] -> size -> 25 
adversary victory points: -4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 11.] 
cards in discard: [ 3. 14.  3.  3.  8.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14
 15  8  3  3  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 25. 30. 21. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [ 0.  8.  6.  6. 25.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6] -> size -> 25 
adversary victory points: -4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 11.] 
cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14
 15  8  3  3  6  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [ 0.  8.  6.  6. 25.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6] -> size -> 25 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[11.393525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [ 0.  8.  6.  6. 25.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [ 3.  3.  0.  1. 15.] 
adversary cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3. 16.  8.  1. 11.] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14
 15  8  3  3  6  3] -> size -> 30 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: buy - action -1
Learning step: -7.8457536697387695
desired expected reward: 35.19639205932617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 4.978997 ]
 [ 7.8915577]
 [ 6.9475126]
 [ 9.984232 ]
 [ 7.0987263]
 [ 6.4734087]
 [11.750809 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [ 0.  8.  6.  6. 25.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  8.  9.  9.] 
adversary cards in hand: [ 3.  3.  0.  1. 15.] 
adversary cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3. 16.  8.  1. 11.] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14
 15  8  3  3  6  3] -> size -> 30 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: take_action - action -1.0
Learning step: -6.3182196617126465
desired expected reward: 5.075305461883545



buy possibilites: [-1] 
expected returns: [[41.84398]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [ 0.  8.  6.  6. 25.  8. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  3.  0.  1. 15.] 
adversary cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3. 16.  8.  1. 11.] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14
 15  8  3  3  6  3] -> size -> 30 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -101 

action type: buy - action 10.0
Learning step: -4.432180881500244
desired expected reward: 2.041224956512451






Player: 1 
cards in hand: [ 3.  3.  0.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  1. 15.] 
cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3. 16.  8.  1. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14
 15  8  3  3  6  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [ 0.  8.  6.  6. 25.  8. 10.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10] -> size -> 26 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  1. 15.] 
cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3. 16.  8.  1. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14
 15  8  3  3  6  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [ 0.  8.  6.  6. 25.  8. 10.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10] -> size -> 26 
adversary victory points: -4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  1. 15.] 
cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3. 16.  8.  1. 11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14
 15  8  3  3  6  3  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [ 0.  8.  6.  6. 25.  8. 10.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10] -> size -> 26 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[21.65073  ]
 [ 3.8089325]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 14.  3.] 
cards in discard: [ 0.  8.  6.  6. 25.  8. 10.  0.  0.  0.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  8.  0. 10. 11.] 
adversary cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3. 16.  8.  1. 11.  1.  3.  3.  0.  1. 15.] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14
 15  8  3  3  6  3  1] -> size -> 31 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: buy - action -1
Learning step: -7.6999192237854
desired expected reward: 34.14405822753906



action possibilites: [-1] 
expected returns: [[17.385674]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [ 0.  8.  6.  6. 25.  8. 10.  0.  0.  0.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 24. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.] 
adversary cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3. 16.  8.  1. 11.  1.  3.  3.  0.  1. 15.
  0. 11.] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14
 15  8  3  3  6  3  1] -> size -> 31 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -99 

action type: take_action - action 14.0
Learning step: -4.749269008636475
desired expected reward: -0.9403307437896729





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[10.652073 ]
 [14.943071 ]
 [13.715563 ]
 [12.502644 ]
 [18.039057 ]
 [13.67124  ]
 [14.313499 ]
 [ 6.9731693]
 [12.915051 ]
 [11.283892 ]
 [20.381453 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [ 0.  8.  6.  6. 25.  8. 10.  0.  0.  0.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 24. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.] 
adversary cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3. 16.  8.  1. 11.  1.  3.  3.  0.  1. 15.
  0. 11.] 
adversary owned cards: [ 0  0  0  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14
 15  8  3  3  6  3  1] -> size -> 31 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -99 

action type: take_action - action -1
Learning step: -5.47113037109375
desired expected reward: 11.914543151855469






Player: 1 
cards in hand: [ 8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.] 
cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3. 16.  8.  1. 11.  1.  3.  3.  0.  1. 15.
  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14
 15  8  3  3  6  3  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [29.  8. 16.  0.  6.] 
adversary cards in discard: [ 0.  8.  6.  6. 25.  8. 10.  0.  0.  0.  6.  6. 14.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10] -> size -> 26 
adversary victory points: -4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3. 16.  8.  1. 11.  1.  3.  3.  0.  1. 15.
  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [29.  8. 16.  0.  6.] 
adversary cards in discard: [ 0.  8.  6.  6. 25.  8. 10.  0.  0.  0.  6.  6. 14.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10] -> size -> 26 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3. 16.  8.  1. 11.  1.  3.  3.  0.  1. 15.
  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 24. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [29.  8. 16.  0.  6.] 
adversary cards in discard: [ 0.  8.  6.  6. 25.  8. 10.  0.  0.  0.  6.  6. 14.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10] -> size -> 26 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [29.  8. 16.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 16.] 
expected returns: [[-1.5098678]
 [-3.1777134]
 [-3.3213725]
 [-3.5439444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 16.  0.  6.] 
cards in discard: [ 0.  8.  6.  6. 25.  8. 10.  0.  0.  0.  6.  6. 14.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  0.  3.  3. 22.] 
adversary cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3. 16.  8.  1. 11.  1.  3.  3.  0.  1. 15.
  0. 11.  8.] 
adversary owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1] -> size -> 29 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: buy - action -1.0
Learning step: -7.025427341461182
desired expected reward: 13.356027603149414





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-3.6755414 ]
 [-0.99545586]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8. 16.  0.  6.] 
cards in discard: [ 0.  8.  6.  6. 25.  8. 10.  0.  0.  0.  6.  6. 14.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 24. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  0.  3.  3. 22.] 
adversary cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3. 16.  8.  1. 11.  1.  3.  3.  0.  1. 15.
  0. 11.  8.] 
adversary owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1] -> size -> 29 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: take_action - action -1.0
Learning step: -5.918664455413818
desired expected reward: -7.428534984588623



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0.  3.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  3. 22.] 
cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3. 16.  8.  1. 11.  1.  3.  3.  0.  1. 15.
  0. 11.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [10.  6.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10] -> size -> 26 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  3. 22.] 
cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3. 16.  8.  1. 11.  1.  3.  3.  0.  1. 15.
  0. 11.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 24. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [10.  6.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10] -> size -> 26 
adversary victory points: -4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  3. 22.] 
cards in discard: [ 3. 14.  3.  3.  8.  0.  6.  3. 16.  8.  1. 11.  1.  3.  3.  0.  1. 15.
  0. 11.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 24. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [10.  6.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10] -> size -> 26 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [10.  6.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[29.582312]
 [23.177923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 6. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0] -> size -> 30 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: buy - action -1.0
Learning step: -5.317342758178711
desired expected reward: -6.312800884246826





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.526567]
 [23.788292]
 [22.839552]
 [21.890947]
 [26.322657]
 [22.856653]
 [23.476315]
 [14.35928 ]
 [22.304016]
 [20.471329]
 [28.366495]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 24. 30. 20. 30.  8.  0.  7.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 6. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0] -> size -> 30 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: take_action - action -1.0
Learning step: -6.831000804901123
desired expected reward: 21.610363006591797



buy possibilites: [-1] 
expected returns: [[21.41972]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  0.  1.] 
cards in discard: [16.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 20. 30.  8.  0.  6.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 6. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0] -> size -> 30 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
   32    0] 
sum of rewards: -87 

action type: buy - action 16.0
Learning step: -4.962604522705078
desired expected reward: 16.92835807800293






Player: 1 
cards in hand: [0. 6. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 20. 30.  8.  0.  6.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [29.  8.  6.  0.  3.] 
adversary cards in discard: [16. 10.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10 16] -> size -> 27 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 24. 30. 20. 30.  8.  0.  6.  7.  4.  9.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [29.  8.  6.  0.  3.] 
adversary cards in discard: [16. 10.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10 16] -> size -> 27 
adversary victory points: -4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 0.] 
cards in discard: [25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 20. 30.  8.  0.  6.  7.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [29.  8.  6.  0.  3.] 
adversary cards in discard: [16. 10.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10 16] -> size -> 27 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [29.  8.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[18.666632 ]
 [11.052168 ]
 [10.7555275]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  6.  0.  3.] 
cards in discard: [16. 10.  6.  0.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8  3 14  6  0  6  0  8  3  8  6  6  6 29 25  0
  6 10 16] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 20. 30.  8.  0.  6.  7.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [14.  3.  8.  0.  1.] 
adversary cards in discard: [25.  0.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0 25] -> size -> 31 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: buy - action -1
Learning step: -6.685023784637451
desired expected reward: 14.734695434570312



action possibilites: [-1] 
expected returns: [[39.554665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [16. 10.  6.  0.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  6  0  8  3  8  6  6  6 25  0  6 10 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 20. 30.  8.  0.  6.  7.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [14.  3.  8.  0.  1.] 
adversary cards in discard: [25.  0.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0 25] -> size -> 31 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -99 

action type: trash_cards_n_from_hand - action 10
Learning step: -4.4909491539001465
desired expected reward: 4.127638339996338





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[32.725792]
 [39.999657]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [16. 10.  6.  0.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  6  0  8  3  8  6  6  6 25  0  6 10 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 24. 30. 20. 30.  8.  0.  6.  7.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [14.  3.  8.  0.  1.] 
adversary cards in discard: [25.  0.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0 25] -> size -> 31 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -99 

action type: take_action - action -1
Learning step: -6.086799144744873
desired expected reward: 33.467864990234375






Player: 1 
cards in hand: [14.  3.  8.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8.  0.  1.] 
cards in discard: [25.  0.  6.  0.  1.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 20. 30.  8.  0.  6.  7.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 16. 25.  8.  0.] 
adversary cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  6  0  8  3  8  6  6  6 25  0  6 10 16] -> size -> 24 
adversary victory points: -4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 1.] 
cards in discard: [25.  0.  6.  0.  1.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 24. 30. 20. 30.  8.  0.  6.  7.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [16. 25.  0.] 
adversary cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  6  0  8  3  8  6  6  6 25  0  6 10 16] -> size -> 24 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 1.] 
cards in discard: [25.  0.  6.  0.  1.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0 25] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 24. 30. 20. 30.  8.  0.  6.  7.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [16. 25.  0.] 
adversary cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  6  0  8  3  8  6  6  6 25  0  6 10 16] -> size -> 24 
adversary victory points: -4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 1.] 
cards in discard: [25.  0.  6.  0.  1.  0.  4.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0 25  4] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 20. 29.  8.  0.  6.  7.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [16. 25.  0.] 
adversary cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  6  0  8  3  8  6  6  6 25  0  6 10 16] -> size -> 24 
adversary victory points: -4
player victory points: 10 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [16. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.] 
expected returns: [[13.387779]
 [ 8.654962]
 [14.332197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 25.  0.] 
cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  6  0  8  3  8  6  6  6 25  0  6 10 16] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 20. 29.  8.  0.  6.  7.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 22. 15.  0.  8.] 
adversary cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1.] 
adversary owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0 25  4] -> size -> 32 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -149 

action type: discard_down_to_3_cards - action 4
Learning step: -8.449646949768066
desired expected reward: 17.27593994140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 7.228919]
 [13.378665]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 25.  0.] 
cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  6  0  8  3  8  6  6  6 25  0  6 10 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 24. 30. 20. 29.  8.  0.  6.  7.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 22. 15.  0.  8.] 
adversary cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1.] 
adversary owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0 25  4] -> size -> 32 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -149 

action type: take_action - action -1.0
Learning step: -7.868299961090088
desired expected reward: 5.51947546005249



buy possibilites: [-1] 
expected returns: [[29.054535]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 25.  0.] 
cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  6  0  8  3  8  6  6  6 25  0  6 10 16
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 20. 29.  8.  0.  6.  7.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 22. 15.  0.  8.] 
adversary cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1.] 
adversary owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0 25  4] -> size -> 32 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -140.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -179.0 

action type: buy - action 0.0
Learning step: -8.657718658447266
desired expected reward: -1.4288015365600586






Player: 1 
cards in hand: [ 3. 22. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 22. 15.  0.  8.] 
cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8
  3  3  6  3  1  0 25  4] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 20. 29.  8.  0.  6.  7.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [6. 6. 8. 0. 3.] 
adversary cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.  0. 16. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  6  0  8  3  8  6  6  6 25  0  6 10 16
  0] -> size -> 25 
adversary victory points: -4
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 22.  8.] 
cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 24. 30. 20. 29.  8.  0.  6.  7.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [6. 6. 8. 0. 3.] 
adversary cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.  0. 16. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  6  0  8  3  8  6  6  6 25  0  6 10 16
  0] -> size -> 25 
adversary victory points: -4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22.  8.] 
cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 24. 30. 20. 29.  8.  0.  6.  7.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [6. 6. 8. 0. 3.] 
adversary cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.  0. 16. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  6  0  8  3  8  6  6  6 25  0  6 10 16
  0] -> size -> 25 
adversary victory points: -4
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22.  8.] 
cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 20. 29.  8.  0.  6.  6.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [6. 6. 8. 0. 3.] 
adversary cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.  0. 16. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  6  0  8  3  8  6  6  6 25  0  6 10 16
  0] -> size -> 25 
adversary victory points: -4
player victory points: 10 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [6. 6. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-0.646693 ]
 [-2.5959709]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 0. 3.] 
cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.  0. 16. 25.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  6  0  8  3  8  6  6  6 25  0  6 10 16
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 20. 29.  8.  0.  6.  6.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [3. 3. 3. 1. 3.] 
adversary cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.] 
adversary owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11] -> size -> 32 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -149 

action type: buy - action -1
Learning step: -8.933104515075684
desired expected reward: 20.121429443359375



action possibilites: [-1] 
expected returns: [[11.798317]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.  0. 16. 25.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6  6 25  0  6 10 16  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 20. 29.  8.  0.  6.  6.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [3. 3. 3. 1. 3.] 
adversary cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.] 
adversary owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11] -> size -> 32 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -129 

action type: trash_cards_n_from_hand - action 5
Learning step: -6.0738420486450195
desired expected reward: -8.287765502929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.188124]
 [12.307183]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.  0. 16. 25.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6  6 25  0  6 10 16  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 24. 30. 20. 29.  8.  0.  6.  6.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [3. 3. 3. 1. 3.] 
adversary cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.] 
adversary owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11] -> size -> 32 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -129 

action type: take_action - action -1
Learning step: -6.763970851898193
desired expected reward: 5.034346103668213



buy possibilites: [-1] 
expected returns: [[-11.350046]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.  0. 16. 25.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6  6 25  0  6 10 16  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 24. 30. 20. 29.  8.  0.  6.  6.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [3. 3. 3. 1. 3.] 
adversary cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.] 
adversary owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11] -> size -> 32 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -140.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -159.0 

action type: buy - action 0.0
Learning step: -8.81478214263916
desired expected reward: 3.3733444213867188






Player: 1 
cards in hand: [3. 3. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 1. 3.] 
cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 20. 29.  8.  0.  6.  6.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.  0. 16. 25.  0.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6  6 25  0  6 10 16  0  0] -> size -> 24 
adversary victory points: -4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 1. 3.] 
cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 30. 20. 29.  8.  0.  6.  6.  4.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.  0. 16. 25.  0.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6  6 25  0  6 10 16  0  0] -> size -> 24 
adversary victory points: -4
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 1. 3.] 
cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 20. 29.  8.  0.  6.  6.  3.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.  0. 16. 25.  0.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6  6 25  0  6 10 16  0  0] -> size -> 24 
adversary victory points: -4
player victory points: 10 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[7.136263]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.  0. 16. 25.  0.  0.  8.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6  6 25  0  6 10 16  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 20. 29.  8.  0.  6.  6.  3.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 1. 8. 3. 3.] 
adversary cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.  8.
  3.  3.  3.  1.  3.] 
adversary owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8] -> size -> 33 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -149 

action type: buy - action -1
Learning step: -6.721931457519531
desired expected reward: -18.071977615356445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 4.915398]
 [ 9.686884]
 [ 7.141288]
 [11.370357]
 [ 8.564971]
 [ 6.278742]
 [11.712308]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.  0. 16. 25.  0.  0.  8.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6  6 25  0  6 10 16  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 30. 20. 29.  8.  0.  6.  6.  3.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 1. 8. 3. 3.] 
adversary cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.  8.
  3.  3.  3.  1.  3.] 
adversary owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8] -> size -> 33 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -149 

action type: take_action - action -1.0
Learning step: -7.595054626464844
desired expected reward: -0.45879173278808594



buy possibilites: [-1] 
expected returns: [[7.2982073]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [16. 10.  6.  0.  0.  1.  8.  0.  8.  0.  0. 16. 25.  0.  0.  8.  6.  0.
  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6  6 25  0  6 10 16  0  0
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 20. 29.  8.  0.  6.  6.  3.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 1. 8. 3. 3.] 
adversary cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.  8.
  3.  3.  3.  1.  3.] 
adversary owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8] -> size -> 33 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -140    0    0    0    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -131 

action type: buy - action 1.0
Learning step: -6.870133876800537
desired expected reward: 2.816737651824951






Player: 1 
cards in hand: [0. 1. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 3. 3.] 
cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.  8.
  3.  3.  3.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 20. 29.  8.  0.  6.  6.  3.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 6.  8. 10.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6  6 25  0  6 10 16  0  0
  1] -> size -> 25 
adversary victory points: -4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 3. 3.] 
cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.  8.
  3.  3.  3.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 23. 30. 20. 29.  8.  0.  6.  6.  3.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 6.  8. 10.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6  6 25  0  6 10 16  0  0
  1] -> size -> 25 
adversary victory points: -4
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 3. 3.] 
cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.  8.
  3.  3.  3.  1.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 23. 30. 19. 29.  8.  0.  6.  6.  3.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 6.  8. 10.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6  6 25  0  6 10 16  0  0
  1] -> size -> 25 
adversary victory points: -4
player victory points: 11 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 6.  8. 10.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 14.] 
expected returns: [[0.8220072]
 [1.8152337]
 [1.6151314]
 [1.7988958]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 10.  6. 14.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6  6 25  0  6 10 16  0  0
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 19. 29.  8.  0.  6.  6.  3.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [11.  1. 11.  0. 16.] 
adversary cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.  8.
  3.  3.  3.  1.  3.  3.  0.  1.  8.  3.  3.] 
adversary owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8  3] -> size -> 34 
adversary victory points: 11
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -159 

action type: buy - action -1
Learning step: -8.27897834777832
desired expected reward: -0.9807710647583008



action possibilites: [-1] 
expected returns: [[44.867886]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 19. 29.  8.  0.  6.  6.  3.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [11.  1. 11.  0. 16.] 
adversary cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.  8.
  3.  3.  3.  1.  3.  3.  0.  1.  8.  3.  3.] 
adversary owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8  3] -> size -> 34 
adversary victory points: 11
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -128 

action type: trash_cards_n_from_hand - action 5
Learning step: -5.476914405822754
desired expected reward: -3.748077392578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[38.48721]
 [44.32223]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 23. 30. 19. 29.  8.  0.  6.  6.  3.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [11.  1. 11.  0. 16.] 
adversary cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.  8.
  3.  3.  3.  1.  3.  3.  0.  1.  8.  3.  3.] 
adversary owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8  3] -> size -> 34 
adversary victory points: 11
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -128 

action type: take_action - action -1
Learning step: -7.693520545959473
desired expected reward: 37.17436599731445






Player: 1 
cards in hand: [11.  1. 11.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 11.  0. 16.] 
cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.  8.
  3.  3.  3.  1.  3.  3.  0.  1.  8.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 19. 29.  8.  0.  6.  6.  3.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1] -> size -> 23 
adversary victory points: -3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 11.  0. 16.] 
cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.  8.
  3.  3.  3.  1.  3.  3.  0.  1.  8.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 23. 30. 19. 29.  8.  0.  6.  6.  3.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1] -> size -> 23 
adversary victory points: -3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 11.  0. 16.] 
cards in discard: [25.  0.  6.  0.  1.  0.  4. 14.  3.  8.  0.  1. 11. 15.  3. 22.  8.  8.
  3.  3.  3.  1.  3.  3.  0.  1.  8.  3.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8  3  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 19. 29.  8.  0.  6.  6.  3.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1] -> size -> 23 
adversary victory points: -3
player victory points: 11 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-8.1947155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  6. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 19. 29.  8.  0.  6.  6.  3.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  8.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8  3  1] -> size -> 35 
adversary victory points: 11
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -148 

action type: buy - action -1.0
Learning step: -9.287480354309082
desired expected reward: 24.774494171142578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-8.195779 ]
 [-8.640715 ]
 [-7.7093797]
 [-6.1212263]
 [-8.352438 ]
 [-8.052864 ]
 [-8.641291 ]
 [-9.141256 ]
 [-8.5889435]
 [-6.2515893]
 [-7.2433643]
 [-7.6042037]
 [-5.837928 ]
 [-7.4040008]
 [-8.1947155]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  6. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 22. 30. 19. 29.  8.  0.  6.  6.  3.  8.  9.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  8.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8  3  1] -> size -> 35 
adversary victory points: 11
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -148 

action type: take_action - action -1.0
Learning step: -7.152374267578125
desired expected reward: -15.347089767456055



buy possibilites: [-1] 
expected returns: [[-0.6649728]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  6. 14. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 22. 30. 19. 29.  8.  0.  6.  6.  3.  8.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  8.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8  3  1] -> size -> 35 
adversary victory points: 11
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -140.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    8.    0.] 
sum of rewards: -140.0 

action type: buy - action 29.0
Learning step: -6.585515022277832
desired expected reward: -15.174459457397461






Player: 1 
cards in hand: [ 1.  8.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0.  8. 16.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8  3  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 19. 29.  8.  0.  6.  6.  3.  8.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [16.  6.  0.  8.  1.] 
adversary cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29] -> size -> 24 
adversary victory points: -3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0.  8. 16.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8  3  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 22. 30. 19. 29.  8.  0.  6.  6.  3.  8.  8.  8.  9.  7.  9.  9.] 
adversary cards in hand: [16.  6.  0.  8.  1.] 
adversary cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29] -> size -> 24 
adversary victory points: -3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0.  8. 16.] 
cards in discard: [10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8  3  1 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 19. 29.  8.  0.  6.  6.  3.  8.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [16.  6.  0.  8.  1.] 
adversary cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29] -> size -> 24 
adversary victory points: -3
player victory points: 11 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [16.  6.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[26.512096]
 [24.370708]
 [24.673592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0.  8.  1.] 
cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 19. 29.  8.  0.  6.  6.  3.  8.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [3. 0. 6. 8. 0.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.] 
adversary owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8  3  1 10] -> size -> 36 
adversary victory points: 11
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -148 

action type: buy - action -1
Learning step: -6.79177188873291
desired expected reward: -7.45674467086792





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[26.773455]
 [27.605953]
 [27.785744]
 [28.963223]
 [27.355787]
 [27.492588]
 [29.698463]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  0.  8.  1.] 
cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 22. 30. 19. 29.  8.  0.  6.  6.  3.  8.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [3. 0. 6. 8. 0.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.] 
adversary owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8  3  1 10] -> size -> 36 
adversary victory points: 11
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -148 

action type: take_action - action -1.0
Learning step: -8.085723876953125
desired expected reward: 18.426387786865234



buy possibilites: [-1] 
expected returns: [[5.5230308]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  0.  8.  1.] 
cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 22. 30. 19. 29.  8.  0.  6.  6.  3.  8.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [3. 0. 6. 8. 0.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.] 
adversary owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8  3  1 10] -> size -> 36 
adversary victory points: 11
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -140.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -178.0 

action type: buy - action 0.0
Learning step: -10.114404678344727
desired expected reward: 16.659048080444336






Player: 1 
cards in hand: [3. 0. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 8. 0.] 
cards in discard: [10.  1.  8.  0.  8. 16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3
  3  6  3  1  0 25  4 11  8  3  1 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 19. 29.  8.  0.  6.  6.  3.  8.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [16.  1.  0.  0.  0.] 
adversary cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.  0. 16.  6.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29
  0] -> size -> 25 
adversary victory points: -3
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [10.  1.  8.  0.  8. 16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 19. 29.  8.  0.  6.  6.  3.  8.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [16.  1.  0.  0.  0.] 
adversary cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.  0. 16.  6.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29
  0] -> size -> 25 
adversary victory points: -3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [10.  1.  8.  0.  8. 16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 22. 30. 19. 29.  8.  0.  6.  6.  3.  8.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [16.  1.  0.  0.  0.] 
adversary cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.  0. 16.  6.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29
  0] -> size -> 25 
adversary victory points: -3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [10.  1.  8.  0.  8. 16.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 18. 29.  8.  0.  6.  6.  3.  8.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [16.  1.  0.  0.  0.] 
adversary cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.  0. 16.  6.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29
  0] -> size -> 25 
adversary victory points: -3
player victory points: 11 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [16.  1.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[32.279408]
 [28.23352 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  0.  0.  0.] 
cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.  0. 16.  6.  0.  8.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 18. 29.  8.  0.  6.  6.  3.  8.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3] -> size -> 36 
adversary victory points: 11
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -148 

action type: buy - action -1
Learning step: -6.9827141761779785
desired expected reward: -1.4596834182739258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[25.505518]
 [27.82643 ]
 [27.272078]
 [22.531961]
 [26.512512]
 [29.588886]
 [27.066433]
 [31.20842 ]
 [27.35051 ]
 [23.305294]
 [25.011301]
 [26.768051]
 [22.41553 ]
 [25.830856]
 [30.88219 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0.  0.  0.] 
cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.  0. 16.  6.  0.  8.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 22. 30. 18. 29.  8.  0.  6.  6.  3.  8.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3] -> size -> 36 
adversary victory points: 11
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -148 

action type: take_action - action -1.0
Learning step: -8.386531829833984
desired expected reward: 23.89287567138672



buy possibilites: [-1] 
expected returns: [[57.988277]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0.  0.  0.] 
cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.  0. 16.  6.  0.  8.  1. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29
  0 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3] -> size -> 36 
adversary victory points: 11
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -140    0    0    0    0    0    0    0    0    0    0
   50    0] 
sum of rewards: -98 

action type: buy - action 25.0
Learning step: -5.155684947967529
desired expected reward: 26.052730560302734






Player: 1 
cards in hand: [0. 3. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [25.  6.  0.  8.  0.] 
adversary cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.  0. 16.  6.  0.  8.  1. 25. 16.  1.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29
  0 25] -> size -> 26 
adversary victory points: -3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [25.  6.  0.  8.  0.] 
adversary cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.  0. 16.  6.  0.  8.  1. 25. 16.  1.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29
  0 25] -> size -> 26 
adversary victory points: -3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [25.  6.  0.  8.  0.] 
adversary cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.  0. 16.  6.  0.  8.  1. 25. 16.  1.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29
  0 25] -> size -> 26 
adversary victory points: -3
player victory points: 11 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [25.  6.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[11.5981045]
 [13.351318 ]
 [ 1.3633122]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.  0.  8.  0.] 
cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.  0. 16.  6.  0.  8.  1. 25. 16.  1.
  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  1  8 14  0  0  8  8  6  6 25  0  6 16  0  0  1 29
  0 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [15.  1. 11.  3. 14.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0] -> size -> 37 
adversary victory points: 11
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -148 

action type: buy - action -1
Learning step: -10.07338809967041
desired expected reward: 47.91489028930664



action possibilites: [-1] 
expected returns: [[-1.7708197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.] 
cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.  0. 16.  6.  0.  8.  1. 25. 16.  1.
  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [15.  1. 11.  3. 14.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -117 

action type: trash_cards_n_from_hand - action 9
Learning step: -6.320321559906006
desired expected reward: 2.289247989654541





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-0.62333584]
 [ 0.8285198 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.] 
cards in discard: [ 8.  6. 14. 29.  0.  0.  0.  0.  0.  0. 16.  6.  0.  8.  1. 25. 16.  1.
  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [15.  1. 11.  3. 14.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -117 

action type: take_action - action -1
Learning step: -5.754605293273926
desired expected reward: -7.525424957275391






Player: 1 
cards in hand: [15.  1. 11.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 11.  3. 14.] 
cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 14. 29.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25] -> size -> 23 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1. 11.  3. 14.] 
cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 14. 29.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25] -> size -> 23 
adversary victory points: -2
player victory points: 11 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 0. 14. 29.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
expected returns: [[20.316488]
 [11.694254]
 [16.932695]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 29.  6.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [11.  8.  3.  1. 22.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -137 

action type: buy - action -1.0
Learning step: -6.499291896820068
desired expected reward: -5.6707563400268555



action possibilites: [-1.  8.] 
expected returns: [[23.943024]
 [22.572075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8.] 
cards in discard: [14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [11.  8.  3.  1. 22.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -117 

action type: discard_n_cards - action 3
Learning step: -6.003013610839844
desired expected reward: 10.114187240600586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[21.184914]
 [21.88291 ]
 [21.713543]
 [22.417423]
 [21.667065]
 [21.582573]
 [22.850372]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8.] 
cards in discard: [14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  6.  9.  9.] 
adversary cards in hand: [11.  8.  3.  1. 22.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -117 

action type: take_action - action -1.0
Learning step: -6.548452854156494
desired expected reward: 17.394563674926758



buy possibilites: [-1] 
expected returns: [[-6.467676]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8.] 
cards in discard: [14. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  5.  9.  9.] 
adversary cards in hand: [11.  8.  3.  1. 22.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0   20    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -99 

action type: buy - action 10.0
Learning step: -6.174651622772217
desired expected reward: 15.40792465209961






Player: 1 
cards in hand: [11.  8.  3.  1. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.  1. 22.] 
cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  5.  9.  9.] 
adversary cards in hand: [ 0.  8. 25. 16. 25.] 
adversary cards in discard: [14. 10. 29.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10] -> size -> 24 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3.  1. 22.] 
cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  5.  9.  9.] 
adversary cards in hand: [ 0.  8. 25. 16. 25.] 
adversary cards in discard: [14. 10. 29.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10] -> size -> 24 
adversary victory points: -2
player victory points: 11 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 25. 16. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 16. 25.] 
expected returns: [[ -8.852084]
 [ -8.825312]
 [-10.090004]
 [ -8.457196]
 [-10.090004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 25. 16. 25.] 
cards in discard: [14. 10. 29.  0.  6.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  5.  9.  9.] 
adversary cards in hand: [ 3.  0.  1. 11.  1.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14. 11.  8.  3.  1. 22.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -137 

action type: buy - action -1
Learning step: -6.729986667633057
desired expected reward: -13.197662353515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-8.087292]
 [-9.030123]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 25. 16. 25.] 
cards in discard: [14. 10. 29.  0.  6.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  5.  9.  9.] 
adversary cards in hand: [ 3.  0.  1. 11.  1.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14. 11.  8.  3.  1. 22.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -137 

action type: take_action - action -1.0
Learning step: -6.597015380859375
desired expected reward: -15.449100494384766



buy possibilites: [-1] 
expected returns: [[-6.8302894]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 25. 16. 25.] 
cards in discard: [14. 10. 29.  0.  6.  0.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  5.  9.  9.] 
adversary cards in hand: [ 3.  0.  1. 11.  1.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14. 11.  8.  3.  1. 22.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2. -130.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -167.0 

action type: buy - action 0.0
Learning step: -8.099316596984863
desired expected reward: -16.186603546142578






Player: 1 
cards in hand: [ 3.  0.  1. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 11.  1.] 
cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14. 11.  8.  3.  1. 22.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  8.  8.  9.  5.  9.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [14. 10. 29.  0.  6.  0.  8.  0.  0.  8. 25. 16. 25.] 
adversary owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10
  0] -> size -> 25 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 1.] 
cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14. 11.  8.  3.  1. 22. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  7.  8.  9.  5.  9.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [14. 10. 29.  0.  6.  0.  8.  0.  0.  8. 25. 16. 25.] 
adversary owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10
  0] -> size -> 25 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 1.] 
cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14. 11.  8.  3.  1. 22. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0 29] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  7.  8.  9.  5.  9.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [14. 10. 29.  0.  6.  0.  8.  0.  0.  8. 25. 16. 25.] 
adversary owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10
  0] -> size -> 25 
adversary victory points: -2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 1.] 
cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14. 11.  8.  3.  1. 22. 29. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0 29 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [14. 10. 29.  0.  6.  0.  8.  0.  0.  8. 25. 16. 25.] 
adversary owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10
  0] -> size -> 25 
adversary victory points: -2
player victory points: 11 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[ 0.75978184]
 [-1.1235919 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [14. 10. 29.  0.  6.  0.  8.  0.  0.  8. 25. 16. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  4.  3.  0. 25.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14. 11.  8.  3.  1. 22. 29. 15. 11.  3.  0.  1.  1.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0 29 15] -> size -> 39 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -137 

action type: buy - action -1
Learning step: -6.5066819190979
desired expected reward: -13.336971282958984



action possibilites: [-1] 
expected returns: [[-19.126244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [14. 10. 29.  0.  6.  0.  8.  0.  0.  8. 25. 16. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  4.  3.  0. 25.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14. 11.  8.  3.  1. 22. 29. 15. 11.  3.  0.  1.  1.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0 29 15] -> size -> 39 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -117 

action type: trash_cards_n_from_hand - action 3
Learning step: -6.201770782470703
desired expected reward: -7.773163318634033





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-20.207438]
 [-19.353569]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [14. 10. 29.  0.  6.  0.  8.  0.  0.  8. 25. 16. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  4.  3.  0. 25.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14. 11.  8.  3.  1. 22. 29. 15. 11.  3.  0.  1.  1.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0 29 15] -> size -> 39 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -117 

action type: take_action - action -1
Learning step: -5.336076259613037
desired expected reward: -24.46232032775879



buy possibilites: [-1] 
expected returns: [[-16.818123]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [14. 10. 29.  0.  6.  0.  8.  0.  0.  8. 25. 16. 25.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  4.  3.  0. 25.] 
adversary cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14. 11.  8.  3.  1. 22. 29. 15. 11.  3.  0.  1.  1.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0 29 15] -> size -> 39 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0   20  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -147 

action type: buy - action 0.0
Learning step: -6.71803617477417
desired expected reward: -26.92548179626465






Player: 1 
cards in hand: [ 3.  4.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  4.  3.  0. 25.] 
cards in discard: [10.  1.  8.  0.  8. 16.  3.  8.  0.  6.  0.  0.  0.  3.  3.  3.  1. 15.
  1. 11.  3. 14. 11.  8.  3.  1. 22. 29. 15. 11.  3.  0.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0 29 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0.  0.  1. 16.] 
adversary cards in discard: [14. 10. 29.  0.  6.  0.  8.  0.  0.  8. 25. 16. 25.  0.  8.] 
adversary owned cards: [16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0] -> size -> 22 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  4.  3.  0.  1. 16.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0 29 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0.  0.  1. 16.] 
adversary cards in discard: [14. 10. 29.  0.  6.  0.  8.  0.  0.  8. 25. 16. 25.  0.  8.] 
adversary owned cards: [16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0] -> size -> 22 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  4.  3.  0.  1. 16.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0 29 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 22. 30. 18. 29.  8.  0.  6.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0.  0.  1. 16.] 
adversary cards in discard: [14. 10. 29.  0.  6.  0.  8.  0.  0.  8. 25. 16. 25.  0.  8.] 
adversary owned cards: [16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0] -> size -> 22 
adversary victory points: -2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  4.  3.  0.  1. 16.] 
cards in discard: [3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0 29 15  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 22. 30. 17. 29.  8.  0.  6.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0.  0.  1. 16.] 
adversary cards in discard: [14. 10. 29.  0.  6.  0.  8.  0.  0.  8. 25. 16. 25.  0.  8.] 
adversary owned cards: [16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0] -> size -> 22 
adversary victory points: -2
player victory points: 12 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[-10.749348]
 [-16.354815]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  1. 16.] 
cards in discard: [14. 10. 29.  0.  6.  0.  8.  0.  0.  8. 25. 16. 25.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  1  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 17. 29.  8.  0.  6.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [8. 0. 8. 3. 3.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0 29 15  3] -> size -> 40 
adversary victory points: 12
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -147 

action type: buy - action -1
Learning step: -6.79646635055542
desired expected reward: -23.61458969116211



action possibilites: [-1] 
expected returns: [[-12.951893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [14. 10. 29.  0.  6.  0.  8.  0.  0.  8. 25. 16. 25.  0.  8. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [8. 0. 8. 3. 3.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0 29 15  3] -> size -> 40 
adversary victory points: 12
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -140    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -111 

action type: gain_card_n - action 4
Learning step: -5.482165813446045
desired expected reward: -12.66720962524414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-19.418716]
 [-18.424429]
 [-16.835619]
 [-15.399204]
 [-19.085806]
 [-17.095545]
 [-12.783058]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [14. 10. 29.  0.  6.  0.  8.  0.  0.  8. 25. 16. 25.  0.  8. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [8. 0. 8. 3. 3.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.] 
adversary owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0 29 15  3] -> size -> 40 
adversary victory points: 12
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -127 

action type: take_action - action -1
Learning step: -6.05859899520874
desired expected reward: -19.0104923248291






Player: 1 
cards in hand: [8. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 3. 3.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8 11  0  1  0  0  3  3  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3
  6  3  1  0 25  4 11  8  3  1 10  3  0 29 15  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 8. 14.  0.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0 16] -> size -> 22 
adversary victory points: -2
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 8. 14.  0.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0 16] -> size -> 22 
adversary victory points: -2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 8. 14.  0.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0 16] -> size -> 22 
adversary victory points: -2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 8. 14.  0.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0 16] -> size -> 22 
adversary victory points: -2
player victory points: 10 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 8. 14.  0.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[-13.046677]
 [-15.127308]
 [-15.601826]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  1.  6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [3. 3. 6. 3. 1.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0] -> size -> 38 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -127 

action type: buy - action -1.0
Learning step: -6.0294904708862305
desired expected reward: -18.812549591064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-12.449014]
 [-12.835146]
 [-11.852468]
 [-11.944514]
 [-12.84232 ]
 [-11.744072]
 [-11.481873]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  0.  1.  6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [3. 3. 6. 3. 1.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0] -> size -> 38 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -127 

action type: take_action - action -1.0
Learning step: -5.97519588470459
desired expected reward: -18.859722137451172



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 3. 6. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 3. 1.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [ 8. 14.  0.  1.  6.] 
adversary owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0 16] -> size -> 22 
adversary victory points: -2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 3. 1.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [ 8. 14.  0.  1.  6.] 
adversary owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0 16] -> size -> 22 
adversary victory points: -2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 3. 1.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [ 8. 14.  0.  1.  6.] 
adversary owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0 16] -> size -> 22 
adversary victory points: -2
player victory points: 10 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [25.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-12.535986]
 [-13.520564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [ 8. 14.  0.  1.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [15.  0. 14.  8. 29.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0] -> size -> 39 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -127 

action type: buy - action -1.0
Learning step: -6.065959930419922
desired expected reward: -17.547832489013672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-13.759603 ]
 [-14.260685 ]
 [-13.35289  ]
 [-13.964769 ]
 [-13.636627 ]
 [-14.21015  ]
 [-14.2153425]
 [-12.411343 ]
 [-13.248337 ]
 [-13.09456  ]
 [-13.679033 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [ 8. 14.  0.  1.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  8.  9.  5.  9.  8.] 
adversary cards in hand: [15.  0. 14.  8. 29.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0] -> size -> 39 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -127 

action type: take_action - action -1.0
Learning step: -6.022102355957031
desired expected reward: -18.558086395263672



buy possibilites: [-1] 
expected returns: [[-6.963978]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [ 8. 14.  0.  1.  6. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0 16 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  7.  9.  5.  9.  8.] 
adversary cards in hand: [15.  0. 14.  8. 29.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0] -> size -> 39 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0    0    0    0    0    0    0    0    0
   32    0] 
sum of rewards: -95 

action type: buy - action 14.0
Learning step: -4.2861223220825195
desired expected reward: -16.697467803955078






Player: 1 
cards in hand: [15.  0. 14.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 14.  8. 29.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  7.  9.  5.  9.  8.] 
adversary cards in hand: [ 8. 29.  8. 16.  0.] 
adversary cards in discard: [ 8. 14.  0.  1.  6. 14. 25.  0.  0.  0.  0.] 
adversary owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0 16 14] -> size -> 23 
adversary victory points: -2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 14.  8. 29.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  7.  9.  5.  9.  8.] 
adversary cards in hand: [ 8. 29.  8. 16.  0.] 
adversary cards in discard: [ 8. 14.  0.  1.  6. 14. 25.  0.  0.  0.  0.] 
adversary owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0 16 14] -> size -> 23 
adversary victory points: -2
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 8. 29.  8. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8. 16.] 
expected returns: [[-13.09971 ]
 [-12.415227]
 [-12.418053]
 [-12.415227]
 [-11.75957 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  8. 16.  0.] 
cards in discard: [ 8. 14.  0.  1.  6. 14. 25.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1 29  0 25 10  0  0 16 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  7.  9.  5.  9.  8.] 
adversary cards in hand: [ 0. 22.  3.  0.  1.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0] -> size -> 39 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -127 

action type: buy - action -1
Learning step: -6.277141571044922
desired expected reward: -13.241119384765625



action possibilites: [-1] 
expected returns: [[-12.752781]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0.] 
cards in discard: [ 8. 14.  0.  1.  6. 14. 25.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  7.  9.  5.  9.  8.] 
adversary cards in hand: [ 0. 22.  3.  0.  1.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0] -> size -> 39 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: trash_cards_n_from_hand - action 1
Learning step: -4.956049919128418
desired expected reward: -18.573810577392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-18.058704]
 [-12.543626]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  0.] 
cards in discard: [ 8. 14.  0.  1.  6. 14. 25.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  7.  9.  5.  9.  8.] 
adversary cards in hand: [ 0. 22.  3.  0.  1.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0] -> size -> 39 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: take_action - action -1
Learning step: -5.039371013641357
desired expected reward: -17.792152404785156



buy possibilites: [-1] 
expected returns: [[-6.246787]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  0.] 
cards in discard: [ 8. 14.  0.  1.  6. 14. 25.  0.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  7.  9.  5.  9.  8.] 
adversary cards in hand: [ 0. 22.  3.  0.  1.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0] -> size -> 39 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2. -120.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -137.0 

action type: buy - action 0.0
Learning step: -6.08761739730835
desired expected reward: -24.146318435668945






Player: 1 
cards in hand: [ 0. 22.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  3.  0.  1.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  7.  9.  5.  9.  8.] 
adversary cards in hand: [25.  0. 16. 16.  0.] 
adversary cards in discard: [ 8. 14.  0.  1.  6. 14. 25.  0.  0.  0.  0.  0.  8.  8. 16.  0.] 
adversary owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0] -> size -> 23 
adversary victory points: -2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  3.  0.  1.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  6.  3.  7.  7.  7.  9.  5.  9.  8.] 
adversary cards in hand: [25.  0. 16. 16.  0.] 
adversary cards in discard: [ 8. 14.  0.  1.  6. 14. 25.  0.  0.  0.  0.  0.  8.  8. 16.  0.] 
adversary owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0] -> size -> 23 
adversary victory points: -2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  3.  0.  1.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  6.  2.  7.  7.  7.  9.  5.  9.  8.] 
adversary cards in hand: [25.  0. 16. 16.  0.] 
adversary cards in discard: [ 8. 14.  0.  1.  6. 14. 25.  0.  0.  0.  0.  0.  8.  8. 16.  0.] 
adversary owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0] -> size -> 23 
adversary victory points: -2
player victory points: 10 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [25.  0. 16. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 16. 16.] 
expected returns: [[-9.161077]
 [-9.881464]
 [-8.760362]
 [-8.760362]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 16. 16.  0.] 
cards in discard: [ 8. 14.  0.  1.  6. 14. 25.  0.  0.  0.  0.  0.  8.  8. 16.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  6.  2.  7.  7.  7.  9.  5.  9.  8.] 
adversary cards in hand: [10.  0.  0. 11. 11.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.  8.  0. 22.  3.  0.  1.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8] -> size -> 40 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -127 

action type: buy - action -1
Learning step: -6.2409467697143555
desired expected reward: -12.487733840942383



action possibilites: [-1] 
expected returns: [[-9.545197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.] 
cards in discard: [ 8. 14.  0.  1.  6. 14. 25.  0.  0.  0.  0.  0.  8.  8. 16.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  6.  2.  7.  7.  7.  9.  5.  9.  7.] 
adversary cards in hand: [10.  0.  0. 11. 11.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.  8.  0. 22.  3.  0.  1.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8] -> size -> 40 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -91 

action type: gain_card_n - action 14
Learning step: -3.5232574939727783
desired expected reward: -28.353450775146484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ -9.668509]
 [ -9.204038]
 [-10.186062]
 [ -9.490714]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.] 
cards in discard: [ 8. 14.  0.  1.  6. 14. 25.  0.  0.  0.  0.  0.  8.  8. 16.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  6.  2.  7.  7.  7.  9.  5.  9.  7.] 
adversary cards in hand: [10.  0.  0. 11. 11.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.  8.  0. 22.  3.  0.  1.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8] -> size -> 40 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: take_action - action -1
Learning step: -5.086867332458496
desired expected reward: -14.632063865661621



buy possibilites: [-1] 
expected returns: [[-6.963978]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.] 
cards in discard: [ 8. 14.  0.  1.  6. 14. 25.  0.  0.  0.  0.  0.  8.  8. 16.  0. 15.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  6.  1.  7.  7.  7.  9.  5.  9.  7.] 
adversary cards in hand: [10.  0.  0. 11. 11.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.  8.  0. 22.  3.  0.  1.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8] -> size -> 40 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0   20    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -99 

action type: buy - action 8.0
Learning step: -4.597386360168457
desired expected reward: -14.783448219299316






Player: 1 
cards in hand: [10.  0.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11. 11.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.  8.  0. 22.  3.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  6.  1.  7.  7.  7.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  0. 14. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8] -> size -> 24 
adversary victory points: -2
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.  8.  0. 22.  3.  0.  1. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  5.  1.  7.  7.  7.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  0. 14. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8] -> size -> 24 
adversary victory points: -2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.  8.  0. 22.  3.  0.  1. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  5.  1.  7.  7.  7.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  0. 14. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8] -> size -> 24 
adversary victory points: -2
player victory points: 10 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 14. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[-12.342911]
 [-11.8714  ]
 [-12.377244]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14. 10.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  5.  1.  7.  7.  7.  9.  5.  9.  7.] 
adversary cards in hand: [15.  1. 11.  1.  3.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.  8.  0. 22.  3.  0.  1. 11. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11] -> size -> 41 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -127 

action type: buy - action -1
Learning step: -6.274198055267334
desired expected reward: -13.238176345825195



action possibilites: [-1. 14. 25.] 
expected returns: [[-10.200277 ]
 [ -6.4041357]
 [-11.162819 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  6. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  5.  1.  7.  7.  7.  9.  5.  9.  7.] 
adversary cards in hand: [15.  1. 11.  1.  3.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.  8.  0. 22.  3.  0.  1. 11. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11] -> size -> 41 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: take_action - action 10.0
Learning step: -4.880141735076904
desired expected reward: -18.085285186767578



action possibilites: [-1. 25.] 
expected returns: [[11.546686]
 [11.335934]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  5.  1.  7.  7.  7.  9.  5.  9.  7.] 
adversary cards in hand: [ 1. 11.  1.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.  8.  0. 22.  3.  0.  1. 11. 11. 10.  0.  0. 11. 15.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11] -> size -> 41 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -87 

action type: take_action - action 14.0
Learning step: -3.7717041969299316
desired expected reward: -10.175834655761719



action possibilites: [-1] 
expected returns: [[2.6651502]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  0. 25.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 14. 25.] 
owned cards: [ 8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  5.  1.  7.  7.  7.  9.  5.  9.  7.] 
adversary cards in hand: [ 1. 11.  1.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.  8.  0. 22.  3.  0.  1. 11. 11. 10.  0.  0. 11. 15.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11] -> size -> 41 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0   60    0    0    0    0    0    0    0
    0    1] 
sum of rewards: -66 

action type: take_action - action 25.0
Learning step: -3.8068301677703857
desired expected reward: 7.5290937423706055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[1.9710817]
 [1.4957237]
 [1.9888229]
 [1.6431198]
 [1.765347 ]
 [1.776093 ]
 [1.6104412]
 [2.8235884]
 [1.7237387]
 [1.9149466]
 [2.4596896]
 [2.1578202]
 [1.5796638]
 [2.4332242]
 [2.2375536]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  0. 25.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 14. 25.] 
owned cards: [ 8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  5.  1.  7.  7.  7.  9.  5.  9.  7.] 
adversary cards in hand: [ 1. 11.  1.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.  8.  0. 22.  3.  0.  1. 11. 11. 10.  0.  0. 11. 15.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11] -> size -> 41 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -3.4335544109344482
desired expected reward: -0.7684042453765869



buy possibilites: [-1] 
expected returns: [[-10.244905]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  0. 25.] 
cards in discard: [25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 14. 25.] 
owned cards: [ 8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  5.  1.  6.  7.  7.  9.  5.  9.  7.] 
adversary cards in hand: [ 1. 11.  1.] 
adversary cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.  8.  0. 22.  3.  0.  1. 11. 11. 10.  0.  0. 11. 15.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11] -> size -> 41 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0   60    0    0    0    0    0    0    0
   50    0] 
sum of rewards: -17 

action type: buy - action 25.0
Learning step: -1.221690058708191
desired expected reward: 1.6019035577774048






Player: 1 
cards in hand: [ 1. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  1.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.  8.  0. 22.  3.  0.  1. 11. 11. 10.  0.  0. 11. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  5.  1.  6.  7.  7.  9.  5.  9.  7.] 
adversary cards in hand: [ 6. 15.  0.  8. 16.] 
adversary cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.] 
adversary owned cards: [ 8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8
 25] -> size -> 25 
adversary victory points: -2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  1.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.  8.  0. 22.  3.  0.  1. 11. 11. 10.  0.  0. 11. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  5.  1.  6.  7.  7.  9.  5.  9.  7.] 
adversary cards in hand: [ 6. 15.  0.  8. 16.] 
adversary cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.] 
adversary owned cards: [ 8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8
 25] -> size -> 25 
adversary victory points: -2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  1.] 
cards in discard: [ 3. 25.  3.  4.  3.  0.  1. 16.  0.  8.  8.  0.  3.  3.  6.  3.  1. 15.
  0. 14.  8. 29.  8.  0. 22.  3.  0.  1. 11. 11. 10.  0.  0. 11. 15.  3.
 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  5.  1.  6.  6.  7.  9.  5.  9.  7.] 
adversary cards in hand: [ 6. 15.  0.  8. 16.] 
adversary cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.] 
adversary owned cards: [ 8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8
 25] -> size -> 25 
adversary victory points: -2
player victory points: 10 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 6. 15.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 16.] 
expected returns: [[-25.16955 ]
 [-26.094614]
 [-27.652788]
 [-27.227442]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.  8. 16.] 
cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  0  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 17. 29.  8.  0.  5.  5.  1.  6.  6.  7.  9.  5.  9.  7.] 
adversary cards in hand: [3. 0. 0. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29] -> size -> 42 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -127 

action type: buy - action -1
Learning step: -6.426260471343994
desired expected reward: -16.671165466308594



action possibilites: [-1] 
expected returns: [[-15.25625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  8.] 
cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 14  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  1.  6.  6.  7.  9.  5.  9.  7.] 
adversary cards in hand: [3. 0. 0. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29] -> size -> 42 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0   20    0    0    0    0    0    0    0
    4    0] 
sum of rewards: -92 

action type: gain_card_n - action 1
Learning step: -3.889364719390869
desired expected reward: -24.96738052368164





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-15.306778]
 [-14.994616]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  8.] 
cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 14  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  1.  6.  6.  7.  9.  5.  9.  7.] 
adversary cards in hand: [3. 0. 0. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29] -> size -> 42 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -96 

action type: take_action - action -1
Learning step: -4.377100944519043
desired expected reward: -19.633350372314453






Player: 1 
cards in hand: [3. 0. 0. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 1.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  1.  6.  6.  7.  9.  5.  9.  7.] 
adversary cards in hand: [ 8.  0.  0. 14.  1.] 
adversary cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.  3. 16.  6. 15.  8.] 
adversary owned cards: [ 8 14  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25
  3] -> size -> 25 
adversary victory points: -1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 1.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  1.  6.  6.  7.  9.  5.  9.  7.] 
adversary cards in hand: [ 8.  0.  0. 14.  1.] 
adversary cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.  3. 16.  6. 15.  8.] 
adversary owned cards: [ 8 14  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25
  3] -> size -> 25 
adversary victory points: -1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 1.] 
cards in discard: [10.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  1.  6.  6.  7.  9.  4.  9.  7.] 
adversary cards in hand: [ 8.  0.  0. 14.  1.] 
adversary cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.  3. 16.  6. 15.  8.] 
adversary owned cards: [ 8 14  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25
  3] -> size -> 25 
adversary victory points: -1
player victory points: 10 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  0. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[ -8.5847645]
 [-14.1327   ]
 [-12.276325 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 14.  1.] 
cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.  3. 16.  6. 15.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  1.  6.  6.  7.  9.  4.  9.  7.] 
adversary cards in hand: [8. 1. 4. 1. 3.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10] -> size -> 43 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: buy - action -1.0
Learning step: -5.29343843460083
desired expected reward: -20.28805160522461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-12.083824]
 [-11.693775]
 [ -9.267502]
 [-11.694601]
 [ -8.736364]
 [-12.313993]
 [-11.528269]
 [-10.811159]
 [ -9.32272 ]
 [ -9.329582]
 [ -8.547802]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 14.  1.] 
cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.  3. 16.  6. 15.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  1.  6.  6.  7.  9.  4.  9.  7.] 
adversary cards in hand: [8. 1. 4. 1. 3.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10] -> size -> 43 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: take_action - action -1.0
Learning step: -5.594536781311035
desired expected reward: -14.17929744720459



buy possibilites: [-1] 
expected returns: [[-12.893894]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 14.  1.] 
cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.  3. 16.  6. 15.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25
  3 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  1.  6.  6.  7.  9.  3.  9.  7.] 
adversary cards in hand: [8. 1. 4. 1. 3.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10] -> size -> 43 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5.     0.    -1.  -110.     0.     0.     0.     0.     0.     0.
    0.     0.     0.     0.     4.5    0. ] 
sum of rewards: -111.5 

action type: buy - action 10.0
Learning step: -5.398976802825928
desired expected reward: -14.721702575683594






Player: 1 
cards in hand: [8. 1. 4. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 4. 1. 3.] 
cards in discard: [10.  3.  0.  0.  8.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  1.  6.  6.  7.  9.  3.  9.  7.] 
adversary cards in hand: [0. 8. 0. 8. 0.] 
adversary cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.  3. 16.  6. 15.  8. 10.  8.  0.  0.
 14.  1.] 
adversary owned cards: [ 8 14  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25
  3 10] -> size -> 26 
adversary victory points: -1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 4. 1. 3.] 
cards in discard: [10.  3.  0.  0.  8.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  1.  6.  6.  7.  9.  3.  9.  7.] 
adversary cards in hand: [0. 8. 0. 8. 0.] 
adversary cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.  3. 16.  6. 15.  8. 10.  8.  0.  0.
 14.  1.] 
adversary owned cards: [ 8 14  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25
  3 10] -> size -> 26 
adversary victory points: -1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 4. 1. 3.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  1.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [0. 8. 0. 8. 0.] 
adversary cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.  3. 16.  6. 15.  8. 10.  8.  0.  0.
 14.  1.] 
adversary owned cards: [ 8 14  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25
  3 10] -> size -> 26 
adversary victory points: -1
player victory points: 10 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[-12.201944 ]
 [-15.8024235]
 [-15.8024235]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8. 0.] 
cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.  3. 16.  6. 15.  8. 10.  8.  0.  0.
 14.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  0  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25
  3 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  1.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  3. 15.  3.  3.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14] -> size -> 44 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: buy - action -1
Learning step: -5.4688262939453125
desired expected reward: -18.362720489501953



action possibilites: [-1] 
expected returns: [[-16.314837]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.  3. 16.  6. 15.  8. 10.  8.  0.  0.
 14.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25  3 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  1.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  3. 15.  3.  3.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14] -> size -> 44 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -96 

action type: trash_cards_n_from_hand - action 3
Learning step: -4.41040563583374
desired expected reward: -18.577896118164062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-17.760199]
 [-17.638136]
 [-18.270647]
 [-15.342447]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.  3. 16.  6. 15.  8. 10.  8.  0.  0.
 14.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25  3 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  1.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  3. 15.  3.  3.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14] -> size -> 44 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -96 

action type: take_action - action -1
Learning step: -4.360485553741455
desired expected reward: -20.675321578979492



buy possibilites: [-1] 
expected returns: [[-18.462729]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [25. 10. 14. 25.  0.  0.  6.  0. 25.  3. 16.  6. 15.  8. 10.  8.  0.  0.
 14.  1.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25  3 10
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  3. 15.  3.  3.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14] -> size -> 44 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0   20    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -88 

action type: buy - action 8.0
Learning step: -3.901879072189331
desired expected reward: -22.172521591186523






Player: 1 
cards in hand: [ 3.  3. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.  3.  3.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 8.  0. 14.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25  3 10
  8] -> size -> 25 
adversary victory points: -1
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 3.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 8.  0. 14.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25  3 10
  8] -> size -> 25 
adversary victory points: -1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 3.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 22. 30. 16. 29.  8.  0.  5.  5.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 8.  0. 14.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25  3 10
  8] -> size -> 25 
adversary victory points: -1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 3.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 16. 29.  8.  0.  5.  5.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 8.  0. 14.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25  3 10
  8] -> size -> 25 
adversary victory points: -1
player victory points: 10 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 14.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 16.] 
expected returns: [[-8.704633 ]
 [-8.4062805]
 [-5.7024903]
 [-8.053444 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 14.  0. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25  3 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 16. 29.  8.  0.  5.  5.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [11.  1. 25.  1. 29.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0] -> size -> 45 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: buy - action -1
Learning step: -5.037877559661865
desired expected reward: -23.500606536865234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-7.6606  ]
 [-7.49626 ]
 [-8.704633]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 14.  0. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25  3 10
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 22. 30. 16. 29.  8.  0.  5.  5.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [11.  1. 25.  1. 29.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0] -> size -> 45 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: take_action - action -1.0
Learning step: -5.54086446762085
desired expected reward: -14.24549674987793



buy possibilites: [-1] 
expected returns: [[-9.273044]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 14.  0. 16.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25  3 10
  8  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 15. 29.  8.  0.  5.  5.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [11.  1. 25.  1. 29.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0] -> size -> 45 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -97 

action type: buy - action 3.0
Learning step: -4.683830261230469
desired expected reward: -12.18009090423584






Player: 1 
cards in hand: [11.  1. 25.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 25.  1. 29.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 15. 29.  8.  0.  5.  5.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 8.  0.  8. 16.  1.] 
adversary cards in discard: [ 3.  8.  0. 14.  0. 16.] 
adversary owned cards: [14  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25  3 10
  8  3] -> size -> 26 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  1. 29.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 15. 29.  8.  0.  5.  4.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 8.  0.  8. 16.  1.] 
adversary cards in discard: [ 3.  8.  0. 14.  0. 16.] 
adversary owned cards: [14  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25  3 10
  8  3] -> size -> 26 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  1. 29.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 22. 30. 15. 29.  8.  0.  5.  4.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 8.  0.  8. 16.  1.] 
adversary cards in discard: [ 3.  8.  0. 14.  0. 16.] 
adversary owned cards: [14  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25  3 10
  8  3] -> size -> 26 
adversary victory points: 0
player victory points: 10 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  8. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16.] 
expected returns: [[-13.001713 ]
 [-13.737553 ]
 [-13.737553 ]
 [-12.9963875]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 16.  1.] 
cards in discard: [ 3.  8.  0. 14.  0. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6 25  0  6 16  0  0  1  0 25 10  0  0 16 14  0 15  8 25  3 10
  8  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 15. 29.  8.  0.  5.  4.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  8. 11. 10. 11.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11] -> size -> 46 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1
Learning step: -5.084805965423584
desired expected reward: -14.35784912109375



action possibilites: [-1] 
expected returns: [[2.5945272]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [ 3.  8.  0. 14.  0. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  6 25  0  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 15. 29.  8.  0.  5.  4.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  8. 11. 10. 11.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11] -> size -> 46 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: trash_cards_n_from_hand - action 9
Learning step: -3.4393105506896973
desired expected reward: -18.485570907592773





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[1.4202752]
 [2.8973823]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [ 3.  8.  0. 14.  0. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  6 25  0  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 22. 30. 15. 29.  8.  0.  5.  4.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  8. 11. 10. 11.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11] -> size -> 46 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: -4.326528072357178
desired expected reward: -1.7320008277893066






Player: 1 
cards in hand: [ 3.  8. 11. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11. 10. 11.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 15. 29.  8.  0.  5.  4.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [10.  6. 15.  6.  0.] 
adversary cards in discard: [ 3.  8.  0. 14.  0. 16.  8.  0.  8.] 
adversary owned cards: [14  8  8  6 25  0  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3] -> size -> 24 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11. 10. 11.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11] -> size -> 46 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 22. 30. 15. 29.  8.  0.  5.  4.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [10.  6. 15.  6.  0.] 
adversary cards in discard: [ 3.  8.  0. 14.  0. 16.  8.  0.  8.] 
adversary owned cards: [14  8  8  6 25  0  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3] -> size -> 24 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11. 10. 11.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 15. 29.  8.  0.  5.  4.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [10.  6. 15.  6.  0.] 
adversary cards in discard: [ 3.  8.  0. 14.  0. 16.  8.  0.  8.] 
adversary owned cards: [14  8  8  6 25  0  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3] -> size -> 24 
adversary victory points: 0
player victory points: 10 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [10.  6. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[-10.597359]
 [ -8.788389]
 [ -8.322819]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 15.  6.  0.] 
cards in discard: [ 3.  8.  0. 14.  0. 16.  8.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6 25  0  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 15. 29.  8.  0.  5.  4.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  3. 29.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0] -> size -> 47 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1.0
Learning step: -5.596964359283447
desired expected reward: -2.699583053588867



action possibilites: [-1. 15.] 
expected returns: [[-10.597359]
 [ -8.322819]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  6.  0.  0.] 
cards in discard: [ 3.  8.  0. 14.  0. 16.  8.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [14  8  8  6 25  0  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 15. 29.  8.  0.  5.  4.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  3. 29.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0] -> size -> 47 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    1] 
sum of rewards: -84 

action type: take_action - action 10.0
Learning step: -3.96631121635437
desired expected reward: -12.754700660705566



action possibilites: [-1.] 
expected returns: [[-15.779478]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [ 3.  8.  0. 14.  0. 16.  8.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 3 
card supply: [10. 22. 30. 15. 29.  8.  0.  5.  4.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  3. 29.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0] -> size -> 47 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action 15.0
Learning step: -3.188897132873535
desired expected reward: -11.51171588897705





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-16.7826   ]
 [-16.648342 ]
 [-14.7871685]
 [-16.543825 ]
 [-14.829157 ]
 [-16.680595 ]
 [-15.581268 ]
 [-14.8527565]
 [-14.990322 ]
 [-15.480713 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 3.  8.  0. 14.  0. 16.  8.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 22. 30. 15. 29.  8.  0.  5.  4.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  3. 29.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0] -> size -> 47 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -2.808847427368164
desired expected reward: -18.58832550048828



buy possibilites: [-1] 
expected returns: [[-15.893831]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 3.  8.  0. 14.  0. 16.  8.  0.  8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 22. 30. 15. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  3. 29.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0] -> size -> 47 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5.     0.     0.  -100.     0.     0.    40.     0.     0.     0.
    0.     0.     0.     0.     4.5    0. ] 
sum of rewards: -60.5 

action type: buy - action 11.0
Learning step: -2.641153335571289
desired expected reward: -17.470308303833008






Player: 1 
cards in hand: [ 0.  0. 15.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  3. 29.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 15. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0. 14.  3. 25.  0.] 
adversary cards in discard: [ 3.  8.  0. 14.  0. 16.  8.  0.  8. 11. 10. 15.  6.  6.  0.] 
adversary owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11] -> size -> 24 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 22. 30. 15. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0. 14.  3. 25.  0.] 
adversary cards in discard: [ 3.  8.  0. 14.  0. 16.  8.  0.  8. 11. 10. 15.  6.  6.  0.] 
adversary owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11] -> size -> 24 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 22. 30. 15. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0. 14.  3. 25.  0.] 
adversary cards in discard: [ 3.  8.  0. 14.  0. 16.  8.  0.  8. 11. 10. 15.  6.  6.  0.] 
adversary owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11] -> size -> 24 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 14. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0. 14.  3. 25.  0.] 
adversary cards in discard: [ 3.  8.  0. 14.  0. 16.  8.  0.  8. 11. 10. 15.  6.  6.  0.] 
adversary owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11] -> size -> 24 
adversary victory points: 0
player victory points: 11 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
expected returns: [[-15.284487]
 [-16.219584]
 [-15.700916]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3. 25.  0.] 
cards in discard: [ 3.  8.  0. 14.  0. 16.  8.  0.  8. 11. 10. 15.  6.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 14. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  8.  6.  1. 11.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.  3. 29.  0.  3.
  8.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3] -> size -> 48 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: buy - action -1
Learning step: -5.306525230407715
desired expected reward: -21.200355529785156



action possibilites: [-1] 
expected returns: [[-17.768265]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0. 10. 25.] 
cards in discard: [ 3.  8.  0. 14.  0. 16.  8.  0.  8. 11. 10. 15.  6.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 14. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  8.  6.  1. 11.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.  3. 29.  0.  3.
  8.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3] -> size -> 48 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action 25.0
Learning step: -4.320186614990234
desired expected reward: -20.021106719970703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-17.83819 ]
 [-17.791302]
 [-18.135784]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  0. 10. 25.] 
cards in discard: [ 3.  8.  0. 14.  0. 16.  8.  0.  8. 11. 10. 15.  6.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 22. 30. 14. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  8.  6.  1. 11.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.  3. 29.  0.  3.
  8.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3] -> size -> 48 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action -1
Learning step: -4.264009475708008
desired expected reward: -22.03227424621582



buy possibilites: [-1] 
expected returns: [[-18.624435]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  0. 10. 25.] 
cards in discard: [ 3.  8.  0. 14.  0. 16.  8.  0.  8. 11. 10. 15.  6.  6.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 13. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  8.  6.  1. 11.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.  3. 29.  0.  3.
  8.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3] -> size -> 48 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -100    0    0   20    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -76 

action type: buy - action 3.0
Learning step: -3.329484701156616
desired expected reward: -21.12078857421875






Player: 1 
cards in hand: [ 0.  8.  6.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6.  1. 11.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.  3. 29.  0.  3.
  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 13. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [10.  3.  0.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3] -> size -> 25 
adversary victory points: 1
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 1.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.  3. 29.  0.  3.
  8.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 13. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [10.  3.  0.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3] -> size -> 25 
adversary victory points: 1
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 1.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.  3. 29.  0.  3.
  8.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 21. 30. 13. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [10.  3.  0.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3] -> size -> 25 
adversary victory points: 1
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 1.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.  3. 29.  0.  3.
  8.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [10.  3.  0.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3] -> size -> 25 
adversary victory points: 1
player victory points: 12 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 25.] 
expected returns: [[-14.0130005]
 [-13.140247 ]
 [-13.956781 ]
 [-15.389154 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  8. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [22.  0. 14.  0.  0.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.  3. 29.  0.  3.
  8.  1.  3. 11.  0.  8.  6.  1.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3] -> size -> 50 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -114 

action type: buy - action -1
Learning step: -5.080421447753906
desired expected reward: -23.704856872558594



action possibilites: [-1] 
expected returns: [[-11.124311]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  8.  3. 14.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [22.  0. 14.  0.  0.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.  3. 29.  0.  3.
  8.  1.  3. 11.  0.  8.  6.  1.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3] -> size -> 50 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -94 

action type: take_action - action 25.0
Learning step: -4.1808390617370605
desired expected reward: -19.569997787475586





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ -9.925452]
 [-11.250975]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  8.  3. 14.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [22.  0. 14.  0.  0.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.  3. 29.  0.  3.
  8.  1.  3. 11.  0.  8.  6.  1.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3] -> size -> 50 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -94 

action type: take_action - action -1
Learning step: -4.377869606018066
desired expected reward: -15.502181053161621



buy possibilites: [-1] 
expected returns: [[4.58604]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  8.  3. 14.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [22.  0. 14.  0.  0.] 
adversary cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.  3. 29.  0.  3.
  8.  1.  3. 11.  0.  8.  6.  1.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3] -> size -> 50 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1. -110.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -124.0 

action type: buy - action 0.0
Learning step: -5.600541591644287
desired expected reward: -15.525993347167969






Player: 1 
cards in hand: [22.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 14.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0. 14.  0.  0.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.  3. 29.  0.  3.
  8.  1.  3. 11.  0.  8.  6.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0. 10. 14.  6. 25.] 
adversary cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.] 
adversary owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0. 16.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.  3. 29.  0.  3.
  8.  1.  3. 11.  0.  8.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0. 10. 14.  6. 25.] 
adversary cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.] 
adversary owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0. 16.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.  3. 29.  0.  3.
  8.  1.  3. 11.  0.  8.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0. 10. 14.  6. 25.] 
adversary cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.] 
adversary owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0. 16.] 
cards in discard: [10.  3.  0.  0.  8.  1. 14.  8.  1.  4.  1.  3.  0. 15.  3.  3.  3.  3.
 11. 11.  1. 25.  1. 29.  0.  3.  8. 11. 10. 11.  0. 15.  3. 29.  0.  3.
  8.  1.  3. 11.  0.  8.  6.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0. 10. 14.  6. 25.] 
adversary cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.] 
adversary owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 12 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 14.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 25.] 
expected returns: [[-10.947086]
 [-11.046688]
 [ -9.36574 ]
 [-12.473082]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 14.  6. 25.] 
cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [10.  8.  1. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0] -> size -> 51 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -114 

action type: buy - action -1
Learning step: -6.165889263153076
desired expected reward: -1.5798492431640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-11.2467785]
 [-10.802866 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 14.  6. 25.] 
cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [10.  8.  1. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0] -> size -> 51 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -114 

action type: take_action - action -1.0
Learning step: -5.3993144035339355
desired expected reward: -16.34640121459961



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  8.  1. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  1. 29.  3.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [25.  8.  0.  8.  0.] 
adversary cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.  0. 10. 14.  6. 25.] 
adversary owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 12 


action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  1.] 
cards in discard: [ 3. 11.] 
cards in deck: 45 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [25.  8.  0.  8.  0.] 
adversary cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.  0. 10. 14.  6. 25.] 
adversary owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 12 


action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 16.] 
cards in discard: [ 3. 11.] 
cards in deck: 44 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0] -> size -> 51 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 8. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [25.  8.  0.  8.  0.] 
adversary cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.  0. 10. 14.  6. 25.] 
adversary owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 16.] 
cards in discard: [ 3. 11.] 
cards in deck: 44 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [25.  8.  0.  8.  0.] 
adversary cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.  0. 10. 14.  6. 25.] 
adversary owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 12 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [25.  8.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.  8.] 
expected returns: [[-11.717163]
 [-12.515425]
 [-10.370018]
 [-10.370018]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  0.  8.  0.] 
cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.  0. 10. 14.  6. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6 25  6  0  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0. 25.  3.  1.  1.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0] -> size -> 51 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -114 

action type: buy - action -1.0
Learning step: -5.407360553741455
desired expected reward: -16.21022605895996



action possibilites: [-1] 
expected returns: [[-17.67333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.  0. 10. 14.  6. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  6  6  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0. 25.  3.  1.  1.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0] -> size -> 51 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -94 

action type: trash_cards_n_from_hand - action 10
Learning step: -4.62929105758667
desired expected reward: -13.996467590332031





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-16.078362]
 [-17.629251]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.  0. 10. 14.  6. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  6  6  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0. 25.  3.  1.  1.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0] -> size -> 51 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -94 

action type: take_action - action -1
Learning step: -4.190688610076904
desired expected reward: -21.8640193939209



buy possibilites: [-1] 
expected returns: [[-13.578714]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.  0. 10. 14.  6. 25.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  6  6  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11  3  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0. 25.  3.  1.  1.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0] -> size -> 51 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1. -110.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -124.0 

action type: buy - action 0.0
Learning step: -5.701603412628174
desired expected reward: -21.779964447021484






Player: 1 
cards in hand: [ 0. 25.  3.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  1.  1.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [6. 0. 3. 8. 0.] 
adversary cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.  0. 10. 14.  6. 25.  0.  8.  0.] 
adversary owned cards: [14  8  6  6  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11  3  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 1. 4. 3.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16.] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [6. 0. 3. 8. 0.] 
adversary cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.  0. 10. 14.  6. 25.  0.  8.  0.] 
adversary owned cards: [14  8  6  6  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11  3  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1. 4. 3.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16.] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0] -> size -> 51 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  6.  6.  9.  3.  9.  7.] 
adversary cards in hand: [6. 0. 3. 8. 0.] 
adversary cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.  0. 10. 14.  6. 25.  0.  8.  0.] 
adversary owned cards: [14  8  6  6  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11  3  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1. 4. 3.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29.] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [6. 0. 3. 8. 0.] 
adversary cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.  0. 10. 14.  6. 25.  0.  8.  0.] 
adversary owned cards: [14  8  6  6  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11  3  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 12 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-13.920029]
 [-11.60099 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 8. 0.] 
cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.  0. 10. 14.  6. 25.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  6  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11  3  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [14.  8.  8.  0.  0.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29] -> size -> 52 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -114 

action type: buy - action -1
Learning step: -5.300915718078613
desired expected reward: -18.87963104248047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-10.295458 ]
 [-10.476731 ]
 [-13.4134865]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 8. 0.] 
cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.  0. 10. 14.  6. 25.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  6  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11  3  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [14.  8.  8.  0.  0.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29] -> size -> 52 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -114 

action type: take_action - action -1.0
Learning step: -5.253505229949951
desired expected reward: -19.17353630065918



buy possibilites: [-1] 
expected returns: [[8.598997]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 8. 0.] 
cards in discard: [ 0. 25. 10.  3.  0.  8.  3. 14.  0. 10. 14.  6. 25.  0.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  6  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11  3  0  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [14.  8.  8.  0.  0.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29] -> size -> 52 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1. -110.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -144.0 

action type: buy - action 0.0
Learning step: -6.465602874755859
desired expected reward: -16.761062622070312






Player: 1 
cards in hand: [14.  8.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  8.  0.  0.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0. 10. 11. 15. 16.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  6  6  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  8.  0.  0.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0. 10. 11. 15. 16.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  6  6  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11  3  0  0
  0] -> size -> 25 
adversary victory points: 1
player victory points: 12 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11. 15. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15. 16.] 
expected returns: [[-5.346846 ]
 [-5.9352555]
 [-6.065918 ]
 [-5.7900534]
 [-6.6479025]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 15. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  6  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11  3  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  6.  0. 15.  3.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29] -> size -> 52 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -114 

action type: buy - action -1
Learning step: -6.260165214538574
desired expected reward: 2.338831901550293



action possibilites: [-1. 11. 15. 16.] 
expected returns: [[-11.284225 ]
 [-10.159424 ]
 [ -7.7196417]
 [ -9.0710125]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15. 16.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [14  8  6  6  0  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11  3  0  0
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  6.  0. 15.  3.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29] -> size -> 52 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -94 

action type: take_action - action 10.0
Learning step: -4.606790065765381
desired expected reward: -10.542051315307617



action possibilites: [-1. 11. 16.] 
expected returns: [[-21.846962]
 [-22.316303]
 [-21.68597 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3 11  3  0  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 3 
card supply: [ 6. 21. 30. 12. 29.  8.  0.  5.  3.  0.  6.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  6.  0. 15.  3.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29] -> size -> 52 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -110    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -74 

action type: take_action - action 15.0
Learning step: -3.8062355518341064
desired expected reward: -11.525876998901367



action possibilites: [-1] 
expected returns: [[-18.755182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 15. 16.] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3  3  0  0  0 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 21. 30. 12. 29.  8.  0.  5.  3.  0.  5.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  6.  0. 15.  3.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29] -> size -> 52 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -110    0    0   60    0    0    0    0    0    0    0
   25    0] 
sum of rewards: -29 

action type: gain_card_n - action 6
Learning step: -1.558029055595398
desired expected reward: -7.837280750274658





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-17.710356]
 [-19.01554 ]
 [-18.004887]
 [-18.960392]
 [-17.733067]
 [-18.903486]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 15. 16.] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3  3  0  0  0 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 21. 30. 12. 29.  8.  0.  5.  3.  0.  5.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  6.  0. 15.  3.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29] -> size -> 52 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -110    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -54 

action type: take_action - action -1
Learning step: -2.171726942062378
desired expected reward: -20.926908493041992



buy possibilites: [-1] 
expected returns: [[-12.423199]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [25.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 15. 16.] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3  3  0  0  0 25
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 21. 30. 12. 29.  8.  0.  5.  3.  0.  5.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  6.  0. 15.  3.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29] -> size -> 52 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1. -110.    0.    0.   60.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -84.0 

action type: buy - action 0.0
Learning step: -3.5940041542053223
desired expected reward: -21.304357528686523






Player: 1 
cards in hand: [ 0.  6.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 15.  3.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 30. 12. 29.  8.  0.  5.  3.  0.  5.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 8.  0. 14. 10.  3.] 
adversary cards in discard: [25.  0. 10. 15. 16.  3.] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3  3  0  0  0 25
  0] -> size -> 25 
adversary victory points: 1
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 15.  3.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 21. 30. 12. 29.  8.  0.  5.  3.  0.  5.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 8.  0. 14. 10.  3.] 
adversary cards in discard: [25.  0. 10. 15. 16.  3.] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3  3  0  0  0 25
  0] -> size -> 25 
adversary victory points: 1
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 15.  3.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 21. 30. 12. 29.  8.  0.  5.  3.  0.  5.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 8.  0. 14. 10.  3.] 
adversary cards in discard: [25.  0. 10. 15. 16.  3.] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3  3  0  0  0 25
  0] -> size -> 25 
adversary victory points: 1
player victory points: 12 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 14. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 10.] 
expected returns: [[-23.287437]
 [-26.586964]
 [-25.300236]
 [-24.83583 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 14. 10.  3.] 
cards in discard: [25.  0. 10. 15. 16.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25  3 10  8  3  3  0  0  0 25
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 30. 12. 29.  8.  0.  5.  3.  0.  5.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0] -> size -> 53 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -114 

action type: buy - action -1
Learning step: -5.630659580230713
desired expected reward: -18.053857803344727



action possibilites: [-1] 
expected returns: [[-15.941574]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 10.] 
cards in discard: [25.  0. 10. 15. 16.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 21. 30. 12. 29.  8.  0.  5.  3.  0.  5.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0] -> size -> 53 
adversary victory points: 12
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: trash_cards_n_from_hand - action 1
Learning step: -4.325275421142578
desired expected reward: -29.99347496032715





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-13.470831]
 [-16.22385 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 10.] 
cards in discard: [25.  0. 10. 15. 16.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 21. 30. 12. 29.  8.  0.  5.  3.  0.  5.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0] -> size -> 53 
adversary victory points: 12
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: -4.778367519378662
desired expected reward: -20.719942092895508






Player: 1 
cards in hand: [0. 1. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 30. 12. 29.  8.  0.  5.  3.  0.  5.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  0. 14.  0.  6.] 
adversary cards in discard: [25.  0. 10. 15. 16.  3.  8.  0. 14. 10.] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0] -> size -> 24 
adversary victory points: 0
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 21. 30. 12. 29.  8.  0.  5.  3.  0.  5.  5.  6.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  0. 14.  0.  6.] 
adversary cards in discard: [25.  0. 10. 15. 16.  3.  8.  0. 14. 10.] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0] -> size -> 24 
adversary victory points: 0
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 21. 30. 12. 29.  8.  0.  5.  3.  0.  5.  5.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 0.  0. 14.  0.  6.] 
adversary cards in discard: [25.  0. 10. 15. 16.  3.  8.  0. 14. 10.] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0] -> size -> 24 
adversary victory points: 0
player victory points: 12 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 14.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-10.99156 ]
 [ -9.089973]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.  6.] 
cards in discard: [25.  0. 10. 15. 16.  3.  8.  0. 14. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 30. 12. 29.  8.  0.  5.  3.  0.  5.  5.  6.  9.  3.  9.  6.] 
adversary cards in hand: [10. 29. 11.  0.  0.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15] -> size -> 54 
adversary victory points: 12
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: -5.658771514892578
desired expected reward: -21.88262176513672



action possibilites: [-1] 
expected returns: [[-12.910072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [25.  0. 10. 15. 16.  3.  8.  0. 14. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 21. 30. 12. 29.  8.  0.  5.  3.  0.  5.  5.  6.  9.  3.  9.  6.] 
adversary cards in hand: [11.  0.  0.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15] -> size -> 54 
adversary victory points: 12
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 14.0
Learning step: -5.085978031158447
desired expected reward: -14.17595100402832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.004072 ]
 [-11.543291 ]
 [-10.398319 ]
 [ -7.8584146]
 [-10.597553 ]
 [-11.851572 ]
 [-13.705246 ]
 [-11.219942 ]
 [ -7.640096 ]
 [ -8.758484 ]
 [-10.025671 ]
 [ -6.8140683]
 [ -9.343882 ]
 [-12.926624 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [25.  0. 10. 15. 16.  3.  8.  0. 14. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 4. 21. 30. 12. 29.  8.  0.  5.  3.  0.  5.  5.  6.  9.  3.  9.  6.] 
adversary cards in hand: [11.  0.  0.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15] -> size -> 54 
adversary victory points: 12
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: -4.81266450881958
desired expected reward: -17.722736358642578



buy possibilites: [-1] 
expected returns: [[-4.5026355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [25.  0. 10. 15. 16.  3.  8.  0. 14. 10. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 21. 30. 12. 29.  8.  0.  5.  3.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [11.  0.  0.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15] -> size -> 54 
adversary victory points: 12
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   20.    0.    0.    0.    0.    0.
    0.    0.    8.    0.] 
sum of rewards: -97.0 

action type: buy - action 14.0
Learning step: -4.512701988220215
desired expected reward: -12.152798652648926






Player: 1 
cards in hand: [11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 30. 12. 29.  8.  0.  5.  3.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [3. 0. 6. 8. 0.] 
adversary cards in discard: [25.  0. 10. 15. 16.  3.  8.  0. 14. 10. 14. 14.  0.  0.  0.  6.] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14] -> size -> 25 
adversary victory points: 0
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 21. 30. 11. 29.  8.  0.  5.  3.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [3. 0. 6. 8. 0.] 
adversary cards in discard: [25.  0. 10. 15. 16.  3.  8.  0. 14. 10. 14. 14.  0.  0.  0.  6.] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14] -> size -> 25 
adversary victory points: 0
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3] -> size -> 55 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 21. 30. 11. 29.  8.  0.  5.  3.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [3. 0. 6. 8. 0.] 
adversary cards in discard: [25.  0. 10. 15. 16.  3.  8.  0. 14. 10. 14. 14.  0.  0.  0.  6.] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14] -> size -> 25 
adversary victory points: 0
player victory points: 13 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0] -> size -> 56 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 21. 30. 11. 29.  8.  0.  5.  3.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [3. 0. 6. 8. 0.] 
adversary cards in discard: [25.  0. 10. 15. 16.  3.  8.  0. 14. 10. 14. 14.  0.  0.  0.  6.] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14] -> size -> 25 
adversary victory points: 0
player victory points: 13 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-17.053612]
 [-13.467253]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 8. 0.] 
cards in discard: [25.  0. 10. 15. 16.  3.  8.  0. 14. 10. 14. 14.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 21. 30. 11. 29.  8.  0.  5.  3.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [ 0.  1. 14. 11.  3.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.
 11.  0.  0.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0] -> size -> 56 
adversary victory points: 13
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: buy - action -1
Learning step: -6.85699987411499
desired expected reward: -11.359635353088379





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-15.203012]
 [-14.485546]
 [-18.57059 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 8. 0.] 
cards in discard: [25.  0. 10. 15. 16.  3.  8.  0. 14. 10. 14. 14.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 21. 30. 11. 29.  8.  0.  5.  3.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [ 0.  1. 14. 11.  3.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.
 11.  0.  0.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0] -> size -> 56 
adversary victory points: 13
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1.0
Learning step: -6.24923849105835
desired expected reward: -23.3028564453125



buy possibilites: [-1] 
expected returns: [[-11.524847]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 8. 0.] 
cards in discard: [25.  0. 10. 15. 16.  3.  8.  0. 14. 10. 14. 14.  0.  0.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 21. 30. 11. 29.  8.  0.  5.  3.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [ 0.  1. 14. 11.  3.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.
 11.  0.  0.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0] -> size -> 56 
adversary victory points: 13
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -130.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -165.0 

action type: buy - action 0.0
Learning step: -7.7491583824157715
desired expected reward: -22.952178955078125






Player: 1 
cards in hand: [ 0.  1. 14. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14. 11.  3.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.
 11.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 21. 30. 11. 29.  8.  0.  5.  3.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [25.  0. 25.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14  0] -> size -> 26 
adversary victory points: 0
player victory points: 13 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  3.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.
 11.  0.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0 11] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 21. 30. 11. 29.  8.  0.  5.  2.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [25.  0. 25.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14  0] -> size -> 26 
adversary victory points: 0
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  3.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.
 11.  0.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0 11] -> size -> 57 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 21. 30. 11. 29.  8.  0.  5.  2.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [25.  0. 25.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14  0] -> size -> 26 
adversary victory points: 0
player victory points: 13 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  3.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.
 11.  0.  0. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0 11  0] -> size -> 58 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 21. 30. 11. 29.  8.  0.  5.  2.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [25.  0. 25.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14  0] -> size -> 26 
adversary victory points: 0
player victory points: 13 





         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [25.  0. 25.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.  8. 25.] 
expected returns: [[-25.019253]
 [-25.699076]
 [-25.699076]
 [-23.049147]
 [-25.699076]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25.  8. 25.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 21. 30. 11. 29.  8.  0.  5.  2.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [ 1.  3.  0. 15. 11.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.
 11.  0.  0. 11.  0. 11.  0.  1. 14.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0 11  0] -> size -> 58 
adversary victory points: 13
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: buy - action -1
Learning step: -6.72458028793335
desired expected reward: -18.249427795410156



action possibilites: [-1] 
expected returns: [[-30.297022]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  8. 25.  6.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 21. 30. 11. 29.  8.  0.  5.  2.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [ 1.  3.  0. 15. 11.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.
 11.  0.  0. 11.  0. 11.  0.  1. 14.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0 11  0] -> size -> 58 
adversary victory points: 13
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action 25.0
Learning step: -5.146728992462158
desired expected reward: -30.84580421447754





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-24.672663]
 [-28.50564 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  8. 25.  6.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 21. 30. 11. 29.  8.  0.  5.  2.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [ 1.  3.  0. 15. 11.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.
 11.  0.  0. 11.  0. 11.  0.  1. 14.  3.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0 11  0] -> size -> 58 
adversary victory points: 13
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: -4.821404933929443
desired expected reward: -35.11842727661133






Player: 1 
cards in hand: [ 1.  3.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 15. 11.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.
 11.  0.  0. 11.  0. 11.  0.  1. 14.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0 11  0] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 21. 30. 11. 29.  8.  0.  5.  2.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [25.  0. 25.  8. 25.  6.  6.] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14  0] -> size -> 26 
adversary victory points: 0
player victory points: 13 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 15.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.
 11.  0.  0. 11.  0. 11.  0.  1. 14.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0 11  0  1] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 20. 30. 11. 29.  8.  0.  5.  2.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [25.  0. 25.  8. 25.  6.  6.] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14  0] -> size -> 26 
adversary victory points: 0
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 15.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.
 11.  0.  0. 11.  0. 11.  0.  1. 14.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0 11  0  1] -> size -> 59 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 20. 30. 11. 29.  8.  0.  5.  2.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [25.  0. 25.  8. 25.  6.  6.] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14  0] -> size -> 26 
adversary victory points: 0
player victory points: 13 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 15.] 
cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.
 11.  0.  0. 11.  0. 11.  0.  1. 14.  3.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0 11  0  1  1] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 19. 30. 11. 29.  8.  0.  5.  2.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [25.  0. 25.  8. 25.  6.  6.] 
adversary owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14  0] -> size -> 26 
adversary victory points: 0
player victory points: 13 





         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [8. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[-13.683645]
 [-12.05413 ]
 [-12.05413 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [25.  0. 25.  8. 25.  6.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 19. 30. 11. 29.  8.  0.  5.  2.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [11.  3.  1.  8.  8.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.
 11.  0.  0. 11.  0. 11.  0.  1. 14.  3.  1.  1. 11.  1.  3.  0. 15.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0 11  0  1  1] -> size -> 60 
adversary victory points: 13
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: buy - action -1.0
Learning step: -5.6047563552856445
desired expected reward: -34.11040496826172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-12.776158 ]
 [-14.158353 ]
 [-13.169292 ]
 [-14.128962 ]
 [-12.7912855]
 [-13.859751 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [25.  0. 25.  8. 25.  6.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 19. 30. 11. 29.  8.  0.  5.  2.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [11.  3.  1.  8.  8.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.
 11.  0.  0. 11.  0. 11.  0.  1. 14.  3.  1.  1. 11.  1.  3.  0. 15.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0 11  0  1  1] -> size -> 60 
adversary victory points: 13
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1.0
Learning step: -6.364720821380615
desired expected reward: -20.048370361328125



Player 1 won the game! 



Player 0 bought cards:
Copper: 15 
Silver: 2 
Gold: 0 
Estate: 4 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 2 
Workshop: 1 
Chapel: 4 
Witch: 3 
Poacher: 1 
Militia: 3 
Market: 0 
Village: 4 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [25.  0. 25.  8. 25.  6.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  6  0 25 10  0  0 16 14  0 15  8 25 10  8  3  3  0  0  0 25  0
 14  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 19. 30. 11. 29.  8.  0.  5.  2.  0.  5.  5.  5.  9.  3.  9.  6.] 
adversary cards in hand: [11.  3.  1.  8.  8.] 
adversary cards in discard: [ 3. 11. 29. 10.  8.  1. 16. 29. 25.  0.  3.  1.  1.  4.  3. 14.  8.  8.
  0.  0.  0.  0.  6.  0. 15.  3. 15.  0.  1.  0.  3.  3. 10. 29.  3.  0.
 11.  0.  0. 11.  0. 11.  0.  1. 14.  3.  1.  1. 11.  1.  3.  0. 15.] 
adversary owned cards: [ 8 11  0  1  0  0  1  1  8  1  3 11 22  3  0 16 14 15  8  3  3  6  3  1
  0 25  4 11  8  3  1 10  3  0 29 15  3  0  0  8 11 29 10 14  0 11  0  3
  1  3  0 29  0 15  3  0 11  0  1  1] -> size -> 60 
adversary victory points: 13
player victory points: 0 

Reward from previous game state: 
[  -5 -500    0 -130    0    0    0  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -665 

action type: buy - action 0.0
Learning step: -32.61119079589844
desired expected reward: -45.387351989746094



