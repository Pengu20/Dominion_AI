 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[4.9766846]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      30       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000025 

action type: buy - action -1.0
Learning step: 120006.7578125
desired expected reward: 119862.828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[   6.1705465]
 [  20.522602 ]
 [  12.131289 ]
 [-100.15347  ]
 [  17.468605 ]
 [   7.063388 ]
 [  15.304869 ]
 [   3.4111593]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 4.657939910888672



buy possibilites: [-1] 
expected returns: [[5.72859]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 20.522611618041992






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[11.511924]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.72859001159668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 13.168251]
 [ 27.520285]
 [ 19.12898 ]
 [-92.394806]
 [ 22.388004]
 [ 24.4663  ]
 [ 14.061087]
 [ 36.31953 ]
 [ 23.802893]
 [ 22.302563]
 [ 28.166882]
 [ 10.408841]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 10.044278144836426



buy possibilites: [-1] 
expected returns: [[-9.828204]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 1.  0.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 36.31953811645508






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[2.6832259]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -9.828204154968262





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[  5.7502337]
 [ 12.01046  ]
 [-99.66476  ]
 [  6.6272182]
 [  3.1311262]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 2.0085361003875732



buy possibilites: [-1] 
expected returns: [[-11.654134]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 41 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 12.010467529296875






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  1.] 
adversary cards in discard: [3. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  1.] 
adversary cards in discard: [3. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  1.] 
adversary cards in discard: [3. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-20.529232]
 [  6.748377]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  1.] 
cards in discard: [3. 0. 3. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -11.654133796691895



action possibilites: [-1.] 
expected returns: [[-0.15545535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [3. 0. 3. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 5.139398574829102





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  6.611347 ]
 [ 20.398071 ]
 [-24.1196   ]
 [ 12.68022  ]
 [-28.026484 ]
 [-91.29631  ]
 [ 15.660944 ]
 [ 17.898033 ]
 [  7.612075 ]
 [ 22.249277 ]
 [ 28.902445 ]
 [ 17.252491 ]
 [ 21.94475  ]
 [ 15.782507 ]
 [ 10.949414 ]
 [ 21.207748 ]
 [  4.2193546]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [3. 0. 3. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.1554553508758545



buy possibilites: [-1] 
expected returns: [[-10.664652]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 3.  0.  3.  3.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 77.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 28.90244483947754






Player: 1 
cards in hand: [3. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29] -> size -> 14 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29] -> size -> 14 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [14.  0.  0.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29] -> size -> 14 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [1. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-3.222817]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.664651870727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  -3.454112 ]
 [  11.408767 ]
 [   2.8417437]
 [-117.02514  ]
 [   6.243784 ]
 [   8.460248 ]
 [  -2.397346 ]
 [  20.378477 ]
 [   7.7733955]
 [   6.2147646]
 [  12.203786 ]
 [  -6.093835 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.479234218597412



buy possibilites: [-1] 
expected returns: [[-17.003912]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 20.378463745117188






Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [29.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [29.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14 11  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [29.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29] -> size -> 15 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[2.4359405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.  1.  3.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  0.  0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14 11  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -17.0039119720459





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  5.1434336]
 [ 19.097485 ]
 [ 11.031097 ]
 [-94.88112  ]
 [ 14.225939 ]
 [ 16.240759 ]
 [  6.0206537]
 [ 27.496082 ]
 [ 15.604355 ]
 [ 14.150175 ]
 [ 19.762068 ]
 [  2.7555277]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.  1.  3.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  0.  0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14 11  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 1.307929277420044



buy possibilites: [-1] 
expected returns: [[-3.9965112]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.  1.  3.  3.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  0.  0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14 11  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 27.496082305908203






Player: 1 
cards in hand: [ 0.  8. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  0.  0.] 
cards in discard: [3. 0. 0. 3. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8 14 11  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29] -> size -> 16 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [3. 0. 0. 3. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 14  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29] -> size -> 16 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3. 0. 0. 3. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 14  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29] -> size -> 16 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-11.699266]
 [ 12.49695 ]
 [ 12.49695 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -3.996511220932007



action possibilites: [-1. 29.] 
expected returns: [[-4.185522]
 [21.124372]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 10.396819114685059



action possibilites: [-1.] 
expected returns: [[13.237118]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 21.12436294555664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  12.667616]
 [  27.207481]
 [ -31.902452]
 [  19.421938]
 [ -39.83746 ]
 [-110.382065]
 [  22.668655]
 [  24.83803 ]
 [  13.315689]
 [  29.125341]
 [  35.340324]
 [  24.19901 ]
 [  28.819796]
 [  22.659964]
 [  17.52775 ]
 [  28.175497]
 [  11.29747 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 13.237117767333984



buy possibilites: [-1] 
expected returns: [[22.760145]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 67.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 35.34033203125






Player: 1 
cards in hand: [ 3. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 14  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29.  3.] 
adversary cards in discard: [29. 29. 29.  0.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29] -> size -> 17 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 14  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29.  3.] 
adversary cards in discard: [29. 29. 29.  0.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29] -> size -> 17 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 14  3  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29.  3.] 
adversary cards in discard: [29. 29. 29.  0.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29] -> size -> 17 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [29.  3.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 7.65956 ]
 [28.585466]
 [28.585466]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 29.  3.] 
cards in discard: [29. 29. 29.  0.  3.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [ 8.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 14  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.76014518737793



action possibilites: [-1. 29.] 
expected returns: [[ 5.3563175]
 [27.723616 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3.  3.] 
cards in discard: [29. 29. 29.  0.  3.  0.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [ 8.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 14  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 26.971750259399414



action possibilites: [-1.] 
expected returns: [[34.616226]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [29. 29. 29.  0.  3.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [ 8.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 14  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.723621368408203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 39.739193]
 [ 53.661118]
 [ 45.62095 ]
 [-85.91516 ]
 [ 48.995453]
 [ 50.96943 ]
 [ 40.92999 ]
 [ 61.749535]
 [ 50.35298 ]
 [ 48.935673]
 [ 54.34998 ]
 [ 37.907173]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [29. 29. 29.  0.  3.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [ 8.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 14  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 34.61622619628906



buy possibilites: [-1] 
expected returns: [[59.97088]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [29. 29. 29.  0.  3.  0.  1.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  4.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [ 8.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 14  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 61.74952697753906






Player: 1 
cards in hand: [3. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [ 8.  3. 14.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 14  3  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  4.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29] -> size -> 18 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  3. 14.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  0  8 14  3  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  4.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29] -> size -> 18 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  3. 14.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  0  8 14  3  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  4.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29] -> size -> 18 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[20.42671]
 [44.79889]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  4.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8] -> size -> 11 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.97087860107422



action possibilites: [-1. 29.] 
expected returns: [[30.79391 ]
 [56.296432]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  4.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8] -> size -> 11 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.38859558105469



action possibilites: [-1.] 
expected returns: [[53.354458]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  4.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8] -> size -> 11 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 56.29642868041992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 59.79056 ]
 [ 73.78041 ]
 [ 66.36842 ]
 [ 21.416721]
 [-42.44122 ]
 [ 69.54662 ]
 [ 71.66735 ]
 [ 60.52098 ]
 [ 75.58103 ]
 [ 81.20267 ]
 [ 71.056274]
 [ 75.298195]
 [ 69.57902 ]
 [ 64.4655  ]
 [ 74.74046 ]
 [ 58.71892 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  4.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8] -> size -> 11 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 53.35445785522461



buy possibilites: [-1] 
expected returns: [[25.32525]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  3.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8] -> size -> 11 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0. 60.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 127.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 81.20268249511719






Player: 1 
cards in hand: [14.  8.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 14  3  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  3.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  3.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 14  3  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  3.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  3.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[50.784607]
 [73.03443 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  3.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  3.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [14.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8] -> size -> 11 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.32525062561035



action possibilites: [-1. 29.] 
expected returns: [[44.63798]
 [66.88781]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 29.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  3.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [14.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8] -> size -> 11 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 70.77576446533203



action possibilites: [-1.] 
expected returns: [[59.842545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  3.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [14.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8] -> size -> 11 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 66.88780975341797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 64.11079 ]
 [ 77.48928 ]
 [ 29.68524 ]
 [ 69.85779 ]
 [ 20.624058]
 [-48.47439 ]
 [ 73.1581  ]
 [ 74.983086]
 [ 65.20288 ]
 [ 79.10206 ]
 [ 85.0088  ]
 [ 74.41147 ]
 [ 78.837425]
 [ 73.06776 ]
 [ 67.96629 ]
 [ 78.12512 ]
 [ 62.870865]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  3.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [14.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8] -> size -> 11 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 59.84254455566406



buy possibilites: [-1] 
expected returns: [[125.41967]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  2.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [14.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8] -> size -> 11 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0. 60.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 127.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 85.00879669189453






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [14.  8.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 14  3  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  2.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [14.  8.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 14  3  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  2.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [14.  8.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 14  3  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  2.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[27.533092]
 [48.916153]
 [48.916153]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  2.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 125.41967010498047



action possibilites: [-1. 29.] 
expected returns: [[33.90647]
 [57.61065]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  2.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 46.45998764038086



action possibilites: [-1.] 
expected returns: [[50.78942]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  2.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 57.61065673828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 55.95719 ]
 [ 70.0952  ]
 [ 23.691479]
 [ 62.288887]
 [ 18.497692]
 [-32.163055]
 [ 65.54858 ]
 [ 67.52589 ]
 [ 56.636646]
 [ 71.847786]
 [ 78.061   ]
 [ 66.915924]
 [ 71.563156]
 [ 65.4537  ]
 [ 60.43876 ]
 [ 70.83823 ]
 [ 54.600998]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  2.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 50.78942108154297



buy possibilites: [-1] 
expected returns: [[48.88527]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  1.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0. 60.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 127.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 78.06098937988281






Player: 1 
cards in hand: [ 0.  3.  0. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 14  3  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  1.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.  0. 29.] 
adversary cards in discard: [29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 14  3  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  8. 10.  1.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.  0. 29.] 
adversary cards in discard: [29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14.  8.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 14  3  8  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  7. 10.  1.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.  0. 29.] 
adversary cards in discard: [29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[57.770226]
 [79.55941 ]
 [79.55941 ]
 [79.55941 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  0. 29.] 
cards in discard: [29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  7. 10.  1.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8  0  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.88526916503906



action possibilites: [-1. 29. 29.] 
expected returns: [[ 81.495865]
 [102.828995]
 [102.828995]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 29.  0.] 
cards in discard: [29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  7. 10.  1.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8  0  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 76.6219711303711



action possibilites: [-1. 29.] 
expected returns: [[ 91.343254]
 [113.474144]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  1.] 
cards in discard: [29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  7. 10.  1.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8  0  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 102.8290023803711



action possibilites: [-1.] 
expected returns: [[122.895744]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  7. 10.  1.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8  0  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 113.4741439819336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[132.88052 ]
 [146.28    ]
 [ 99.310524]
 [138.92328 ]
 [ 93.177414]
 [ 50.66317 ]
 [142.22064 ]
 [144.07816 ]
 [133.90808 ]
 [147.92632 ]
 [153.48247 ]
 [143.51921 ]
 [147.66208 ]
 [142.16734 ]
 [136.9627  ]
 [147.0515  ]
 [132.23466 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  7. 10.  1.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8  0  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 122.89574432373047



buy possibilites: [-1] 
expected returns: [[159.84892]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [29. 29. 29.  0.  0.  0.  3.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 14  3  8  0  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0. 60.  0.  0. 60.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 147.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 153.48243713378906






Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0. 14.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 14  3  8  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 29. 29.] 
adversary cards in discard: [29. 29. 29.  0.  0.  0.  3.  0. 29. 29. 29. 29.  3.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8.  0.  3.  0. 14.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  8 14  3  8  0  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 29. 29.] 
adversary cards in discard: [29. 29. 29.  0.  0.  0.  3.  0. 29. 29. 29. 29.  3.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  0.  3.  0. 14.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  8 14  3  8  0  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 29. 29.] 
adversary cards in discard: [29. 29. 29.  0.  0.  0.  3.  0. 29. 29. 29. 29.  3.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  0.  3.  0. 14.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  8 14  3  8  0  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 29. 29.] 
adversary cards in discard: [29. 29. 29.  0.  0.  0.  3.  0. 29. 29. 29. 29.  3.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[154.9859 ]
 [171.95396]
 [171.95396]
 [171.95396]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 29. 29.] 
cards in discard: [29. 29. 29.  0.  0.  0.  3.  0. 29. 29. 29. 29.  3.  0.  0.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  8 14  3  8  0  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 159.8489227294922



action possibilites: [-1. 29.] 
expected returns: [[59.98627]
 [82.82261]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  8 14  3  8  0  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 163.8984832763672



action possibilites: [-1.] 
expected returns: [[64.8701]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [29. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  8 14  3  8  0  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 74.39442443847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 68.24183 ]
 [ 82.360374]
 [ 74.48565 ]
 [-18.82105 ]
 [ 79.68279 ]
 [ 68.89876 ]
 [ 77.64968 ]
 [ 67.07764 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [29. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  8 14  3  8  0  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 64.87010192871094



buy possibilites: [-1] 
expected returns: [[79.1547]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [29. 29.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  8 14  3  8  0  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 149 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 82.3603744506836






Player: 1 
cards in hand: [8. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  8 14  3  8  0  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29.  0.] 
adversary cards in discard: [29. 29.  1. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1] -> size -> 23 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8 14  3  8  0  8  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29.  0.] 
adversary cards in discard: [29. 29.  1. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1] -> size -> 23 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8 14  3  8  0  8  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29.  0.] 
adversary cards in discard: [29. 29.  1. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1] -> size -> 23 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8 14  3  8  0  8  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29.  0.] 
adversary cards in discard: [29. 29.  1. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1] -> size -> 23 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[70.983955]
 [93.28756 ]
 [93.28756 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 29.  0.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  8 14  3  8  0  8  0  0] -> size -> 10 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.15470123291016



action possibilites: [-1. 29.] 
expected returns: [[ 92.06916]
 [113.54581]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  8 14  3  8  0  8  0  0] -> size -> 10 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 82.62834930419922



action possibilites: [-1.] 
expected returns: [[97.67531]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  8 14  3  8  0  8  0  0] -> size -> 10 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 105.1500473022461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[102.415054]
 [115.42086 ]
 [108.41578 ]
 [-22.125132]
 [111.666176]
 [113.2244  ]
 [103.00232 ]
 [112.73064 ]
 [111.45886 ]
 [115.96327 ]
 [102.82614 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  8 14  3  8  0  8  0  0] -> size -> 10 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 97.67530822753906



buy possibilites: [-1] 
expected returns: [[222.99945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  8 14  3  8  0  8  0  0] -> size -> 10 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 253 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 115.96331024169922






Player: 1 
cards in hand: [0. 0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 8.] 
cards in discard: [0. 8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 14  3  8  0  8  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29. 15. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15] -> size -> 24 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 8.] 
cards in discard: [0. 8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 14  3  8  0  8  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  7. 10.  0.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29. 15. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15] -> size -> 24 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 8.] 
cards in discard: [0. 8. 3. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 14  3  8  0  8  0  0  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6. 10.  0.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29. 15. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15] -> size -> 24 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 95.95033]
 [114.80992]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29. 15. 29. 29.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6. 10.  0.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8 14  3  8  0  8  0  0  8] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 222.99945068359375



action possibilites: [-1.] 
expected returns: [[120.768196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29. 15. 29. 29.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6. 10.  0.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8 14  3  8  0  8  0  0  8] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 105.57353210449219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[119.77403 ]
 [133.00471 ]
 [126.44271 ]
 [ 81.22817 ]
 [ 30.688166]
 [129.59026 ]
 [131.27243 ]
 [120.01814 ]
 [134.52896 ]
 [130.78143 ]
 [134.29303 ]
 [129.4486  ]
 [124.49503 ]
 [133.81601 ]
 [120.86843 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29. 15. 29. 29.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6. 10.  0.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8 14  3  8  0  8  0  0  8] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 120.76819610595703



buy possibilites: [-1] 
expected returns: [[102.99427]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29. 15. 29. 29.  3.  0.  0.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  9.  0.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8 14  3  8  0  8  0  0  8] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 355 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 134.52894592285156






Player: 1 
cards in hand: [ 8.  8.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3.  0. 14.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 14  3  8  0  8  0  0  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  9.  0.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  3.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25] -> size -> 25 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8 8 0 8 0 0 8] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  9.  0.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  3.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25] -> size -> 25 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8 8 0 8 0 0 8] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  9.  0.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  3.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25] -> size -> 25 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29.  0.  3.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[54.99547 ]
 [76.766884]
 [76.766884]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  1. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  9.  0.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [0 8 8 0 8 0 0 8] -> size -> 8 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 102.99427032470703



action possibilites: [-1. 29. 29.] 
expected returns: [[61.69619]
 [84.44828]
 [84.44828]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 29.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  9.  0.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [0 8 8 0 8 0 0 8] -> size -> 8 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 65.98108673095703



action possibilites: [-1.] 
expected returns: [[85.92007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  9.  0.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [0 8 8 0 8 0 0 8] -> size -> 8 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 75.85140228271484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 88.86161 ]
 [103.13246 ]
 [ 95.234245]
 [  8.103986]
 [ 98.53518 ]
 [100.578026]
 [ 89.6652  ]
 [ 99.95482 ]
 [ 98.47419 ]
 [103.931625]
 [ 87.37261 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  9.  0.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [0 8 8 0 8 0 0 8] -> size -> 8 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 85.9200668334961



buy possibilites: [-1] 
expected returns: [[80.750824]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1. 29. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  9.  0.  9. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [0 8 8 0 8 0 0 8] -> size -> 8 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 283 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 103.93160247802734






Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [8. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 8 8 0 8 0 0 8] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  9.  0.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 29. 29.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15] -> size -> 26 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [8. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 8 8 0 8 0 0 8] -> size -> 8 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  9.  0.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 29. 29.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15] -> size -> 26 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [ 8.  8. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  0  8  0  0  8 15] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  9.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [ 0. 29.  0. 29. 29.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15] -> size -> 26 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[ 93.99468]
 [116.29827]
 [116.29827]
 [116.29827]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29. 29.] 
cards in discard: [ 1. 29. 15. 29. 29.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  9.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [8. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8  0  8  0  0  8 15] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 80.75082397460938



action possibilites: [-1. 29. 29.] 
expected returns: [[102.92357]
 [121.63661]
 [121.63661]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29.] 
cards in discard: [ 1. 29. 15. 29. 29.  0.  3.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  9.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [8. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8  0  8  0  0  8 15] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 105.25763702392578



action possibilites: [-1.] 
expected returns: [[181.81554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1. 29. 15. 29. 29.  0.  3.  0. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  9.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [8. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8  0  8  0  0  8 15] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 113.79312133789062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[183.01138]
 [195.35896]
 [188.87825]
 [145.03091]
 [105.42491]
 [192.08105]
 [193.39224]
 [183.42972]
 [196.56346]
 [192.96747]
 [196.37016]
 [191.8003 ]
 [186.9578 ]
 [195.78801]
 [184.39177]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1. 29. 15. 29. 29.  0.  3.  0. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  9.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [8. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8  0  8  0  0  8 15] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 181.81553649902344



buy possibilites: [-1] 
expected returns: [[232.29141]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1. 29. 15. 29. 29.  0.  3.  0. 29. 29. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [8. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8  0  8  0  0  8 15] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 405 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 196.56344604492188






Player: 1 
cards in hand: [8. 8. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  0  8  0  0  8 15] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [29.  0.  1.  3.  3.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  0.  3.  0. 29. 29. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15 25] -> size -> 27 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  8  0  0  8 15] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [29.  0.  1.  3.  3.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  0.  3.  0. 29. 29. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15 25] -> size -> 27 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  8  0  0  8 15] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [29.  0.  1.  3.  3.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  0.  3.  0. 29. 29. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15 25] -> size -> 27 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  8  0  0  8 15  3] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [29.  0.  1.  3.  3.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  0.  3.  0. 29. 29. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15 25] -> size -> 27 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29.  0.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[60.7218 ]
 [77.06336]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  3.  3.] 
cards in discard: [ 1. 29. 15. 29. 29.  0.  3.  0. 29. 29. 25. 29. 29.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [ 3. 15.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  8  0  0  8 15  3] -> size -> 9 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 232.29141235351562



action possibilites: [-1. 29.] 
expected returns: [[126.91076]
 [145.00806]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 29.] 
cards in discard: [ 1. 29. 15. 29. 29.  0.  3.  0. 29. 29. 25. 29. 29.  0.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 27. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [ 3. 15.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  8  0  0  8 15  3] -> size -> 9 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 68.99434661865234



action possibilites: [-1.] 
expected returns: [[135.8835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [ 1. 29. 15. 29. 29.  0.  3.  0. 29. 29. 25. 29. 29.  0.  0.  0.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 27. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [ 3. 15.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  8  0  0  8 15  3] -> size -> 9 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 138.75552368164062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[133.48598]
 [146.8268 ]
 [140.2071 ]
 [ 55.78147]
 [144.99774]
 [133.58913]
 [143.1988 ]
 [135.32811]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 1. 29. 15. 29. 29.  0.  3.  0. 29. 29. 25. 29. 29.  0.  0.  0.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 27. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [ 3. 15.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  8  0  0  8 15  3] -> size -> 9 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 135.8834991455078



buy possibilites: [-1] 
expected returns: [[120.50533]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 1. 29. 15. 29. 29.  0.  3.  0. 29. 29. 25. 29. 29.  0.  0.  0.  1.  3.
  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15 25  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [ 3. 15.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  8  0  0  8 15  3] -> size -> 9 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 179 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 146.82681274414062






Player: 1 
cards in hand: [ 3. 15.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  8  0  0  8 15  3] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [29. 25. 15. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15 25  1] -> size -> 28 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  0  8  0  0  8 15  3] -> size -> 8 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [29. 25. 15. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15 25  1] -> size -> 28 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  0  8  0  0  8 15  3] -> size -> 8 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [29. 25. 15. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15 25  1] -> size -> 28 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  0  8  0  0  8 15  3  3] -> size -> 9 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 26. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [29. 25. 15. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15 25  1] -> size -> 28 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [29. 25. 15. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 15. 29.] 
expected returns: [[57.66467 ]
 [79.774414]
 [73.75643 ]
 [72.714745]
 [79.774414]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 15. 29.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15 25  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [15.  8.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  8 15  3  3] -> size -> 9 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 120.50533294677734



action possibilites: [-1. 25. 15. 29.] 
expected returns: [[54.369614]
 [68.983   ]
 [66.30101 ]
 [76.3951  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15. 29.  0.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15 25  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 26. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [15.  8.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  8 15  3  3] -> size -> 9 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 68.73611450195312



action possibilites: [-1. 15.] 
expected returns: [[47.405464]
 [63.39261 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.] 
cards in discard: [ 1. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15
 25 15 25  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 26. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [15.  8.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  8 15  3  3] -> size -> 9 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 67.80289459228516



action possibilites: [-1] 
expected returns: [[36.51806]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25
 15 25  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 5 
card supply: [26. 27. 30. 26. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [15.  8.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  8 15  3  3] -> size -> 9 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 63.392616271972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 39.200264 ]
 [ 53.258312 ]
 [  7.06073  ]
 [ 45.524384 ]
 [  1.9217813]
 [-48.11234  ]
 [ 48.837143 ]
 [ 50.642563 ]
 [ 39.70909  ]
 [ 54.87314  ]
 [ 50.066727 ]
 [ 54.60903  ]
 [ 48.64541  ]
 [ 43.654526 ]
 [ 53.85259  ]
 [ 38.490868 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25
 15 25  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 27. 30. 26. 30.  8. 10. 10.  9.  6.  8.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [15.  8.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  8 15  3  3] -> size -> 9 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.51805877685547



buy possibilites: [-1] 
expected returns: [[45.497654]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 25. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25
 15 25  1 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 26. 30.  8. 10. 10.  9.  6.  7.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [15.  8.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  8 15  3  3] -> size -> 9 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 177.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 54.87314987182617






Player: 1 
cards in hand: [15.  8.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  8 15  3  3] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8. 10. 10.  9.  6.  7.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [29. 29. 29. 15.  0.] 
adversary cards in discard: [ 1. 25. 25. 29. 29. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25
 15 25  1 25] -> size -> 28 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 8 3 3] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8. 10. 10.  9.  6.  7.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [29. 29. 29. 15.  0.] 
adversary cards in discard: [ 1. 25. 25. 29. 29. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25
 15 25  1 25] -> size -> 28 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 8 3 3] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 26. 30.  8. 10. 10.  9.  6.  7.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [29. 29. 29. 15.  0.] 
adversary cards in discard: [ 1. 25. 25. 29. 29. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25
 15 25  1 25] -> size -> 28 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 8 3 3 0] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8. 10. 10.  9.  6.  7.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [29. 29. 29. 15.  0.] 
adversary cards in discard: [ 1. 25. 25. 29. 29. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25
 15 25  1 25] -> size -> 28 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [29. 29. 29. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 15.] 
expected returns: [[ 82.48686 ]
 [101.71605 ]
 [101.71605 ]
 [101.71605 ]
 [ 95.658905]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 15.  0.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25
 15 25  1 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8. 10. 10.  9.  6.  7.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 3 3 0] -> size -> 7 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 45.49765396118164



action possibilites: [-1. 29. 15. 29.] 
expected returns: [[115.76824]
 [135.17989]
 [129.1448 ]
 [135.17989]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  0. 29.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25
 15 25  1 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8. 10. 10.  9.  6.  7.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 3 3 0] -> size -> 7 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 91.74536895751953



action possibilites: [-1. 15. 29.] 
expected returns: [[119.345276]
 [132.8851  ]
 [138.87704 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 29.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25
 15 25  1 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 26. 30.  8. 10. 10.  9.  6.  7.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 3 3 0] -> size -> 7 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 127.82099151611328



action possibilites: [-1. 15.] 
expected returns: [[110.172745]
 [124.08924 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29. 29. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25
 15 25  1 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 27. 30. 26. 30.  8. 10. 10.  9.  6.  7.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 3 3 0] -> size -> 7 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 130.2802276611328



action possibilites: [-1] 
expected returns: [[124.93331]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29. 29. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 6 
card supply: [25. 27. 30. 26. 30.  8. 10. 10.  9.  6.  7.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 3 3 0] -> size -> 7 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 135 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 124.08921813964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[127.36173]
 [140.02328]
 [ 95.93451]
 [133.0616 ]
 [ 90.2291 ]
 [ 46.84769]
 [136.20393]
 [137.84657]
 [128.17809]
 [141.48886]
 [137.33636]
 [141.25165]
 [136.07826]
 [131.2176 ]
 [140.63214]
 [127.03625]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29. 29. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 27. 30. 26. 30.  8. 10. 10.  9.  6.  7.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 3 3 0] -> size -> 7 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 124.93331146240234



buy possibilites: [-1] 
expected returns: [[117.08397]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29. 29. 29. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8. 10. 10.  9.  6.  6.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 3 3 0] -> size -> 7 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 197.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 141.48886108398438






Player: 1 
cards in hand: [0. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8 3 3 0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8. 10. 10.  9.  6.  6.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [29.  0.  3.  1.  3.] 
adversary cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29. 29. 29. 25. 29. 29. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25] -> size -> 28 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8 3 3 0] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 26. 30.  8. 10. 10.  9.  6.  6.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [29.  0.  3.  1.  3.] 
adversary cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29. 29. 29. 25. 29. 29. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25] -> size -> 28 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8 3 3 0 0] -> size -> 8 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  9.  6.  6.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [29.  0.  3.  1.  3.] 
adversary cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29. 29. 29. 25. 29. 29. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25] -> size -> 28 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [29.  0.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[132.58989]
 [148.49353]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  1.  3.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29. 29. 29. 25. 29. 29. 29. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  9.  6.  6.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 3 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 117.08396911621094



action possibilites: [-1.] 
expected returns: [[149.05835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29. 29. 29. 25. 29. 29. 29. 15.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  9.  6.  6.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 3 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 140.89605712890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[146.528  ]
 [159.02124]
 [153.08395]
 [ 75.31181]
 [156.0889 ]
 [157.5695 ]
 [146.52689]
 [157.14096]
 [155.90132]
 [159.77255]
 [148.48935]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29. 29. 29. 25. 29. 29. 29. 15.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  9.  6.  6.  0.  9. 10. 10. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 3 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 149.058349609375



buy possibilites: [-1] 
expected returns: [[156.71211]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29. 29. 29. 25. 29. 29. 29. 15.  1. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  9.  6.  6.  0.  9. 10. 10. 10.  6.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 3 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 159.77259826660156






Player: 1 
cards in hand: [0. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8 3 3 0 0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  9.  6.  6.  0.  9. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  0. 29.  0. 25.] 
adversary cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29. 29. 29. 25. 29. 29. 29. 15.  1. 15. 29.
  0.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15] -> size -> 29 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8 3 3 0 0] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  9.  6.  6.  0.  9. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  0. 29.  0. 25.] 
adversary cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29. 29. 29. 25. 29. 29. 29. 15.  1. 15. 29.
  0.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15] -> size -> 29 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  8  3  3  0  0 10] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  9.  6.  6.  0.  9. 10.  9. 10.  6.] 
adversary cards in hand: [ 0.  0. 29.  0. 25.] 
adversary cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29. 29. 29. 25. 29. 29. 29. 15.  1. 15. 29.
  0.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15] -> size -> 29 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[27.651741]
 [46.851826]
 [41.561623]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0. 25.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29. 29. 29. 25. 29. 29. 29. 15.  1. 15. 29.
  0.  3.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  9.  6.  6.  0.  9. 10.  9. 10.  6.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  8  3  3  0  0 10] -> size -> 9 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 156.7121124267578



action possibilites: [-1. 25.] 
expected returns: [[22.180813]
 [35.613285]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0. 29. 29. 29. 25. 29. 29. 29. 15.  1. 15. 29.
  0.  3.  3.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  9.  6.  6.  0.  9. 10.  9. 10.  6.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  8  3  3  0  0 10] -> size -> 9 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 40.246150970458984



action possibilites: [-1] 
expected returns: [[61.178505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8.  9. 10.  9.  6.  6.  0.  9. 10.  9. 10.  6.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  0  0  8  3  3  0  0 10  6] -> size -> 10 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.61328887939453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 61.981155]
 [ 76.18277 ]
 [ 68.27655 ]
 [-37.467968]
 [ 71.63206 ]
 [ 73.53948 ]
 [ 62.706314]
 [ 72.939835]
 [ 71.4943  ]
 [ 76.84529 ]
 [ 60.833   ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 26. 30.  8.  9. 10.  9.  6.  6.  0.  9. 10.  9. 10.  6.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  0  0  8  3  3  0  0 10  6] -> size -> 10 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.178504943847656



buy possibilites: [-1] 
expected returns: [[72.3373]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  9. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  0  0  8  3  3  0  0 10  6] -> size -> 10 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 223 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 76.84530639648438






Player: 1 
cards in hand: [10.  0.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  8.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  8  3  3  0  0 10  6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  9. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [29.  0. 25.  1. 15.] 
adversary cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15] -> size -> 30 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  3  0  0 10  6] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  9. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [29.  0. 25.  1. 15.] 
adversary cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15] -> size -> 30 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  3  0  0 10  6] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8.  9. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [29.  0. 25.  1. 15.] 
adversary cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15] -> size -> 30 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  3  0  0 10  6  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 26. 30.  8.  9. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [29.  0. 25.  1. 15.] 
adversary cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15] -> size -> 30 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [29.  0. 25.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 15.] 
expected returns: [[111.1267 ]
 [128.95862]
 [124.4419 ]
 [123.78901]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  1. 15.] 
cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  9. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  3  0  0 10  6  0] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.3373031616211



action possibilites: [-1. 25. 15. 29.] 
expected returns: [[120.12878]
 [134.83154]
 [133.99445]
 [140.07611]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 15. 29.] 
cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 26. 30.  8.  9. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  3  0  0 10  6  0] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 118.0988540649414



action possibilites: [-1. 25. 15.] 
expected returns: [[104.64692]
 [119.41599]
 [118.58759]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 15.] 
cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.  1. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 26. 30.  8.  9. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  3  0  0 10  6  0] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 133.4088592529297



action possibilites: [-1] 
expected returns: [[59.97403]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 29. 29.] 
cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.  1. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 26. 30.  8.  8. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  0  8  3  0  0 10  6  0  6] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 119.41596221923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 57.54459 ]
 [ 70.02891 ]
 [ 63.54036 ]
 [-16.371958]
 [ 68.12255 ]
 [ 57.934753]
 [ 66.38552 ]
 [ 57.904743]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 29. 29.] 
cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.  1. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 26. 30.  8.  8. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  0  8  3  0  0 10  6  0  6] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.974029541015625



buy possibilites: [-1] 
expected returns: [[83.8546]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 29. 29.] 
cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.  1. 29.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 30.  8.  8. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  0  8  3  0  0 10  6  0  6] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 229 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 70.02891540527344






Player: 1 
cards in hand: [10.  0.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  8.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  3  0  0 10  6  0  6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 30.  8.  8. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [ 3.  0. 29.  3. 29.] 
adversary cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.  1. 29.  1. 29. 29. 25.  0. 15. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1] -> size -> 31 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 8 3 0 0 6 0 6] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 30.  8.  8. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [ 3.  0. 29.  3. 29.] 
adversary cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.  1. 29.  1. 29. 29. 25.  0. 15. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1] -> size -> 31 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 8 3 0 0 6 0 6] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 26. 30.  8.  8. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [ 3.  0. 29.  3. 29.] 
adversary cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.  1. 29.  1. 29. 29. 25.  0. 15. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1] -> size -> 31 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [6. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 8 3 0 0 6 0 6 3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  8. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [ 3.  0. 29.  3. 29.] 
adversary cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.  1. 29.  1. 29. 29. 25.  0. 15. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1] -> size -> 31 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[45.131977]
 [62.75271 ]
 [62.75271 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3. 29.] 
cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.  1. 29.  1. 29. 29. 25.  0. 15. 29. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  8. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [0. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 3 0 0 6 0 6 3] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.85459899902344



action possibilites: [-1. 29.] 
expected returns: [[76.280495]
 [93.51331 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 29.] 
cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.  1. 29.  1. 29. 29. 25.  0. 15. 29. 29.
 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 25. 30.  8.  8. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [0. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 3 0 0 6 0 6 3] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 56.68352508544922



action possibilites: [-1. 25.] 
expected returns: [[59.314705]
 [71.961555]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.] 
cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.  1. 29.  1. 29. 29. 25.  0. 15. 29. 29.
 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 25. 30.  8.  8. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [0. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 8 3 0 0 6 0 6 3] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 87.61516571044922



action possibilites: [-1] 
expected returns: [[25.870207]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  1.] 
cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.  1. 29.  1. 29. 29. 25.  0. 15. 29. 29.
 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 25. 30.  8.  7. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [0. 6. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 8 3 0 0 6 0 6 3 6] -> size -> 11 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 71.9615478515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 25.161173]
 [ 37.473377]
 [ 31.201792]
 [ -6.369893]
 [-40.94202 ]
 [ 34.048725]
 [ 35.377922]
 [ 24.832018]
 [ 38.701088]
 [ 34.940136]
 [ 38.50356 ]
 [ 33.719704]
 [ 29.574244]
 [ 37.877335]
 [ 26.185995]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  1.] 
cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.  1. 29.  1. 29. 29. 25.  0. 15. 29. 29.
 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 26. 30. 25. 30.  8.  7. 10.  9.  6.  6.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [0. 6. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 8 3 0 0 6 0 6 3 6] -> size -> 11 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.870206832885742



buy possibilites: [-1] 
expected returns: [[56.553127]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  1.] 
cards in discard: [15. 29. 25.  0.  0.  0. 15.  3.  1. 29.  1. 29. 29. 25.  0. 15. 29. 29.
 29.  3. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  7. 10.  9.  6.  5.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [0. 6. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 8 3 0 0 6 0 6 3 6] -> size -> 11 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 425 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 38.70106506347656






Player: 1 
cards in hand: [0. 6. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 8.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 8 3 0 0 6 0 6 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  7. 10.  9.  6.  5.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [29. 25.  1. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25] -> size -> 32 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 3 0 0 0 6 3 6] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  7. 10.  9.  6.  5.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [29. 25.  1. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25] -> size -> 32 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 3 0 0 0 6 3 6] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 25. 30.  8.  7. 10.  9.  6.  5.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [29. 25.  1. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25] -> size -> 32 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [29. 25.  1. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[19.724493]
 [41.03292 ]
 [35.15597 ]
 [41.03292 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  1. 29.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  7. 10.  9.  6.  5.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [8. 3. 3. 6. 0.] 
adversary cards in discard: [6. 8. 0. 0.] 
adversary owned cards: [8 8 3 0 0 0 6 3 6] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 56.55312728881836



action possibilites: [-1. 25. 29. 29.] 
expected returns: [[34.066154]
 [46.820946]
 [54.141624]
 [54.141624]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 29. 29.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 25. 30.  8.  7. 10.  9.  6.  5.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [8. 3. 3. 6. 0.] 
adversary cards in discard: [6. 8. 0. 0.] 
adversary owned cards: [8 8 3 0 0 0 6 3 6] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 30.013917922973633



action possibilites: [-1. 29. 29.] 
expected returns: [[32.592842]
 [55.07522 ]
 [55.07522 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.] 
cards in discard: [ 3. 25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 25. 30.  8.  7. 10.  9.  6.  5.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [8. 3. 3. 6. 0.] 
adversary cards in discard: [6. 8. 0. 0.] 
adversary owned cards: [8 8 3 0 0 0 6 3 6] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 47.13863754272461



action possibilites: [-1. 29.] 
expected returns: [[71.84397 ]
 [89.114265]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.] 
cards in discard: [ 3. 25. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 3 
card supply: [23. 26. 30. 25. 30.  8.  7. 10.  9.  6.  5.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [8. 3. 3. 6. 0.] 
adversary cards in discard: [6. 8. 0. 0.] 
adversary owned cards: [8 8 3 0 0 0 6 3 6] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.880088806152344



action possibilites: [-1.] 
expected returns: [[100.3675]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 3. 25. 29. 25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 4 
card supply: [23. 26. 30. 25. 30.  8.  7. 10.  9.  6.  5.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [8. 3. 3. 6. 0.] 
adversary cards in discard: [6. 8. 0. 0.] 
adversary owned cards: [8 8 3 0 0 0 6 3 6] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 82.57758331298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[104.01793  ]
 [117.76884  ]
 [ 69.71166  ]
 [110.24673  ]
 [ 63.42183  ]
 [ -4.1963606]
 [113.629654 ]
 [115.52371  ]
 [105.03733  ]
 [119.44934  ]
 [114.953674 ]
 [119.17986  ]
 [113.56775  ]
 [108.232834 ]
 [118.55671  ]
 [103.44473  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 3. 25. 29. 25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 26. 30. 25. 30.  8.  7. 10.  9.  6.  5.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [8. 3. 3. 6. 0.] 
adversary cards in discard: [6. 8. 0. 0.] 
adversary owned cards: [8 8 3 0 0 0 6 3 6] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 100.36750030517578



buy possibilites: [-1] 
expected returns: [[129.31877]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 3. 25. 29. 25. 25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 25. 30.  8.  7. 10.  9.  6.  4.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [8. 3. 3. 6. 0.] 
adversary cards in discard: [6. 8. 0. 0.] 
adversary owned cards: [8 8 3 0 0 0 6 3 6] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  120.    0.    0.   80.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 257.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 119.44933319091797






Player: 1 
cards in hand: [8. 3. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 6. 0.] 
cards in discard: [6. 8. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 0 0 6 3 6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  7. 10.  9.  6.  4.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [ 0. 29. 25.  1.  0.] 
adversary cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25] -> size -> 33 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 6. 0.] 
cards in discard: [6. 8. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 0 0 6 3 6] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 25. 30.  8.  7. 10.  9.  6.  4.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [ 0. 29. 25.  1.  0.] 
adversary cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25] -> size -> 33 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 6. 0.] 
cards in discard: [6. 8. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 0 0 6 3 6 0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  7. 10.  9.  6.  4.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [ 0. 29. 25.  1.  0.] 
adversary cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25] -> size -> 33 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 25.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[53.933296]
 [70.97528 ]
 [66.41103 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  1.  0.] 
cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  7. 10.  9.  6.  4.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 0 0 6 3 6 0] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 129.3187713623047



action possibilites: [-1. 25. 29.] 
expected returns: [[ 84.967636]
 [ 97.84504 ]
 [102.44012 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 29.] 
cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  7. 10.  9.  6.  4.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 0 0 6 3 6 0] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 63.864845275878906



action possibilites: [-1. 25.] 
expected returns: [[65.180244]
 [77.92953 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.] 
cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 25. 30.  8.  7. 10.  9.  6.  4.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 0 0 6 3 6 0] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 96.49082946777344



action possibilites: [-1] 
expected returns: [[107.10105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  1.] 
cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 25. 30.  8.  6. 10.  9.  6.  4.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 3 0 0 0 6 3 6 0 6] -> size -> 11 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 77.92957305908203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 97.56155 ]
 [109.20235 ]
 [ 69.49389 ]
 [103.43712 ]
 [ 63.398415]
 [ 27.05004 ]
 [106.29774 ]
 [107.56289 ]
 [ 97.56096 ]
 [110.3718  ]
 [107.16973 ]
 [110.18906 ]
 [106.040115]
 [101.694016]
 [109.71071 ]
 [ 99.23172 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  1.] 
cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 6 
card supply: [22. 26. 30. 25. 30.  8.  6. 10.  9.  6.  4.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 3 0 0 0 6 3 6 0 6] -> size -> 11 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 107.1010513305664



buy possibilites: [-1] 
expected returns: [[72.39869]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  1.] 
cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  6. 10.  9.  6.  3.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 3 0 0 0 6 3 6 0 6] -> size -> 11 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  120.    0.    0.   60.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 237.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 110.37181091308594






Player: 1 
cards in hand: [3. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 0 0 6 3 6 0 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  6. 10.  9.  6.  3.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [ 0.  0.  1.  3. 25.] 
adversary cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29. 25. 29. 29. 25.  0.  0.
 15.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25 25] -> size -> 34 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 0 0 6 3 6 0 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 25. 30.  8.  6. 10.  9.  6.  3.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [ 0.  0.  1.  3. 25.] 
adversary cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29. 25. 29. 29. 25.  0.  0.
 15.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25 25] -> size -> 34 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [6. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 0 0 6 3 6 0 6 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  6. 10.  9.  6.  3.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [ 0.  0.  1.  3. 25.] 
adversary cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29. 25. 29. 29. 25.  0.  0.
 15.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25 25] -> size -> 34 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  1.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 7.5987053]
 [20.81834  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  3. 25.] 
cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29. 25. 29. 29. 25.  0.  0.
 15.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  6. 10.  9.  6.  3.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [6. 8. 0. 0. 8.] 
adversary cards in discard: [6. 3. 3. 0. 0. 3. 6.] 
adversary owned cards: [8 8 3 0 0 0 6 3 6 0 6 3] -> size -> 12 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.39868927001953



action possibilites: [-1] 
expected returns: [[-3.9609509]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  3.  3. 15.] 
cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29. 25. 29. 29. 25.  0.  0.
 15.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  5. 10.  9.  6.  3.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [6. 8. 0. 0. 8.] 
adversary cards in discard: [6. 3. 3. 0. 0. 3. 6. 6.] 
adversary owned cards: [8 8 3 0 0 0 6 3 6 0 6 3 6] -> size -> 13 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 20.818336486816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ -5.5119505]
 [  8.112558 ]
 [  1.5070603]
 [-73.541916 ]
 [  4.5754967]
 [  6.118267 ]
 [ -5.9977474]
 [  5.6438293]
 [  4.2787113]
 [  8.754271 ]
 [ -4.0731387]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  3.  3. 15.] 
cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29. 25. 29. 29. 25.  0.  0.
 15.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25 25] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 26. 30. 24. 30.  8.  5. 10.  9.  6.  3.  0.  9. 10.  9. 10.  5.] 
adversary cards in hand: [6. 8. 0. 0. 8.] 
adversary cards in discard: [6. 3. 3. 0. 0. 3. 6. 6.] 
adversary owned cards: [8 8 3 0 0 0 6 3 6 0 6 3 6] -> size -> 13 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.9609508514404297



buy possibilites: [-1] 
expected returns: [[16.397394]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  3.  3. 15.] 
cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29. 25. 29. 29. 25.  0.  0.
 15.  1. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25 25 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  5. 10.  9.  6.  3.  0.  9. 10.  9. 10.  4.] 
adversary cards in hand: [6. 8. 0. 0. 8.] 
adversary cards in discard: [6. 3. 3. 0. 0. 3. 6. 6.] 
adversary owned cards: [8 8 3 0 0 0 6 3 6 0 6 3 6] -> size -> 13 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 263 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 8.754281044006348






Player: 1 
cards in hand: [6. 8. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 0. 8.] 
cards in discard: [6. 3. 3. 0. 0. 3. 6. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 0 0 6 3 6 0 6 3 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  5. 10.  9.  6.  3.  0.  9. 10.  9. 10.  4.] 
adversary cards in hand: [15. 15. 29.  0. 29.] 
adversary cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29. 25. 29. 29. 25.  0.  0.
 15.  1. 15. 25.  0.  0.  1.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25 25 15] -> size -> 35 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 0. 8.] 
cards in discard: [6. 3. 3. 0. 0. 3. 6. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 0 0 6 3 6 0 6 3 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 24. 30.  8.  5. 10.  9.  6.  3.  0.  9. 10.  9. 10.  4.] 
adversary cards in hand: [15. 15. 29.  0. 29.] 
adversary cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29. 25. 29. 29. 25.  0.  0.
 15.  1. 15. 25.  0.  0.  1.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25 25 15] -> size -> 35 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 0. 8.] 
cards in discard: [6. 3. 3. 0. 0. 3. 6. 6. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 0 0 6 3 6 0 6 3 6 3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  5. 10.  9.  6.  3.  0.  9. 10.  9. 10.  4.] 
adversary cards in hand: [15. 15. 29.  0. 29.] 
adversary cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29. 25. 29. 29. 25.  0.  0.
 15.  1. 15. 25.  0.  0.  1.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25 25 15] -> size -> 35 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [15. 15. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 29. 29.] 
expected returns: [[-16.283823 ]
 [ -0.3674612]
 [ -0.3674612]
 [  6.5092716]
 [  6.5092716]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 29.  0. 29.] 
cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29. 25. 29. 29. 25.  0.  0.
 15.  1. 15. 25.  0.  0.  1.  3.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25 25 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  5. 10.  9.  6.  3.  0.  9. 10.  9. 10.  4.] 
adversary cards in hand: [0. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 0 0 6 3 6 0 6 3 6 3] -> size -> 14 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.39739418029785



action possibilites: [-1. 15. 15.] 
expected returns: [[-14.331268 ]
 [ -1.7449162]
 [ -1.7449162]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  0.  3.] 
cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29. 25. 29. 29. 25.  0.  0.
 15.  1. 15. 25.  0.  0.  1.  3.  3. 15. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15
 25  1 25 25 15 15  1 25 25 25 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 23. 30.  8.  5. 10.  9.  6.  3.  0.  9. 10.  9. 10.  4.] 
adversary cards in hand: [0. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 0 0 6 3 6 0 6 3 6 3] -> size -> 14 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -0.9417629241943359



action possibilites: [-1] 
expected returns: [[-9.343832]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.] 
cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29. 25. 29. 29. 25.  0.  0.
 15.  1. 15. 25.  0.  0.  1.  3.  3. 15. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 4 
card supply: [22. 26. 30. 23. 30.  8.  5. 10.  9.  6.  3.  0.  9. 10.  9. 10.  4.] 
adversary cards in hand: [0. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 0 0 6 3 6 0 6 3 6 3] -> size -> 14 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -1.744911551475525





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ -9.79691   ]
 [  2.5498393 ]
 [ -3.9604034 ]
 [-73.2757    ]
 [ -1.1400669 ]
 [  0.24400449]
 [-10.02021   ]
 [ -0.21930933]
 [ -1.4547474 ]
 [  2.9197352 ]
 [ -9.573465  ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.] 
cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29. 25. 29. 29. 25.  0.  0.
 15.  1. 15. 25.  0.  0.  1.  3.  3. 15. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 26. 30. 23. 30.  8.  5. 10.  9.  6.  3.  0.  9. 10.  9. 10.  4.] 
adversary cards in hand: [0. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 0 0 6 3 6 0 6 3 6 3] -> size -> 14 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.343832015991211



buy possibilites: [-1] 
expected returns: [[-27.047583]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.] 
cards in discard: [ 3. 25. 29. 25. 25. 29. 29. 29. 29.  1.  1. 29. 25. 29. 29. 25.  0.  0.
 15.  1. 15. 25.  0.  0.  1.  3.  3. 15. 29. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  5. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [0. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 0 0 6 3 6 0 6 3 6 3] -> size -> 14 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 283 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 2.9197237491607666






Player: 1 
cards in hand: [0. 0. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 0 0 6 3 6 0 6 3 6 3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  5. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [29.  1. 29. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15] -> size -> 35 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 3 0 3 6 0 6 3 6 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  5. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [29.  1. 29. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15] -> size -> 35 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 3 0 3 6 0 6 3 6 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 23. 30.  8.  5. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [29.  1. 29. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15] -> size -> 35 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [29.  1. 29. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 15. 25.] 
expected returns: [[38.345974]
 [56.350616]
 [56.350616]
 [50.701202]
 [51.500317]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 29. 15. 25.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  5. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [6. 3. 6. 6. 0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -27.047582626342773



action possibilites: [-1. 29. 15. 25.] 
expected returns: [[34.4255  ]
 [51.2517  ]
 [46.002403]
 [46.748665]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 25.  3.] 
cards in discard: [1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 23. 30.  8.  5. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [6. 3. 6. 6. 0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.832733154296875



action possibilites: [-1. 15. 25.] 
expected returns: [[33.750977]
 [45.51039 ]
 [46.30341 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25.  0.] 
cards in discard: [1. 3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 23. 30.  8.  5. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [6. 3. 6. 6. 0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.40369415283203



action possibilites: [-1] 
expected returns: [[53.345154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3. 29.] 
cards in discard: [1. 3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 23. 30.  8.  4. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [6. 3. 6. 6. 0.] 
adversary cards in discard: [8. 0. 6.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 46.303375244140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 52.129955]
 [ 64.90215 ]
 [ 58.53362 ]
 [-24.486616]
 [ 63.37921 ]
 [ 52.710407]
 [ 61.52176 ]
 [ 52.321953]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3. 29.] 
cards in discard: [1. 3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 23. 30.  8.  4. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [6. 3. 6. 6. 0.] 
adversary cards in discard: [8. 0. 6.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.34515380859375



buy possibilites: [-1] 
expected returns: [[118.47257]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3. 29.] 
cards in discard: [1. 3. 1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 23. 30.  8.  4. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [6. 3. 6. 6. 0.] 
adversary cards in discard: [8. 0. 6.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  90   0   0  60   0   0   0   0 -10   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 64.90213775634766






Player: 1 
cards in hand: [6. 3. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 6. 0.] 
cards in discard: [8. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 3 6 0 6 3 6 3 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 23. 30.  8.  4. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [ 0. 25.  3.  3. 15.] 
adversary cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1] -> size -> 36 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 6. 0.] 
cards in discard: [8. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 3 6 0 6 3 6 3 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 23. 30.  8.  4. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [ 0. 25.  3.  3. 15.] 
adversary cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1] -> size -> 36 
adversary victory points: 4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
expected returns: [[-1.1647167]
 [12.420652 ]
 [11.634368 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  3. 15.] 
cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 23. 30.  8.  4. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [6. 3. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6] -> size -> 12 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 118.47257232666016



action possibilites: [-1] 
expected returns: [[57.406578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 15. 25. 29.] 
cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 23. 30.  8.  3. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [6. 3. 3. 3. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6] -> size -> 13 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 12.058317184448242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 57.06006 ]
 [-18.557402]
 [ 57.03858 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 15. 25. 29.] 
cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 23. 30.  8.  3. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [6. 3. 3. 3. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6] -> size -> 13 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.406578063964844



buy possibilites: [-1] 
expected returns: [[92.07625]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 15. 25. 29.] 
cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 25. 30. 23. 30.  8.  3. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [6. 3. 3. 3. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6] -> size -> 13 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0. 120.   0.   0.  20.   0.   0.   0.   0. -20.   0.   0.
   0.   0.] 
sum of rewards: 115.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 57.0600700378418






Player: 1 
cards in hand: [6. 3. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 3. 8.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 23. 30.  8.  3. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [ 1. 29. 15. 25. 15.] 
adversary cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.  0. 25.  0.  3.  3. 15. 25. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0] -> size -> 37 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 8.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6] -> size -> 13 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 25. 30. 23. 30.  8.  3. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [ 1. 29. 15. 25. 15.] 
adversary cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.  0. 25.  0.  3.  3. 15. 25. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0] -> size -> 37 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 8.] 
cards in discard: [6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 23. 30.  8.  3. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [ 1. 29. 15. 25. 15.] 
adversary cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.  0. 25.  0.  3.  3. 15. 25. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0] -> size -> 37 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 1. 29. 15. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 25. 15.] 
expected returns: [[-0.05211616]
 [17.347834  ]
 [11.873513  ]
 [12.663897  ]
 [11.873513  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 15. 25. 15.] 
cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.  0. 25.  0.  3.  3. 15. 25. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 23. 30.  8.  3. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [8. 6. 3. 6. 0.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 8.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0] -> size -> 14 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 92.07624816894531



action possibilites: [-1. 15. 15. 25.] 
expected returns: [[27.20053 ]
 [38.962196]
 [38.962196]
 [39.757935]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 15. 25.] 
cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.  0. 25.  0.  3.  3. 15. 25. 29.
 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 23. 30.  8.  3. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [8. 6. 3. 6. 0.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 8.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0] -> size -> 14 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 11.389799118041992



action possibilites: [-1] 
expected returns: [[-9.167068]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 15. 29. 29.] 
cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.  0. 25.  0.  3.  3. 15. 25. 29.
 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 23. 30.  8.  2. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [8. 6. 3. 6. 0.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 8. 6.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6] -> size -> 15 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 39.757930755615234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-10.266436  ]
 [  2.08031   ]
 [ -4.429932  ]
 [-74.36563   ]
 [ -0.22552037]
 [-10.489738  ]
 [ -1.9242688 ]
 [-10.042991  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 15. 29. 29.] 
cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.  0. 25.  0.  3.  3. 15. 25. 29.
 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 25. 30. 23. 30.  8.  2. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [8. 6. 3. 6. 0.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 8. 6.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6] -> size -> 15 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.167067527770996



buy possibilites: [-1] 
expected returns: [[-14.608543]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 15. 29. 29.] 
cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.  0. 25.  0.  3.  3. 15. 25. 29.
 25.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 23. 30.  8.  2. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [8. 6. 3. 6. 0.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 8. 6.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6] -> size -> 15 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -30   0   0  54   0] 
sum of rewards: 209 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 2.080312490463257






Player: 1 
cards in hand: [8. 6. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3. 6. 0.] 
cards in discard: [6. 0. 6. 3. 3. 3. 8. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 23. 30.  8.  2. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [25.  1.  0. 29. 29.] 
adversary cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.  0. 25.  0.  3.  3. 15. 25. 29.
 25.  1. 29. 25.  1. 15. 15. 29. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0  1] -> size -> 38 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3. 6. 0.] 
cards in discard: [6. 0. 6. 3. 3. 3. 8. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 24. 30. 23. 30.  8.  2. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [25.  1.  0. 29. 29.] 
adversary cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.  0. 25.  0.  3.  3. 15. 25. 29.
 25.  1. 29. 25.  1. 15. 15. 29. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0  1] -> size -> 38 
adversary victory points: 4
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [25.  1.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[-4.088276]
 [ 9.301589]
 [14.375294]
 [14.375294]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0. 29. 29.] 
cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.  0. 25.  0.  3.  3. 15. 25. 29.
 25.  1. 29. 25.  1. 15. 15. 29. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 23. 30.  8.  2. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [3. 3. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6] -> size -> 15 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.608543395996094



action possibilites: [-1. 25. 29.] 
expected returns: [[ 0.73920417]
 [14.129072  ]
 [19.202768  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29.  0.] 
cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.  0. 25.  0.  3.  3. 15. 25. 29.
 25.  1. 29. 25.  1. 15. 15. 29. 29.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 23. 30.  8.  2. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [3. 3. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6] -> size -> 15 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 8.035012245178223



action possibilites: [-1. 25.] 
expected returns: [[-23.574518]
 [-10.189145]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.] 
cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.  0. 25.  0.  3.  3. 15. 25. 29.
 25.  1. 29. 25.  1. 15. 15. 29. 29.  1. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 24. 30. 23. 30.  8.  2. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [3. 3. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6] -> size -> 15 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 12.862506866455078



action possibilites: [-1] 
expected returns: [[0.18564677]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  1.] 
cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.  0. 25.  0.  3.  3. 15. 25. 29.
 25.  1. 29. 25.  1. 15. 15. 29. 29.  1. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 24. 30. 23. 30.  8.  1. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [3. 3. 6. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6] -> size -> 16 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -10.189140319824219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-3.77638340e-02]
 [ 1.23089867e+01]
 [-2.62025738e+01]
 [ 5.79873753e+00]
 [-3.04242611e+01]
 [-6.39154816e+01]
 [ 8.61907387e+00]
 [ 1.00031462e+01]
 [-2.61073112e-01]
 [ 1.35755405e+01]
 [ 9.53983688e+00]
 [ 1.33681965e+01]
 [ 8.30439568e+00]
 [ 4.23617649e+00]
 [ 1.26788750e+01]
 [ 1.85680151e-01]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25.  1.] 
cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.  0. 25.  0.  3.  3. 15. 25. 29.
 25.  1. 29. 25.  1. 15. 15. 29. 29.  1. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 24. 30. 23. 30.  8.  1. 10.  9.  6.  3.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [3. 3. 6. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6] -> size -> 16 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.18564677238464355



buy possibilites: [-1] 
expected returns: [[-2.5622942]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25.  1.] 
cards in discard: [ 1.  3.  1. 29. 29. 25. 15.  0.  3. 29.  0. 25.  0.  3.  3. 15. 25. 29.
 25.  1. 29. 25.  1. 15. 15. 29. 29.  1. 29. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0  1 25] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 23. 30.  8.  1. 10.  9.  6.  2.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [3. 3. 6. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6] -> size -> 16 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   60.    0.    0.    0.    0.  -40.
   0.    0.   62.5   0. ] 
sum of rewards: 257.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 13.575511932373047






Player: 1 
cards in hand: [3. 3. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 6. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 23. 30.  8.  1. 10.  9.  6.  2.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [ 1.  0. 15. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0  1 25] -> size -> 39 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 6. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 24. 30. 23. 30.  8.  1. 10.  9.  6.  2.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [ 1.  0. 15. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0  1 25] -> size -> 39 
adversary victory points: 4
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 15. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[-4.780732 ]
 [ 2.1058204]
 [ 2.1058204]
 [ 2.1058204]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15. 15. 15.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25
  1 25 25 15 15  1 25 25 25 15 15  1  0  1 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 23. 30.  8.  1. 10.  9.  6.  2.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [6. 3. 3. 6. 8.] 
adversary cards in discard: [6. 3. 3. 6. 6. 0.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6] -> size -> 16 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.5622942447662354



action possibilites: [-1] 
expected returns: [[-15.084866]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 15.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 24. 30. 23. 30.  8.  1. 10.  9.  6.  2.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [6. 3. 3. 6. 8.] 
adversary cards in discard: [6. 3. 3. 6. 6. 0.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6] -> size -> 16 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 1.826880693435669





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -16.757324 ]
 [  -4.1415453]
 [ -10.3275585]
 [ -53.07494  ]
 [-112.5046   ]
 [  -7.240803 ]
 [  -5.9531126]
 [ -16.972828 ]
 [  -2.9386377]
 [  -6.3636274]
 [  -3.1269596]
 [  -7.5787964]
 [ -12.193932 ]
 [  -3.6655152]
 [ -14.651662 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 15.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 24. 30. 23. 30.  8.  1. 10.  9.  6.  2.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [6. 3. 3. 6. 8.] 
adversary cards in discard: [6. 3. 3. 6. 6. 0.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6] -> size -> 16 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -15.08486557006836



buy possibilites: [-1] 
expected returns: [[-30.306166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 15.] 
cards in discard: [25.] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 23. 30.  8.  1. 10.  9.  6.  1.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [6. 3. 3. 6. 8.] 
adversary cards in discard: [6. 3. 3. 6. 6. 0.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6] -> size -> 16 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -40   0   0 250   0] 
sum of rewards: 435 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -2.938659191131592






Player: 1 
cards in hand: [6. 3. 3. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 6. 8.] 
cards in discard: [6. 3. 3. 6. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 23. 30.  8.  1. 10.  9.  6.  1.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [25. 15.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25] -> size -> 39 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 6. 8.] 
cards in discard: [6. 3. 3. 6. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6] -> size -> 16 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 24. 30. 23. 30.  8.  1. 10.  9.  6.  1.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [25. 15.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25] -> size -> 39 
adversary victory points: 4
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 6. 8.] 
cards in discard: [6. 3. 3. 6. 6. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6 0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 23. 30.  8.  1. 10.  9.  6.  1.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [25. 15.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25] -> size -> 39 
adversary victory points: 4
player victory points: -3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [29. 29. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[ 1.9834907]
 [20.519327 ]
 [20.519327 ]
 [20.519327 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  3.  0.] 
cards in discard: [25. 15.  1. 15. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 23. 30.  8.  1. 10.  9.  6.  1.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [8. 0. 0. 6. 6.] 
adversary cards in discard: [6. 3. 3. 6. 6. 0. 0. 6. 3. 3. 6. 8.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6 0] -> size -> 17 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -30.30616569519043



action possibilites: [-1. 29. 25.] 
expected returns: [[23.637245]
 [42.108116]
 [37.203907]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 25.] 
cards in discard: [25. 15.  1. 15. 15. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 24. 30. 23. 30.  8.  1. 10.  9.  6.  1.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [8. 0. 0. 6. 6.] 
adversary cards in discard: [6. 3. 3. 6. 6. 0. 0. 6. 3. 3. 6. 8.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6 0] -> size -> 17 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 14.19706916809082



action possibilites: [-1. 25. 25.] 
expected returns: [[27.372007]
 [40.090294]
 [40.090294]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25.] 
cards in discard: [25. 15.  1. 15. 15. 29.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 24. 30. 23. 30.  8.  1. 10.  9.  6.  1.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [8. 0. 0. 6. 6.] 
adversary cards in discard: [6. 3. 3. 6. 6. 0. 0. 6. 3. 3. 6. 8.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6 0] -> size -> 17 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 35.81483459472656



action possibilites: [-1] 
expected returns: [[22.460825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0.] 
cards in discard: [25. 15.  1. 15. 15. 29.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 24. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [8. 0. 0. 6. 6.] 
adversary cards in discard: [6. 3. 3. 6. 6. 0. 0. 6. 3. 3. 6. 8. 6.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6 0 6] -> size -> 18 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 40.09025573730469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[23.319138]
 [35.798676]
 [29.019388]
 [31.885958]
 [33.4653  ]
 [23.547249]
 [32.957905]
 [31.687723]
 [36.307514]
 [22.733404]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3.  0.] 
cards in discard: [25. 15.  1. 15. 15. 29.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 24. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  3.] 
adversary cards in hand: [8. 0. 0. 6. 6.] 
adversary cards in discard: [6. 3. 3. 6. 6. 0. 0. 6. 3. 3. 6. 8. 6.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6 0 6] -> size -> 18 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.460824966430664



buy possibilites: [-1] 
expected returns: [[21.577759]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3.  0.] 
cards in discard: [25. 15.  1. 15. 15. 29.  3. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [8. 0. 0. 6. 6.] 
adversary cards in discard: [6. 3. 3. 6. 6. 0. 0. 6. 3. 3. 6. 8. 6.] 
adversary owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6 0 6] -> size -> 18 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0 -50   0   0 128   0] 
sum of rewards: 343 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 36.3074951171875






Player: 1 
cards in hand: [8. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 6. 6.] 
cards in discard: [6. 3. 3. 6. 6. 0. 0. 6. 3. 3. 6. 8. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 0 3 6 0 6 3 6 3 6 6 0 6 6 0 6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [25. 29. 29. 29. 15.] 
adversary cards in discard: [25. 15.  1. 15. 15. 29.  3. 15. 29. 29. 25.  0. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15] -> size -> 40 
adversary victory points: 4
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6.] 
cards in discard: [6. 3. 3. 6. 6. 0. 0. 6. 3. 3. 6. 8. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 3 3 6 0 6 3 6 3 6 6 0 6 6 0 6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [25. 29. 29. 29. 15.] 
adversary cards in discard: [25. 15.  1. 15. 15. 29.  3. 15. 29. 29. 25.  0. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15] -> size -> 40 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [6. 3. 3. 6. 6. 0. 0. 6. 3. 3. 6. 8. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 3 3 6 0 6 3 6 3 6 6 0 6 6 0 6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [25. 29. 29. 29. 15.] 
adversary cards in discard: [25. 15.  1. 15. 15. 29.  3. 15. 29. 29. 25.  0. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15] -> size -> 40 
adversary victory points: 4
player victory points: -4 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [25. 29. 29. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29. 29. 15.] 
expected returns: [[33.369896]
 [45.821484]
 [50.38457 ]
 [50.38457 ]
 [50.38457 ]
 [45.05769 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29. 29. 15.] 
cards in discard: [25. 15.  1. 15. 15. 29.  3. 15. 29. 29. 25.  0. 25.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [6. 6. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 3 6 0 6 3 6 3 6 6 0 6 6 0 6] -> size -> 17 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.5777587890625



action possibilites: [-1. 29. 29. 15.] 
expected returns: [[51.04692]
 [66.90182]
 [66.90182]
 [62.0019 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 15.] 
cards in discard: [25. 15.  1. 15. 15. 29.  3. 15. 29. 29. 25.  0. 25.  3.  0. 25.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 24. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [6. 6. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 3 6 0 6 3 6 3 6 6 0 6 6 0 6] -> size -> 17 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 44.560997009277344



action possibilites: [-1. 29.] 
expected returns: [[ 5.4378815]
 [21.985048 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [25. 15.  1. 15. 15. 29.  3. 15. 29. 29. 25.  0. 25.  3.  0. 25.  3. 15.
  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 24. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [6. 6. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 3 6 0 6 3 6 3 6 6 0 6 6 0 6] -> size -> 17 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 61.46984100341797



action possibilites: [-1.] 
expected returns: [[27.580273]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25. 15.  1. 15. 15. 29.  3. 15. 29. 29. 25.  0. 25.  3.  0. 25.  3. 15.
  1. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 3 
card supply: [19. 24. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [6. 6. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 3 6 0 6 3 6 3 6 6 0 6 6 0 6] -> size -> 17 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 4.276191711425781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[27.26137 ]
 [39.41854 ]
 [32.950127]
 [37.397873]
 [27.667467]
 [35.695797]
 [27.238762]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25. 15.  1. 15. 15. 29.  3. 15. 29. 29. 25.  0. 25.  3.  0. 25.  3. 15.
  1. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15] -> size -> 40 
action values: 1 
buys: 1 
player value: 3 
card supply: [19. 24. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [6. 6. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 3 6 0 6 3 6 3 6 6 0 6 6 0 6] -> size -> 17 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.580272674560547



buy possibilites: [-1] 
expected returns: [[-6.4268937]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25. 15.  1. 15. 15. 29.  3. 15. 29. 29. 25.  0. 25.  3.  0. 25.  3. 15.
  1. 29.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [6. 6. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 3 6 0 6 3 6 3 6 6 0 6 6 0 6] -> size -> 17 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0 -60   0   0  54   0] 
sum of rewards: 289 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 39.4185791015625






Player: 1 
cards in hand: [6. 6. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 3. 6.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 3 6 0 6 3 6 3 6 6 0 6 6 0 6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [29.  1. 25.  1.  1.] 
adversary cards in discard: [25. 15.  1. 15. 15. 29.  3. 15. 29. 29. 25.  0. 25.  3.  0. 25.  3. 15.
  1. 29.  1. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15  1] -> size -> 41 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 3. 6.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 3 6 0 6 3 6 3 6 6 0 6 6 0 6] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 23. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [29.  1. 25.  1.  1.] 
adversary cards in discard: [25. 15.  1. 15. 15. 29.  3. 15. 29. 29. 25.  0. 25.  3.  0. 25.  3. 15.
  1. 29.  1. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15  1] -> size -> 41 
adversary victory points: 4
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 3. 6.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 3 6 0 6 3 6 3 6 6 0 6 6 0 6 0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [29.  1. 25.  1.  1.] 
adversary cards in discard: [25. 15.  1. 15. 15. 29.  3. 15. 29. 29. 25.  0. 25.  3.  0. 25.  3. 15.
  1. 29.  1. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15  1] -> size -> 41 
adversary victory points: 4
player victory points: -4 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [29.  1. 25.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-3.1177735]
 [15.345791 ]
 [10.272089 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 25.  1.  1.] 
cards in discard: [25. 15.  1. 15. 15. 29.  3. 15. 29. 29. 25.  0. 25.  3.  0. 25.  3. 15.
  1. 29.  1. 29. 29. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [8. 6. 0. 6. 3.] 
adversary cards in discard: [0. 6. 6. 6. 3. 6.] 
adversary owned cards: [8 8 3 3 6 0 6 3 6 3 6 6 0 6 6 0 6 0] -> size -> 18 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -6.426893711090088



action possibilites: [-1. 25.] 
expected returns: [[-21.9012  ]
 [ -8.515828]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 25.] 
cards in discard: [25. 15.  1. 15. 15. 29.  3. 15. 29. 29. 25.  0. 25.  3.  0. 25.  3. 15.
  1. 29.  1. 29. 29. 29. 25.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 23. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [8. 6. 0. 6. 3.] 
adversary cards in discard: [0. 6. 6. 6. 3. 6.] 
adversary owned cards: [8 8 3 3 6 0 6 3 6 3 6 6 0 6 6 0 6 0] -> size -> 18 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 9.005521774291992



action possibilites: [-1] 
expected returns: [[-40.335518]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 25. 15.] 
cards in discard: [25. 15.  1. 15. 15. 29.  3. 15. 29. 29. 25.  0. 25.  3.  0. 25.  3. 15.
  1. 29.  1. 29. 29. 29. 25.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 23. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [8. 6. 0. 6. 3.] 
adversary cards in discard: [0. 6. 6. 6. 3. 6.] 
adversary owned cards: [8 8 3 3 6 0 6 3 6 3 6 6 0 6 6 0 6 0] -> size -> 18 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -8.515830039978027





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-40.56077 ]
 [-28.216055]
 [-34.724365]
 [-89.562874]
 [-31.90511 ]
 [-30.521868]
 [-40.786785]
 [-26.950144]
 [-30.985003]
 [-27.157381]
 [-32.220253]
 [-36.286087]
 [-27.846779]
 [-40.335526]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 25. 15.] 
cards in discard: [25. 15.  1. 15. 15. 29.  3. 15. 29. 29. 25.  0. 25.  3.  0. 25.  3. 15.
  1. 29.  1. 29. 29. 29. 25.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 23. 30. 23. 30.  8.  0. 10.  9.  6.  1.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [8. 6. 0. 6. 3.] 
adversary cards in discard: [0. 6. 6. 6. 3. 6.] 
adversary owned cards: [8 8 3 3 6 0 6 3 6 3 6 6 0 6 6 0 6 0] -> size -> 18 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: -40.33551788330078



Player 0 won the game! 



Player 0 bought cards:
Copper: 1 
Silver: 7 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 10 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 7 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1.  1. 25. 15.] 
cards in discard: [25. 15.  1. 15. 15. 29.  3. 15. 29. 29. 25.  0. 25.  3.  0. 25.  3. 15.
  1. 29.  1. 29. 29. 29. 25.  1. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  3  3  3  1 29  3 29 29 29 29 29 29 29 29 29  1 15 25 15 25  1
 25 25 15 15  1 25 25 25 15 15  1  0  1 25 25 15  1 25] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 23. 30.  8.  0. 10.  9.  6.  0.  0.  9. 10.  9. 10.  2.] 
adversary cards in hand: [8. 6. 0. 6. 3.] 
adversary cards in discard: [0. 6. 6. 6. 3. 6.] 
adversary owned cards: [8 8 3 3 6 0 6 3 6 3 6 6 0 6 6 0 6 0] -> size -> 18 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[     -5 3000000       0     240       0       0      40       0       0
       0       0     -70       0       0     125       0] 
sum of rewards: 3000330 

action type: buy - action 25.0
Learning step: 120014.2734375
desired expected reward: 119987.3203125



