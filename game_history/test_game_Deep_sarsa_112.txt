 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[34.461105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000095 

action type: buy - action -1.0
Learning step: -300004.5625
desired expected reward: -300053.96875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[34.004112]
 [65.691025]
 [48.10415 ]
 [17.398985]
 [70.04969 ]
 [52.126534]
 [37.47585 ]
 [33.039597]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.80723190307617



buy possibilites: [-1] 
expected returns: [[24.963331]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 70.0496826171875






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[42.28165]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.96333122253418





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 43.478466]
 [ 74.33288 ]
 [ 58.298344]
 [ 22.66681 ]
 [ 67.21931 ]
 [ 78.41466 ]
 [ 61.82568 ]
 [112.017265]
 [ 36.287975]
 [ 47.430855]
 [ 65.25095 ]
 [ 42.33714 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 40.06060791015625



buy possibilites: [-1] 
expected returns: [[9.626433]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 112.01724243164062






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 5.348877]
 [41.407516]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.626433372497559



action possibilites: [-1.] 
expected returns: [[36.549282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 39.56555938720703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 39.058277]
 [ 65.31174 ]
 [ 27.136728]
 [ 50.532368]
 [ 31.21772 ]
 [ 20.738667]
 [ 59.810825]
 [ 67.75488 ]
 [ 54.00018 ]
 [118.182655]
 [103.040054]
 [ 32.367867]
 [ 62.45193 ]
 [ 41.469193]
 [ 36.65352 ]
 [ 56.641293]
 [ 35.94873 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 36.54928207397461



buy possibilites: [-1] 
expected returns: [[21.81281]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 77.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 118.18266296386719






Player: 1 
cards in hand: [ 0.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 9.500154]
 [33.558865]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  3.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 10.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.81281089782715



action possibilites: [-1] 
expected returns: [[-13.423447]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 10.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 46.27375411987305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-11.721256 ]
 [  1.0932415]
 [-28.071447 ]
 [  5.698433 ]
 [-11.364726 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 10.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -13.423446655273438



buy possibilites: [-1] 
expected returns: [[6.0337877]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 10.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 5.698423385620117






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 8. 10.  0.  3.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 8. 10.  0.  3.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[-0.5983536]
 [-1.1377404]
 [32.909145 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.033787727355957



action possibilites: [-1] 
expected returns: [[8.708933]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  3.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 30.316635131835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[12.477182 ]
 [25.407917 ]
 [-3.7253425]
 [28.790379 ]
 [12.259874 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  3.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.708932876586914



buy possibilites: [-1] 
expected returns: [[19.21439]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  3.  8.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 28.790386199951172






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 8. 25. 10.  0.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 8. 25. 10.  0.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 8. 25. 10.  0.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 5.0135098]
 [24.08683  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [ 8. 25. 10.  0.  0.  3.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  3.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.21438980102539



action possibilites: [-1] 
expected returns: [[-17.35047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 8. 25. 10.  0.  0.  3.  3.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8.  7.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  3.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 28.166797637939453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-18.828955 ]
 [ -5.255102 ]
 [-12.841659 ]
 [-27.000216 ]
 [ -3.3880277]
 [-11.133017 ]
 [-17.006907 ]
 [-17.470972 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 8. 25. 10.  0.  0.  3.  3.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8.  7.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  3.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -17.3504695892334



buy possibilites: [-1] 
expected returns: [[-9.953365]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 8. 25. 10.  0.  0.  3.  3.  8. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  7.  7.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  3.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -3.3880248069763184






Player: 1 
cards in hand: [ 8. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  3.] 
cards in discard: [ 6. 15.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  7.  7.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.  3.] 
cards in discard: [ 6. 15.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  7.  7.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.  3.] 
cards in discard: [ 6. 15.  0.  0.  0.  3.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  7.  6.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 4.0354366]
 [50.30748  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  7.  6.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  6. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -9.953365325927734



action possibilites: [-1.] 
expected returns: [[31.002785]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  7.  6.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  6. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 47.598915100097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 44.566826]
 [ 70.20697 ]
 [ 31.943428]
 [ 54.15996 ]
 [ 37.407513]
 [ 25.985603]
 [ 65.83595 ]
 [ 70.7004  ]
 [ 58.62975 ]
 [121.19469 ]
 [106.856895]
 [ 37.19293 ]
 [ 67.78367 ]
 [ 45.004505]
 [ 42.72764 ]
 [ 60.56493 ]
 [ 37.271286]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  7.  6.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  6. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 31.002784729003906



buy possibilites: [-1] 
expected returns: [[19.03299]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  7.  6.  8.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  6. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 107.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 121.1947021484375






Player: 1 
cards in hand: [ 3.  6. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  7.  6.  8.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10. 11.  8.  3. 25.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25] -> size -> 19 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15  8] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  7.  6.  8.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10. 11.  8.  3. 25.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  7.  6.  8.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10. 11.  8.  3. 25.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25] -> size -> 19 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  3.  0. 11.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  7.  6.  8.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10. 11.  8.  3. 25.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25] -> size -> 19 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [10. 11.  8.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8. 25.] 
expected returns: [[-7.905177 ]
 [-1.2914298]
 [ 2.6475604]
 [ 3.014259 ]
 [14.558939 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8.  3. 25.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  7.  6.  8.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0. 15.  0.  0.] 
adversary cards in discard: [ 0. 10.  3.  6.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15  8  0] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.032989501953125



action possibilites: [-1] 
expected returns: [[28.412525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8.  3.  8.  0.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  8. 10.  7.  6.  8.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0. 15.  0.  0.] 
adversary cards in discard: [ 0. 10.  3.  6.  3.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15  8  0  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 9.669876098632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[36.481953]
 [19.41692 ]
 [33.05935 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  8.  3.  8.  0.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8.  8. 10.  7.  6.  8.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0. 15.  0.  0.] 
adversary cards in discard: [ 0. 10.  3.  6.  3.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15  8  0  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.412525177001953



buy possibilites: [-1] 
expected returns: [[39.09501]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  8.  3.  8.  0.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8.  8. 10.  7.  6.  8.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0. 15.  0.  0.] 
adversary cards in discard: [ 0. 10.  3.  6.  3.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15  8  0  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 45.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 36.481929779052734






Player: 1 
cards in hand: [ 8.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  0.  0.] 
cards in discard: [ 0. 10.  3.  6.  3.  0. 11.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  8  6 15  8  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  8. 10.  7.  6.  8.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 11. 10.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.  0. 25. 10. 11.  8.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0] -> size -> 20 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [ 0. 10.  3.  6.  3.  0. 11.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  8  6 15  8  0  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  8. 10.  7.  6.  8.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 11. 10.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.  0. 25. 10. 11.  8.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0] -> size -> 20 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [ 0. 10.  3.  6.  3.  0. 11.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  8  6 15  8  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 30. 30.  8.  8. 10.  7.  6.  8.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 11. 10.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.  0. 25. 10. 11.  8.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0] -> size -> 20 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [ 0. 10.  3.  6.  3.  0. 11.  6.  4.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  8  6 15  8  0  6  4] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  7.  6.  8.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 11. 10.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.  0. 25. 10. 11.  8.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[ 0.7723863]
 [12.176413 ]
 [-1.5898697]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11. 10.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0.  0. 25. 10. 11.  8.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  7.  6.  8.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 0. 10.  3.  6.  3.  0. 11.  6.  4. 15.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  8  6 15  8  0  6  4] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.095008850097656



action possibilites: [-1] 
expected returns: [[114.24368]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0.  0. 25. 10. 11.  8.  3.  8.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  7.  6.  8.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 0. 10.  3.  6.  3.  0. 11.  6.  4. 15.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  8  6 15  8  0  6  4] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 17.216960906982422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 91.89958]
 [ 66.06591]
 [116.92358]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0.  0. 25. 10. 11.  8.  3.  8.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  7.  6.  8.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 0. 10.  3.  6.  3.  0. 11.  6.  4. 15.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  8  6 15  8  0  6  4] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 114.24368286132812






Player: 1 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [ 0. 10.  3.  6.  3.  0. 11.  6.  4. 15.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  8  6 15  8  0  6  4] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  7.  6.  8.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10] -> size -> 21 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0. 10.  3.  6.  3.  0. 11.  6.  4. 15.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  7.  6.  8.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0. 10.  3.  6.  3.  0. 11.  6.  4. 15.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  7.  6.  8.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10] -> size -> 21 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0. 10.  3.  6.  3.  0. 11.  6.  4. 15.  8.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 29.  8.  8. 10.  7.  6.  8.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10] -> size -> 21 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[-2.586418  ]
 [-0.82754254]
 [41.650547  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 29.  8.  8. 10.  7.  6.  8.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3. 15.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 116.92359924316406



action possibilites: [-1] 
expected returns: [[20.676294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 29.  8.  7. 10.  7.  6.  8.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3. 15.  8. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 36.82864761352539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[34.872997]
 [57.93902 ]
 [42.920963]
 [20.59911 ]
 [58.950157]
 [47.246307]
 [34.910515]
 [28.862892]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 29.  8.  7. 10.  7.  6.  8.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3. 15.  8. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.676294326782227



buy possibilites: [-1] 
expected returns: [[8.276599]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.  8.] 
cards in discard: [11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 29.  8.  7. 10.  6.  6.  8.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3. 15.  8. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 58.95014953613281






Player: 1 
cards in hand: [ 3.  3. 15.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.  8. 10.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 29.  8.  7. 10.  6.  6.  8.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [11. 25. 10.  0.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15.  8. 10.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 29. 29.  8.  7. 10.  6.  6.  8.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [11. 25. 10.  0.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15.  8. 10.] 
cards in discard: [6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  7. 10.  6.  6.  8.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [11. 25. 10.  0.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[22.629702]
 [46.247246]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [11. 25. 10.  0.  0.  0.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  7. 10.  6.  6.  8.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 6. 0. 3. 4.] 
adversary cards in discard: [ 6.  0.  3.  3. 15.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6  0] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.276598930358887



action possibilites: [-1] 
expected returns: [[19.593538]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [11. 25. 10.  0.  0.  0.  3.  8. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  7. 10.  6.  6.  8.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 6. 0. 3. 4.] 
adversary cards in discard: [ 6.  0.  3.  3. 15.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6  0] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 48.7239875793457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[13.071074 ]
 [19.429293 ]
 [ 4.8183756]
 [20.762245 ]
 [17.184517 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [11. 25. 10.  0.  0.  0.  3.  8. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 29.  8.  7. 10.  6.  6.  8.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 6. 0. 3. 4.] 
adversary cards in discard: [ 6.  0.  3.  3. 15.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6  0] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.593538284301758



buy possibilites: [-1] 
expected returns: [[17.75048]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [11. 25. 10.  0.  0.  0.  3.  8. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  7. 10.  6.  5.  8.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 6. 0. 3. 4.] 
adversary cards in discard: [ 6.  0.  3.  3. 15.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6  0] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 20.762237548828125






Player: 1 
cards in hand: [0. 6. 0. 3. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 4.] 
cards in discard: [ 6.  0.  3.  3. 15.  8. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  7. 10.  6.  5.  8.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 29. 10.] 
adversary cards in discard: [11. 25. 10.  0.  0.  0.  3.  8. 10.  8. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 4.] 
cards in discard: [ 6.  0.  3.  3. 15.  8. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 29.  8.  7. 10.  6.  5.  8.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 29. 10.] 
adversary cards in discard: [11. 25. 10.  0.  0.  0.  3.  8. 10.  8. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 4.] 
cards in discard: [ 6.  0.  3.  3. 15.  8. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 29. 29.  8.  7. 10.  6.  5.  8.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 29. 10.] 
adversary cards in discard: [11. 25. 10.  0.  0.  0.  3.  8. 10.  8. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8] -> size -> 24 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[ 80.09801]
 [ 98.55475]
 [106.31135]
 [ 73.25073]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 29. 10.] 
cards in discard: [11. 25. 10.  0.  0.  0.  3.  8. 10.  8. 11.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  7. 10.  6.  5.  8.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  8.] 
adversary cards in discard: [ 6.  0.  3.  3. 15.  8. 10.  0.  0.  6.  0.  3.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.75048065185547



action possibilites: [-1. 11. 10.] 
expected returns: [[ 73.99736]
 [101.30712]
 [ 68.91477]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.  0.] 
cards in discard: [11. 25. 10.  0.  0.  0.  3.  8. 10.  8. 11.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 29.  8.  7. 10.  6.  5.  8.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  8.] 
adversary cards in discard: [ 6.  0.  3.  3. 15.  8. 10.  0.  0.  6.  0.  3.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 106.31134796142578



action possibilites: [-1] 
expected returns: [[174.45648]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [11. 25. 10.  0.  0.  0.  3.  8. 10.  8. 11.  3.  0.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 29.  8.  7. 10.  6.  5.  8.  9. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  8.] 
adversary cards in discard: [ 6.  0.  3.  3. 15.  8. 10.  0.  0.  6.  0.  3.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 108.25204467773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[149.02663]
 [178.63782]
 [170.55202]
 [128.8213 ]
 [167.14326]
 [190.76811]
 [170.26514]
 [200.78122]
 [146.84045]
 [161.85007]
 [176.67543]
 [173.13176]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [11. 25. 10.  0.  0.  0.  3.  8. 10.  8. 11.  3.  0.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 29. 29.  8.  7. 10.  6.  5.  8.  9. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  8.] 
adversary cards in discard: [ 6.  0.  3.  3. 15.  8. 10.  0.  0.  6.  0.  3.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 174.45648193359375



buy possibilites: [-1] 
expected returns: [[94.13115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [11. 25. 10.  0.  0.  0.  3.  8. 10.  8. 11.  3.  0.  0.  3. 10. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  7. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  8.] 
adversary cards in discard: [ 6.  0.  3.  3. 15.  8. 10.  0.  0.  6.  0.  3.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 200.78123474121094






Player: 1 
cards in hand: [ 6. 11.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0.  8.] 
cards in discard: [ 6.  0.  3.  3. 15.  8. 10.  0.  0.  6.  0.  3.  4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  8  6 15  8  0  6  4  3  6  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  7. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29] -> size -> 26 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 6.  0.  3.  3. 15.  8. 10.  0.  0.  6.  0.  3.  4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10  8  6 15  8  0  6  4  3  6  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  7. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29] -> size -> 26 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 6.  0.  3.  3. 15.  8. 10.  0.  0.  6.  0.  3.  4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10  8  6 15  8  0  6  4  3  6  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  7. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29] -> size -> 26 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 6.  0.  3.  3. 15.  8. 10.  0.  0.  6.  0.  3.  4.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10  8  6 15  8  0  6  4  3  6  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 29.  8.  7. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29] -> size -> 26 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 10.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8. 25.] 
expected returns: [[16.542091]
 [21.671352]
 [21.671352]
 [30.780205]
 [68.25928 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  8. 25.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 29.  8.  7. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  8. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  8  6 15  8  0  6  4  3  6  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.13114929199219



action possibilites: [-1] 
expected returns: [[25.779423]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  8. 29.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 29.  8.  6. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  8. 15.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3 10  8  6 15  8  0  6  4  3  6  0  0  0  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 57.51979446411133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[34.169735]
 [19.513618]
 [30.509125]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  8. 29.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 29. 29.  8.  6. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  8. 15.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3 10  8  6 15  8  0  6  4  3  6  0  0  0  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.779422760009766



buy possibilites: [-1] 
expected returns: [[36.22857]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  8. 29.  0.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 29. 29.  8.  6. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  8. 15.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3 10  8  6 15  8  0  6  4  3  6  0  0  0  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 34.16973114013672






Player: 1 
cards in hand: [ 8.  8. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 15.  0.  0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8  6 15  8  0  6  4  3  6  0  0  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 29.  8.  6. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 11. 25. 10. 10.] 
adversary cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0] -> size -> 27 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 29.  8.  6. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 11. 25. 10. 10.] 
adversary cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0] -> size -> 27 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 29. 29.  8.  6. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 11. 25. 10. 10.] 
adversary cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0] -> size -> 27 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 25. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 25. 10. 10.] 
expected returns: [[-3.160431  ]
 [ 1.8260081 ]
 [ 2.1060612 ]
 [ 7.2484674 ]
 [ 0.94719243]
 [ 0.94719243]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 25. 10. 10.] 
cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 29.  8.  6. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 6. 6. 0. 4.] 
adversary cards in discard: [ 6.  8. 15.  0.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.22856903076172



action possibilites: [-1] 
expected returns: [[9.7628975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10. 10.  8. 11.] 
cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 29.  8.  5. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 6. 6. 0. 4.] 
adversary cards in discard: [ 6.  8. 15.  0.  6.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 5.384343147277832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 5.7700396]
 [-6.2477407]
 [12.191557 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 10. 10.  8. 11.] 
cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 29. 29.  8.  5. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 6. 6. 0. 4.] 
adversary cards in discard: [ 6.  8. 15.  0.  6.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.762897491455078






Player: 1 
cards in hand: [6. 6. 6. 0. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 0. 4.] 
cards in discard: [ 6.  8. 15.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 29.  8.  5. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0. 25.  8. 11. 10. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0] -> size -> 27 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 4.] 
cards in discard: [ 6.  8. 15.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 29. 29.  8.  5. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0. 25.  8. 11. 10. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0] -> size -> 27 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[18.531319]
 [63.319576]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0. 25.  8. 11. 10. 10.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 29.  8.  5. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.  0.  3.] 
adversary cards in discard: [ 6.  8. 15.  0.  6.  6.  6.  6.  0.  4.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 12.19155502319336



action possibilites: [-1. 11.] 
expected returns: [[50.538433]
 [67.12782 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0. 25.  8. 11. 10. 10.  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 29. 29.  8.  5. 10.  6.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.  0.  3.] 
adversary cards in discard: [ 6.  8. 15.  0.  6.  6.  6.  6.  0.  4.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 63.31959915161133



action possibilites: [-1] 
expected returns: [[61.834988]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0. 25.  8. 11. 10. 10.  8. 11. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 29. 29.  8.  5. 10.  6.  5.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.  0.  3.] 
adversary cards in discard: [ 6.  8. 15.  0.  6.  6.  6.  6.  0.  4.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 122 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 71.57029724121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[41.99091 ]
 [62.00926 ]
 [55.8414  ]
 [34.576862]
 [28.9614  ]
 [54.171597]
 [70.16613 ]
 [56.04616 ]
 [88.487434]
 [78.538315]
 [41.806583]
 [58.48364 ]
 [51.476986]
 [38.68455 ]
 [60.12056 ]
 [59.50777 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0. 25.  8. 11. 10. 10.  8. 11. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 30. 30. 29. 29.  8.  5. 10.  6.  5.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.  0.  3.] 
adversary cards in discard: [ 6.  8. 15.  0.  6.  6.  6.  6.  0.  4.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.83498764038086



buy possibilites: [-1] 
expected returns: [[49.320366]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0. 25.  8. 11. 10. 10.  8. 11. 10. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 29.  8.  5. 10.  6.  5.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.  0.  3.] 
adversary cards in discard: [ 6.  8. 15.  0.  6.  6.  6.  6.  0.  4.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 345 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 88.4874496459961






Player: 1 
cards in hand: [ 3.  3. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.  3.] 
cards in discard: [ 6.  8. 15.  0.  6.  6.  6.  6.  0.  4.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 29.  8.  5. 10.  6.  5.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0.  3.  3.  0.] 
adversary cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0. 25.  8. 11. 10. 10.  8. 11. 10. 25. 29.
 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25] -> size -> 29 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0.  3.] 
cards in discard: [ 6.  8. 15.  0.  6.  6.  6.  6.  0.  4.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 29. 29.  8.  5. 10.  6.  5.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0.  3.  3.  0.] 
adversary cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0. 25.  8. 11. 10. 10.  8. 11. 10. 25. 29.
 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25] -> size -> 29 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0.  3.] 
cards in discard: [ 6.  8. 15.  0.  6.  6.  6.  6.  0.  4.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 29. 29.  8.  5. 10.  6.  5.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0.  3.  3.  0.] 
adversary cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0. 25.  8. 11. 10. 10.  8. 11. 10. 25. 29.
 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25] -> size -> 29 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[21.84116 ]
 [21.952045]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3.  0.] 
cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0. 25.  8. 11. 10. 10.  8. 11. 10. 25. 29.
 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 29. 29.  8.  5. 10.  6.  5.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.32036590576172



action possibilites: [-1.] 
expected returns: [[6.754203]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0. 25.  8. 11. 10. 10.  8. 11. 10. 25. 29.
 11.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 29. 29.  8.  5. 10.  6.  5.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 21.952054977416992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 1.549514 ]
 [24.978214 ]
 [15.343584 ]
 [-1.4666266]
 [33.55552  ]
 [15.548565 ]
 [ 8.447269 ]
 [11.175367 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0. 25.  8. 11. 10. 10.  8. 11. 10. 25. 29.
 11.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 29. 29.  8.  5. 10.  6.  5.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 6.754202842712402



buy possibilites: [-1] 
expected returns: [[19.79951]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0. 25.  3. 10. 10.  8. 29.  0. 25.  8. 11. 10. 10.  8. 11. 10. 25. 29.
 11.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 29. 29.  8.  5. 10.  5.  5.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 33.55552673339844






Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 29. 29.  8.  5. 10.  5.  5.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 25. 25. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11] -> size -> 30 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 29. 29.  8.  5. 10.  5.  5.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 25. 25. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11] -> size -> 30 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 28. 29.  8.  5. 10.  5.  5.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 25. 25. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11] -> size -> 30 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 8. 25. 25. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 25. 11. 10.] 
expected returns: [[31.585094]
 [41.83626 ]
 [66.02995 ]
 [66.02995 ]
 [49.03342 ]
 [34.08757 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 25. 11. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 29.  8.  5. 10.  5.  5.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 4. 3. 0. 0.] 
adversary cards in discard: [3. 8. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.799509048461914



action possibilites: [-1] 
expected returns: [[60.98939]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 11. 10.  8.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 29.  8.  4. 10.  5.  5.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 4. 3. 0. 0.] 
adversary cards in discard: [3. 8. 3. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 60.09329605102539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[52.58214]
 [37.84344]
 [55.56154]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25. 11. 10.  8.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 28. 29.  8.  4. 10.  5.  5.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 4. 3. 0. 0.] 
adversary cards in discard: [3. 8. 3. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 60.9893913269043






Player: 1 
cards in hand: [6. 4. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 4. 3. 0. 0.] 
cards in discard: [3. 8. 3. 0. 0. 0. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 29.  8.  4. 10.  5.  5.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  3. 10.  0.] 
adversary cards in discard: [25.  8. 25. 11. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11] -> size -> 30 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 4. 3. 0. 0.] 
cards in discard: [3. 8. 3. 0. 0. 0. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 28. 29.  8.  4. 10.  5.  5.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  3. 10.  0.] 
adversary cards in discard: [25.  8. 25. 11. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11] -> size -> 30 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 4. 3. 0. 0.] 
cards in discard: [3. 8. 3. 0. 0. 0. 6. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 29.  8.  4. 10.  5.  4.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  3. 10.  0.] 
adversary cards in discard: [25.  8. 25. 11. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11] -> size -> 30 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[44.08296 ]
 [56.800167]
 [40.136707]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 10.  0.] 
cards in discard: [25.  8. 25. 11. 10.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 29.  8.  4. 10.  5.  4.  7.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 15.  6. 10.  6.] 
adversary cards in discard: [3. 8. 3. 0. 0. 0. 6. 8. 6. 4. 3. 0. 0.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 55.5615234375



action possibilites: [-1] 
expected returns: [[57.25443]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 29.  8.  4. 10.  5.  4.  7.  8. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 6. 15.  6. 10.  6.] 
adversary cards in discard: [3. 8. 3. 0. 0. 0. 6. 8. 6. 4. 3. 0. 0.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 64.68942260742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[48.446594]
 [67.78732 ]
 [19.421488]
 [66.850426]
 [63.345325]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 28. 29.  8.  4. 10.  5.  4.  7.  8. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 6. 15.  6. 10.  6.] 
adversary cards in discard: [3. 8. 3. 0. 0. 0. 6. 8. 6. 4. 3. 0. 0.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.25442886352539



buy possibilites: [-1] 
expected returns: [[46.39917]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 29.  8.  4. 10.  5.  4.  7.  8. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 6. 15.  6. 10.  6.] 
adversary cards in discard: [3. 8. 3. 0. 0. 0. 6. 8. 6. 4. 3. 0. 0.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 67.787353515625






Player: 1 
cards in hand: [ 6. 15.  6. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  6. 10.  6.] 
cards in discard: [3. 8. 3. 0. 0. 0. 6. 8. 6. 4. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 29.  8.  4. 10.  5.  4.  7.  8. 10. 10.  2. 10.  9.] 
adversary cards in hand: [29.  0. 29. 10. 25.] 
adversary cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3] -> size -> 32 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10.  6.] 
cards in discard: [3. 8. 3. 0. 0. 0. 6. 8. 6. 4. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 29.  8.  4. 10.  5.  4.  7.  8. 10. 10.  2. 10.  9.] 
adversary cards in hand: [29.  0. 29. 10. 25.] 
adversary cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3] -> size -> 32 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 10.  6.] 
cards in discard: [3. 8. 3. 0. 0. 0. 6. 8. 6. 4. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 30. 30. 27. 29.  8.  4. 10.  5.  4.  7.  8. 10. 10.  2. 10.  9.] 
adversary cards in hand: [29.  0. 29. 10. 25.] 
adversary cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3] -> size -> 32 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [29.  0. 29. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10. 25.] 
expected returns: [[60.95293]
 [86.61661]
 [86.61661]
 [57.03474]
 [94.57678]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 10. 25.] 
cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3. 11.  0.  3. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 29.  8.  4. 10.  5.  4.  7.  8. 10. 10.  2. 10.  9.] 
adversary cards in hand: [8. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.399169921875



action possibilites: [-1] 
expected returns: [[-9.288776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 10.  0. 11.] 
cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3. 11.  0.  3. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 29.  8.  3. 10.  5.  4.  7.  8. 10. 10.  2. 10.  9.] 
adversary cards in hand: [8. 6. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 94.57678985595703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -9.032127  ]
 [ -0.44524026]
 [-20.333214  ]
 [  1.1892617 ]
 [ -8.327829  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29. 10.  0. 11.] 
cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3. 11.  0.  3. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 27. 29.  8.  3. 10.  5.  4.  7.  8. 10. 10.  2. 10.  9.] 
adversary cards in hand: [8. 6. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.288776397705078



buy possibilites: [-1] 
expected returns: [[17.923342]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29. 10.  0. 11.] 
cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3. 11.  0.  3. 10.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 29.  8.  3. 10.  5.  3.  7.  8. 10. 10.  2. 10.  9.] 
adversary cards in hand: [8. 6. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 1.1892473697662354






Player: 1 
cards in hand: [8. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 29.  8.  3. 10.  5.  3.  7.  8. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10.  0. 10.  3. 10.] 
adversary cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3. 11.  0.  3. 10.  0.  8. 25. 29.  0.
 29. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8] -> size -> 33 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 27. 29.  8.  3. 10.  5.  3.  7.  8. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10.  0. 10.  3. 10.] 
adversary cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3. 11.  0.  3. 10.  0.  8. 25. 29.  0.
 29. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8] -> size -> 33 
adversary victory points: 4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [10.  0. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[56.46472 ]
 [55.590553]
 [55.590553]
 [55.590553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3. 10.] 
cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3. 11.  0.  3. 10.  0.  8. 25. 29.  0.
 29. 10.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 29.  8.  3. 10.  5.  3.  7.  8. 10. 10.  2. 10.  9.] 
adversary cards in hand: [3. 6. 6. 0. 6.] 
adversary cards in discard: [6. 8. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6] -> size -> 23 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.923341751098633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[46.827473]
 [31.877644]
 [54.48355 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  3. 10.] 
cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3. 11.  0.  3. 10.  0.  8. 25. 29.  0.
 29. 10.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 27. 29.  8.  3. 10.  5.  3.  7.  8. 10. 10.  2. 10.  9.] 
adversary cards in hand: [3. 6. 6. 0. 6.] 
adversary cards in discard: [6. 8. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6] -> size -> 23 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 56.464725494384766



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 6. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 6.] 
cards in discard: [6. 8. 6. 3. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 29.  8.  3. 10.  5.  3.  7.  8. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  8.] 
adversary cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3. 11.  0.  3. 10.  0.  8. 25. 29.  0.
 29. 10.  0. 11. 10.  0. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8] -> size -> 33 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 6.] 
cards in discard: [6. 8. 6. 3. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 27. 29.  8.  3. 10.  5.  3.  7.  8. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  8.] 
adversary cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3. 11.  0.  3. 10.  0.  8. 25. 29.  0.
 29. 10.  0. 11. 10.  0. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8] -> size -> 33 
adversary victory points: 4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[-10.294117 ]
 [  9.769247 ]
 [ -0.9861636]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  8.] 
cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3. 11.  0.  3. 10.  0.  8. 25. 29.  0.
 29. 10.  0. 11. 10.  0. 10.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 29.  8.  3. 10.  5.  3.  7.  8. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 3. 0. 4. 8.] 
adversary cards in discard: [6. 8. 6. 3. 0. 0. 3. 6. 6. 0. 6.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6] -> size -> 23 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 54.48353958129883



action possibilites: [-1] 
expected returns: [[39.48061]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3. 11.  0.  3. 10.  0.  8. 25. 29.  0.
 29. 10.  0. 11. 10.  0. 10.  3. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 29.  8.  3. 10.  5.  3.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [6. 3. 0. 4. 8.] 
adversary cards in discard: [6. 8. 6. 3. 0. 0. 3. 6. 6. 0. 6.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6] -> size -> 23 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 21.584426879882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.8037   ]
 [46.484203 ]
 [ 1.9405072]
 [46.538563 ]
 [44.027885 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3. 11.  0.  3. 10.  0.  8. 25. 29.  0.
 29. 10.  0. 11. 10.  0. 10.  3. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 27. 29.  8.  3. 10.  5.  3.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [6. 3. 0. 4. 8.] 
adversary cards in discard: [6. 8. 6. 3. 0. 0. 3. 6. 6. 0. 6.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6] -> size -> 23 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.48060989379883



buy possibilites: [-1] 
expected returns: [[1.7576306]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [25.  8. 25. 11. 10.  8.  0. 10.  3. 11.  0.  3. 10.  0.  8. 25. 29.  0.
 29. 10.  0. 11. 10.  0. 10.  3. 10. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 29.  8.  3. 10.  5.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [6. 3. 0. 4. 8.] 
adversary cards in discard: [6. 8. 6. 3. 0. 0. 3. 6. 6. 0. 6.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6] -> size -> 23 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 46.53857421875






Player: 1 
cards in hand: [6. 3. 0. 4. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 4. 8.] 
cards in discard: [6. 8. 6. 3. 0. 0. 3. 6. 6. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 29.  8.  3. 10.  5.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8] -> size -> 35 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 4. 8.] 
cards in discard: [6. 8. 6. 3. 0. 0. 3. 6. 6. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 27. 29.  8.  3. 10.  5.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8] -> size -> 35 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 4. 8.] 
cards in discard: [6. 8. 6. 3. 0. 0. 3. 6. 6. 0. 6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 27. 29.  8.  3. 10.  5.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8] -> size -> 35 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[29.33276 ]
 [48.503403]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 29.  8.  3. 10.  5.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6. 10.] 
adversary cards in discard: [6. 8. 6. 3. 0. 0. 3. 6. 6. 0. 6. 0. 6. 3. 0. 4. 8.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0] -> size -> 24 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 1.7576305866241455



action possibilites: [-1] 
expected returns: [[37.723007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 29.  8.  2. 10.  5.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6. 10.] 
adversary cards in discard: [6. 8. 6. 3. 0. 0. 3. 6. 6. 0. 6. 0. 6. 3. 0. 4. 8. 6.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0
  6] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 48.503414154052734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[32.979076]
 [63.088642]
 [51.07081 ]
 [10.292989]
 [74.050125]
 [52.488968]
 [41.45319 ]
 [46.77996 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 30. 30. 27. 29.  8.  2. 10.  5.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6. 10.] 
adversary cards in discard: [6. 8. 6. 3. 0. 0. 3. 6. 6. 0. 6. 0. 6. 3. 0. 4. 8. 6.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0
  6] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.72300720214844



buy possibilites: [-1] 
expected returns: [[64.97136]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0.  8. 10.] 
cards in discard: [11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 29.  8.  2. 10.  4.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6. 10.] 
adversary cards in discard: [6. 8. 6. 3. 0. 0. 3. 6. 6. 0. 6. 0. 6. 3. 0. 4. 8. 6.] 
adversary owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0
  6] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -10   0   0  54   0] 
sum of rewards: 179 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 74.0501480102539






Player: 1 
cards in hand: [ 0. 15.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  6. 10.] 
cards in discard: [6. 8. 6. 3. 0. 0. 3. 6. 6. 0. 6. 0. 6. 3. 0. 4. 8. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 29.  8.  2. 10.  4.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [11. 25.  0.  0.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11] -> size -> 36 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  6.  3.] 
cards in discard: [6. 8. 6. 3. 0. 0. 3. 6. 6. 0. 6. 0. 6. 3. 0. 4. 8. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0
  6] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 29.  8.  2. 10.  4.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [11. 25.  0.  0.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11] -> size -> 36 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [6. 8. 6. 3. 0. 0. 3. 6. 6. 0. 6. 0. 6. 3. 0. 4. 8. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 3 
card supply: [22. 30. 30. 27. 29.  8.  2. 10.  4.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [11. 25.  0.  0.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11] -> size -> 36 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [6. 8. 6. 3. 0. 0. 3. 6. 6. 0. 6. 0. 6. 3. 0. 4. 8. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 30. 30. 27. 29.  8.  2. 10.  4.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [11. 25.  0.  0.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11] -> size -> 36 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [6. 8. 6. 3. 0. 0. 3. 6. 6. 0. 6. 0. 6. 3. 0. 4. 8. 6. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 30. 30. 27. 29.  8.  2. 10.  4.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [11. 25.  0.  0.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11] -> size -> 36 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[115.73747 ]
 [104.897995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [11. 25.  0.  0.  3.  0.  8. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 27. 29.  8.  2. 10.  4.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.97135925292969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 88.33744 ]
 [119.23693 ]
 [115.1577  ]
 [ 63.726933]
 [137.1523  ]
 [112.46384 ]
 [107.07911 ]
 [117.289566]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [11. 25.  0.  0.  3.  0.  8. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 30. 30. 27. 29.  8.  2. 10.  4.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 115.73747253417969



buy possibilites: [-1] 
expected returns: [[181.53787]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 179 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 137.15231323242188






Player: 1 
cards in hand: [6. 6. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 8. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0.  8. 10. 10.] 
adversary cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11] -> size -> 37 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 8. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0.  8. 10. 10.] 
adversary cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11] -> size -> 37 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 8. 0.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0.  8. 10. 10.] 
adversary cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11] -> size -> 37 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10.  0.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 10.] 
expected returns: [[168.01825]
 [156.09972]
 [157.06805]
 [156.09972]
 [156.09972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 10. 10.] 
cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [6. 4. 6. 0. 8.] 
adversary cards in discard: [0. 6. 6. 6. 8. 0.] 
adversary owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 181.53787231445312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[143.73358]
 [128.96129]
 [168.78314]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8. 10. 10.] 
cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [6. 4. 6. 0. 8.] 
adversary cards in discard: [0. 6. 6. 6. 8. 0.] 
adversary owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 168.01828002929688



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [6. 4. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 4. 6. 0. 8.] 
cards in discard: [0. 6. 6. 6. 8. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 11. 29.] 
adversary cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11] -> size -> 37 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 4. 6. 0. 8.] 
cards in discard: [0. 6. 6. 6. 8. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 11. 29.] 
adversary cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11] -> size -> 37 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 4. 6. 0. 8.] 
cards in discard: [0. 6. 6. 6. 8. 0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 11. 29.] 
adversary cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11] -> size -> 37 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 29.] 
expected returns: [[139.86742]
 [129.23726]
 [156.48195]
 [156.48195]
 [159.03215]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 11. 29.] 
cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  6.  0.  3. 10.] 
adversary cards in discard: [0. 6. 6. 6. 8. 0. 0. 6. 4. 6. 0. 8.] 
adversary owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 168.78317260742188



action possibilites: [-1. 10. 11. 11. 11.] 
expected returns: [[171.98787]
 [164.71605]
 [194.42287]
 [194.42287]
 [194.42287]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 11. 11.] 
cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  6.  0.  3. 10.] 
adversary cards in discard: [0. 6. 6. 6. 8. 0. 0. 6. 4. 6. 0. 8.] 
adversary owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 159.0321807861328



action possibilites: [-1] 
expected returns: [[101.57698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 11.] 
cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  6.  0.  3. 10.] 
adversary cards in discard: [0. 6. 6. 6. 8. 0. 0. 6. 4. 6. 0. 8.] 
adversary owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -30   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 204.2091064453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 74.62633 ]
 [ 62.991573]
 [103.96632 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11. 11.] 
cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  6.  0.  3. 10.] 
adversary cards in discard: [0. 6. 6. 6. 8. 0. 0. 6. 4. 6. 0. 8.] 
adversary owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.57698059082031






Player: 1 
cards in hand: [ 0.  6.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  3. 10.] 
cards in discard: [0. 6. 6. 6. 8. 0. 0. 6. 4. 6. 0. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  8.  8. 11. 10.] 
adversary cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10. 10. 29. 11.  3. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10] -> size -> 38 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [0. 6. 6. 6. 8. 0. 0. 6. 4. 6. 0. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  8.  8. 11. 10.] 
adversary cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10. 10. 29. 11.  3. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10] -> size -> 38 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [0. 6. 6. 6. 8. 0. 0. 6. 4. 6. 0. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  8.  8. 11. 10.] 
adversary cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10. 10. 29. 11.  3. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10] -> size -> 38 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 11. 10.] 
expected returns: [[134.1022  ]
 [122.113266]
 [122.113266]
 [122.113266]
 [150.86716 ]
 [116.31045 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8. 11. 10.] 
cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10. 10. 29. 11.  3. 10. 11. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [ 0.  6.  6.  6.  8.  0.  0.  6.  4.  6.  0.  8. 10.  0.  6.  0.  3.  0.] 
adversary owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 103.96632385253906



action possibilites: [-1] 
expected returns: [[134.29941]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8. 10.] 
cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10. 10. 29. 11.  3. 10. 11. 11. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [ 0.  6.  6.  6.  8.  0.  0.  6.  4.  6.  0.  8. 10.  0.  6.  0.  3.  0.] 
adversary owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 189 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 156.61143493652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 97.39914]
 [ 74.30725]
 [133.66432]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  8. 10.] 
cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10. 10. 29. 11.  3. 10. 11. 11. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [ 0.  6.  6.  6.  8.  0.  0.  6.  4.  6.  0.  8. 10.  0.  6.  0.  3.  0.] 
adversary owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 134.29940795898438






Player: 1 
cards in hand: [0. 3. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [ 0.  6.  6.  6.  8.  0.  0.  6.  4.  6.  0.  8. 10.  0.  6.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [25.  0. 29.  3.  0.] 
adversary cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10. 10. 29. 11.  3. 10. 11. 11. 15. 11.  8.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15] -> size -> 39 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [ 0.  6.  6.  6.  8.  0.  0.  6.  4.  6.  0.  8. 10.  0.  6.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [25.  0. 29.  3.  0.] 
adversary cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10. 10. 29. 11.  3. 10. 11. 11. 15. 11.  8.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15] -> size -> 39 
adversary victory points: 4
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [25.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[ 86.10252 ]
 [146.68417 ]
 [122.130806]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29.  3.  0.] 
cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10. 10. 29. 11.  3. 10. 11. 11. 15. 11.  8.  8.  8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 29.  8.  2. 10.  3.  2.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0.  6.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 133.66432189941406



action possibilites: [-1] 
expected returns: [[-4.995195]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0. 10. 25.] 
cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10. 10. 29. 11.  3. 10. 11. 11. 15. 11.  8.  8.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 29.  8.  1. 10.  3.  2.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0.  6.  3. 15.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0  6] -> size -> 28 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 146.6842041015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-16.590456 ]
 [ -2.7345257]
 [-21.209553 ]
 [ -2.601377 ]
 [ -4.9952083]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  0. 10. 25.] 
cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10. 10. 29. 11.  3. 10. 11. 11. 15. 11.  8.  8.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 27. 29.  8.  1. 10.  3.  2.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0.  6.  3. 15.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0  6] -> size -> 28 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -4.995194911956787



buy possibilites: [-1] 
expected returns: [[-10.41867]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  0. 10. 25.] 
cards in discard: [11. 25.  0.  0.  3.  0.  8. 10. 11.  0.  0.  3. 10.  0. 10.  0.  8. 10.
 10. 10. 29. 11.  3. 10. 11. 11. 15. 11.  8.  8.  8. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 29.  8.  1. 10.  3.  1.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0.  6.  3. 15.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0  6] -> size -> 28 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -50   0   0  16   0] 
sum of rewards: 131 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -2.6013708114624023






Player: 1 
cards in hand: [ 0.  0.  6.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  3. 15.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6
  0  0  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 29.  8.  1. 10.  3.  1.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 10.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8] -> size -> 40 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 30. 30. 27. 29.  8.  1. 10.  3.  1.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 10.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8] -> size -> 40 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 30. 30. 27. 29.  8.  1. 10.  3.  1.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 10.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8] -> size -> 40 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [ 6. 16.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 29.  8.  1.  9.  3.  1.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 10.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8] -> size -> 40 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [10. 10.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.  8.] 
expected returns: [[139.61986]
 [130.3663 ]
 [130.3663 ]
 [138.4202 ]
 [138.4202 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.  8.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 29.  8.  1.  9.  3.  1.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 4.] 
adversary cards in discard: [ 6. 16. 15.  0.  6.  3.] 
adversary owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16] -> size -> 28 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.418669700622559





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[114.08823 ]
 [ 86.440605]
 [138.67787 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  8.  8.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 30. 30. 27. 29.  8.  1.  9.  3.  1.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 4.] 
adversary cards in discard: [ 6. 16. 15.  0.  6.  3.] 
adversary owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16] -> size -> 28 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 139.61988830566406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 4.] 
cards in discard: [ 6. 16. 15.  0.  6.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 29.  8.  1.  9.  3.  1.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 11.  8.] 
adversary cards in discard: [10. 10.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8] -> size -> 40 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 4.] 
cards in discard: [ 6. 16. 15.  0.  6.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 30. 30. 27. 29.  8.  1.  9.  3.  1.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 11.  8.] 
adversary cards in discard: [10. 10.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8] -> size -> 40 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 4.] 
cards in discard: [ 6. 16. 15.  0.  6.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  3.  1.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 11.  8.] 
adversary cards in discard: [10. 10.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8] -> size -> 40 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8.] 
expected returns: [[41.336063]
 [62.574787]
 [57.069553]
 [41.839134]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 11.  8.] 
cards in discard: [10. 10.  8.  8.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  3.  1.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 6. 8. 6. 6.] 
adversary cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.] 
adversary owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 138.6779022216797



action possibilites: [-1. 11. 10.] 
expected returns: [[56.783745]
 [67.585014]
 [52.272106]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.] 
cards in discard: [10. 10.  8.  8.  0.  8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  3.  1.  7.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 6. 8. 6. 6.] 
adversary cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.] 
adversary owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 47.61915969848633



action possibilites: [-1] 
expected returns: [[80.94981]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [10. 10.  8.  8.  0.  8. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  3.  1.  7.  8. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 6. 8. 6. 6.] 
adversary cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.] 
adversary owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -60   0   0  64   0] 
sum of rewards: 189 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 70.18565368652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[68.0964  ]
 [90.75385 ]
 [84.4484  ]
 [48.27635 ]
 [99.93257 ]
 [84.33799 ]
 [82.854095]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [10. 10.  8.  8.  0.  8. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  3.  1.  7.  8. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 6. 8. 6. 6.] 
adversary cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.] 
adversary owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.9498062133789



buy possibilites: [-1] 
expected returns: [[26.433172]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [10. 10.  8.  8.  0.  8. 15. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  2.  1.  7.  8. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 6. 8. 6. 6.] 
adversary cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.] 
adversary owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -70   0   0  54   0] 
sum of rewards: 169 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 99.93260192871094






Player: 1 
cards in hand: [0. 6. 8. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 6. 6.] 
cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  2.  1.  7.  8. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  8. 10.  8.  0.] 
adversary cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11] -> size -> 42 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 6. 6.] 
cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  2.  1.  7.  8. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  8. 10.  8.  0.] 
adversary cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11] -> size -> 42 
adversary victory points: 4
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
expected returns: [[157.34096]
 [163.95808]
 [151.75626]
 [163.95808]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  8.  0.] 
cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8  8 10 11 25  0 10 11 10  8
 10 29  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  2.  1.  7.  8. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  3. 10.  6.  3.] 
adversary cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.  0.  6.  8.  6.  6.] 
adversary owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.43317222595215



action possibilites: [-1] 
expected returns: [[84.31808]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 25  8  8 10 11 25  0 10 11 10  8 10 29
  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  2.  1.  7.  8. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  3. 10.  6.  3.] 
adversary cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.  0.  6.  8.  6.  6.] 
adversary owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 199.71095275878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[75.22373 ]
 [48.375694]
 [83.250046]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 25  8  8 10 11 25  0 10 11 10  8 10 29
  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  2.  1.  7.  8. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  3. 10.  6.  3.] 
adversary cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.  0.  6.  8.  6.  6.] 
adversary owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.31807708740234






Player: 1 
cards in hand: [ 8.  3. 10.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  6.  3.] 
cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.  0.  6.  8.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  2.  1.  7.  8. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10. 11.  3. 11. 15.] 
adversary cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 25  8  8 10 11 25  0 10 11 10  8 10 29
  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11] -> size -> 40 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 10.  6.  3.] 
cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.  0.  6.  8.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  2.  1.  7.  8. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10. 11.  3. 11. 15.] 
adversary cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 25  8  8 10 11 25  0 10 11 10  8 10 29
  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11] -> size -> 40 
adversary victory points: 4
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [10. 11.  3. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 15.] 
expected returns: [[125.78812]
 [115.65277]
 [149.69304]
 [149.69304]
 [132.46292]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3. 11. 15.] 
cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.  8.  3.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 25  8  8 10 11 25  0 10 11 10  8 10 29
  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  2.  1.  7.  8. 10. 10.  0. 10.  7.] 
adversary cards in hand: [6. 0. 6. 0. 6.] 
adversary cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.  0.  6.  8.  6.  6.  8.
  3. 10.  6.  3.] 
adversary owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 83.25005340576172



action possibilites: [-1] 
expected returns: [[115.18872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11. 15.] 
cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.  8.  3.  8. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 25  8  8 10 11 25  0 10 11 10  8 10 29
  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  2.  1.  7.  8. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 0. 6. 0. 6.] 
adversary cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.  0.  6.  8.  6.  6.  8.
  3. 10.  6.  3.] 
adversary owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -60   0   0  64   0] 
sum of rewards: 169 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 158.60218811035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 90.831406]
 [ 72.9256  ]
 [116.18186 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 11. 15.] 
cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.  8.  3.  8. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 25  8  8 10 11 25  0 10 11 10  8 10 29
  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  2.  1.  7.  8. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 0. 6. 0. 6.] 
adversary cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.  0.  6.  8.  6.  6.  8.
  3. 10.  6.  3.] 
adversary owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 115.188720703125






Player: 1 
cards in hand: [6. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 6.] 
cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.  0.  6.  8.  6.  6.  8.
  3. 10.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  2.  1.  7.  8. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 25. 11.  3.  3.] 
adversary cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.  8.  3.  8. 15. 11.
 10.  3. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 25  8  8 10 11 25  0 10 11 10  8 10 29
  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11 15] -> size -> 41 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 6.] 
cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.  0.  6.  8.  6.  6.  8.
  3. 10.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 26. 29.  8.  1.  9.  2.  1.  7.  8. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 25. 11.  3.  3.] 
adversary cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.  8.  3.  8. 15. 11.
 10.  3. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 25  8  8 10 11 25  0 10 11 10  8 10 29
  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11 15] -> size -> 41 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 6.] 
cards in discard: [ 6. 16. 15.  0.  6.  3.  3.  0.  0.  3.  0.  4.  0.  6.  8.  6.  6.  8.
  3. 10.  6.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 30. 30. 26. 29.  8.  1.  9.  2.  1.  7.  8. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 25. 11.  3.  3.] 
adversary cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.  8.  3.  8. 15. 11.
 10.  3. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 25  8  8 10 11 25  0 10 11 10  8 10 29
  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11 15] -> size -> 41 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [29. 25. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11.] 
expected returns: [[ 4.701537]
 [38.77482 ]
 [54.249405]
 [22.309105]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 11.  3.  3.] 
cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.  8.  3.  8. 15. 11.
 10.  3. 11. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 25  8  8 10 11 25  0 10 11 10  8 10 29
  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 26. 29.  8.  1.  9.  2.  1.  7.  8. 10. 10.  0. 10.  6.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3  0] -> size -> 30 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 116.18186950683594



action possibilites: [-1] 
expected returns: [[-0.46436644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3.  3. 10.  8.] 
cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.  8.  3.  8. 15. 11.
 10.  3. 11. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 25  8  8 10 11 25  0 10 11 10  8 10 29
  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 26. 29.  8.  0.  9.  2.  1.  7.  8. 10. 10.  0. 10.  6.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3  0  6] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 54.24943161010742





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-20.385443  ]
 [  0.61721635]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  3.  3. 10.  8.] 
cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.  8.  3.  8. 15. 11.
 10.  3. 11. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 25  8  8 10 11 25  0 10 11 10  8 10 29
  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 30. 30. 26. 29.  8.  0.  9.  2.  1.  7.  8. 10. 10.  0. 10.  6.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3  0  6] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.46436643600463867






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 26. 29.  8.  0.  9.  2.  1.  7.  8. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11.  0. 10. 10. 25.] 
adversary cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.  8.  3.  8. 15. 11.
 10.  3. 11. 15. 25. 29. 11.  3.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 25  8  8 10 11 25  0 10 11 10  8 10 29
  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11 15] -> size -> 41 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 30. 30. 26. 29.  8.  0.  9.  2.  1.  7.  8. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11.  0. 10. 10. 25.] 
adversary cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.  8.  3.  8. 15. 11.
 10.  3. 11. 15. 25. 29. 11.  3.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 25  8  8 10 11 25  0 10 11 10  8 10 29
  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11 15] -> size -> 41 
adversary victory points: 4
player victory points: -2 


Player 0 won the game! 



Player 0 bought cards:
Copper: 2 
Silver: 0 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 6 
Witch: 3 
Poacher: 2 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [11.  0. 10. 10. 25.] 
cards in discard: [10. 10.  8.  8.  0.  8. 15. 11. 29. 11.  0.  0. 10.  8.  3.  8. 15. 11.
 10.  3. 11. 15. 25. 29. 11.  3.  3. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 25  8  8 10 11 25  0 10 11 10  8 10 29
  0 10 25 11 10  3  8 10  8 11 11 10 15  8 15 11 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 26. 29.  8.  0.  9.  2.  0.  7.  8. 10. 10.  0. 10.  6.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6. 8.] 
adversary owned cards: [ 3  3 10  6 15  8  0  6  4  3  6  0  0  0  6  6  0  3  6  8  6  0  6  0
  0  0  6 16  3  0  6  8] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[     -5 3000000       0     180       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000175 

action type: buy - action -1.0
Learning step: 300017.46875
desired expected reward: 300018.09375



