 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[296.509]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    3  -20    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -522 

action type: buy - action -1.0
Learning step: -35.095947265625
desired expected reward: 144.82298278808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[271.54593]
 [283.02826]
 [280.52026]
 [252.39546]
 [276.83823]
 [291.79944]
 [280.34863]
 [285.49042]
 [263.33688]
 [278.36035]
 [276.6589 ]
 [298.239  ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.72746467590332
desired expected reward: 291.17535400390625



buy possibilites: [-1] 
expected returns: [[259.54062]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 15.0
Learning step: -6.49328088760376
desired expected reward: 270.1656188964844






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[287.4211]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.582032203674316
desired expected reward: 252.95858764648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[267.88583]
 [279.1607 ]
 [276.57578]
 [248.69159]
 [287.52548]
 [276.52408]
 [274.39938]
 [293.7784 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.234960556030273
desired expected reward: 280.4316711425781



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[251.27246]
 [229.04306]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -9.81286334991455
desired expected reward: 283.9655456542969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[228.05421]
 [235.77829]
 [209.75626]
 [236.30609]
 [254.11078]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.844032287597656
desired expected reward: 244.09295654296875



buy possibilites: [-1] 
expected returns: [[276.91574]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0.  3.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -323.0 

action type: buy - action 6.0
Learning step: -20.407209396362305
desired expected reward: 189.3490447998047






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  3. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  3. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  3. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[277.6301]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 6.  3. 15.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -8.795114517211914
desired expected reward: 268.1206359863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[253.47626]
 [263.45517]
 [260.35934]
 [235.88766]
 [258.0101 ]
 [269.52295]
 [261.23853]
 [264.8226 ]
 [245.29361]
 [258.4478 ]
 [256.64   ]
 [273.04874]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 6.  3. 15.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -9.037215232849121
desired expected reward: 266.54827880859375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[297.4326 ]
 [275.54916]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11 16] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -8.226369857788086
desired expected reward: 264.8222961425781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[267.4515 ]
 [278.70334]
 [276.34653]
 [248.61302]
 [287.7054 ]
 [276.03384]
 [274.22095]
 [294.49515]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11 16] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -9.8787260055542
desired expected reward: 290.6988830566406



buy possibilites: [-1] 
expected returns: [[287.24924]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  3.  0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11 16] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -21.0 

action type: buy - action 8.0
Learning step: -8.388585090637207
desired expected reward: 267.645263671875






Player: 1 
cards in hand: [ 0.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [ 8.  0.  0. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11 16 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [ 8.  0.  0. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11 16 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [ 8.  0.  0. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11 16 29 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  8.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [ 8.  0.  0. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 6. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[317.11728]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [ 8.  0.  0. 15.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  8.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  3.  3.] 
adversary cards in discard: [29. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11 16 29 11] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -8.421135902404785
desired expected reward: 278.8280944824219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[296.18448]
 [305.4766 ]
 [276.52048]
 [304.996  ]
 [323.1904 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [ 8.  0.  0. 15.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  8.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  3.  3.] 
adversary cards in discard: [29. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11 16 29 11] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -10.011786460876465
desired expected reward: 305.1582946777344



buy possibilites: [-1] 
expected returns: [[285.75217]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [ 8.  0.  0. 15.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  9.  9.  8.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  3.  3.] 
adversary cards in discard: [29. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11 16 29 11] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -53.0 

action type: buy - action 0.0
Learning step: -11.029799461364746
desired expected reward: 285.1546936035156






Player: 1 
cards in hand: [ 0.  0. 16.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  3.  3.] 
cards in discard: [29. 11. 11.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11 16 29 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9.  9.  8.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [29. 11. 11.  0.  0.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  3 11 16 29 11  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  8.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [29. 11. 11.  0.  0.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  3 11 16 29 11  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  8.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [29. 11. 11.  0.  0.  3.  0.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  3 11 16 29 11  3  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[280.35812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  3 11 16 29 11  3  8] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -9.152148246765137
desired expected reward: 276.6000061035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[253.42969]
 [263.0794 ]
 [260.01544]
 [242.23035]
 [236.63756]
 [257.727  ]
 [269.3575 ]
 [260.96204]
 [277.93625]
 [264.60968]
 [245.71536]
 [252.81793]
 [258.22852]
 [241.92694]
 [256.5983 ]
 [273.59723]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  3 11 16 29 11  3  8] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -8.832653999328613
desired expected reward: 262.78741455078125



buy possibilites: [-1] 
expected returns: [[276.5066]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8  0  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 5 
card supply: [28. 30. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  3 11 16 29 11  3  8] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -334.0 

action type: buy - action 6.0
Learning step: -22.31048011779785
desired expected reward: 214.32705688476562






Player: 1 
cards in hand: [11.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  3 11 16 29 11  3  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8  0  6] -> size -> 15 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  3 11 16 29 11  3  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8  0  6] -> size -> 15 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  3 11 16 29 11  3  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8  0  6] -> size -> 15 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  3 11 16 29 11  3  8  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8  0  6] -> size -> 15 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[267.4304 ]
 [254.95613]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [6. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  6  8  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 11.] 
adversary cards in discard: [ 0.  0. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  3 11 16 29 11  3  8  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -9.619257926940918
desired expected reward: 266.8873291015625



action possibilites: [-1] 
expected returns: [[328.42126]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [6. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  6  8  0  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 11.] 
adversary cards in discard: [ 0.  0. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  3 11 16 29 11  3  8  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: trash_cards_n_from_hand - action 1
Learning step: -6.411496162414551
desired expected reward: 244.6079864501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[318.94684]
 [325.34326]
 [303.43555]
 [325.90143]
 [337.87735]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [6. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  6  8  0  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 28. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 11.] 
adversary cards in discard: [ 0.  0. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  3 11 16 29 11  3  8  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -10.335386276245117
desired expected reward: 318.08587646484375



buy possibilites: [-1] 
expected returns: [[272.3606]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [6. 0. 0. 0. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  6  8  0  6  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 11.] 
adversary cards in discard: [ 0.  0. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  3 11 16 29 11  3  8  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -6 

action type: buy - action 3.0
Learning step: -10.439053535461426
desired expected reward: 314.9042663574219






Player: 1 
cards in hand: [ 8.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  0. 11.] 
cards in discard: [ 0.  0. 11.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  3 11 16 29 11  3  8  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  6.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  6  8  0  6  3] -> size -> 15 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 0.  0. 11.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  0  3 11 16 29 11  3  8  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  6.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  6  8  0  6  3] -> size -> 15 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 0.  0. 11.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  0  3 11 16 29 11  3  8  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  6.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  6  8  0  6  3] -> size -> 15 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 0.  0. 11.  3.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  0  3 11 16 29 11  3  8  0  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  6.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 15  6  8  0  6  3] -> size -> 15 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  6.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[264.44623]
 [241.7096 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6.  0. 15.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 15  6  8  0  6  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 16. 29.  3.] 
adversary cards in discard: [ 0.  0. 11.  3.  0.  0.  0.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  0  3 11 16 29 11  3  8  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -9.059286117553711
desired expected reward: 263.3013000488281



action possibilites: [-1] 
expected returns: [[254.02296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 15  6  8  0  6  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 30. 30. 27. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 16. 29.  3.] 
adversary cards in discard: [ 0.  0. 11.  3.  0.  0.  0.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  0  3 11 16 29 11  3  8  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 15.0
Learning step: -6.592761993408203
desired expected reward: 235.57281494140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[228.22891]
 [237.10762]
 [235.46504]
 [213.49438]
 [244.39322]
 [235.01239]
 [233.82066]
 [249.95233]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 15  6  8  0  6  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 27. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 16. 29.  3.] 
adversary cards in discard: [ 0.  0. 11.  3.  0.  0.  0.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  0  3 11 16 29 11  3  8  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -7.5385050773620605
desired expected reward: 246.48446655273438



buy possibilites: [-1] 
expected returns: [[232.31924]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 15  6  8  0  6  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 30. 30. 27. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 16. 29.  3.] 
adversary cards in discard: [ 0.  0. 11.  3.  0.  0.  0.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  0  3 11 16 29 11  3  8  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -34.0 

action type: buy - action 0.0
Learning step: -7.8842644691467285
desired expected reward: 220.3446807861328






Player: 1 
cards in hand: [ 3.  0. 16. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16. 29.  3.] 
cards in discard: [ 0.  0. 11.  3.  0.  0.  0.  0.  8. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  3 11 16 29 11  3  8  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 0. 6. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  6  8  0  6  3  0] -> size -> 15 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  3.  0.] 
cards in discard: [ 0.  0. 11.  3.  0.  0.  0.  0.  8. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  0  3 11 16 29 11  3  8  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 27. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 0. 6. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  6  8  0  6  3  0] -> size -> 15 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0.  0. 11.  3.  0.  0.  0.  0.  8. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  3  0  3 11 16 29 11  3  8  0  0  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 26. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 0. 6. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  6  8  0  6  3  0] -> size -> 15 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0.  0. 11.  3.  0.  0.  0.  0.  8. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  3  0  3 11 16 29 11  3  8  0  0  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 26. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 0. 6. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  6  8  0  6  3  0] -> size -> 15 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0.  0. 11.  3.  0.  0.  0.  0.  8. 11.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  3  0  3 11 16 29 11  3  8  0  0  0  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 26. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 0. 6. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15  6  8  0  6  3  0] -> size -> 15 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [3. 8. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[235.44771]
 [219.73402]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 6. 0.] 
cards in discard: [ 0. 15.  3.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 15  6  8  0  6  3  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  3 11 16 29 11  3  8  0  0  0  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -8.135416030883789
desired expected reward: 224.18382263183594



action possibilites: [-1] 
expected returns: [[218.8748]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [ 0. 15.  3.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 15  6  8  0  6  3  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  3 11 16 29 11  3  8  0  0  0  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: trash_cards_n_from_hand - action 2
Learning step: -6.946666717529297
desired expected reward: 205.48033142089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[192.79419]
 [199.71342]
 [176.97571]
 [200.25711]
 [214.13786]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [ 0. 15.  3.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 15  6  8  0  6  3  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 26. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  3 11 16 29 11  3  8  0  0  0  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -7.672760009765625
desired expected reward: 211.20204162597656






Player: 1 
cards in hand: [16.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  3 11 16 29 11  3  8  0  0  0  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  6.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 15  6  8  0  6  3  0] -> size -> 14 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  6.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 15  6  8  0  6  3  0] -> size -> 14 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 26. 30.  8.  8.  9.  8.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  6.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 15  6  8  0  6  3  0] -> size -> 14 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  8.  9.  8.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  6.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 15  6  8  0  6  3  0] -> size -> 14 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[297.8891]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 15.  3.  3.  6.  8.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 15  6  8  0  6  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  8.  9.  8.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  3.  3. 11.  0.] 
adversary cards in discard: [10.  8. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -5.888145446777344
desired expected reward: 208.24972534179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[252.13324]
 [265.90094]
 [263.48444]
 [237.25949]
 [230.63837]
 [258.63712]
 [277.23773]
 [262.4566 ]
 [287.92358]
 [268.94284]
 [242.94585]
 [253.73592]
 [260.74326]
 [238.45058]
 [258.67807]
 [286.3742 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 15.  3.  3.  6.  8.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 15  6  8  0  6  3  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 30. 30. 26. 30.  8.  8.  9.  8.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  3.  3. 11.  0.] 
adversary cards in discard: [10.  8. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -9.6869478225708
desired expected reward: 268.7511291503906



buy possibilites: [-1] 
expected returns: [[269.54904]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 15.  3.  3.  6.  8.  0.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 15  6  8  0  6  3  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 5 
card supply: [22. 30. 30. 26. 30.  8.  8.  9.  8.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  3.  3. 11.  0.] 
adversary cards in discard: [10.  8. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: -9.791808128356934
desired expected reward: 242.34141540527344






Player: 1 
cards in hand: [ 8.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3. 11.  0.] 
cards in discard: [10.  8. 16.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  8.  9.  8.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 15  6  8  0  6  3  0  0] -> size -> 15 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  3. 11.  0.] 
cards in discard: [10.  8. 16.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 30. 30. 26. 30.  8.  8.  9.  8.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 15  6  8  0  6  3  0  0] -> size -> 15 
adversary victory points: 0
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 15.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[216.90977]
 [199.94926]
 [202.28636]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  6.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 15  6  8  0  6  3  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  8.  9.  8.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [10.  8. 16.  0.  3.  0.  8.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -10.451033592224121
desired expected reward: 259.0980224609375



action possibilites: [-1] 
expected returns: [[222.52983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 30. 30. 26. 30.  8.  8.  9.  8.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [10.  8. 16.  0.  3.  0.  8.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 15.0
Learning step: -5.9076337814331055
desired expected reward: 197.38345336914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[200.89479]
 [210.56924]
 [207.99779]
 [185.54749]
 [205.3035 ]
 [217.32361]
 [208.37425]
 [212.35243]
 [193.92711]
 [206.19162]
 [204.61038]
 [221.49606]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 30. 30. 26. 30.  8.  8.  9.  8.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [10.  8. 16.  0.  3.  0.  8.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: -7.15432596206665
desired expected reward: 215.37550354003906



buy possibilites: [-1] 
expected returns: [[233.80466]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 30. 30. 26. 30.  8.  8.  9.  8.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [10.  8. 16.  0.  3.  0.  8.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -13.0 

action type: buy - action 8.0
Learning step: -5.808108329772949
desired expected reward: 202.56614685058594






Player: 1 
cards in hand: [ 0.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [10.  8. 16.  0.  3.  0.  8.  3.  3. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  8.  9.  8.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 15.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8] -> size -> 15 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.  8. 16.  0.  3.  0.  8.  3.  3. 11.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 25. 30.  8.  8.  9.  8.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 15.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8] -> size -> 15 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.  8. 16.  0.  3.  0.  8.  3.  3. 11.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 30. 30. 25. 30.  8.  8.  9.  8.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 15.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8] -> size -> 15 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.  8. 16.  0.  3.  0.  8.  3.  3. 11.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8  3  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 30. 30. 25. 30.  8.  8.  9.  8.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 15.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8] -> size -> 15 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[196.88754]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8. 15.  0.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 25. 30.  8.  8.  9.  8.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8  3  0] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -9.555285453796387
desired expected reward: 224.24937438964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[184.88948]
 [193.82275]
 [190.92506]
 [169.3198 ]
 [188.86273]
 [199.34056]
 [191.87006]
 [195.2086 ]
 [177.68765]
 [189.27455]
 [187.74559]
 [202.55022]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8. 15.  0.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 30. 30. 25. 30.  8.  8.  9.  8.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8  3  0] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -7.663846015930176
desired expected reward: 187.22267150878906



buy possibilites: [-1] 
expected returns: [[130.50832]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8. 15.  0.  6.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8  3  0] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -356.0 

action type: buy - action 6.0
Learning step: -23.32955551147461
desired expected reward: 145.99026489257812






Player: 1 
cards in hand: [ 0.  8.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 16 29 11  3  8  0  0  0  3  0 10  8  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 15.  0.  6.  8.  6.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6] -> size -> 16 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 15.  0.  6.  8.  6.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6] -> size -> 16 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 25. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 15.  0.  6.  8.  6.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6] -> size -> 16 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 15.  0.  6.  8.  6.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6] -> size -> 16 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[201.75197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 8. 15.  0.  6.  8.  6.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3] -> size -> 20 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -5.412377834320068
desired expected reward: 125.09593963623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[175.4598 ]
 [186.05432]
 [183.77989]
 [158.04482]
 [194.06972]
 [183.5351 ]
 [181.72702]
 [199.89735]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 8. 15.  0.  6.  8.  6.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 30. 30. 24. 30.  8.  7.  9.  8.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3] -> size -> 20 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -8.901290893554688
desired expected reward: 187.23373413085938



buy possibilites: [-1] 
expected returns: [[188.83289]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 8. 15.  0.  6.  8.  6.  3.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3] -> size -> 20 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -48 

action type: buy - action 11.0
Learning step: -7.854745388031006
desired expected reward: 186.2149658203125






Player: 1 
cards in hand: [3. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 3. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11] -> size -> 17 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 3. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11] -> size -> 17 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [3. 8. 0. 0. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  7.  9.  7.  5. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 3. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11] -> size -> 17 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [6. 3. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[142.73428]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  7.  9.  7.  5. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 11. 16. 10.] 
adversary cards in discard: [3. 8. 0. 0. 8. 3. 0. 0. 3. 8.] 
adversary owned cards: [ 0  0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8] -> size -> 21 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -9.471661567687988
desired expected reward: 179.36122131347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[127.61323]
 [117.1644 ]
 [145.2794 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 30. 30. 24. 30.  8.  7.  9.  7.  5. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 11. 16. 10.] 
adversary cards in discard: [3. 8. 0. 0. 8. 3. 0. 0. 3. 8.] 
adversary owned cards: [ 0  0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8] -> size -> 21 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -7.558995246887207
desired expected reward: 137.77357482910156



buy possibilites: [-1] 
expected returns: [[166.04619]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 6. 0.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 24. 30.  8.  7.  9.  7.  5. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 11. 16. 10.] 
adversary cards in discard: [3. 8. 0. 0. 8. 3. 0. 0. 3. 8.] 
adversary owned cards: [ 0  0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8] -> size -> 21 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -96.0 

action type: buy - action 0.0
Learning step: -7.444622993469238
desired expected reward: 120.16861724853516






Player: 1 
cards in hand: [ 0.  3. 11. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 16. 10.] 
cards in discard: [3. 8. 0. 0. 8. 3. 0. 0. 3. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 24. 30.  8.  7.  9.  7.  5. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 15.  0.  0.  6.] 
adversary cards in discard: [0. 6. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0] -> size -> 18 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.] 
cards in discard: [3. 8. 0. 0. 8. 3. 0. 0. 3. 8. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 24. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 15.  0.  0.  6.] 
adversary cards in discard: [0. 6. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0] -> size -> 18 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.] 
cards in discard: [3. 8. 0. 0. 8. 3. 0. 0. 3. 8. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 30. 30. 24. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 15.  0.  0.  6.] 
adversary cards in discard: [0. 6. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0] -> size -> 18 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.] 
cards in discard: [3. 8. 0. 0. 8. 3. 0. 0. 3. 8. 8. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 15.  0.  0.  6.] 
adversary cards in discard: [0. 6. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0] -> size -> 18 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 8. 15.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[157.99797]
 [140.43626]
 [137.27538]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0.  0.  6.] 
cards in discard: [0. 6. 3. 3. 6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  0.  8.  3.  0.  0.  3.  8.  8.  0. 16.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8  0] -> size -> 22 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -8.369853019714355
desired expected reward: 157.67633056640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[120.131485]
 [127.80803 ]
 [106.42898 ]
 [127.14014 ]
 [144.00316 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0.  0.  6.] 
cards in discard: [0. 6. 3. 3. 6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 24. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  0.  8.  3.  0.  0.  3.  8.  8.  0. 16.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8  0] -> size -> 22 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -7.395545482635498
desired expected reward: 132.84774780273438



buy possibilites: [-1] 
expected returns: [[169.83104]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0.  0.  6.] 
cards in discard: [0. 6. 3. 3. 6. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 30. 30. 24. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  0.  8.  3.  0.  0.  3.  8.  8.  0. 16.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8  0] -> size -> 22 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -96.0 

action type: buy - action 0.0
Learning step: -6.985376834869385
desired expected reward: 113.14613342285156






Player: 1 
cards in hand: [ 0.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 3.  8.  0.  0.  8.  3.  0.  0.  3.  8.  8.  0. 16.  3. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 24. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  6.  3.  3.  6.  0.  0.  8. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0] -> size -> 19 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 3.  8.  0.  0.  8.  3.  0.  0.  3.  8.  8.  0. 16.  3. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 30. 30. 24. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  6.  3.  3.  6.  0.  0.  8. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0] -> size -> 19 
adversary victory points: -1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[149.0039]
 [144.6987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [ 0.  6.  3.  3.  6.  0.  0.  8. 15.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 24. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8  0] -> size -> 22 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -8.580991744995117
desired expected reward: 161.2500457763672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[130.88673 ]
 [139.50749 ]
 [137.31003 ]
 [117.65666 ]
 [134.71521 ]
 [145.83966 ]
 [137.4542  ]
 [141.083   ]
 [124.706314]
 [135.62323 ]
 [134.12035 ]
 [150.14485 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [ 0.  6.  3.  3.  6.  0.  0.  8. 15.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 30. 30. 24. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8  0] -> size -> 22 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -7.384620666503906
desired expected reward: 136.947509765625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16.  0.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 24. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0] -> size -> 19 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 30. 30. 24. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0] -> size -> 19 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  8.  0.  3.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 23. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0] -> size -> 19 
adversary victory points: -1
player victory points: 6 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [6. 8. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[133.90356]
 [120.0909 ]
 [120.0909 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 23. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 11. 10.  8.] 
adversary cards in discard: [ 3. 16.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8  0  3] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1.0
Learning step: -8.526579856872559
desired expected reward: 141.61827087402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[114.49754 ]
 [121.270645]
 [100.67596 ]
 [120.84217 ]
 [134.52342 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 30. 30. 23. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 11. 10.  8.] 
adversary cards in discard: [ 3. 16.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8  0  3] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -7.573416233062744
desired expected reward: 122.89897918701172



buy possibilites: [-1] 
expected returns: [[123.82062]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 0. 8.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 22. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 11. 10.  8.] 
adversary cards in discard: [ 3. 16.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8  0  3] -> size -> 23 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -57 

action type: buy - action 3.0
Learning step: -6.12756872177124
desired expected reward: 115.14308166503906






Player: 1 
cards in hand: [ 0.  3. 11. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 10.  8.] 
cards in discard: [ 3. 16.  0.  8.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 22. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  3.  3. 11.  0.] 
adversary cards in discard: [3. 6. 8. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1. 11.  8.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  8.  8.] 
cards in discard: [ 3. 16.  0.  8.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8  0  3] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 22. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  3.  3. 11.  0.] 
adversary cards in discard: [3. 6. 8. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 8.] 
cards in discard: [ 3. 16.  0.  8.  0.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  3 11 16 11  3  8  0  0  0  3  0 10  8  3  0  3  8  8  0  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 21. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  3.  3. 11.  0.] 
adversary cards in discard: [3. 6. 8. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 16.  0.  8.  0.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 0  0 11 16 11  3  0  0  0  3  0 10  8  3  0  3  8  8  0  3  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 21. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  3.  3. 11.  0.] 
adversary cards in discard: [3. 6. 8. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 16.  0.  8.  0.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 0  0 11 16 11  3  0  0  0  3  0 10  8  3  0  3  8  8  0  3  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 30. 30. 21. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  3.  3. 11.  0.] 
adversary cards in discard: [3. 6. 8. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [15.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[99.18185 ]
 [81.766594]
 [94.792015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3. 11.  0.] 
cards in discard: [3. 6. 8. 0. 0. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 21. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [ 3. 16.  0.  8.  0.  3.  3. 10. 11.  8.] 
adversary owned cards: [ 0  0 11 16 11  3  0  0  0  3  0 10  8  3  0  3  8  8  0  3  3] -> size -> 21 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -7.407452583312988
desired expected reward: 116.41316223144531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 80.069565]
 [ 64.69728 ]
 [100.73178 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  3. 11.  0.] 
cards in discard: [3. 6. 8. 0. 0. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 30. 30. 21. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [ 3. 16.  0.  8.  0.  3.  3. 10. 11.  8.] 
adversary owned cards: [ 0  0 11 16 11  3  0  0  0  3  0 10  8  3  0  3  8  8  0  3  3] -> size -> 21 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -6.104360580444336
desired expected reward: 89.84375762939453



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [ 3. 16.  0.  8.  0.  3.  3. 10. 11.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 16 11  3  0  0  0  3  0 10  8  3  0  3  8  8  0  3  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 21. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 3.  6.  8.  0.  0.  8. 15.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [ 3. 16.  0.  8.  0.  3.  3. 10. 11.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 16 11  3  0  0  0  3  0 10  8  3  0  3  8  8  0  3  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 30. 30. 21. 30.  8.  7.  9.  7.  4. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 3.  6.  8.  0.  0.  8. 15.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [ 3. 16.  0.  8.  0.  3.  3. 10. 11.  8.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 16 11  3  0  0  0  3  0 10  8  3  0  3  8  8  0  3  3  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 30. 30. 21. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 3.  6.  8.  0.  0.  8. 15.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[65.68499]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 3.  6.  8.  0.  0.  8. 15.  3.  3. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 21. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 3. 16.  0.  8.  0.  3.  3. 10. 11.  8.  8.  3.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0 11 16 11  3  0  0  0  3  0 10  8  3  0  3  8  8  0  3  3  8] -> size -> 22 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: -6.868457317352295
desired expected reward: 93.86332702636719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[53.234985]
 [59.95635 ]
 [58.26851 ]
 [42.197853]
 [56.30874 ]
 [65.081   ]
 [58.418438]
 [61.16772 ]
 [48.314606]
 [57.007282]
 [55.855766]
 [68.5723  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 3.  6.  8.  0.  0.  8. 15.  3.  3. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 30. 30. 21. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 3. 16.  0.  8.  0.  3.  3. 10. 11.  8.  8.  3.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0 11 16 11  3  0  0  0  3  0 10  8  3  0  3  8  8  0  3  3  8] -> size -> 22 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -5.0560197830200195
desired expected reward: 57.972076416015625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 3. 16.  0.  8.  0.  3.  3. 10. 11.  8.  8.  3.  0. 11.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 16 11  3  0  0  0  3  0 10  8  3  0  3  8  8  0  3  3  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 21. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 3. 16.  0.  8.  0.  3.  3. 10. 11.  8.  8.  3.  0. 11.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 16 11  3  0  0  0  3  0 10  8  3  0  3  8  8  0  3  3  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 30. 30. 21. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 3. 16.  0.  8.  0.  3.  3. 10. 11.  8.  8.  3.  0. 11.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 16 11  3  0  0  0  3  0 10  8  3  0  3  8  8  0  3  3  8  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 30. 30. 20. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[162.25201]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 20. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11 16 11  3  0  0  0  3  0 10  8  3  0  3  8  8  0  3  3  8  3] -> size -> 23 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1.0
Learning step: -3.629132032394409
desired expected reward: 64.94316864013672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[140.99907]
 [148.3653 ]
 [146.60414]
 [126.28624]
 [144.49898]
 [153.52954]
 [146.71925]
 [149.68077]
 [134.41977]
 [145.2595 ]
 [144.06723]
 [157.11182]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 30. 30. 20. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11 16 11  3  0  0  0  3  0 10  8  3  0  3  8  8  0  3  3  8  3] -> size -> 23 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -8.313502311706543
desired expected reward: 149.44129943847656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 16 11  3  0  0  0  3  0 10  8  3  0  3  8  8  0  3  3  8  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 20. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 3.] 
adversary cards in discard: [0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 20. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 3.] 
adversary cards in discard: [0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 30. 30. 20. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 3.] 
adversary cards in discard: [0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[127.4872 ]
 [116.29129]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 3.] 
cards in discard: [0. 0. 0. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 20. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  8.  0.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3] -> size -> 21 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: -8.416494369506836
desired expected reward: 148.69532775878906



action possibilites: [-1] 
expected returns: [[115.86231]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [0. 0. 0. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 20. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  8.  0.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3] -> size -> 21 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: trash_cards_n_from_hand - action 2
Learning step: -4.949097633361816
desired expected reward: 94.5523910522461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[104.09359 ]
 [ 91.871346]
 [119.46653 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [0. 0. 0. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 30. 30. 20. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  8.  0.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3] -> size -> 21 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1
Learning step: -6.1502251625061035
desired expected reward: 109.71208953857422






Player: 1 
cards in hand: [ 3. 10.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  8.  0.] 
cards in discard: [8. 0. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 20. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  6.  6.] 
adversary cards in discard: [0. 0. 0. 6. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 18 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  8.  0.] 
cards in discard: [8. 0. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 30. 30. 20. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  6.  6.] 
adversary cards in discard: [0. 0. 0. 6. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 18 
adversary victory points: -1
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 15.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[85.46324]
 [74.09682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  6.  6.] 
cards in discard: [0. 0. 0. 6. 0. 8. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 20. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  8.  0.] 
adversary cards in discard: [ 8.  0.  3.  3. 10.  3.  8.  0.] 
adversary owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3] -> size -> 21 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1.0
Learning step: -8.02248764038086
desired expected reward: 111.44404602050781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[71.71341 ]
 [76.42257 ]
 [61.287815]
 [76.39532 ]
 [85.52261 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  6.  6.] 
cards in discard: [0. 0. 0. 6. 0. 8. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 30. 30. 20. 30.  8.  7.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  8.  0.] 
adversary cards in discard: [ 8.  0.  3.  3. 10.  3.  8.  0.] 
adversary owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3] -> size -> 21 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -6.173476696014404
desired expected reward: 75.92930603027344



buy possibilites: [-1] 
expected returns: [[96.85937]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  6.  6.] 
cards in discard: [0. 0. 0. 6. 0. 8. 3. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 30. 30. 20. 30.  8.  6.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  8.  0.] 
adversary cards in discard: [ 8.  0.  3.  3. 10.  3.  8.  0.] 
adversary owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3] -> size -> 21 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -387.0 

action type: buy - action 6.0
Learning step: -20.23505401611328
desired expected reward: 41.05276107788086






Player: 1 
cards in hand: [ 3.  0. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  8.  0.] 
cards in discard: [ 8.  0.  3.  3. 10.  3.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 20. 30.  8.  6.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 11.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  0.  8.  3.  3.  6.  0.  0. 15.  6.  6.] 
adversary owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6] -> size -> 19 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  8.  0.] 
cards in discard: [ 8.  0.  3.  3. 10.  3.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 30. 30. 20. 30.  8.  6.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 11.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  0.  8.  3.  3.  6.  0.  0. 15.  6.  6.] 
adversary owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6] -> size -> 19 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  8.  0.] 
cards in discard: [ 8.  0.  3.  3. 10.  3.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 30. 30. 20. 30.  8.  6.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 11.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  0.  8.  3.  3.  6.  0.  0. 15.  6.  6.] 
adversary owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6] -> size -> 19 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[155.29077]
 [148.12418]
 [153.8418 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 11.  0.] 
cards in discard: [ 0.  0.  0.  6.  0.  8.  3.  3.  6.  0.  0. 15.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  6.  9.  7.  3. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16. 11.  3.  0.] 
adversary cards in discard: [ 8.  0.  3.  3. 10.  3.  8.  0.  0.  3.  0. 11.  8.  0.] 
adversary owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3  0] -> size -> 22 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -5.842541217803955
desired expected reward: 91.0168228149414



action possibilites: [-1] 
expected returns: [[85.98398]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [ 0.  0.  0.  6.  0.  8.  3.  3.  6.  0.  0. 15.  6.  6. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  6.  9.  7.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16. 11.  3.  0.] 
adversary cards in discard: [ 8.  0.  3.  3. 10.  3.  8.  0.  0.  3.  0. 11.  8.  0.] 
adversary owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3  0] -> size -> 22 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -51 

action type: gain_card_n - action 8
Learning step: -7.811415195465088
desired expected reward: 136.10968017578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[69.19952 ]
 [76.81651 ]
 [74.80058 ]
 [56.25266 ]
 [81.98818 ]
 [75.03456 ]
 [73.304825]
 [85.37844 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [ 0.  0.  0.  6.  0.  8.  3.  3.  6.  0.  0. 15.  6.  6. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 30. 30. 20. 30.  8.  6.  9.  7.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16. 11.  3.  0.] 
adversary cards in discard: [ 8.  0.  3.  3. 10.  3.  8.  0.  0.  3.  0. 11.  8.  0.] 
adversary owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3  0] -> size -> 22 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -5.921246528625488
desired expected reward: 80.06272888183594



buy possibilites: [-1] 
expected returns: [[82.60775]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [ 0.  0.  0.  6.  0.  8.  3.  3.  6.  0.  0. 15.  6.  6. 14.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 30. 30. 20. 30.  8.  5.  9.  7.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16. 11.  3.  0.] 
adversary cards in discard: [ 8.  0.  3.  3. 10.  3.  8.  0.  0.  3.  0. 11.  8.  0.] 
adversary owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3  0] -> size -> 22 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -90.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -378.0 

action type: buy - action 6.0
Learning step: -19.853958129882812
desired expected reward: 36.39870071411133






Player: 1 
cards in hand: [ 0. 16. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 11.  3.  0.] 
cards in discard: [ 8.  0.  3.  3. 10.  3.  8.  0.  0.  3.  0. 11.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 20. 30.  8.  5.  9.  7.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 21 
adversary victory points: -3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 11.  3.  0.] 
cards in discard: [ 8.  0.  3.  3. 10.  3.  8.  0.  0.  3.  0. 11.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 30. 30. 20. 30.  8.  5.  9.  7.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 21 
adversary victory points: -3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 11.  3.  0.] 
cards in discard: [ 8.  0.  3.  3. 10.  3.  8.  0.  0.  3.  0. 11.  8.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  5.  9.  7.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 21 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[81.59121]
 [70.82824]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  5.  9.  7.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3  0  3] -> size -> 23 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1
Learning step: -7.8578386306762695
desired expected reward: 74.74990844726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[63.944546]
 [68.9759  ]
 [57.274708]
 [68.914185]
 [79.83983 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 30. 30. 19. 30.  8.  5.  9.  7.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3  0  3] -> size -> 23 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action -1.0
Learning step: -7.731245517730713
desired expected reward: 70.69731903076172



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 16.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 16 11  0  0  0  3  0 10  3  0  3  8  8  0  3  3  8  3  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  5.  9.  7.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  3.  0.] 
adversary cards in discard: [6. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 21 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11 16 11  0  0  0  0 10  3  0  3  8  8  0  3  3  8  3  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  5.  9.  7.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  3.  0.] 
adversary cards in discard: [6. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 21 
adversary victory points: -3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11 16 11  0  0  0  0 10  3  0  3  8  8  0  3  3  8  3  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 30. 30. 19. 30.  8.  5.  9.  7.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  3.  0.] 
adversary cards in discard: [6. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 21 
adversary victory points: -3
player victory points: 6 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[62.457294]
 [58.439613]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  3.  0.] 
cards in discard: [6. 0. 0. 8. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  5.  9.  7.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 8. 16.  0.] 
adversary owned cards: [ 0 11 16 11  0  0  0  0 10  3  0  3  8  8  0  3  3  8  3  0  3] -> size -> 21 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: buy - action -1.0
Learning step: -7.613865852355957
desired expected reward: 72.2259750366211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[49.011757]
 [54.117916]
 [39.36362 ]
 [53.35783 ]
 [63.943348]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  3.  0.] 
cards in discard: [6. 0. 0. 8. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 30. 30. 19. 30.  8.  5.  9.  7.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 8. 16.  0.] 
adversary owned cards: [ 0 11 16 11  0  0  0  0 10  3  0  3  8  8  0  3  3  8  3  0  3] -> size -> 21 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: take_action - action -1.0
Learning step: -6.583043098449707
desired expected reward: 51.75048828125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8. 16.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11 16 11  0  0  0  0 10  3  0  3  8  8  0  3  3  8  3  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  5.  9.  7.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0. 15.  3.  8.] 
adversary cards in discard: [ 6.  0.  0.  8.  6.  6.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 21 
adversary victory points: -3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8. 16.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11 16 11  0  0  0  0 10  3  0  3  8  8  0  3  3  8  3  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 30. 30. 19. 30.  8.  5.  9.  7.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0. 15.  3.  8.] 
adversary cards in discard: [ 6.  0.  0.  8.  6.  6.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 21 
adversary victory points: -3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8. 16.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11 16 11  0  0  0  0 10  3  0  3  8  8  0  3  3  8  3  0  3  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 30. 30. 19. 30.  8.  5.  9.  7.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0. 15.  3.  8.] 
adversary cards in discard: [ 6.  0.  0.  8.  6.  6.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 21 
adversary victory points: -3
player victory points: 6 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [14.  0. 15.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.  8.] 
expected returns: [[43.982853]
 [24.321287]
 [31.272356]
 [33.341785]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 15.  3.  8.] 
cards in discard: [ 6.  0.  0.  8.  6.  6.  0. 11.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  5.  9.  7.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  8.  3.] 
adversary cards in discard: [ 8. 16.  0.  8.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0 11 16 11  0  0  0  0 10  3  0  3  8  8  0  3  3  8  3  0  3  8] -> size -> 22 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: buy - action -1.0
Learning step: -7.3610076904296875
desired expected reward: 56.58234786987305



action possibilites: [-1] 
expected returns: [[36.443005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 15.  3.] 
cards in discard: [ 6.  0.  0.  8.  6.  6.  0. 11.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  5.  9.  7.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  8.  3.] 
adversary cards in discard: [ 8. 16.  0.  8.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0 11 16 11  0  0  0  0 10  3  0  3  8  8  0  3  3  8  3  0  3  8] -> size -> 22 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: trash_cards_n_from_hand - action 0
Learning step: -4.0861077308654785
desired expected reward: 22.496856689453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.549421]
 [15.238367]
 [42.969585]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 15.  3.] 
cards in discard: [ 6.  0.  0.  8.  6.  6.  0. 11.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  5.  9.  7.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  8.  3.] 
adversary cards in discard: [ 8. 16.  0.  8.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0 11 16 11  0  0  0  0 10  3  0  3  8  8  0  3  3  8  3  0  3  8] -> size -> 22 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1
Learning step: -5.012895107269287
desired expected reward: 31.43010902404785






Player: 1 
cards in hand: [ 0. 11.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  8.  3.] 
cards in discard: [ 8. 16.  0.  8.  0.  3.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11 16 11  0  0  0  0 10  3  0  3  8  8  0  3  3  8  3  0  3  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  5.  9.  7.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 6.  0.  0.  8.  6.  6.  0. 11.  3.  0.  8. 14. 15.  3.] 
adversary owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 20 
adversary victory points: -3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 8. 16.  0.  8.  0.  3.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 16 11  0  0  0  0 10  0  3  8  8  0  3  3  8  3  0  3  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 19. 30.  8.  5.  9.  7.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 6.  0.  0.  8.  6.  6.  0. 11.  3.  0.  8. 14. 15.  3.] 
adversary owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 20 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 8. 16.  0.  8.  0.  3.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 16 11  0  0  0  0 10  0  3  8  8  0  3  3  8  3  0  3  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 30. 30. 19. 30.  8.  5.  9.  7.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 6.  0.  0.  8.  6.  6.  0. 11.  3.  0.  8. 14. 15.  3.] 
adversary owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 20 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 8. 16.  0.  8.  0.  3.  0.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 16 11  0  0  0  0 10  0  3  8  8  0  3  3  8  3  0  3  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 30. 30. 19. 30.  8.  5.  9.  7.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 6.  0.  0.  8.  6.  6.  0. 11.  3.  0.  8. 14. 15.  3.] 
adversary owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 20 
adversary victory points: -3
player victory points: 5 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [6. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[71.49128]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 6.  0.  0.  8.  6.  6.  0. 11.  3.  0.  8. 14. 15.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 19. 30.  8.  5.  9.  7.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 10.  8.] 
adversary cards in discard: [ 8. 16.  0.  8.  0.  3.  0.  0.  3.  0.  8.  0.  3.] 
adversary owned cards: [ 0 16 11  0  0  0  0 10  0  3  8  8  0  3  3  8  3  0  3  8  0] -> size -> 21 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: buy - action -1.0
Learning step: -4.97029447555542
desired expected reward: 37.99930191040039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[57.809017]
 [64.87621 ]
 [61.999947]
 [46.406654]
 [68.08321 ]
 [63.390877]
 [60.676765]
 [68.25354 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 6.  0.  0.  8.  6.  6.  0. 11.  3.  0.  8. 14. 15.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 30. 30. 19. 30.  8.  5.  9.  7.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 10.  8.] 
adversary cards in discard: [ 8. 16.  0.  8.  0.  3.  0.  0.  3.  0.  8.  0.  3.] 
adversary owned cards: [ 0 16 11  0  0  0  0 10  0  3  8  8  0  3  3  8  3  0  3  8  0] -> size -> 21 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: take_action - action -1.0
Learning step: -6.4880266189575195
desired expected reward: 63.65354537963867



buy possibilites: [-1] 
expected returns: [[56.296074]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 6.  0.  0.  8.  6.  6.  0. 11.  3.  0.  8. 14. 15.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  7.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 10.  8.] 
adversary cards in discard: [ 8. 16.  0.  8.  0.  3.  0.  0.  3.  0.  8.  0.  3.] 
adversary owned cards: [ 0 16 11  0  0  0  0 10  0  3  8  8  0  3  3  8  3  0  3  8  0] -> size -> 21 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -70 

action type: buy - action 1.0
Learning step: -5.477148532867432
desired expected reward: 59.39905548095703






Player: 1 
cards in hand: [ 0. 11.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.  8.] 
cards in discard: [ 8. 16.  0.  8.  0.  3.  0.  0.  3.  0.  8.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 11  0  0  0  0 10  0  3  8  8  0  3  3  8  3  0  3  8  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  7.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1] -> size -> 21 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  8.  0.] 
cards in discard: [ 8. 16.  0.  8.  0.  3.  0.  0.  3.  0.  8.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 16 11  0  0  0  0 10  0  3  8  8  0  3  3  8  3  0  3  8  0] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  7.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1] -> size -> 21 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [ 8. 16.  0.  8.  0.  3.  0.  0.  3.  0.  8.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0 16 11  0  0  0  0 10  0  3  8  8  0  3  3  8  3  0  3  8  0 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  7.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1] -> size -> 21 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [ 8. 16.  0.  8.  0.  3.  0.  0.  3.  0.  8.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0 16 11  0  0  0  0 10  0  3  8  8  0  3  3  8  3  0  3  8  0 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  7.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1] -> size -> 21 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [ 8. 16.  0.  8.  0.  3.  0.  0.  3.  0.  8.  0.  3. 29. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0 16 11  0  0  0  0 10  0  3  8  8  0  3  3  8  3  0  3  8  0 29 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1] -> size -> 21 
adversary victory points: -3
player victory points: 5 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [0. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[58.04724]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16 11  0  0  0  0 10  0  3  8  8  0  3  3  8  3  0  3  8  0 29 10] -> size -> 23 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: buy - action -1
Learning step: -5.969222545623779
desired expected reward: 50.32685089111328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[43.094498]
 [48.95219 ]
 [47.532772]
 [34.885033]
 [54.117283]
 [47.24332 ]
 [46.160892]
 [57.876125]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16 11  0  0  0  0 10  0  3  8  8  0  3  3  8  3  0  3  8  0 29 10] -> size -> 23 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: take_action - action -1.0
Learning step: -6.04360818862915
desired expected reward: 49.31554412841797



buy possibilites: [-1] 
expected returns: [[54.220802]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 0.] 
cards in discard: [11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  6.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16 11  0  0  0  0 10  0  3  8  8  0  3  3  8  3  0  3  8  0 29 10] -> size -> 23 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -70 

action type: buy - action 11.0
Learning step: -4.985896587371826
desired expected reward: 49.13139343261719






Player: 1 
cards in hand: [ 0.  3. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 11  0  0  0  0 10  0  3  8  8  0  3  3  8  3  0  3  8  0 29 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  6.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  8. 11.] 
adversary cards in discard: [11.  0.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11] -> size -> 22 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 16 11  0  0  0  0 10  0  3  8  8  0  3  3  8  3  0  3  8  0 29 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  6.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  8. 11.] 
adversary cards in discard: [11.  0.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11] -> size -> 22 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [16 11  0  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  6.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  8. 11.] 
adversary cards in discard: [11.  0.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11] -> size -> 22 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [16 11  0  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  6.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  8. 11.] 
adversary cards in discard: [11.  0.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11] -> size -> 22 
adversary victory points: -3
player victory points: 4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 11.] 
expected returns: [[24.150156]
 [ 5.249358]
 [13.867849]
 [20.603247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  8. 11.] 
cards in discard: [11.  0.  6.  6.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  6.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [29.  8.  3.  3.] 
adversary owned cards: [16 11  0  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10] -> size -> 21 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1
Learning step: -6.288864612579346
desired expected reward: 47.93193817138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 4.7170067]
 [ 9.88315  ]
 [-2.7897441]
 [ 9.145147 ]
 [19.54457  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  8. 11.] 
cards in discard: [11.  0.  6.  6.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  6.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [29.  8.  3.  3.] 
adversary owned cards: [16 11  0  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10] -> size -> 21 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -4.67681884765625
desired expected reward: 15.737573623657227



buy possibilites: [-1] 
expected returns: [[44.109066]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  8. 11.] 
cards in discard: [11.  0.  6.  6.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 29. 30. 19. 30.  8.  4.  9.  6.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [29.  8.  3.  3.] 
adversary owned cards: [16 11  0  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10] -> size -> 21 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -389.0 

action type: buy - action 6.0
Learning step: -18.31805992126465
desired expected reward: -21.107803344726562






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.  8.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 30.  8.  4.  9.  6.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  0.  3.] 
adversary cards in discard: [11.  0.  6.  6.  0.  0.  6.  0. 14.  0.  8. 11.] 
adversary owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6] -> size -> 23 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.  8.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 29. 30. 19. 30.  8.  4.  9.  6.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  0.  3.] 
adversary cards in discard: [11.  0.  6.  6.  0.  0.  6.  0. 14.  0.  8. 11.] 
adversary owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6] -> size -> 23 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.  8.  3.  3. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  0.  3.] 
adversary cards in discard: [11.  0.  6.  6.  0.  0.  6.  0. 14.  0.  8. 11.] 
adversary owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6] -> size -> 23 
adversary victory points: -4
player victory points: 4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[59.834797]
 [54.995148]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0.  3.] 
cards in discard: [11.  0.  6.  6.  0.  0.  6.  0. 14.  0.  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 16. 10.  0.] 
adversary cards in discard: [29.  8.  3.  3. 16.  0.  3.  0.  0.  0.] 
adversary owned cards: [16 11  0  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16] -> size -> 22 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1
Learning step: -5.376126289367676
desired expected reward: 38.732940673828125



action possibilites: [-1] 
expected returns: [[23.915699]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [11.  0.  6.  6.  0.  0.  6.  0. 14.  0.  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 29. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 16. 10.  0.] 
adversary cards in discard: [29.  8.  3.  3. 16.  0.  3.  0.  0.  0.] 
adversary owned cards: [16 11  0  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16] -> size -> 22 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action 15.0
Learning step: -5.583878517150879
desired expected reward: 47.855751037597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.377584]
 [18.561377]
 [17.966784]
 [ 6.717223]
 [16.44684 ]
 [21.761868]
 [17.551058]
 [19.27714 ]
 [11.325945]
 [17.135908]
 [16.352707]
 [24.490767]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [11.  0.  6.  6.  0.  0.  6.  0. 14.  0.  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 29. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 16. 10.  0.] 
adversary cards in discard: [29.  8.  3.  3. 16.  0.  3.  0.  0.  0.] 
adversary owned cards: [16 11  0  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16] -> size -> 22 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1
Learning step: -4.22583532333374
desired expected reward: 19.689863204956055



buy possibilites: [-1] 
expected returns: [[26.27092]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [11.  0.  6.  6.  0.  0.  6.  0. 14.  0.  8. 11. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 16. 10.  0.] 
adversary cards in discard: [29.  8.  3.  3. 16.  0.  3.  0.  0.  0.] 
adversary owned cards: [16 11  0  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16] -> size -> 22 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: -37 

action type: buy - action 14.0
Learning step: -1.8252018690109253
desired expected reward: 9.500747680664062






Player: 1 
cards in hand: [ 0.  8. 16. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 16. 10.  0.] 
cards in discard: [29.  8.  3.  3. 16.  0.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 6. 1. 6.] 
adversary cards in discard: [11.  0.  6.  6.  0.  0.  6.  0. 14.  0.  8. 11. 14. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14] -> size -> 23 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.] 
cards in discard: [29.  8.  3.  3. 16.  0.  3.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 6. 1. 6.] 
adversary cards in discard: [11.  0.  6.  6.  0.  0.  6.  0. 14.  0.  8. 11. 14. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14] -> size -> 23 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.] 
cards in discard: [29.  8.  3.  3. 16.  0.  3.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 29. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 6. 1. 6.] 
adversary cards in discard: [11.  0.  6.  6.  0.  0.  6.  0. 14.  0.  8. 11. 14. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14] -> size -> 23 
adversary victory points: -4
player victory points: 4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [0. 6. 6. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[9.036703]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 1. 6.] 
cards in discard: [11.  0.  6.  6.  0.  0.  6.  0. 14.  0.  8. 11. 14. 15.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 10. 11.] 
adversary cards in discard: [29.  8.  3.  3. 16.  0.  3.  0.  0.  0.  0. 16.  8. 10.  0.] 
adversary owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0] -> size -> 22 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1
Learning step: -5.560220241546631
desired expected reward: 20.7106990814209





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[4.2579775]
 [5.4976444]
 [5.016654 ]
 [2.062905 ]
 [6.1434555]
 [5.261263 ]
 [4.8185987]
 [6.4094   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 1. 6.] 
cards in discard: [11.  0.  6.  6.  0.  0.  6.  0. 14.  0.  8. 11. 14. 15.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 29. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 10. 11.] 
adversary cards in discard: [29.  8.  3.  3. 16.  0.  3.  0.  0.  0.  0. 16.  8. 10.  0.] 
adversary owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0] -> size -> 22 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: take_action - action -1.0
Learning step: -4.782881259918213
desired expected reward: 4.253821849822998



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10. 11.] 
cards in discard: [29.  8.  3.  3. 16.  0.  3.  0.  0.  0.  0. 16.  8. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  1.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14] -> size -> 23 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10.] 
cards in discard: [29.  8.  3.  3. 16.  0.  3.  0.  0.  0.  0. 16.  8. 10.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  1.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14] -> size -> 23 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 10.] 
cards in discard: [29.  8.  3.  3. 16.  0.  3.  0.  0.  0.  0. 16.  8. 10.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 28. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  1.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14] -> size -> 23 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 10.] 
cards in discard: [29.  8.  3.  3. 16.  0.  3.  0.  0.  0.  0. 16.  8. 10.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 28. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  1.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14] -> size -> 23 
adversary victory points: -4
player victory points: 4 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  1.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
expected returns: [[ 4.558476 ]
 [-2.9518247]
 [-3.3030117]
 [-3.3030117]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  1.  8.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0] -> size -> 24 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1.0
Learning step: -4.584563255310059
desired expected reward: -2.7533254623413086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-4.9224315]
 [-4.1645255]
 [-3.0244224]
 [-4.4837756]
 [ 4.1253185]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  1.  8.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0] -> size -> 24 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: take_action - action -1.0
Learning step: -4.49619722366333
desired expected reward: -3.981398344039917



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  6. 11.] 
adversary cards in discard: [ 3. 15.  1.  8.  8.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14] -> size -> 23 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  6. 11.] 
adversary cards in discard: [ 3. 15.  1.  8.  8.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14] -> size -> 23 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  8.  3.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  6. 11.] 
adversary cards in discard: [ 3. 15.  1.  8.  8.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14] -> size -> 23 
adversary victory points: -4
player victory points: 4 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  6.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[14.5776005]
 [11.558609 ]
 [11.558609 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  6. 11.] 
cards in discard: [ 3. 15.  1.  8.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  8.  3.] 
adversary owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1.0
Learning step: -4.361978054046631
desired expected reward: -0.23666048049926758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 4.448304 ]
 [-1.0543376]
 [14.665998 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  6. 11.] 
cards in discard: [ 3. 15.  1.  8.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 28. 30. 19. 30.  8.  4.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  8.  3.] 
adversary owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: take_action - action -1.0
Learning step: -5.00193977355957
desired expected reward: 9.67734146118164



buy possibilites: [-1] 
expected returns: [[0.8780272]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  6. 11.] 
cards in discard: [ 3. 15.  1.  8.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 19. 30.  8.  3.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  8.  3.] 
adversary owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5.  -90.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -400.0 

action type: buy - action 6.0
Learning step: -19.927526473999023
desired expected reward: -20.981863021850586






Player: 1 
cards in hand: [ 0. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [ 0.  0.  3. 10.  8.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 19. 30.  8.  3.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0.  0.  6.  0.] 
adversary cards in discard: [ 3. 15.  1.  8.  8.  6.  0. 11.  6.  6. 11.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6] -> size -> 24 
adversary victory points: -5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [ 0.  0.  3. 10.  8.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 28. 30. 19. 30.  8.  3.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0.  0.  6.  0.] 
adversary cards in discard: [ 3. 15.  1.  8.  8.  6.  0. 11.  6.  6. 11.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6] -> size -> 24 
adversary victory points: -5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [ 0.  0.  3. 10.  8.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 18. 30.  8.  3.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0.  0.  6.  0.] 
adversary cards in discard: [ 3. 15.  1.  8.  8.  6.  0. 11.  6.  6. 11.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6] -> size -> 24 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [14.  0.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[12.485798]
 [ 6.894517]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  6.  0.] 
cards in discard: [ 3. 15.  1.  8.  8.  6.  0. 11.  6.  6. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 18. 30.  8.  3.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [16.  8. 10.  8.  3.] 
adversary cards in discard: [ 0.  0.  3. 10.  8.  3.  3.  0. 11.  3.  0.  0.] 
adversary owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0  3] -> size -> 26 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1
Learning step: -5.3108134269714355
desired expected reward: -4.432785987854004



action possibilites: [-1] 
expected returns: [[28.98194]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [ 3. 15.  1.  8.  8.  6.  0. 11.  6.  6. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 28. 30. 18. 30.  8.  3.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10.  8.  3.] 
adversary cards in discard: [ 0.  0.  3. 10.  8.  3.  3.  0. 11.  3.  0.  0. 16.  8.] 
adversary owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0  3] -> size -> 26 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: take_action - action 14.0
Learning step: -4.19263219833374
desired expected reward: 2.7018837928771973





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[17.620861]
 [20.670927]
 [19.433615]
 [14.011208]
 [12.189801]
 [18.927475]
 [22.278063]
 [20.04906 ]
 [25.322332]
 [21.012197]
 [14.929792]
 [17.03613 ]
 [18.900192]
 [13.656845]
 [18.30323 ]
 [23.072996]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [ 3. 15.  1.  8.  8.  6.  0. 11.  6.  6. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 28. 30. 18. 30.  8.  3.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10.  8.  3.] 
adversary cards in discard: [ 0.  0.  3. 10.  8.  3.  3.  0. 11.  3.  0.  0. 16.  8.] 
adversary owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0  3] -> size -> 26 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: take_action - action -1
Learning step: -5.4945831298828125
desired expected reward: 23.487356185913086






Player: 1 
cards in hand: [10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.] 
cards in discard: [ 0.  0.  3. 10.  8.  3.  3.  0. 11.  3.  0.  0. 16.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 18. 30.  8.  3.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [ 3. 15.  1.  8.  8.  6.  0. 11.  6.  6. 11. 14.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6] -> size -> 24 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.] 
cards in discard: [ 0.  0.  3. 10.  8.  3.  3.  0. 11.  3.  0.  0. 16.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0  3] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 28. 30. 18. 30.  8.  3.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [ 3. 15.  1.  8.  8.  6.  0. 11.  6.  6. 11. 14.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6] -> size -> 24 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.] 
cards in discard: [ 0.  0.  3. 10.  8.  3.  3.  0. 11.  3.  0.  0. 16.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 18. 30.  8.  3.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [ 3. 15.  1.  8.  8.  6.  0. 11.  6.  6. 11. 14.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6] -> size -> 24 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [0. 6. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-6.1444144]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 6.] 
cards in discard: [ 3. 15.  1.  8.  8.  6.  0. 11.  6.  6. 11. 14.  0.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 18. 30.  8.  3.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 29.  8. 16.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  8.  3.  3.  0. 11.  3.  0.  0. 16.  8.  0. 10.  8.  3.] 
adversary owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0  3  0] -> size -> 27 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1.0
Learning step: -6.791898250579834
desired expected reward: 16.281085968017578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-6.0421324]
 [-6.378566 ]
 [-4.1845274]
 [-6.863493 ]
 [-6.1151047]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 6.] 
cards in discard: [ 3. 15.  1.  8.  8.  6.  0. 11.  6.  6. 11. 14.  0.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 28. 30. 18. 30.  8.  3.  8.  6.  2. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 29.  8. 16.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  8.  3.  3.  0. 11.  3.  0.  0. 16.  8.  0. 10.  8.  3.] 
adversary owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0  3  0] -> size -> 27 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: take_action - action -1.0
Learning step: -5.316575527191162
desired expected reward: -11.460989952087402



buy possibilites: [-1] 
expected returns: [[27.294062]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 6.] 
cards in discard: [ 3. 15.  1.  8.  8.  6.  0. 11.  6.  6. 11. 14.  0.  0.  6.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 18. 30.  8.  3.  8.  6.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 29.  8. 16.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  8.  3.  3.  0. 11.  3.  0.  0. 16.  8.  0. 10.  8.  3.] 
adversary owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0  3  0] -> size -> 27 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -102 

action type: buy - action 8.0
Learning step: -4.142709255218506
desired expected reward: -11.006202697753906






Player: 1 
cards in hand: [ 1. 29.  8. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  8. 16.  0.] 
cards in discard: [ 0.  0.  3. 10.  8.  3.  3.  0. 11.  3.  0.  0. 16.  8.  0. 10.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 18. 30.  8.  3.  8.  6.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  8.  6. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8] -> size -> 25 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 16.  0.  0.] 
cards in discard: [ 0.  0.  3. 10.  8.  3.  3.  0. 11.  3.  0.  0. 16.  8.  0. 10.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [16 11  0  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0
  0  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 18. 30.  8.  3.  8.  6.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  8.  6. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8] -> size -> 25 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [ 0.  0.  3. 10.  8.  3.  3.  0. 11.  3.  0.  0. 16.  8.  0. 10.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [11  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0  0  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 18. 30.  8.  3.  8.  6.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  8.  6. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8] -> size -> 25 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 0.  0.  3. 10.  8.  3.  3.  0. 11.  3.  0.  0. 16.  8.  0. 10.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [11  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0  0  3
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 28. 30. 18. 30.  8.  3.  8.  6.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  8.  6. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8] -> size -> 25 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 0.  0.  3. 10.  8.  3.  3.  0. 11.  3.  0.  0. 16.  8.  0. 10.  8.  3.
 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [11  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0  0  3
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 18. 30.  8.  3.  8.  5.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  8.  6. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8] -> size -> 25 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [11.  8.  6. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 14.] 
expected returns: [[2.45928  ]
 [2.788404 ]
 [2.8915205]
 [3.4881988]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  6. 14.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 18. 30.  8.  3.  8.  5.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0  0  3
  0 11] -> size -> 26 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1
Learning step: -6.8001389503479
desired expected reward: 20.49392318725586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[2.7369814]
 [2.782886 ]
 [1.9438548]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  6. 14.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 28. 30. 18. 30.  8.  3.  8.  5.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0  0  3
  0 11] -> size -> 26 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: take_action - action -1.0
Learning step: -5.564737319946289
desired expected reward: -3.118655204772949



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [11  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0  0  3
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 18. 30.  8.  3.  8.  5.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0. 14.] 
adversary cards in discard: [11.  8.  6. 14.  0.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8] -> size -> 25 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [11  0  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0  0  3
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 18. 30.  8.  3.  8.  5.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0. 14.] 
adversary cards in discard: [11.  8.  6. 14.  0.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8] -> size -> 25 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [11  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0  0  3  0
 11  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 18. 30.  8.  3.  8.  5.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0. 14.] 
adversary cards in discard: [11.  8.  6. 14.  0.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8] -> size -> 25 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [11  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0  0  3  0
 11  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 28. 30. 18. 30.  8.  3.  8.  5.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0. 14.] 
adversary cards in discard: [11.  8.  6. 14.  0.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8] -> size -> 25 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [11  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0  0  3  0
 11  0 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 30.  8.  3.  8.  4.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0. 14.] 
adversary cards in discard: [11.  8.  6. 14.  0.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8] -> size -> 25 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
expected returns: [[-5.327927]
 [-5.935233]
 [-6.225563]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  0. 14.] 
cards in discard: [11.  8.  6. 14.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 30.  8.  3.  8.  4.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10. 10.  0.  8.  3.] 
adversary cards in discard: [ 0. 11. 29. 16.  3.  0.  0.] 
adversary owned cards: [11  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0  0  3  0
 11  0 11] -> size -> 27 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1.0
Learning step: -5.729692459106445
desired expected reward: -3.7858376502990723



action possibilites: [-1] 
expected returns: [[-5.8633046]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  0.] 
cards in discard: [11.  8.  6. 14.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 28. 30. 18. 30.  8.  3.  8.  4.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10. 10.  8.] 
adversary cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.] 
adversary owned cards: [11  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0  0  3  0
 11  0 11] -> size -> 27 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: take_action - action 14.0
Learning step: -4.31898832321167
desired expected reward: -10.577709197998047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-7.423464 ]
 [-8.366255 ]
 [-7.8884344]
 [-4.962315 ]
 [-8.145643 ]
 [-7.8590126]
 [-8.266282 ]
 [-8.12323  ]
 [-6.178918 ]
 [-7.6959605]
 [-7.3542385]
 [-6.8617716]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0.] 
cards in discard: [11.  8.  6. 14.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 28. 30. 18. 30.  8.  3.  8.  4.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10. 10.  8.] 
adversary cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.] 
adversary owned cards: [11  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0  0  3  0
 11  0 11] -> size -> 27 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: take_action - action -1
Learning step: -4.360667705535889
desired expected reward: -10.22397232055664



buy possibilites: [-1] 
expected returns: [[2.200859]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0.] 
cards in discard: [11.  8.  6. 14.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 4 
card supply: [11. 28. 30. 18. 30.  8.  2.  8.  4.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10. 10.  8.] 
adversary cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.] 
adversary owned cards: [11  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0  0  3  0
 11  0 11] -> size -> 27 
adversary victory points: 5
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -110.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -401.0 

action type: buy - action 6.0
Learning step: -19.755964279174805
desired expected reward: -24.646324157714844






Player: 1 
cards in hand: [10. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.] 
cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [11  0 10  0  8  8  0  3  3  8  3  0  3  8  0 29 10 16  0  1  0  0  3  0
 11  0 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 30.  8.  2.  8.  4.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  6.  8.  6.  0.] 
adversary cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8  6] -> size -> 26 
adversary victory points: -6
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 30.  8.  2.  8.  4.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  6.  8.  6.  0.] 
adversary cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8  6] -> size -> 26 
adversary victory points: -6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 28. 30. 18. 30.  8.  2.  8.  4.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  6.  8.  6.  0.] 
adversary cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8  6] -> size -> 26 
adversary victory points: -6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 18. 30.  8.  2.  8.  4.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  6.  8.  6.  0.] 
adversary cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8  6] -> size -> 26 
adversary victory points: -6
player victory points: 5 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [11.  6.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[3.731131 ]
 [3.6383572]
 [2.3666134]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  8.  6.  0.] 
cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  6  8  0  6  3  0  0  8  6 11  0  0  3  6 14  6  1 11  6 14  6
  8  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 18. 30.  8.  2.  8.  4.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  8.] 
adversary cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8.] 
adversary owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0] -> size -> 26 
adversary victory points: 5
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -121 

action type: buy - action -1
Learning step: -6.084405422210693
desired expected reward: -3.8835463523864746



action possibilites: [-1] 
expected returns: [[-4.775267]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 15  8  0  6  3  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 18. 30.  8.  2.  8.  4.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  8.] 
adversary cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8.] 
adversary owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0] -> size -> 26 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: trash_cards_n_from_hand - action 6
Learning step: -4.638285160064697
desired expected reward: -4.02145528793335





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-5.1115623]
 [-4.2571096]
 [-4.840579 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 15  8  0  6  3  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 28. 30. 18. 30.  8.  2.  8.  4.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  8.] 
adversary cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8.] 
adversary owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0] -> size -> 26 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: take_action - action -1
Learning step: -4.365224361419678
desired expected reward: -9.140491485595703



buy possibilites: [-1] 
expected returns: [[34.218956]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 15  8  0  6  3  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 28. 30. 18. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  8.] 
adversary cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8.] 
adversary owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0] -> size -> 26 
adversary victory points: 5
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -110.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -401.0 

action type: buy - action 6.0
Learning step: -19.067218780517578
desired expected reward: -23.32432746887207






Player: 1 
cards in hand: [ 3. 11.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  8.] 
cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 18. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 1. 6. 0. 6.] 
adversary cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.  6.  8.  6.  0.] 
adversary owned cards: [ 0  0 15  8  0  6  3  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6
  6] -> size -> 25 
adversary victory points: -6
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 18. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [6. 1. 6. 0. 6.] 
adversary cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.  6.  8.  6.  0.] 
adversary owned cards: [ 0  0 15  8  0  6  3  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6
  6] -> size -> 25 
adversary victory points: -6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 28. 30. 18. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [6. 1. 6. 0. 6.] 
adversary cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.  6.  8.  6.  0.] 
adversary owned cards: [ 0  0 15  8  0  6  3  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6
  6] -> size -> 25 
adversary victory points: -6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8. 10.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0 10  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 17. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [6. 1. 6. 0. 6.] 
adversary cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.  6.  8.  6.  0.] 
adversary owned cards: [ 0  0 15  8  0  6  3  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6
  6] -> size -> 25 
adversary victory points: -6
player victory points: 6 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [6. 1. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-6.25849]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 6. 0. 6.] 
cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.  6.  8.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  0  6  3  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 17. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 11.  0.] 
adversary cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8. 10.  3. 11.  3.  0.  0.  8.] 
adversary owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0 10  3] -> size -> 28 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -131 

action type: buy - action -1
Learning step: -8.401763916015625
desired expected reward: 25.81719207763672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-6.7822247]
 [-7.145832 ]
 [-6.6715612]
 [-4.9337826]
 [-6.3334265]
 [-7.0869474]
 [-6.547463 ]
 [-5.9992676]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 6. 0. 6.] 
cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.  6.  8.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  0  6  3  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 28. 30. 17. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 11.  0.] 
adversary cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8. 10.  3. 11.  3.  0.  0.  8.] 
adversary owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0 10  3] -> size -> 28 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -131 

action type: take_action - action -1.0
Learning step: -6.3738203048706055
desired expected reward: -12.63231086730957



buy possibilites: [-1] 
expected returns: [[5.910228]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 6. 0. 6.] 
cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.  6.  8.  6.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  0  6  3  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6
  6  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 17. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 11.  0.] 
adversary cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8. 10.  3. 11.  3.  0.  0.  8.] 
adversary owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0 10  3] -> size -> 28 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -120    0    0    0    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -113 

action type: buy - action 1.0
Learning step: -5.159728527069092
desired expected reward: -12.305566787719727






Player: 1 
cards in hand: [ 0.  1.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 11.  0.] 
cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8. 10.  3. 11.  3.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0 10  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 17. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 6. 8. 0.] 
adversary cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.  6.  8.  6.  0.  1.  6.  1.
  6.  0.  6.] 
adversary owned cards: [ 0  0 15  8  0  6  3  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6
  6  1] -> size -> 26 
adversary victory points: -6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 11.  0.] 
cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8. 10.  3. 11.  3.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0 10  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 27. 30. 17. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 6. 8. 0.] 
adversary cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.  6.  8.  6.  0.  1.  6.  1.
  6.  0.  6.] 
adversary owned cards: [ 0  0 15  8  0  6  3  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6
  6  1] -> size -> 26 
adversary victory points: -6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 11.  0.] 
cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8. 10.  3. 11.  3.  0.  0.  8.
  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0 10  3  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 27. 30. 16. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 6. 8. 0.] 
adversary cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.  6.  8.  6.  0.  1.  6.  1.
  6.  0.  6.] 
adversary owned cards: [ 0  0 15  8  0  6  3  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6
  6  1] -> size -> 26 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[13.513377]
 [12.191801]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 8. 0.] 
cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.  6.  8.  6.  0.  1.  6.  1.
  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  0  6  3  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6
  6  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 16. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 8. 0. 8.] 
adversary cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8. 10.  3. 11.  3.  0.  0.  8.
  3.  0.  1.  3. 11.  0.] 
adversary owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0 10  3  3] -> size -> 29 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1
Learning step: -7.052768707275391
desired expected reward: -1.1425409317016602



action possibilites: [-1] 
expected returns: [[-2.3538918]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.  6.  8.  6.  0.  1.  6.  1.
  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 16. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 8. 0. 8.] 
adversary cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8. 10.  3. 11.  3.  0.  0.  8.
  3.  0.  1.  3. 11.  0.] 
adversary owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0 10  3  3] -> size -> 29 
adversary victory points: 7
player victory points: -7 

Reward from previous game state: 
[  -5    0   -7 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -132 

action type: trash_cards_n_from_hand - action 5
Learning step: -7.231301784515381
desired expected reward: 4.335484027862549





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-3.4365938]
 [-2.26347  ]
 [-2.5210807]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.  6.  8.  6.  0.  1.  6.  1.
  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 27. 30. 16. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 8. 0. 8.] 
adversary cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8. 10.  3. 11.  3.  0.  0.  8.
  3.  0.  1.  3. 11.  0.] 
adversary owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0 10  3  3] -> size -> 29 
adversary victory points: 7
player victory points: -7 

Reward from previous game state: 
[  -5    0   -7 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -132 

action type: take_action - action -1
Learning step: -6.5413947105407715
desired expected reward: -8.895286560058594



buy possibilites: [-1] 
expected returns: [[-5.7904177]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [11.  8.  6. 14.  0.  6. 14.  3. 15.  0.  0.  6.  8.  6.  0.  1.  6.  1.
  6.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 27. 30. 16. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 8. 0. 8.] 
adversary cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8. 10.  3. 11.  3.  0.  0.  8.
  3.  0.  1.  3. 11.  0.] 
adversary owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0 10  3  3] -> size -> 29 
adversary victory points: 7
player victory points: -7 

Reward from previous game state: 
[  -5.    0.   -7. -140.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -162.0 

action type: buy - action 0.0
Learning step: -8.058455467224121
desired expected reward: -11.495046615600586






Player: 1 
cards in hand: [3. 0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 8.] 
cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8. 10.  3. 11.  3.  0.  0.  8.
  3.  0.  1.  3. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11  0  0  8  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0
 11  0 10  3  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 16. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0] -> size -> 25 
adversary victory points: -7
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8. 10.  3. 11.  3.  0.  0.  8.
  3.  0.  1.  3. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  0  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0
 10  3  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 16. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0] -> size -> 25 
adversary victory points: -7
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0. 11. 29. 16.  3.  0.  0.  0.  3.  0.  8. 10.  3. 11.  3.  0.  0.  8.
  3.  0.  1.  3. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  0  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0
 10  3  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 27. 30. 16. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0] -> size -> 25 
adversary victory points: -7
player victory points: 7 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [6. 6. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-3.643713]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 16. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11  0  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0
 10  3  3] -> size -> 27 
adversary victory points: 7
player victory points: -7 

Reward from previous game state: 
[  -5    0   -7 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -152 

action type: buy - action -1
Learning step: -7.3854289054870605
desired expected reward: -13.175846099853516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-5.20426  ]
 [-4.77592  ]
 [-5.9282665]
 [-5.3177977]
 [-3.192797 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 27. 30. 16. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11  0  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0
 10  3  3] -> size -> 27 
adversary victory points: 7
player victory points: -7 

Reward from previous game state: 
[  -5    0   -7 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -152 

action type: take_action - action -1.0
Learning step: -7.534221649169922
desired expected reward: -10.865325927734375



buy possibilites: [-1] 
expected returns: [[-14.9221115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 0.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 27. 30. 16. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11  0  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0
 10  3  3] -> size -> 27 
adversary victory points: 7
player victory points: -7 

Reward from previous game state: 
[  -5.    0.   -7. -140.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -182.0 

action type: buy - action 0.0
Learning step: -8.993269920349121
desired expected reward: -17.842830657958984






Player: 1 
cards in hand: [11. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [11  0  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0
 10  3  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 30.  8.  1.  8.  4.  1. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  1.  0.  8. 15.] 
adversary cards in discard: [0. 6. 6. 0. 6. 0.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0  0] -> size -> 26 
adversary victory points: -7
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [11  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10
  3  3  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  1.  0.  8. 15.] 
adversary cards in discard: [0. 6. 6. 0. 6. 0.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0  0] -> size -> 26 
adversary victory points: -7
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [11  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10
  3  3  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 27. 30. 16. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  1.  0.  8. 15.] 
adversary cards in discard: [0. 6. 6. 0. 6. 0.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0  0] -> size -> 26 
adversary victory points: -7
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [8. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [11  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10
  3  3  8  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 27. 30. 16. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  1.  0.  8. 15.] 
adversary cards in discard: [0. 6. 6. 0. 6. 0.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0  0] -> size -> 26 
adversary victory points: -7
player victory points: 7 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 6.  1.  0.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[-2.0673702]
 [-1.7674806]
 [-1.2239745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  0.  8. 15.] 
cards in discard: [0. 6. 6. 0. 6. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 16. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [ 8.  0. 16. 11.  0.  0.] 
adversary owned cards: [11  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10
  3  3  8  0] -> size -> 28 
adversary victory points: 7
player victory points: -7 

Reward from previous game state: 
[  -5    0   -7 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -152 

action type: buy - action -1
Learning step: -6.889344692230225
desired expected reward: -21.81145668029785





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[-1.6417962]
 [-2.1959102]
 [-1.8406332]
 [-0.6665448]
 [-2.174113 ]
 [-1.6440499]
 [-2.2028553]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0.  8. 15.] 
cards in discard: [0. 6. 6. 0. 6. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 27. 30. 16. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [ 8.  0. 16. 11.  0.  0.] 
adversary owned cards: [11  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10
  3  3  8  0] -> size -> 28 
adversary victory points: 7
player victory points: -7 

Reward from previous game state: 
[  -5    0   -7 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -152 

action type: take_action - action -1.0
Learning step: -7.530453681945801
desired expected reward: -9.597824096679688



buy possibilites: [-1] 
expected returns: [[-10.694548]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0.  8. 15.] 
cards in discard: [0. 6. 6. 0. 6. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 27. 30. 15. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [ 8.  0. 16. 11.  0.  0.] 
adversary owned cards: [11  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10
  3  3  8  0] -> size -> 28 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -130.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    2.    0.] 
sum of rewards: -139.0 

action type: buy - action 3.0
Learning step: -7.09859561920166
desired expected reward: -8.939229965209961






Player: 1 
cards in hand: [0. 3. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [ 8.  0. 16. 11.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  0  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10
  3  3  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 15. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  6. 14.  8.] 
adversary cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0  0  3] -> size -> 27 
adversary victory points: -6
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8.  0. 16. 11.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 15. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  6. 14.  8.] 
adversary cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0  0  3] -> size -> 27 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8.  0. 16. 11.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 27. 30. 15. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  6. 14.  8.] 
adversary cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0  0  3] -> size -> 27 
adversary victory points: -6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8.  0. 16. 11.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 27. 30. 15. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  6. 14.  8.] 
adversary cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0  0  3] -> size -> 27 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  6. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
expected returns: [[-6.4970856]
 [-4.6319237]
 [-3.3014092]
 [-4.6319237]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  6. 14.  8.] 
cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  3  6 14  6  1 11  6 14  6  8  6  6  1
  0  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11. 29.  0.  0.  3.] 
adversary cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.] 
adversary owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0] -> size -> 28 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1
Learning step: -6.6146111488342285
desired expected reward: -17.309158325195312



action possibilites: [-1] 
expected returns: [[-10.736668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8.] 
cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11. 29.  0.  0.  3.] 
adversary cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.] 
adversary owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0] -> size -> 28 
adversary victory points: 7
player victory points: -7 

Reward from previous game state: 
[  -5    0   -7 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -132 

action type: trash_cards_n_from_hand - action 5
Learning step: -6.775364875793457
desired expected reward: -8.099563598632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -9.367451]
 [ -7.900265]
 [-11.326815]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 27. 30. 15. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11. 29.  0.  0.  3.] 
adversary cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.] 
adversary owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0] -> size -> 28 
adversary victory points: 7
player victory points: -7 

Reward from previous game state: 
[  -5    0   -7 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -132 

action type: take_action - action -1
Learning step: -6.268838405609131
desired expected reward: -17.00550651550293






Player: 1 
cards in hand: [11. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  0.  3.] 
cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [1. 6. 0. 6. 0.] 
adversary cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.  8.  6.  8.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3] -> size -> 25 
adversary victory points: -7
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0.  0.  3.] 
cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 27. 30. 15. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [1. 6. 0. 6. 0.] 
adversary cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.  8.  6.  8.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3] -> size -> 25 
adversary victory points: -7
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0.  0.  3.] 
cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [1. 6. 0. 6. 0.] 
adversary cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.  8.  6.  8.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3] -> size -> 25 
adversary victory points: -7
player victory points: 8 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [1. 6. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[15.385906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 6. 0.] 
cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.  8.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 1. 3. 8. 0.] 
adversary cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.  3. 11. 29.  0.  0.  3.] 
adversary owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0  3] -> size -> 29 
adversary victory points: 8
player victory points: -7 

Reward from previous game state: 
[  -5    0   -7 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -162 

action type: buy - action -1.0
Learning step: -7.187476634979248
desired expected reward: -18.514291763305664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[ 4.5532293]
 [ 8.917948 ]
 [ 8.586668 ]
 [-1.0258915]
 [ 6.708161 ]
 [12.98991  ]
 [ 9.799873 ]
 [ 1.9061584]
 [ 7.6188664]
 [ 6.8064113]
 [15.79895  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 6. 0.] 
cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.  8.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 27. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 1. 3. 8. 0.] 
adversary cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.  3. 11. 29.  0.  0.  3.] 
adversary owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0  3] -> size -> 29 
adversary victory points: 8
player victory points: -7 

Reward from previous game state: 
[  -5    0   -7 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -162 

action type: take_action - action -1.0
Learning step: -8.655591011047363
desired expected reward: 6.730315208435059



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 1. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 8. 0.] 
cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.  3. 11. 29.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14. 11.  0.  0.  6.] 
adversary cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.  8.  6.  8.  1.  6.  0.
  6.  0.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3] -> size -> 25 
adversary victory points: -7
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 8. 0.] 
cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.  3. 11. 29.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 27. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14. 11.  0.  0.  6.] 
adversary cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.  8.  6.  8.  1.  6.  0.
  6.  0.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3] -> size -> 25 
adversary victory points: -7
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 8. 0.] 
cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.  3. 11. 29.  0.  0.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0  3  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14. 11.  0.  0.  6.] 
adversary cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.  8.  6.  8.  1.  6.  0.
  6.  0.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3] -> size -> 25 
adversary victory points: -7
player victory points: 8 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [14. 11.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[ -7.4953904]
 [-10.741676 ]
 [ -8.14375  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  0.  0.  6.] 
cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.  8.  6.  8.  1.  6.  0.
  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.  3. 11. 29.  0.  0.  3.  1.
  3.  1.  3.  8.  0.] 
adversary owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0  3  1] -> size -> 30 
adversary victory points: 8
player victory points: -7 

Reward from previous game state: 
[  -5    0   -7 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -162 

action type: buy - action -1.0
Learning step: -9.080810546875
desired expected reward: 6.718137741088867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-10.282557 ]
 [ -8.059008 ]
 [-12.624384 ]
 [ -7.2064233]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  0.  0.  6.] 
cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.  8.  6.  8.  1.  6.  0.
  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 26. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.  3. 11. 29.  0.  0.  3.  1.
  3.  1.  3.  8.  0.] 
adversary owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0  3  1] -> size -> 30 
adversary victory points: 8
player victory points: -7 

Reward from previous game state: 
[  -5    0   -7 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -162 

action type: take_action - action -1.0
Learning step: -7.92736291885376
desired expected reward: -15.422755241394043



buy possibilites: [-1] 
expected returns: [[-12.114161]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  0.  0.  6.] 
cards in discard: [ 0.  6.  6.  0.  6.  0.  3.  6.  1.  0.  8. 15.  8.  6.  8.  1.  6.  0.
  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 26. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.  3. 11. 29.  0.  0.  3.  1.
  3.  1.  3.  8.  0.] 
adversary owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0  3  1] -> size -> 30 
adversary victory points: 8
player victory points: -7 

Reward from previous game state: 
[  -5.    0.   -7. -150.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -192.0 

action type: buy - action 0.0
Learning step: -9.358440399169922
desired expected reward: -19.64100456237793






Player: 1 
cards in hand: [ 0.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.  3. 11. 29.  0.  0.  3.  1.
  3.  1.  3.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0  3  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [6. 6. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0] -> size -> 26 
adversary victory points: -7
player victory points: 8 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.  3. 11. 29.  0.  0.  3.  1.
  3.  1.  3.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0  3  1] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [6. 6. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0] -> size -> 26 
adversary victory points: -7
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.  3. 11. 29.  0.  0.  3.  1.
  3.  1.  3.  8.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0  3  1 14] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 6. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0] -> size -> 26 
adversary victory points: -7
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.  3. 11. 29.  0.  0.  3.  1.
  3.  1.  3.  8.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0  3  1 14] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 26. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 6. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0] -> size -> 26 
adversary victory points: -7
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 8.  0. 16. 11.  0.  0.  0.  8.  3.  3.  0.  3. 11. 29.  0.  0.  3.  1.
  3.  1.  3.  8.  0. 14.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0  3  1 14  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 26. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 6. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0] -> size -> 26 
adversary victory points: -7
player victory points: 8 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [6. 6. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[4.558172]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0  3  1 14  0] -> size -> 32 
adversary victory points: 8
player victory points: -7 

Reward from previous game state: 
[  -5    0   -7 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -162 

action type: buy - action -1
Learning step: -7.39544153213501
desired expected reward: -19.509601593017578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.5356648]
 [-5.1590047]
 [ 3.9211469]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 26. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0  3  1 14  0] -> size -> 32 
adversary victory points: 8
player victory points: -7 

Reward from previous game state: 
[  -5    0   -7 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -162 

action type: take_action - action -1.0
Learning step: -8.308662414550781
desired expected reward: -3.915308952331543



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [1. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  0  3  8  0 29 16  0  1  0  0  3  0 11  0 11  0 10  3
  3  8  0  0  3  1 14  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [6. 6. 6. 6. 0.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0] -> size -> 26 
adversary victory points: -7
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [6. 6. 6. 6. 0.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0] -> size -> 26 
adversary victory points: -7
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 14. 30.  8.  1.  8.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [6. 6. 6. 6. 0.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0] -> size -> 26 
adversary victory points: -7
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 13. 30.  8.  1.  8.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [6. 6. 6. 6. 0.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0] -> size -> 26 
adversary victory points: -7
player victory points: 9 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.951197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [6. 6. 6. 6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 13. 30.  8.  1.  8.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3. 11.  1.  0.] 
adversary cards in discard: [3. 8. 1. 3.] 
adversary owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3] -> size -> 31 
adversary victory points: 9
player victory points: -7 

Reward from previous game state: 
[  -5    0   -7 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -172 

action type: buy - action -1.0
Learning step: -9.042458534240723
desired expected reward: -5.121325969696045





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -9.418249 ]
 [-10.922509 ]
 [ -8.581443 ]
 [-10.05332  ]
 [ -7.6664577]
 [ -6.7546496]
 [-10.107623 ]
 [-10.890437 ]
 [-12.095521 ]
 [-10.757314 ]
 [ -7.7535305]
 [ -8.82265  ]
 [ -9.639878 ]
 [ -7.299047 ]
 [ -9.217455 ]
 [-10.854961 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [6. 6. 6. 6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 4. 26. 30. 13. 30.  8.  1.  8.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3. 11.  1.  0.] 
adversary cards in discard: [3. 8. 1. 3.] 
adversary owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3] -> size -> 31 
adversary victory points: 9
player victory points: -7 

Reward from previous game state: 
[  -5    0   -7 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -172 

action type: take_action - action -1.0
Learning step: -8.237339973449707
desired expected reward: -19.444843292236328



buy possibilites: [-1] 
expected returns: [[-1.1928074]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [6. 6. 6. 6. 0. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 6 
card supply: [ 4. 26. 30. 13. 30.  8.  0.  8.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3. 11.  1.  0.] 
adversary cards in discard: [3. 8. 1. 3.] 
adversary owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3] -> size -> 31 
adversary victory points: 9
player victory points: -8 

Reward from previous game state: 
[  -5.    0.   -8. -170.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -483.0 

action type: buy - action 6.0
Learning step: -23.839107513427734
desired expected reward: -30.59375762939453






Player: 1 
cards in hand: [29.  3. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11.  1.  0.] 
cards in discard: [3. 8. 1. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 13. 30.  8.  0.  8.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  0.  6.  6.] 
adversary cards in discard: [6. 6. 6. 6. 0. 6. 0. 0. 0. 0. 1.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6] -> size -> 27 
adversary victory points: -8
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 11.  1.  0.] 
cards in discard: [3. 8. 1. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 26. 30. 13. 30.  8.  0.  8.  4.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  0.  6.  6.] 
adversary cards in discard: [6. 6. 6. 6. 0. 6. 0. 0. 0. 0. 1.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6] -> size -> 27 
adversary victory points: -8
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 11.  1.  0.] 
cards in discard: [ 3.  8.  1.  3. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 13. 30.  8.  0.  8.  3.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  0.  6.  6.] 
adversary cards in discard: [6. 6. 6. 6. 0. 6. 0. 0. 0. 0. 1.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6] -> size -> 27 
adversary victory points: -8
player victory points: 9 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [14.  0.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[0.34159374]
 [0.30879545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  6.  6.] 
cards in discard: [6. 6. 6. 6. 0. 6. 0. 0. 0. 0. 1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 13. 30.  8.  0.  8.  3.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [16. 14.  3.  8. 10.] 
adversary cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.] 
adversary owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11] -> size -> 32 
adversary victory points: 9
player victory points: -8 

Reward from previous game state: 
[  -5    0   -8 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -183 

action type: buy - action -1
Learning step: -9.082954406738281
desired expected reward: -10.275761604309082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-1.018876  ]
 [-0.97173643]
 [-0.5483712 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  6.  6.] 
cards in discard: [6. 6. 6. 6. 0. 6. 0. 0. 0. 0. 1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 13. 30.  8.  0.  8.  3.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [16. 14.  3.  8. 10.] 
adversary cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.] 
adversary owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11] -> size -> 32 
adversary victory points: 9
player victory points: -8 

Reward from previous game state: 
[  -5    0   -8 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -183 

action type: take_action - action -1.0
Learning step: -9.184515953063965
desired expected reward: -8.842931747436523



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16. 14.  3.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.  8. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 14.  3.  8. 10.] 
cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 13. 30.  8.  0.  8.  3.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8. 15. 11.  3.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  0.  0.  0.  0.  1. 14.  0.  0.  6.  6.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6] -> size -> 27 
adversary victory points: -8
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  8. 10.] 
cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 26. 30. 13. 30.  8.  0.  8.  3.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  0.  0.  0.  0.  1. 14.  0.  0.  6.  6.  8. 11.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6] -> size -> 27 
adversary victory points: -8
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  8. 10.] 
cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 13. 30.  8.  0.  8.  3.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  0.  0.  0.  0.  1. 14.  0.  0.  6.  6.  8. 11.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6] -> size -> 27 
adversary victory points: -8
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  8. 10.] 
cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 26. 30. 13. 30.  8.  0.  8.  3.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  0.  0.  0.  0.  1. 14.  0.  0.  6.  6.  8. 11.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6] -> size -> 27 
adversary victory points: -8
player victory points: 9 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[4.7904406]
 [4.493085 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.] 
cards in discard: [ 6.  6.  6.  6.  0.  6.  0.  0.  0.  0.  1. 14.  0.  0.  6.  6.  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 13. 30.  8.  0.  8.  3.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 11.] 
adversary cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.] 
adversary owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0] -> size -> 33 
adversary victory points: 9
player victory points: -8 

Reward from previous game state: 
[  -5    0   -8 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -183 

action type: discard_down_to_3_cards - action 6
Learning step: -8.308093070983887
desired expected reward: -23.041431427001953





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[3.724594 ]
 [3.5178795]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.] 
cards in discard: [ 6.  6.  6.  6.  0.  6.  0.  0.  0.  0.  1. 14.  0.  0.  6.  6.  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 26. 30. 13. 30.  8.  0.  8.  3.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 11.] 
adversary cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.] 
adversary owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0] -> size -> 33 
adversary victory points: 9
player victory points: -8 

Reward from previous game state: 
[  -5    0   -8 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -183 

action type: take_action - action -1.0
Learning step: -9.307487487792969
desired expected reward: -4.517057418823242



buy possibilites: [-1] 
expected returns: [[3.5029244]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.] 
cards in discard: [ 6.  6.  6.  6.  0.  6.  0.  0.  0.  0.  1. 14.  0.  0.  6.  6.  8. 11.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 13. 30.  8.  0.  8.  3.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 11.] 
adversary cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.] 
adversary owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0] -> size -> 33 
adversary victory points: 9
player victory points: -8 

Reward from previous game state: 
[  -5.    0.   -8. -170.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -213.0 

action type: buy - action 0.0
Learning step: -10.757414817810059
desired expected reward: -7.032822608947754






Player: 1 
cards in hand: [ 8.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 11.] 
cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 13. 30.  8.  0.  8.  3.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 6. 8. 6. 0.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  0.  0.  0.  0.  1. 14.  0.  0.  6.  6.  8. 11.
  0.  0. 15.  3.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0] -> size -> 28 
adversary victory points: -8
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 11.] 
cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 26. 30. 13. 30.  8.  0.  8.  3.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 6. 8. 6. 0.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  0.  0.  0.  0.  1. 14.  0.  0.  6.  6.  8. 11.
  0.  0. 15.  3.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0] -> size -> 28 
adversary victory points: -8
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 11.] 
cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 26. 30. 13. 30.  8.  0.  8.  3.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 6. 8. 6. 0.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  0.  0.  0.  0.  1. 14.  0.  0.  6.  6.  8. 11.
  0.  0. 15.  3.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0] -> size -> 28 
adversary victory points: -8
player victory points: 9 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [8. 6. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[-3.508439 ]
 [-4.1691732]
 [-4.1691732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 8. 6. 0.] 
cards in discard: [ 6.  6.  6.  6.  0.  6.  0.  0.  0.  0.  1. 14.  0.  0.  6.  6.  8. 11.
  0.  0. 15.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 13. 30.  8.  0.  8.  3.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.  0.  8.
  0.  0.  0. 11.] 
adversary owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0  0] -> size -> 34 
adversary victory points: 9
player victory points: -8 

Reward from previous game state: 
[  -5    0   -8 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -183 

action type: buy - action -1
Learning step: -9.41162395477295
desired expected reward: -5.9086995124816895





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-5.1545296]
 [-4.820277 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 8. 6. 0.] 
cards in discard: [ 6.  6.  6.  6.  0.  6.  0.  0.  0.  0.  1. 14.  0.  0.  6.  6.  8. 11.
  0.  0. 15.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 26. 30. 13. 30.  8.  0.  8.  3.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.  0.  8.
  0.  0.  0. 11.] 
adversary owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0  0] -> size -> 34 
adversary victory points: 9
player victory points: -8 

Reward from previous game state: 
[  -5    0   -8 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -183 

action type: take_action - action -1.0
Learning step: -9.085894584655762
desired expected reward: -12.594331741333008



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.  0.  8.
  0.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 13. 30.  8.  0.  8.  3.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0] -> size -> 28 
adversary victory points: -8
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.  0.  8.
  0.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 26. 30. 13. 30.  8.  0.  8.  3.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0] -> size -> 28 
adversary victory points: -8
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.  0.  8.
  0.  0.  0. 11. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0  0 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 13. 30.  8.  0.  8.  2.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0] -> size -> 28 
adversary victory points: -8
player victory points: 9 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[1.2414627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 13. 30.  8.  0.  8.  2.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11.  3.] 
adversary cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.  0.  8.
  0.  0.  0. 11. 11.  0.  3.  8.  0.  0.] 
adversary owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0  0 11] -> size -> 35 
adversary victory points: 9
player victory points: -8 

Reward from previous game state: 
[  -5    0   -8 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -183 

action type: buy - action -1.0
Learning step: -8.88105297088623
desired expected reward: -13.701330184936523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-5.5752487]
 [-3.8119497]
 [-4.5057077]
 [-4.818639 ]
 [-3.2031546]
 [-3.7454517]
 [-7.170359 ]
 [-4.851516 ]
 [-5.2689023]
 [-3.178836 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 26. 30. 13. 30.  8.  0.  8.  2.  0. 10.  8.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11.  3.] 
adversary cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.  0.  8.
  0.  0.  0. 11. 11.  0.  3.  8.  0.  0.] 
adversary owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0  0 11] -> size -> 35 
adversary victory points: 9
player victory points: -8 

Reward from previous game state: 
[  -5    0   -8 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -183 

action type: take_action - action -1.0
Learning step: -9.308138847351074
desired expected reward: -8.066676139831543



buy possibilites: [-1] 
expected returns: [[-6.020466]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 1.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 26. 30. 13. 30.  8.  0.  8.  2.  0. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11.  3.] 
adversary cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.  0.  8.
  0.  0.  0. 11. 11.  0.  3.  8.  0.  0.] 
adversary owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0  0 11] -> size -> 35 
adversary victory points: 9
player victory points: -8 

Reward from previous game state: 
[  -5.     0.    -8.  -170.     0.     0.     0.     0.     0.     0.
    0.     0.     0.     0.     4.5    0. ] 
sum of rewards: -178.5 

action type: buy - action 10.0
Learning step: -8.817885398864746
desired expected reward: -13.669394493103027






Player: 1 
cards in hand: [ 0.  3.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  3.] 
cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.  0.  8.
  0.  0.  0. 11. 11.  0.  3.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0  0 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 13. 30.  8.  0.  8.  2.  0. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  6.  1.  0. 14.] 
adversary cards in discard: [10.  6.  0.  3.  0.  1.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0 10] -> size -> 29 
adversary victory points: -8
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.  0.  8.
  0.  0.  0. 11. 11.  0.  3.  8.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0  0 11  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  8.  2.  0. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  6.  1.  0. 14.] 
adversary cards in discard: [10.  6.  0.  3.  0.  1.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0 10] -> size -> 29 
adversary victory points: -8
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.  0.  8.
  0.  0.  0. 11. 11.  0.  3.  8.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0  0 11  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  8.  2.  0. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  6.  1.  0. 14.] 
adversary cards in discard: [10.  6.  0.  3.  0.  1.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0 10] -> size -> 29 
adversary victory points: -8
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 3.  8.  1.  3. 11. 29.  3. 11.  1.  0.  0. 14. 16.  3.  8. 10.  0.  8.
  0.  0.  0. 11. 11.  0.  3.  8.  0.  0.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0  0 11  1  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 12. 30.  8.  0.  8.  2.  0. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  6.  1.  0. 14.] 
adversary cards in discard: [10.  6.  0.  3.  0.  1.] 
adversary owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0 10] -> size -> 29 
adversary victory points: -8
player victory points: 10 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 8.  6.  1.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[9.94838  ]
 [6.5392857]
 [4.1923842]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  1.  0. 14.] 
cards in discard: [10.  6.  0.  3.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 12. 30.  8.  0.  8.  2.  0. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 29.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0  0 11  1  3] -> size -> 37 
adversary victory points: 10
player victory points: -8 

Reward from previous game state: 
[  -5    0   -8 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -193 

action type: buy - action -1
Learning step: -9.177419662475586
desired expected reward: -15.197885513305664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[1.8409038]
 [2.8028145]
 [2.49084  ]
 [4.0175443]
 [2.195579 ]
 [5.1164794]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  1.  0. 14.] 
cards in discard: [10.  6.  0.  3.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 25. 30. 12. 30.  8.  0.  8.  2.  0. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 29.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0  0 11  1  3] -> size -> 37 
adversary victory points: 10
player victory points: -8 

Reward from previous game state: 
[  -5    0   -8 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -193 

action type: take_action - action -1.0
Learning step: -10.067193984985352
desired expected reward: -0.11881160736083984



Player 1 won the game! 



Player 0 bought cards:
Copper: 10 
Silver: 2 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 10 

Remodel: 0 
Workshop: 2 
Chapel: 3 
Witch: 0 
Poacher: 0 
Militia: 1 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 8.  6.  1.  0. 14.] 
cards in discard: [10.  6.  0.  3.  0.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  0  6  0  0  8  6  0  0  6  6  1 11  6 14  6  8  6  6  1  0  0
  3  0  6  0 10  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 25. 30. 12. 30.  8.  0.  8.  2.  0. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 29.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11  8  3  3  8  3  3  8 29 16  0  1  0  0  3  0 11  0 11  0 10  3  3  8
  0  0  3  1 14  0  3 11  0  0 11  1  3] -> size -> 37 
adversary victory points: 10
player victory points: -8 

Reward from previous game state: 
[  -5 -500   -8 -180    0    0    0  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -723 

action type: buy - action 0.0
Learning step: -36.24204635620117
desired expected reward: -34.40114212036133



