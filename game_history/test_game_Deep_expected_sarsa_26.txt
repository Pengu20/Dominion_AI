 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[79.36632]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -60        0        0       60        0
        0        0        0     -190        0        0        8        0] 
sum of rewards: -3000187 

action type: buy - action 8.0
Learning step: -120006.34375
desired expected reward: -120034.7109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[71.986534]
 [77.35172 ]
 [77.665634]
 [67.32245 ]
 [74.09035 ]
 [85.81337 ]
 [80.07028 ]
 [82.57096 ]
 [75.35    ]
 [80.38419 ]
 [80.755585]
 [78.826454]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 77.49752807617188



buy possibilites: [-1] 
expected returns: [[83.81099]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 8.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 85.8133773803711






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[83.53299]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.81098937988281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[76.74105 ]
 [82.183685]
 [82.49995 ]
 [71.98802 ]
 [90.75875 ]
 [84.934456]
 [85.25294 ]
 [83.67122 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 80.46266174316406



buy possibilites: [-1] 
expected returns: [[84.23282]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 90.75875854492188






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [11.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[85.150925]
 [92.48828 ]
 [92.48828 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [4. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 84.23281860351562



action possibilites: [-1] 
expected returns: [[76.94687]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [4. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 93.15863800048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[73.01547 ]
 [78.79433 ]
 [68.26217 ]
 [81.21944 ]
 [79.954865]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 30. 29.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [4. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.94686889648438



buy possibilites: [-1] 
expected returns: [[75.93431]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [4. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -59 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 81.21944427490234






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [4. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  8. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [4. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 29.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  8. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [4. 0. 0. 0. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  8. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[92.21005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  8. 11.  0.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.93431091308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 84.97035 ]
 [ 91.29607 ]
 [ 91.654816]
 [ 79.48434 ]
 [ 87.4595  ]
 [101.15931 ]
 [ 94.46644 ]
 [ 97.39897 ]
 [ 88.94281 ]
 [ 94.825195]
 [ 95.268555]
 [ 93.067505]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  8. 11.  0.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 29.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 88.83348083496094



buy possibilites: [-1] 
expected returns: [[94.26377]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  8. 11.  0.  3.  0. 11. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10  8 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -90.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: -81.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 101.1593017578125






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10  8 11] -> size -> 15 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10  8 11] -> size -> 15 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 10.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[82.44792]
 [84.03548]
 [83.71602]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10  8 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 4. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.2637710571289



action possibilites: [-1.  8. 11.] 
expected returns: [[79.52928]
 [80.81976]
 [86.8794 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10  8 11] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 4. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 80.81678009033203



action possibilites: [-1.  8.] 
expected returns: [[86.27875]
 [87.67176]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10  8 11 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 4. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: -28 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 86.66871643066406



action possibilites: [-1] 
expected returns: [[82.34]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 4. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1] -> size -> 14 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 3
Learning step: 0
desired expected reward: 79.44487762451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[78.24768 ]
 [72.961136]
 [86.15555 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 30. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 4. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1] -> size -> 14 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.33999633789062






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 4. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 4. 3.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [10. 10. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10] -> size -> 14 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 4. 3.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [10. 10. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10] -> size -> 14 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 4. 3.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [10. 10. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10] -> size -> 14 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [11.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[91.93943]
 [99.96863]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  3.] 
cards in discard: [10. 10. 11.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0] -> size -> 15 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 86.1555404663086



action possibilites: [-1] 
expected returns: [[93.13147]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [10. 10. 11.  8.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0] -> size -> 15 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 96.00642395019531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[88.76414]
 [95.57269]
 [83.14031]
 [98.43908]
 [97.02403]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [10. 10. 11.  8.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0] -> size -> 15 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.1314697265625



buy possibilites: [-1] 
expected returns: [[102.53843]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [10. 10. 11.  8.  0. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 29.  8. 10. 10.  7.  8. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0] -> size -> 15 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -89 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 98.43909454345703






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [3. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 29.  8. 10. 10.  7.  8. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8] -> size -> 16 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 30. 29.  8. 10. 10.  7.  8. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8] -> size -> 16 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 30. 29.  8. 10. 10.  7.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8] -> size -> 16 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 8. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[73.28826]
 [74.52811]
 [80.29688]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 29.  8. 10. 10.  7.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 3. 0. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8] -> size -> 16 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 102.5384292602539



action possibilites: [-1] 
expected returns: [[72.86764]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 29.  8. 10. 10.  7.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 3. 0. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8] -> size -> 16 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 77.18133544921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[68.92204 ]
 [75.12616 ]
 [75.479675]
 [63.864967]
 [84.912605]
 [78.265976]
 [78.6221  ]
 [76.87999 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 29.  8. 10. 10.  7.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 3. 0. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8] -> size -> 16 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 72.86763763427734



buy possibilites: [-1] 
expected returns: [[94.58116]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 29.  8. 10. 10.  6.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 3. 0. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8] -> size -> 16 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -51 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 84.91261291503906






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 3. 0. 1. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 29.  8. 10. 10.  6.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0. 10.] 
adversary cards in discard: [10. 11. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11] -> size -> 18 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 3. 0. 1. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 30. 29.  8. 10. 10.  6.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0. 10.] 
adversary cards in discard: [10. 11. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11] -> size -> 18 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 3. 0. 1. 0. 0. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8 1] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0. 10.] 
adversary cards in discard: [10. 11. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11] -> size -> 18 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 0. 11. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[88.23923]
 [96.11423]
 [89.94197]
 [89.94197]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0. 10.] 
cards in discard: [10. 11. 11.  8.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 4. 0. 3.] 
adversary cards in discard: [8. 3. 0. 1. 0. 0. 1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8 1] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.58116149902344



action possibilites: [-1] 
expected returns: [[84.028465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [10. 11. 11.  8.  0.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  7. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 4. 0. 3.] 
adversary cards in discard: [8. 3. 0. 1. 0. 0. 1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8 1] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 91.96076965332031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[81.25271 ]
 [87.616745]
 [76.044266]
 [90.2971  ]
 [88.96362 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [10. 11. 11.  8.  0.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  7. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 4. 0. 3.] 
adversary cards in discard: [8. 3. 0. 1. 0. 0. 1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8 1] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.0284652709961



buy possibilites: [-1] 
expected returns: [[98.4983]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [10. 11. 11.  8.  0.  0.  0. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 4. 0. 3.] 
adversary cards in discard: [8. 3. 0. 1. 0. 0. 1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8 1] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -89 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 90.29710388183594






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 0. 4. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 4. 0. 3.] 
cards in discard: [8. 3. 0. 1. 0. 0. 1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8 1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 10.  3.  3.  8.] 
adversary cards in discard: [10. 11. 11.  8.  0.  0.  0. 10.  8. 11.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8] -> size -> 20 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 0. 3.] 
cards in discard: [8. 3. 0. 1. 0. 0. 1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8 1] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 10.  3.  3.  8.] 
adversary cards in discard: [10. 11. 11.  8.  0.  0.  0. 10.  8. 11.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8] -> size -> 20 
adversary victory points: 2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 10.  3.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[74.687805]
 [81.69318 ]
 [76.1778  ]
 [75.87036 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  3.  8.] 
cards in discard: [10. 11. 11.  8.  0.  0.  0. 10.  8. 11.  0. 10.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8 1] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 98.49829864501953



action possibilites: [-1] 
expected returns: [[49.76567]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  8.] 
cards in discard: [10. 11. 11.  8.  0.  0.  0. 10.  8. 11.  0. 10.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8 1] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 76.78346252441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.480255]
 [40.34627 ]
 [50.579647]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  8.] 
cards in discard: [10. 11. 11.  8.  0.  0.  0. 10.  8. 11.  0. 10.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8 1] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.76567077636719






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8 1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 11.  8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10] -> size -> 21 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8 1] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 11.  8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10] -> size -> 21 
adversary victory points: 2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 11.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8. 10.] 
expected returns: [[77.18413 ]
 [78.907814]
 [85.13958 ]
 [78.55609 ]
 [78.907814]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8. 10.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 4. 0. 1. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8 1] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 50.57964324951172



action possibilites: [-1] 
expected returns: [[93.606674]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10.  0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 4. 0. 1. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8 1] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 81.39749145507812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[88.57405]
 [82.99367]
 [96.76869]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10.  0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 4. 0. 1. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8 1] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.60667419433594






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [8. 4. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 4. 0. 1. 0.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 4 1 0 8 1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [10. 11. 10.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10] -> size -> 22 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 0 0 1 0 8 1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [10. 11. 10.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10] -> size -> 22 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 0 0 1 0 8 1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 30. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [10. 11. 10.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10] -> size -> 22 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [0. 0. 0. 3. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 0 0 1 0 8 1 3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [10. 11. 10.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10] -> size -> 22 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 0. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[102.23858]
 [103.98394]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [10. 11. 10.  8. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3. 8. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 0 0 1 0 8 1 3] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 96.76869201660156



action possibilites: [-1. 10.] 
expected returns: [[92.633575]
 [94.37894 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [10. 11. 10.  8. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3. 8. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 0 0 1 0 8 1 3] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 98.78265380859375



action possibilites: [-1. 11.] 
expected returns: [[107.26913]
 [115.34108]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [10. 11. 10.  8. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10] -> size -> 22 
action values: 3 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3. 8. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 0 0 1 0 8 1 3] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 94.3789291381836



action possibilites: [-1.] 
expected returns: [[92.098175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11. 10.  8. 10.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  2. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3. 8. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 0 0 1 0 8 1 3] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 22 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 115.16127014160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 89.60181 ]
 [ 95.13531 ]
 [ 95.446846]
 [ 84.79852 ]
 [103.76847 ]
 [ 97.91469 ]
 [ 98.22622 ]
 [ 96.71096 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11. 10.  8. 10.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  6.  6. 10. 10. 10. 10.  2. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3. 8. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 0 0 1 0 8 1 3] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 92.09817504882812



buy possibilites: [-1] 
expected returns: [[99.44441]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11. 10.  8. 10.  0. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  5.  6. 10. 10. 10. 10.  2. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3. 8. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 0 0 1 0 8 1 3] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 103.76848602294922






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 3. 8. 1. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 0 0 1 0 8 1 3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  5.  6. 10. 10. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  3.  0.] 
adversary cards in discard: [10. 11. 10.  8. 10.  0. 10. 11. 10. 10. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11] -> size -> 24 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 3. 8. 1. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 0 0 1 0 8 1 3] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  5.  6. 10. 10. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  3.  0.] 
adversary cards in discard: [10. 11. 10.  8. 10.  0. 10. 11. 10. 10. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11] -> size -> 24 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [ 0.  0.  0.  3.  0.  3.  8.  1.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  5.  6. 10.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  3.  0.] 
adversary cards in discard: [10. 11. 10.  8. 10.  0. 10. 11. 10. 10. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11] -> size -> 24 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 0. 10. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[29.557558]
 [30.787783]
 [35.440277]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  3.  0.] 
cards in discard: [10. 11. 10.  8. 10.  0. 10. 11. 10. 10. 11.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  5.  6. 10.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 99.44441223144531



action possibilites: [-1] 
expected returns: [[6.6525493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10. 11. 10.  8. 10.  0. 10. 11. 10. 10. 11.  0.  0.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  5.  6. 10.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 33.89479064941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 1.6618361 ]
 [ 4.663545  ]
 [-0.74548936]
 [ 5.9818654 ]
 [ 5.3657613 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10. 11. 10.  8. 10.  0. 10. 11. 10. 10. 11.  0.  0.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  5.  6. 10.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.6525492668151855



buy possibilites: [-1] 
expected returns: [[-5.249416]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10. 11. 10.  8. 10.  0. 10. 11. 10. 10. 11.  0.  0.  0.  3. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  5.  5. 10.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 5.981862545013428






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  5.  5. 10.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  8. 10. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  5.  5. 10.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  8. 10. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  5.  4. 10.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  8. 10. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 0.  8. 10. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.  8.] 
expected returns: [[50.277554]
 [51.540226]
 [51.865696]
 [57.668102]
 [51.540226]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 11.  8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  5.  4. 10.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  8.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.249415874481201



action possibilites: [-1] 
expected returns: [[79.215416]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  8.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  5.  4. 10.  9. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  8.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 53.15971755981445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[76.990524]
 [72.391266]
 [83.81576 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  8.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  5.  4. 10.  9. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  8.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.21541595458984






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  8.] 
cards in discard: [8. 0. 3. 0. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  5.  4. 10.  9. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 8. 10. 10. 11. 10.] 
adversary cards in discard: [10. 11.  0.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10] -> size -> 27 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [8. 0. 3. 0. 3. 0. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  5.  4. 10.  9. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 8. 10. 10. 11. 10.] 
adversary cards in discard: [10. 11.  0.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10] -> size -> 27 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [8. 0. 3. 0. 3. 0. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 29. 29.  8. 10. 10.  5.  4. 10.  9. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 8. 10. 10. 11. 10.] 
adversary cards in discard: [10. 11.  0.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10] -> size -> 27 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [8. 0. 3. 0. 3. 0. 8. 1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  4. 10.  9. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 8. 10. 10. 11. 10.] 
adversary cards in discard: [10. 11.  0.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10] -> size -> 27 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 8. 10. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 11. 10.] 
expected returns: [[58.751083]
 [59.65483 ]
 [59.89344 ]
 [59.89344 ]
 [64.33773 ]
 [59.89344 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10. 11. 10.] 
cards in discard: [10. 11.  0.  8. 10.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  4. 10.  9. 10. 10.  0. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [ 8.  0.  3.  0.  3.  0.  8.  1. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 83.81576538085938



action possibilites: [-1] 
expected returns: [[58.285133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10. 10.] 
cards in discard: [10. 11.  0.  8. 10.  8. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  4. 10.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [ 8.  0.  3.  0.  3.  0.  8.  1. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 61.409393310546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[52.407013]
 [48.390522]
 [58.406677]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10. 10.] 
cards in discard: [10. 11.  0.  8. 10.  8. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  4. 10.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [ 8.  0.  3.  0.  3.  0.  8.  1. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.285133361816406






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [1. 3. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [ 8.  0.  3.  0.  3.  0.  8.  1. 29.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  4. 10.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 10. 11.  0. 10.] 
adversary cards in discard: [10. 11.  0.  8. 10.  8. 15. 11.  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10 15] -> size -> 28 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [ 8.  0.  3.  0.  3.  0.  8.  1. 29.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  4. 10.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 10. 11.  0. 10.] 
adversary cards in discard: [10. 11.  0.  8. 10.  8. 15. 11.  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10 15] -> size -> 28 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [ 8.  0.  3.  0.  3.  0.  8.  1. 29.  0.  0.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  4.  9.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 10. 11.  0. 10.] 
adversary cards in discard: [10. 11.  0.  8. 10.  8. 15. 11.  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10 15] -> size -> 28 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [11. 10. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 10.] 
expected returns: [[4.596597 ]
 [7.4298825]
 [5.1208835]
 [7.4298825]
 [5.1208835]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  0. 10.] 
cards in discard: [10. 11.  0.  8. 10.  8. 15. 11.  8. 10. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  4.  9.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1 25] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 58.406673431396484



action possibilites: [-1] 
expected returns: [[3.1046033]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 10.] 
cards in discard: [10. 11.  0.  8. 10.  8. 15. 11.  8. 10. 10. 10. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10 15 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  4.  9.  9. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1 25] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 7.305224895477295





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.83746624]
 [-2.9690087 ]
 [ 2.3826652 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0. 10.] 
cards in discard: [10. 11.  0.  8. 10.  8. 15. 11.  8. 10. 10. 10. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10 15 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  4.  9.  9. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1 25] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.1046032905578613






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  4.  9.  9. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 10. 10.  0.  0.] 
adversary cards in discard: [10. 11.  0.  8. 10.  8. 15. 11.  8. 10. 10. 10. 15. 11. 10. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10 15 15] -> size -> 29 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  4.  9.  9. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 10. 10.  0.  0.] 
adversary cards in discard: [10. 11.  0.  8. 10.  8. 15. 11.  8. 10. 10. 10. 15. 11. 10. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10 15 15] -> size -> 29 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1 25  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 10. 10.  0.  0.] 
adversary cards in discard: [10. 11.  0.  8. 10.  8. 15. 11.  8. 10. 10. 10. 15. 11. 10. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10 15 15] -> size -> 29 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 8. 10. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
expected returns: [[4.712394 ]
 [5.3748565]
 [5.549257 ]
 [5.549257 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.  0.  0.] 
cards in discard: [10. 11.  0.  8. 10.  8. 15. 11.  8. 10. 10. 10. 15. 11. 10. 11.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10 15 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  8.  1.  0. 29.] 
adversary cards in discard: [8. 0. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1 25  8] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 2.382664203643799



action possibilites: [-1.  8. 10. 10.] 
expected returns: [[6.426355 ]
 [7.0815587]
 [7.2514453]
 [7.2514453]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0. 10.] 
cards in discard: [10. 11.  0.  8. 10.  8. 15. 11.  8. 10. 10. 10. 15. 11. 10. 11.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10 15 15] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  8.  1.  0. 29.] 
adversary cards in discard: [8. 0. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1 25  8] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 5.549253940582275



action possibilites: [-1.  8. 10.] 
expected returns: [[3.8104482]
 [4.419891 ]
 [4.5843406]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10.  0.] 
cards in discard: [10. 11.  0.  8. 10.  8. 15. 11.  8. 10. 10. 10. 15. 11. 10. 11.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10 15 15] -> size -> 29 
action values: 3 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  8.  1.  0. 29.] 
adversary cards in discard: [8. 0. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1 25  8] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 7.251443386077881



action possibilites: [-1.  8.] 
expected returns: [[-0.5751958 ]
 [-0.02653456]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [10. 11.  0.  8. 10.  8. 15. 11.  8. 10. 10. 10. 15. 11. 10. 11.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11
 10  8 10 15 15] -> size -> 29 
action values: 4 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  8.  1.  0. 29.] 
adversary cards in discard: [8. 0. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1 25  8] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 4.584338665008545



action possibilites: [-1.] 
expected returns: [[14.2902355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10. 11.  0.  8. 10.  8. 15. 11.  8. 10. 10. 10. 15. 11. 10. 11.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10. 10.  8.] 
owned cards: [ 0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15
 15] -> size -> 25 
action values: 3 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  8.  1.  0. 29.] 
adversary cards in discard: [8. 0. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1 25  8] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 3
Learning step: 0
desired expected reward: -1.187741756439209





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 9.26972  ]
 [ 6.6963096]
 [13.112753 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 11.  0.  8. 10.  8. 15. 11.  8. 10. 10. 10. 15. 11. 10. 11.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10. 10.  8.] 
owned cards: [ 0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15
 15] -> size -> 25 
action values: 3 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  8.  1.  0. 29.] 
adversary cards in discard: [8. 0. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1 25  8] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 14.29023551940918






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  1.  0. 29.] 
cards in discard: [8. 0. 0. 0. 1. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  1  0  8  1  3 29  8  1 25  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 11. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15
 15] -> size -> 25 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.] 
cards in discard: [8. 0. 0. 0. 1. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 11. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15
 15] -> size -> 25 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.] 
cards in discard: [8. 0. 0. 0. 1. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 11. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15
 15] -> size -> 25 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [10. 11. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[47.422028]
 [48.760353]
 [53.606453]
 [53.606453]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 25.  3.] 
adversary cards in discard: [ 8.  0.  0.  0.  1.  0.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 13.112752914428711



action possibilites: [-1] 
expected returns: [[68.249794]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  3.] 
cards in discard: [15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15
 15 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  3.  0. 25.  3.] 
adversary cards in discard: [ 8.  0.  0.  0.  1.  0.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 49.86677932739258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[65.47455 ]
 [61.073547]
 [71.96355 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  3.] 
cards in discard: [15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15
 15 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  3.  0. 25.  3.] 
adversary cards in discard: [ 8.  0.  0.  0.  1.  0.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 68.24979400634766






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 25.  3.] 
cards in discard: [ 8.  0.  0.  0.  1.  0.  8.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10.  8. 10. 10.] 
adversary cards in discard: [15. 11. 10. 11.  3.  3.] 
adversary owned cards: [ 0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15
 15 15] -> size -> 26 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 25.  3.] 
cards in discard: [ 8.  0.  0.  0.  1.  0.  8.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10.  8. 10. 10.] 
adversary cards in discard: [15. 11. 10. 11.  3.  3.] 
adversary owned cards: [ 0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15
 15 15] -> size -> 26 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 10.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 10.] 
expected returns: [[82.797134]
 [84.15039 ]
 [83.86965 ]
 [84.15039 ]
 [84.15039 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 10. 10.] 
cards in discard: [15. 11. 10. 11.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15
 15 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  1.  0.  8.  3. 29.  8.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 71.96354675292969



action possibilites: [-1.  8. 10. 10.  8.] 
expected returns: [[65.61535]
 [66.55095]
 [66.79684]
 [66.79684]
 [66.55095]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 10.  8.] 
cards in discard: [15. 11. 10. 11.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15
 15 15] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  1.  0.  8.  3. 29.  8.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 79.5345458984375



action possibilites: [-1.  8. 10.  8. 11.] 
expected returns: [[59.29267 ]
 [60.205475]
 [60.444786]
 [60.205475]
 [64.849464]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  8. 11.] 
cards in discard: [15. 11. 10. 11.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15
 15 15] -> size -> 26 
action values: 3 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  1.  0.  8.  3. 29.  8.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 66.79684448242188



action possibilites: [-1.  8. 10.  8.] 
expected returns: [[45.426903]
 [46.176003]
 [46.37787 ]
 [46.176003]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  8.] 
cards in discard: [15. 11. 10. 11.  3.  3. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15
 15 15 15] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  6.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  1.  0.  8.  3. 29.  8.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0  64   0] 
sum of rewards: 59 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 64.66536712646484



action possibilites: [-1.  8.  8. 10.] 
expected returns: [[34.197884]
 [34.960445]
 [34.960445]
 [35.163162]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 10.] 
cards in discard: [15. 11. 10. 11.  3.  3. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10. 11. 10.] 
owned cards: [ 0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15
 15 15 15] -> size -> 27 
action values: 3 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  6.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  1.  0.  8.  3. 29.  8.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 46.37787628173828



action possibilites: [-1.  8.  8.  8.] 
expected returns: [[41.86392 ]
 [42.680786]
 [42.680786]
 [42.680786]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 8.] 
cards in discard: [15. 11. 10. 11.  3.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10. 11. 10. 10.] 
owned cards: [ 0  0  3  3 11 11 10  8 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15
 15 15 15] -> size -> 27 
action values: 4 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  6.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  1.  0.  8.  3. 29.  8.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 35.16315841674805



action possibilites: [-1.  8.] 
expected returns: [[80.06955 ]
 [81.012695]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [15. 11. 10. 11.  3.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10. 11. 10. 10.  8.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15] -> size -> 25 
action values: 3 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  6.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  1.  0.  8.  3. 29.  8.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 55 

action type: trash_cards_n_from_hand - action 3
Learning step: 0
desired expected reward: 42.262081146240234



action possibilites: [-1.] 
expected returns: [[87.31116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15. 11. 10. 11.  3.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10. 11. 10. 10.  8.  8.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  6.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  1.  0.  8.  3. 29.  8.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 75 

action type: take_action - action 8.0
Learning step: 0
desired expected reward: 81.0126953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[81.05871]
 [77.12598]
 [87.0573 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15. 11. 10. 11.  3.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10. 11. 10. 10.  8.  8.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15] -> size -> 25 
action values: 2 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  6.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  1.  0.  8.  3. 29.  8.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 87.3111572265625






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [ 8.  0.  0.  0.  1.  0.  8.  3. 29.  8.  3.  0. 25.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10. 10. 11. 15.] 
adversary cards in discard: [15. 11. 10. 11.  3.  3. 15. 10. 10. 11. 10. 10.  8.  8.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15] -> size -> 25 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [ 8.  0.  0.  0.  1.  0.  8.  3. 29.  8.  3.  0. 25.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  9.  9. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10. 10. 11. 15.] 
adversary cards in discard: [15. 11. 10. 11.  3.  3. 15. 10. 10. 11. 10. 10.  8.  8.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15] -> size -> 25 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [ 8.  0.  0.  0.  1.  0.  8.  3. 29.  8.  3.  0. 25.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10. 10. 11. 15.] 
adversary cards in discard: [15. 11. 10. 11.  3.  3. 15. 10. 10. 11. 10. 10.  8.  8.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15] -> size -> 25 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [10. 10. 10. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 11. 15.] 
expected returns: [[10.071602]
 [10.591703]
 [10.591703]
 [10.591703]
 [12.731741]
 [10.749796]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 11. 15.] 
cards in discard: [15. 11. 10. 11.  3.  3. 15. 10. 10. 11. 10. 10.  8.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9. 10. 10.  0. 10.  6.] 
adversary cards in hand: [1. 0. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 87.05729675292969



action possibilites: [-1] 
expected returns: [[9.933189]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 15.] 
cards in discard: [15. 11. 10. 11.  3.  3. 15. 10. 10. 11. 10. 10.  8.  8. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9. 10. 10.  0. 10.  5.] 
adversary cards in hand: [1. 0. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 12.620294570922852





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[5.872805 ]
 [3.5067172]
 [9.475739 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10. 15.] 
cards in discard: [15. 11. 10. 11.  3.  3. 15. 10. 10. 11. 10. 10.  8.  8. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9. 10. 10.  0. 10.  5.] 
adversary cards in hand: [1. 0. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.933189392089844






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [1. 0. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 3. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9. 10. 10.  0. 10.  5.] 
adversary cards in hand: [10.  8. 10. 11.  0.] 
adversary cards in discard: [15. 11. 10. 11.  3.  3. 15. 10. 10. 11. 10. 10.  8.  8. 15. 11. 10. 10.
 10. 15.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15] -> size -> 26 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9. 10. 10.  0. 10.  5.] 
adversary cards in hand: [10.  8. 10. 11.  0.] 
adversary cards in discard: [15. 11. 10. 11.  3.  3. 15. 10. 10. 11. 10. 10.  8.  8. 15. 11. 10. 10.
 10. 15.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15] -> size -> 26 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 3.] 
cards in discard: [14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9.  9. 10.  0. 10.  5.] 
adversary cards in hand: [10.  8. 10. 11.  0.] 
adversary cards in discard: [15. 11. 10. 11.  3.  3. 15. 10. 10. 11. 10. 10.  8.  8. 15. 11. 10. 10.
 10. 15.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15] -> size -> 26 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [10.  8. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 11.] 
expected returns: [[25.358942]
 [26.555656]
 [26.309427]
 [26.555656]
 [31.033148]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10. 11.  0.] 
cards in discard: [15. 11. 10. 11.  3.  3. 15. 10. 10. 11. 10. 10.  8.  8. 15. 11. 10. 10.
 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9.  9. 10.  0. 10.  5.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [14.  1.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 9.47574234008789



action possibilites: [-1] 
expected returns: [[20.683485]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10.  0.] 
cards in discard: [15. 11. 10. 11.  3.  3. 15. 10. 10. 11. 10. 10.  8.  8. 15. 11. 10. 10.
 10. 15. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9.  9. 10.  0. 10.  4.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [14.  1.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 30.7745418548584





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.50111 ]
 [11.317629]
 [19.363106]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10.  0.] 
cards in discard: [15. 11. 10. 11.  3.  3. 15. 10. 10. 11. 10. 10.  8.  8. 15. 11. 10. 10.
 10. 15. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9.  9. 10.  0. 10.  4.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [14.  1.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.68348503112793






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [25.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [14.  1.  0.  1.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 11. 11. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15] -> size -> 27 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [14.  1.  0.  1.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 11. 11. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15] -> size -> 27 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [14.  1.  0.  1.  3.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 11. 11. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15] -> size -> 27 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11. 11. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10. 15.] 
expected returns: [[77.43351 ]
 [83.952614]
 [83.952614]
 [78.80971 ]
 [79.17053 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 10. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29.  8. 25.  8.] 
adversary cards in discard: [14.  1.  0.  1.  3.  3.  0. 25.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0] -> size -> 22 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 19.363100051879883



action possibilites: [-1] 
expected returns: [[103.25093]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 15.] 
cards in discard: [15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0. 29.  8. 25.  8.] 
adversary cards in discard: [14.  1.  0.  1.  3.  3.  0. 25.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0] -> size -> 22 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 78.67315673828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 98.672646]
 [ 94.13919 ]
 [105.44035 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10. 15.] 
cards in discard: [15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0. 29.  8. 25.  8.] 
adversary cards in discard: [14.  1.  0.  1.  3.  3.  0. 25.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0] -> size -> 22 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 103.25093078613281






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  8. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 25.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8. 25.  8.] 
cards in discard: [14.  1.  0.  1.  3.  3.  0. 25.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10. 11.  3. 10. 10.] 
adversary cards in discard: [15. 11.  0. 11. 10. 15.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 25.  8.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  8.  3.] 
cards in discard: [14.  1.  0.  1.  3.  3.  0. 25.  0.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 29.  8. 10. 10.  5.  3.  8.  9.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10. 11.  3. 10. 10.] 
adversary cards in discard: [15. 11.  0. 11. 10. 15.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [14.  1.  0.  1.  3.  3.  0. 25.  0.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10. 11.  3. 10. 10.] 
adversary cards in discard: [15. 11.  0. 11. 10. 15.  6.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6] -> size -> 29 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [14.  1.  0.  1.  3.  3.  0. 25.  0.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10. 11.  3. 10. 10.] 
adversary cards in discard: [15. 11.  0. 11. 10. 15.  6.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6] -> size -> 29 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [10. 11.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 10.] 
expected returns: [[23.676214]
 [24.444921]
 [27.791082]
 [24.444921]
 [24.444921]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3. 10. 10.] 
cards in discard: [15. 11.  0. 11. 10. 15.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  3.] 
adversary cards in hand: [29.  3.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5    0    0  -90    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -395 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 105.44034576416016



action possibilites: [-1] 
expected returns: [[15.668802]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 10.] 
cards in discard: [15. 11.  0. 11. 10. 15.  6. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [29.  3.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: -11 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 27.36661720275879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[11.838362]
 [ 9.730867]
 [15.294952]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10. 10.] 
cards in discard: [15. 11.  0. 11. 10. 15.  6. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [29.  3.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.668802261352539






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [29.  3.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [ 8.  8. 10. 15.  8.] 
adversary cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15] -> size -> 30 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [ 8.  8. 10. 15.  8.] 
adversary cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15] -> size -> 30 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  8.  0.  8.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [ 8.  8. 10. 15.  8.] 
adversary cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15] -> size -> 30 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 8.  8. 10. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10. 15.  8.] 
expected returns: [[6.064572 ]
 [6.5100064]
 [6.5100064]
 [6.6306806]
 [6.801225 ]
 [6.5100064]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10. 15.  8.] 
cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  3.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0] -> size -> 23 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 15.294946670532227



action possibilites: [-1] 
expected returns: [[3.6738353]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.  8.] 
cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  3.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0] -> size -> 23 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 6.801224231719971





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 0.36320066]
 [-1.5416942 ]
 [ 3.332891  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 10.  8.] 
cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  3.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0] -> size -> 23 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.673835277557373






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 29.  3.  8.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [15.  3. 10. 10. 15.] 
adversary cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10. 15.  8.  8. 10.  8.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15] -> size -> 30 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 29.  3.  8.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 27. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [15.  3. 10. 10. 15.] 
adversary cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10. 15.  8.  8. 10.  8.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15] -> size -> 30 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 29.  3.  8.  0.  8.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [15.  3. 10. 10. 15.] 
adversary cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10. 15.  8.  8. 10.  8.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15] -> size -> 30 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [15.  3. 10. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10. 15.] 
expected returns: [[5.699064 ]
 [6.6749616]
 [6.4657903]
 [6.4657903]
 [6.6749616]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 10. 10. 15.] 
cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10. 15.  8.  8. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [ 8. 14. 25. 25.  0.] 
adversary cards in discard: [ 0. 29.  3.  8.  0.  8.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1] -> size -> 24 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 3.3328938484191895



action possibilites: [-1] 
expected returns: [[-4.5342736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 15.] 
cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10. 15.  8.  8. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [ 8. 14. 25. 25.  0.] 
adversary cards in discard: [ 0. 29.  3.  8.  0.  8.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1] -> size -> 24 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 6.674964427947998





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-7.4474916]
 [-9.218215 ]
 [-4.772251 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10. 15.] 
cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10. 15.  8.  8. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 26. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [ 8. 14. 25. 25.  0.] 
adversary cards in discard: [ 0. 29.  3.  8.  0.  8.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1] -> size -> 24 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -4.534273624420166






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 8. 14. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 25. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 25. 25.  0.] 
cards in discard: [ 0. 29.  3.  8.  0.  8.  1.  0.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 29.  8.  9. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [15. 11. 15. 10. 10.] 
adversary cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10. 15.  8.  8. 10.  8.
 15.  3. 10. 10. 15.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15] -> size -> 30 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 25.  0.  0.  3.] 
cards in discard: [ 0. 29.  3.  8.  0.  8.  1.  0.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 29.  8.  8. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [15. 11. 15. 10. 10.] 
adversary cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10. 15.  8.  8. 10.  8.
 15.  3. 10. 10. 15.  6.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6] -> size -> 31 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14. 25.  0.  0.  3.] 
cards in discard: [ 0. 29.  3.  8.  0.  8.  1.  0.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 29. 29.  8.  8. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [15. 11. 15. 10. 10.] 
adversary cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10. 15.  8.  8. 10.  8.
 15.  3. 10. 10. 15.  6.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6] -> size -> 31 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14. 25.  0.  0.  3.] 
cards in discard: [ 0. 29.  3.  8.  0.  8.  1.  0.  0.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 29. 29.  8.  8. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [15. 11. 15. 10. 10.] 
adversary cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10. 15.  8.  8. 10.  8.
 15.  3. 10. 10. 15.  6.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6] -> size -> 31 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [15. 11. 15. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 15. 10. 10.] 
expected returns: [[-8.58151  ]
 [-7.978353 ]
 [-6.1888814]
 [-7.978353 ]
 [-8.117693 ]
 [-8.117693 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 15. 10. 10.] 
cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10. 15.  8.  8. 10.  8.
 15.  3. 10. 10. 15.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  8. 10.  5.  3.  8.  9.  9. 10.  0. 10.  2.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [ 0. 29.  3.  8.  0.  8.  1.  0.  0.  0.  0.  0.  0. 25.  8. 14. 25.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0] -> size -> 25 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -425 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -4.772250652313232



action possibilites: [-1] 
expected returns: [[-12.050936]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10. 10.] 
cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10. 15.  8.  8. 10.  8.
 15.  3. 10. 10. 15.  6. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  8. 10.  5.  3.  8.  9.  9. 10.  0. 10.  1.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [ 0. 29.  3.  8.  0.  8.  1.  0.  0.  0.  0.  0.  0. 25.  8. 14. 25.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0] -> size -> 25 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -41 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -6.293967247009277





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-14.176704]
 [-15.534998]
 [-12.154177]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 10. 10.] 
cards in discard: [15. 11.  0. 11. 10. 15.  6. 15. 11. 10.  3. 10. 10. 15.  8.  8. 10.  8.
 15.  3. 10. 10. 15.  6. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  8. 10.  5.  3.  8.  9.  9. 10.  0. 10.  1.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [ 0. 29.  3.  8.  0.  8.  1.  0.  0.  0.  0.  0.  0. 25.  8. 14. 25.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0] -> size -> 25 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -12.050935745239258






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [1. 3. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [ 0. 29.  3.  8.  0.  8.  1.  0.  0.  0.  0.  0.  0. 25.  8. 14. 25.  0.
  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  8. 10.  5.  3.  8.  9.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 11. 15. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15] -> size -> 32 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [ 0. 29.  3.  8.  0.  8.  1.  0.  0.  0.  0.  0.  0. 25.  8. 14. 25.  0.
  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 29. 29.  8.  8. 10.  5.  3.  8.  9.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 11. 15. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15] -> size -> 32 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [ 0. 29.  3.  8.  0.  8.  1.  0.  0.  0.  0.  0.  0. 25.  8. 14. 25.  0.
  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 29. 29.  8.  8. 10.  4.  3.  8.  9.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 11. 15. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15] -> size -> 32 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [11. 11. 15. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15. 10. 11.] 
expected returns: [[46.29665 ]
 [51.458527]
 [51.458527]
 [47.64015 ]
 [47.342236]
 [51.458527]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15. 10. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  8. 10.  4.  3.  8.  9.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  0. 25.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -12.154176712036133



action possibilites: [-1] 
expected returns: [[37.27999]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 10. 11.] 
cards in discard: [15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  8. 10.  4.  3.  8.  9.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 0.  0. 25.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -41 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 50.89686965942383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.05124 ]
 [30.336191]
 [37.19253 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15. 10. 11.] 
cards in discard: [15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  8. 10.  4.  3.  8.  9.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 0.  0. 25.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.279991149902344






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 25.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  1.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  8. 10.  4.  3.  8.  9.  9. 10.  0. 10.  0.] 
adversary cards in hand: [15. 10.  8. 10. 15.] 
adversary cards in discard: [15. 11. 11. 15. 10. 11.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15 15] -> size -> 33 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  4.  3.  8.  9.  9. 10.  0. 10.  0.] 
adversary cards in hand: [15. 10.  8. 10. 15.] 
adversary cards in discard: [15. 11. 11. 15. 10. 11.  6.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15 15  6] -> size -> 34 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  4.  3.  8.  9.  9. 10.  0. 10.  0.] 
adversary cards in hand: [15. 10.  8. 10. 15.] 
adversary cards in discard: [15. 11. 11. 15. 10. 11.  6.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15 15  6] -> size -> 34 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0. 8.] 
cards in discard: [14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  4.  3.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [15. 10.  8. 10. 15.] 
adversary cards in discard: [15. 11. 11. 15. 10. 11.  6.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15 15  6] -> size -> 34 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [15. 10.  8. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8. 10. 15.] 
expected returns: [[5.8074946]
 [6.613664 ]
 [6.4284263]
 [6.296351 ]
 [6.4284263]
 [6.613664 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  8. 10. 15.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15 15  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  4.  3.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [14. 25.  0.  0.  1.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14] -> size -> 27 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -455 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.192535400390625



action possibilites: [-1] 
expected returns: [[13.139004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10. 15.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15 15  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  4.  3.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [14. 25.  0.  0.  1.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14] -> size -> 27 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 6.613659381866455





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 9.023125]
 [ 6.609937]
 [12.692038]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10. 15.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15 15  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  4.  3.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [14. 25.  0.  0.  1.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14] -> size -> 27 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.13900375366211






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [14. 25.  0.  0.  1.  3.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  4.  3.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [10. 10.  6.  3.  8.] 
adversary cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15 15  6] -> size -> 34 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [14. 25.  0.  0.  1.  3.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  4.  3.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [10. 10.  6.  3.  8.] 
adversary cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15 15  6] -> size -> 34 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [14. 25.  0.  0.  1.  3.  0.  8. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  3.  3.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [10. 10.  6.  3.  8.] 
adversary cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15.] 
adversary owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15 15  6] -> size -> 34 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [10. 10.  6.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[11.296129]
 [11.997608]
 [11.997608]
 [11.842018]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  6.  3.  8.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15 15  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  3.  3.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 8.  0.  8. 11.  0.] 
adversary cards in discard: [14. 25.  0.  0.  1.  3.  0.  8. 11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11] -> size -> 28 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 12.692041397094727



action possibilites: [-1. 10.  8.] 
expected returns: [[6.154858]
 [6.770777]
 [6.640741]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  3.  8.  0.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15 15  6] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  3.  3.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 8.  0.  8. 11.  0.] 
adversary cards in discard: [14. 25.  0.  0.  1.  3.  0.  8. 11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11] -> size -> 28 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 11.997611999511719



action possibilites: [-1.  8. 15.] 
expected returns: [[ 9.651625]
 [10.251217]
 [10.627878]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  8.  0. 15.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15
 15 15 15 15  6 15  6 15 15  6] -> size -> 34 
action values: 3 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  3.  3.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 8.  0.  8. 11.  0.] 
adversary cards in discard: [14. 25.  0.  0.  1.  3.  0.  8. 11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11] -> size -> 28 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 6.770779132843018



action possibilites: [-1.  8.] 
expected returns: [[17.370062]
 [18.01861 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 10. 15.] 
owned cards: [ 3  3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15
 15 15 15  6 15  6 15 15  6] -> size -> 33 
action values: 2 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  3.  3.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 8.  0.  8. 11.  0.] 
adversary cards in discard: [14. 25.  0.  0.  1.  3.  0.  8. 11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11] -> size -> 28 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 10.627878189086914



action possibilites: [-1.] 
expected returns: [[15.50135]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 10. 15.  8.] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  3.  3.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 8.  0.  8. 11.  0.] 
adversary cards in discard: [14. 25.  0.  0.  1.  3.  0.  8. 11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   80    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 16.595386505126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[10.644976]
 [13.444479]
 [13.59688 ]
 [ 8.228691]
 [18.02754 ]
 [14.88625 ]
 [14.307592]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 10. 15.  8.] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6] -> size -> 32 
action values: 1 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  3.  3.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 8.  0.  8. 11.  0.] 
adversary cards in discard: [14. 25.  0.  0.  1.  3.  0.  8. 11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   80    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 15.501350402832031



buy possibilites: [-1] 
expected returns: [[8.273384]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 10. 15.  8.] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  2.  3.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 8.  0.  8. 11.  0.] 
adversary cards in discard: [14. 25.  0.  0.  1.  3.  0.  8. 11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   80    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -51 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 18.02754020690918






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 11.  0.] 
cards in discard: [14. 25.  0.  0.  1.  3.  0.  8. 11.  0.  3.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  2.  3.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [15.  8.  3.  6. 10.] 
adversary cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11] -> size -> 33 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0.] 
cards in discard: [14. 25.  0.  0.  1.  3.  0.  8. 11.  0.  3.  0.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  3.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [15.  8.  3.  6. 10.] 
adversary cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11] -> size -> 33 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 0.] 
cards in discard: [14. 25.  0.  0.  1.  3.  0.  8. 11.  0.  3.  0.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  3.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [15.  8.  3.  6. 10.] 
adversary cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11] -> size -> 33 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 0.] 
cards in discard: [14. 25.  0.  0.  1.  3.  0.  8. 11.  0.  3.  0.  0.  0. 11.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  2.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [15.  8.  3.  6. 10.] 
adversary cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11] -> size -> 33 
adversary victory points: -2
player victory points: 4 





Player: 0 
cards in hand: [15.  8.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.] 
expected returns: [[-1.2779856 ]
 [-0.61317444]
 [-0.8719511 ]
 [-0.76360655]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  3.  6. 10.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  2.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [29.  3. 14.  1. 25.] 
adversary cards in discard: [14. 25.  0.  0.  1.  3.  0.  8. 11.  0.  3.  0.  0.  0. 11.  8. 11.  8.
  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.273384094238281



action possibilites: [-1] 
expected returns: [[-1.1205049]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  6. 10.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  2.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [29.  3. 14.  1. 25.] 
adversary cards in discard: [14. 25.  0.  0.  1.  3.  0.  8. 11.  0.  3.  0.  0.  0. 11.  8. 11.  8.
  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -0.6131725311279297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-3.703585 ]
 [-5.186959 ]
 [-1.2586718]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  6. 10.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  2.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [29.  3. 14.  1. 25.] 
adversary cards in discard: [14. 25.  0.  0.  1.  3.  0.  8. 11.  0.  3.  0.  0.  0. 11.  8. 11.  8.
  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.1205048561096191






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [29.  3. 14.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 14.  1. 25.] 
cards in discard: [14. 25.  0.  0.  1.  3.  0.  8. 11.  0.  3.  0.  0.  0. 11.  8. 11.  8.
  0.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  2.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [11. 10. 10. 15. 15.] 
adversary cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.
 15.  8.  3.  6. 10.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11] -> size -> 33 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 14.  1. 25.] 
cards in discard: [14. 25.  0.  0.  1.  3.  0.  8. 11.  0.  3.  0.  0.  0. 11.  8. 11.  8.
  0.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  2.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [11. 10. 10. 15. 15.] 
adversary cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.
 15.  8.  3.  6. 10.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11] -> size -> 33 
adversary victory points: -2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 10. 10. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 15. 15.] 
expected returns: [[-8.110519]
 [-6.031682]
 [-7.706752]
 [-7.706752]
 [-7.583318]
 [-7.583318]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 15. 15.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.
 15.  8.  3.  6. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  2.  8.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [1. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -1.258669137954712



action possibilites: [-1] 
expected returns: [[-9.094786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 15. 15.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.
 15.  8.  3.  6. 10. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  2.  8.  9.  7. 10.  0. 10.  0.] 
adversary cards in hand: [1. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -101 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: -7.793551445007324





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-11.506018]
 [-12.869108]
 [ -9.260164]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 15. 15.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.
 15.  8.  3.  6. 10. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  2.  8.  9.  7. 10.  0. 10.  0.] 
adversary cards in hand: [1. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.094785690307617






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [1. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  2.  8.  9.  7. 10.  0. 10.  0.] 
adversary cards in hand: [15. 10. 10. 11. 15.] 
adversary cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.
 15.  8.  3.  6. 10. 14. 11. 10. 10. 15. 15.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14] -> size -> 34 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  2.  8.  9.  7. 10.  0. 10.  0.] 
adversary cards in hand: [15. 10. 10. 11. 15.] 
adversary cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.
 15.  8.  3.  6. 10. 14. 11. 10. 10. 15. 15.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14] -> size -> 34 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0. 3.] 
cards in discard: [8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  1.  8.  9.  7. 10.  0. 10.  0.] 
adversary cards in hand: [15. 10. 10. 11. 15.] 
adversary cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.
 15.  8.  3.  6. 10. 14. 11. 10. 10. 15. 15.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14] -> size -> 34 
adversary victory points: -2
player victory points: 4 





Player: 0 
cards in hand: [15. 10. 10. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10. 11. 15.] 
expected returns: [[-8.143034 ]
 [-7.636134 ]
 [-7.761771 ]
 [-7.761771 ]
 [-6.0766907]
 [-7.636134 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10. 11. 15.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.
 15.  8.  3.  6. 10. 14. 11. 10. 10. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  1.  8.  9.  7. 10.  0. 10.  0.] 
adversary cards in hand: [ 0. 11. 25.  8.  0.] 
adversary cards in discard: [8. 1. 0. 1. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8  8] -> size -> 31 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -9.260164260864258



action possibilites: [-1] 
expected returns: [[-13.234383]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10. 15.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.
 15.  8.  3.  6. 10. 14. 11. 10. 10. 15. 15. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  1.  8.  9.  6. 10.  0. 10.  0.] 
adversary cards in hand: [ 0. 11. 25.  8.  0.] 
adversary cards in discard: [8. 1. 0. 1. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8  8] -> size -> 31 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -101 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: -7.845125198364258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-14.844799]
 [-15.87376 ]
 [-13.292913]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 10. 15.] 
cards in discard: [15. 11. 11. 15. 10. 11.  6. 15. 10.  8. 10. 15. 11. 10. 10. 15.  8.  6.
 15.  8.  3.  6. 10. 14. 11. 10. 10. 15. 15. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  1.  8.  9.  6. 10.  0. 10.  0.] 
adversary cards in hand: [ 0. 11. 25.  8.  0.] 
adversary cards in discard: [8. 1. 0. 1. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8  8] -> size -> 31 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -13.234382629394531






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 25.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25.  8.  0.] 
cards in discard: [8. 1. 0. 1. 0. 3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  7. 10.  1.  1.  8.  9.  6. 10.  0. 10.  0.] 
adversary cards in hand: [15. 11. 15.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14] -> size -> 35 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  0.  0. 25.] 
cards in discard: [8. 1. 0. 1. 0. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  6. 10.  0. 10.  0.] 
adversary cards in hand: [15. 11. 15.  8. 14.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6] -> size -> 36 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.  0.  0. 25.] 
cards in discard: [8. 1. 0. 1. 0. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  6. 10.  0. 10.  0.] 
adversary cards in hand: [15. 11. 15.  8. 14.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6] -> size -> 36 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.  0.  0. 25.] 
cards in discard: [8. 1. 0. 1. 0. 3. 1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8  8  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  6. 10.  0. 10.  0.] 
adversary cards in hand: [15. 11. 15.  8. 14.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6] -> size -> 36 
adversary victory points: -2
player victory points: 4 





Player: 0 
cards in hand: [15. 11. 15.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 15.  8. 14.] 
expected returns: [[10.523552]
 [11.17205 ]
 [13.089371]
 [11.17205 ]
 [10.912037]
 [ 9.098204]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 15.  8. 14.] 
cards in discard: [6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  6. 10.  0. 10.  0.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8  8  1] -> size -> 32 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0  -10    0 -300
    0    0] 
sum of rewards: -525 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -13.292911529541016



action possibilites: [-1] 
expected returns: [[19.351755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  8. 14.] 
cards in discard: [ 6. 14.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  5. 10.  0. 10.  0.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8  8  1] -> size -> 32 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0  -20    0    0
   64    0] 
sum of rewards: -151 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 10.91203498840332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.370113]
 [14.538612]
 [19.118822]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  8. 14.] 
cards in discard: [ 6. 14.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6 14] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  5. 10.  0. 10.  0.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8  8  1] -> size -> 32 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.351755142211914






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1
  0 11 14 11 11  8  8  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  5. 10.  0. 10.  0.] 
adversary cards in hand: [ 3. 15. 10.  6. 15.] 
adversary cards in discard: [ 6. 14. 11. 15. 15.  8. 14.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6 14] -> size -> 37 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1  0 11
 14 11 11  8  8  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  5. 10.  0. 10.  0.] 
adversary cards in hand: [ 3. 15. 10.  6. 15.] 
adversary cards in discard: [ 6. 14. 11. 15. 15.  8. 14.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6 14] -> size -> 37 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1  0 11
 14 11 11  8  8  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  5. 10.  0. 10.  0.] 
adversary cards in hand: [ 3. 15. 10.  6. 15.] 
adversary cards in discard: [ 6. 14. 11. 15. 15.  8. 14.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6 14] -> size -> 37 
adversary victory points: -3
player victory points: 3 





Player: 0 
cards in hand: [ 3. 15. 10.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 15.] 
expected returns: [[-1.8100405]
 [-1.1066251]
 [-1.2667651]
 [-1.1066251]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10.  6. 15.] 
cards in discard: [ 6. 14. 11. 15. 15.  8. 14.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6 14] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  5. 10.  0. 10.  0.] 
adversary cards in hand: [11.  8.  1.  0.  0.] 
adversary cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1  0 11
 14 11 11  8  8  1] -> size -> 30 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 19.118818283081055



action possibilites: [-1] 
expected returns: [[10.801561]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6. 15.] 
cards in discard: [ 6. 14. 11. 15. 15.  8. 14.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  5. 10.  0. 10.  0.] 
adversary cards in hand: [11.  8.  1.  0.  0.] 
adversary cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1  0 11
 14 11 11  8  8  1] -> size -> 30 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -1.1066253185272217





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 7.454887 ]
 [ 5.4330955]
 [10.489769 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6. 15.] 
cards in discard: [ 6. 14. 11. 15. 15.  8. 14.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6 14] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  5. 10.  0. 10.  0.] 
adversary cards in hand: [11.  8.  1.  0.  0.] 
adversary cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1  0 11
 14 11 11  8  8  1] -> size -> 30 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.80156135559082






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [11.  8.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  1.  0.  0.] 
cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1  0 11
 14 11 11  8  8  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  5. 10.  0. 10.  0.] 
adversary cards in hand: [11.  6.  6. 10. 15.] 
adversary cards in discard: [ 6. 14. 11. 15. 15.  8. 14. 15.  3. 10.  6. 15.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6 14] -> size -> 37 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  1.  0.  0.] 
cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1  0 11
 14 11 11  8  8  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  5. 10.  0. 10.  0.] 
adversary cards in hand: [11.  6.  6. 10. 15.] 
adversary cards in discard: [ 6. 14. 11. 15. 15.  8. 14. 15.  3. 10.  6. 15.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6 14] -> size -> 37 
adversary victory points: -3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  6.  6. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15.] 
expected returns: [[-0.11301804]
 [ 3.0682626 ]
 [ 0.52072954]
 [ 0.6889868 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  6. 10. 15.] 
cards in discard: [ 6. 14. 11. 15. 15.  8. 14. 15.  3. 10.  6. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6 14] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  5. 10.  0. 10.  0.] 
adversary cards in hand: [11.  0.  8. 14. 29.] 
adversary cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.  8.  0.  3. 11.
  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1  0 11
 14 11 11  8  8  1] -> size -> 30 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 10.489776611328125



action possibilites: [-1] 
expected returns: [[2.1609998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10. 15.] 
cards in discard: [ 6. 14. 11. 15. 15.  8. 14. 15.  3. 10.  6. 15. 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6 14 14] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  4. 10.  0. 10.  0.] 
adversary cards in hand: [11.  0.  8. 14. 29.] 
adversary cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.  8.  0.  3. 11.
  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1  0 11
 14 11 11  8  8  1] -> size -> 30 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0  -30    0    0
   64    0] 
sum of rewards: -131 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 0.38941335678100586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-1.056643 ]
 [-2.8733678]
 [ 1.9868951]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 10. 15.] 
cards in discard: [ 6. 14. 11. 15. 15.  8. 14. 15.  3. 10.  6. 15. 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6 14 14] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  4. 10.  0. 10.  0.] 
adversary cards in hand: [11.  0.  8. 14. 29.] 
adversary cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.  8.  0.  3. 11.
  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1  0 11
 14 11 11  8  8  1] -> size -> 30 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.1609997749328613






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [11.  0.  8. 14. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 14. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 14. 29.] 
cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.  8.  0.  3. 11.
  8.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1  0 11
 14 11 11  8  8  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  4. 10.  0. 10.  0.] 
adversary cards in hand: [11. 14. 15. 15. 15.] 
adversary cards in discard: [ 6. 14. 11. 15. 15.  8. 14. 15.  3. 10.  6. 15. 14. 11.  6.  6. 10. 15.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6 14 14] -> size -> 38 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 29.] 
cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.  8.  0.  3. 11.
  8.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1  0 11
 14 11 11  8  8  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  4. 10.  0. 10.  0.] 
adversary cards in hand: [11. 14. 15.] 
adversary cards in discard: [ 6. 14. 11. 15. 15.  8. 14. 15.  3. 10.  6. 15. 14. 11.  6.  6. 10. 15.
 15. 15.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6 14 14] -> size -> 38 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8. 29.] 
cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.  8.  0.  3. 11.
  8.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1  0 11
 14 11 11  8  8  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  1.  1.  8.  9.  4. 10.  0. 10.  0.] 
adversary cards in hand: [11. 14. 15.] 
adversary cards in discard: [ 6. 14. 11. 15. 15.  8. 14. 15.  3. 10.  6. 15. 14. 11.  6.  6. 10. 15.
 15. 15.] 
adversary owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6 14 14] -> size -> 38 
adversary victory points: -3
player victory points: 3 


Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 4 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [11. 14. 15.] 
cards in discard: [ 6. 14. 11. 15. 15.  8. 14. 15.  3. 10.  6. 15. 14. 11.  6.  6. 10. 15.
 15. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 11 10 11 10 10  8 10 11 10  8 10 10 10 11 10  8 10 15 15 15 15 15
 15 15  6 15  6 15 15  6 11 14 14  6 14 14] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 29. 29.  8.  6. 10.  0.  1.  8.  9.  4. 10.  0. 10.  0.] 
adversary cards in hand: [11.  0.  8. 29.] 
adversary cards in discard: [ 8.  1.  0.  1.  0.  3.  1. 25.  0. 11.  8.  0.  0. 25.  8.  0.  3. 11.
  8.  1.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  0  8  1  3 29  8  1 25  8 25 14  0  0  1  0 11
 14 11 11  8  8  1 11] -> size -> 31 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[      -5 -3000000        0     -180        0        0        0        0
        0        0        0      -30        0    -1200     1119        0] 
sum of rewards: -3000296 

action type: discard_down_to_3_cards - action 3
Learning step: -120010.9765625
desired expected reward: -120032.40625



