 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[101.25515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -180        0        0       40        0
        0        0        0      -50        0        0       27        0] 
sum of rewards: -3000168 

action type: gain_card_n - action 4
Learning step: -120003.9765625
desired expected reward: -120072.5234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 82.99053 ]
 [108.2487  ]
 [ 93.893845]
 [ 51.044704]
 [ 99.78218 ]
 [111.919075]
 [100.141174]
 [122.81603 ]
 [ 66.952324]
 [ 86.330345]
 [ 90.82738 ]
 [ 99.405235]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 103.8776626586914



buy possibilites: [-1] 
expected returns: [[100.20063]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 122.81604766845703






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[103.49563]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 100.20063018798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 88.06445 ]
 [111.65815 ]
 [ 98.57672 ]
 [ 57.465313]
 [114.98772 ]
 [104.3157  ]
 [ 91.300514]
 [103.64924 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 103.11768341064453



buy possibilites: [-1] 
expected returns: [[96.759285]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 114.98772430419922






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [14.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  3.  0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0. 29.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[ 82.3429  ]
 [104.43146 ]
 [ 94.091995]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.75928497314453



action possibilites: [-1. 11.] 
expected returns: [[88.85639]
 [99.76902]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 106.10462188720703



action possibilites: [-1] 
expected returns: [[79.511986]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 107.8683090209961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[63.076046]
 [85.786316]
 [73.04058 ]
 [34.61654 ]
 [89.02905 ]
 [78.62912 ]
 [66.12325 ]
 [77.99455 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.5119857788086



buy possibilites: [-1] 
expected returns: [[75.11267]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 89.02906036376953






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [1. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [ 8. 14.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [ 8. 14.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [ 8. 14.  3.  0.  3.  0. 22.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[62.734135]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10.  9.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.1126708984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[52.089798]
 [72.386826]
 [61.188602]
 [24.87542 ]
 [65.81183 ]
 [75.366806]
 [66.08455 ]
 [84.647316]
 [38.480427]
 [54.92949 ]
 [58.73431 ]
 [65.50547 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 11. 29. 11.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10.  9.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 63.07773208618164



buy possibilites: [-1] 
expected returns: [[87.43896]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 11. 29. 11.  3.  0.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8.  9. 10.  9.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 84.64733123779297






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8.  9. 10.  9.  9. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8.  9. 10.  9.  9. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10.  8.  9. 10.  9.  9. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[81.54176]
 [92.9007 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10.  8.  9. 10.  9.  9. 10.] 
adversary cards in hand: [ 3.  3.  0. 14.  8.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 87.43895721435547



action possibilites: [-1] 
expected returns: [[64.97282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10.  8.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3.  0. 14.  8.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 105.95882415771484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[53.891056]
 [72.24619 ]
 [61.85638 ]
 [30.356247]
 [74.89341 ]
 [66.409325]
 [56.3427  ]
 [65.93156 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10.  8.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3.  0. 14.  8.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 64.97281646728516



buy possibilites: [-1] 
expected returns: [[78.043205]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  8. 10.  8.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3.  0. 14.  8.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 74.89341735839844






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 14.  8.] 
cards in discard: [8. 3. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  8. 10.  8.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29. 10.  0.  0.  3.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8.] 
cards in discard: [8. 3. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  8. 10.  8.  9. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8.] 
cards in discard: [8. 3. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  8. 10.  8.  9. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8.] 
cards in discard: [8. 3. 0. 0. 0. 0. 1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  7.  8. 10.  8.  9. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[63.79024]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 29. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  7.  8. 10.  8.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  1. 22.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 263   0] 
sum of rewards: 258 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 129.63351440429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[51.983803]
 [61.347706]
 [27.929932]
 [66.5205  ]
 [65.94451 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 29. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  7.  8. 10.  8.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  1. 22.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 63.01534652709961



buy possibilites: [-1] 
expected returns: [[61.117184]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 29. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  7.  7. 10.  8.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  1. 22.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 11 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 66.5205078125






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 3.  1. 22.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 22.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  7.  7. 10.  8.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0. 11.  3.  0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 29. 10.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 22.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  7.  7. 10.  8.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0. 11.  3.  0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 29. 10.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 22.  0.  0.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8  1 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  6.  7. 10.  8.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0. 11.  3.  0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 29. 10.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[106.87003]
 [124.62408]
 [116.0897 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  3.  0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 29. 10.  8.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  6.  7. 10.  8.  9. 10.  8.  9. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [11.  3.  1. 22.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8  1 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 61.117183685302734



action possibilites: [-1. 11. 11.] 
expected returns: [[66.08924 ]
 [75.466606]
 [75.466606]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  6.  7. 10.  8.  9. 10.  8.  9. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [11.  3.  1. 22.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8  1 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 121.22364807128906



action possibilites: [-1] 
expected returns: [[69.44164]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  6.  7. 10.  8.  9. 10.  7.  9. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [11.  3.  1. 22.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8  1 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 86.43241119384766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[59.120724]
 [78.23727 ]
 [67.39206 ]
 [35.83628 ]
 [81.08387 ]
 [71.986694]
 [61.636265]
 [71.50474 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  6.  7. 10.  8.  9. 10.  7.  9. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [11.  3.  1. 22.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8  1 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 69.44164276123047



buy possibilites: [-1] 
expected returns: [[91.873505]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  5.  7. 10.  8.  9. 10.  7.  9. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [11.  3.  1. 22.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8  1 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 81.08386993408203






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [11.  3.  1. 22.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  8 22  8  1 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  5.  7. 10.  8.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 11. 10.  3. 29.] 
adversary cards in discard: [10. 11. 29. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [11.  3.  1. 22.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  5.  7. 10.  8.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 11. 10.  3. 29.] 
adversary cards in discard: [10. 11. 29. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [11.  3.  1. 22.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  5.  7. 10.  8.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 11. 10.  3. 29.] 
adversary cards in discard: [10. 11. 29. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [11.  3.  1. 22.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  5.  7. 10.  8.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 11. 10.  3. 29.] 
adversary cards in discard: [10. 11. 29. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 11. 10.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[51.58974]
 [60.505  ]
 [41.91371]
 [68.36016]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3. 29.] 
cards in discard: [10. 11. 29. 11.  0.  3.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  5.  7. 10.  8.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0.  1. 14.  8.] 
adversary cards in discard: [11.  3.  1. 22.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 91.87350463867188



action possibilites: [-1. 11. 10.  8.] 
expected returns: [[ 98.027626]
 [106.65516 ]
 [ 88.54115 ]
 [ 98.506584]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3.  8.] 
cards in discard: [10. 11. 29. 11.  0.  3.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  5.  7. 10.  8.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0.  1. 14.  8.] 
adversary cards in discard: [11.  3.  1. 22.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 65.99079132080078



action possibilites: [-1] 
expected returns: [[105.26618]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  8.] 
cards in discard: [10. 11. 29. 11.  0.  3.  0. 11. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  5.  7. 10.  8.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  1. 14.  8.] 
adversary cards in discard: [11.  3.  1. 22.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 117.10076141357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 95.1729  ]
 [104.51754 ]
 [ 70.227684]
 [109.54097 ]
 [108.976685]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  8.] 
cards in discard: [10. 11. 29. 11.  0.  3.  0. 11. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  5.  7. 10.  8.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  1. 14.  8.] 
adversary cards in discard: [11.  3.  1. 22.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.26618194580078



buy possibilites: [-1] 
expected returns: [[94.602356]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  8.] 
cards in discard: [10. 11. 29. 11.  0.  3.  0. 11. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  5.  6. 10.  8.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  1. 14.  8.] 
adversary cards in discard: [11.  3.  1. 22.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 81 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 109.5409927368164






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 14.  8.] 
cards in discard: [11.  3.  1. 22.  0.  0.  0.  8.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  5.  6. 10.  8.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0.  3.  0. 11. 10.  8. 29. 11.  0. 10.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 14.  8.] 
cards in discard: [11.  3.  1. 22.  0.  0.  0.  8.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  5.  6. 10.  8.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0.  3.  0. 11. 10.  8. 29. 11.  0. 10.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 14.  8.] 
cards in discard: [11.  3.  1. 22.  0.  0.  0.  8.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  5.  6. 10.  8.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0.  3.  0. 11. 10.  8. 29. 11.  0. 10.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[30.769794]
 [21.424026]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [10. 11. 29. 11.  0.  3.  0. 11. 10.  8. 29. 11.  0. 10.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  5.  6. 10.  8.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 11.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.60235595703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.949308 ]
 [38.884182 ]
 [27.66872  ]
 [-3.5580893]
 [32.265434 ]
 [41.79314  ]
 [32.545094 ]
 [50.80079  ]
 [ 7.370394 ]
 [21.423481 ]
 [25.220137 ]
 [31.998028 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [10. 11. 29. 11.  0.  3.  0. 11. 10.  8. 29. 11.  0. 10.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  5.  6. 10.  8.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 11.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 29.451702117919922



buy possibilites: [-1] 
expected returns: [[54.760525]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [10. 11. 29. 11.  0.  3.  0. 11. 10.  8. 29. 11.  0. 10.  3.  8. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  5.  6. 10.  7.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 11.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 50.8007926940918






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  5.  6. 10.  7.  9. 10.  6.  9. 10.] 
adversary cards in hand: [11.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  5.  6. 10.  6.  9. 10.  6.  9. 10.] 
adversary cards in hand: [11.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  5.  6. 10.  6.  9. 10.  6.  9. 10.] 
adversary cards in hand: [11.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [29.  4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  5.  6. 10.  6.  9. 10.  6.  9. 10.] 
adversary cards in hand: [11.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29] -> size -> 23 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [11.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[68.26973]
 [78.29655]
 [87.2713 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  5.  6. 10.  6.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  8.] 
adversary cards in discard: [29.  4. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.76052474975586



action possibilites: [-1. 11. 10.] 
expected returns: [[90.12959]
 [98.44004]
 [80.82437]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  5.  6. 10.  6.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  8.] 
adversary cards in discard: [29.  4. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 84.8979263305664



action possibilites: [-1] 
expected returns: [[93.27424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  5.  6. 10.  6.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  8.] 
adversary cards in discard: [29.  4. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: -28 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 108.18250274658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 87.76647 ]
 [101.599625]
 [ 93.99297 ]
 [ 68.90898 ]
 [103.55401 ]
 [ 97.32713 ]
 [ 89.720726]
 [ 97.05204 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  5.  6. 10.  6.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  8.] 
adversary cards in discard: [29.  4. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.27423858642578



buy possibilites: [-1] 
expected returns: [[112.54561]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.] 
cards in discard: [10. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  6.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  8.] 
adversary cards in discard: [29.  4. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: -1 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 103.55399322509766






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0.  8.] 
cards in discard: [29.  4. 11.  0.  0.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  6.  9. 10.  5.  9. 10.] 
adversary cards in hand: [10.  0. 11. 29. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.  8.] 
cards in discard: [29.  4. 11.  0.  0.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  6.  9. 10.  5.  9. 10.] 
adversary cards in hand: [10.  0. 11. 29. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.  8.] 
cards in discard: [29.  4. 11.  0.  0.  1.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  6.  9. 10.  4.  9. 10.] 
adversary cards in hand: [10.  0. 11. 29. 10.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [10.  0. 11. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 10.] 
expected returns: [[61.351704]
 [51.53718 ]
 [70.52654 ]
 [78.552704]
 [51.53718 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 29. 10.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  6.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 22.  1.  3.  8.] 
adversary cards in discard: [29.  4. 11.  0.  0.  1.  0. 10.  0. 14.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 112.54560852050781



action possibilites: [-1. 10. 11. 10.] 
expected returns: [[75.05921]
 [64.03992]
 [85.1621 ]
 [64.03992]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10.  3.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  6.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 22.  1.  3.  8.] 
adversary cards in discard: [29.  4. 11.  0.  0.  1.  0. 10.  0. 14.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 75.8648910522461



action possibilites: [-1] 
expected returns: [[67.70709]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  6.  9. 10.  3.  9. 10.] 
adversary cards in hand: [ 0. 22.  1.  3.  8.] 
adversary cards in discard: [29.  4. 11.  0.  0.  1.  0. 10.  0. 14.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: -28 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 96.81831359863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[55.511303]
 [64.31818 ]
 [34.084534]
 [69.057045]
 [68.496796]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  3.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  4.  6. 10.  6.  9. 10.  3.  9. 10.] 
adversary cards in hand: [ 0. 22.  1.  3.  8.] 
adversary cards in discard: [29.  4. 11.  0.  0.  1.  0. 10.  0. 14.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 67.70709228515625



buy possibilites: [-1] 
expected returns: [[75.51565]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  3.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 10. 10.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11 10  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  6.  9. 10.  3.  9. 10.] 
adversary cards in hand: [ 0. 22.  1.  3.  8.] 
adversary cards in discard: [29.  4. 11.  0.  0.  1.  0. 10.  0. 14.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: -39 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 69.05704498291016






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0. 22.  1.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  1.  3.  8.] 
cards in discard: [29.  4. 11.  0.  0.  1.  0. 10.  0. 14.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  6.  9. 10.  3.  9. 10.] 
adversary cards in hand: [ 8.  0. 11. 11.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3. 10. 10.  8. 29. 11. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11 10  8] -> size -> 27 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  1.  3.  8.] 
cards in discard: [29.  4. 11.  0.  0.  1.  0. 10.  0. 14.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  6.  9. 10.  3.  9. 10.] 
adversary cards in hand: [ 8.  0. 11. 11.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3. 10. 10.  8. 29. 11. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11 10  8] -> size -> 27 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  1.  3.  8.] 
cards in discard: [29.  4. 11.  0.  0.  1.  0. 10.  0. 14.  0.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  6.  9. 10.  3.  9. 10.] 
adversary cards in hand: [ 8.  0. 11. 11.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3. 10. 10.  8. 29. 11. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11 10  8] -> size -> 27 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 8.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
expected returns: [[47.718296]
 [48.079044]
 [55.88542 ]
 [55.88542 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 11.  0.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 10. 10.  8. 29. 11. 10.  0. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11 10  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  6.  9. 10.  3.  9. 10.] 
adversary cards in hand: [1. 8. 4. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.5156478881836



action possibilites: [-1] 
expected returns: [[40.91598]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 10. 10.  8. 29. 11. 10.  0. 10.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11 10  8 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [1. 8. 4. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 65.44989013671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.709324]
 [37.136696]
 [ 9.047167]
 [41.117397]
 [40.75839 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  0.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 10. 10.  8. 29. 11. 10.  0. 10.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11 10  8 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  5. 10.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [1. 8. 4. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.91598129272461



buy possibilites: [-1] 
expected returns: [[28.648952]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  0.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 10. 10.  8. 29. 11. 10.  0. 10.  3. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11 10  8 10  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [1. 8. 4. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -59 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 41.11741256713867






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [1. 8. 4. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 4. 3. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [10.  8. 29.  0.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3. 10. 10.  8. 29. 11. 10.  0. 10.  3. 10.  8.
 11.  8.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11 10  8 10  8] -> size -> 29 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 4. 3. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [10.  8. 29.  0.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0.  3. 10. 10.  8. 29. 11. 10.  0. 10.  3. 10.  8.
 11.  8.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11 10  8 10  8] -> size -> 29 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  8. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
expected returns: [[17.140965]
 [ 7.610128]
 [17.574633]
 [34.08597 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29.  0.  0.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 10. 10.  8. 29. 11. 10.  0. 10.  3. 10.  8.
 11.  8.  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11 10  8 10  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [ 0.  3. 22.  0. 14.] 
adversary cards in discard: [1. 8. 4. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.64895248413086



action possibilites: [-1. 10.  8.] 
expected returns: [[13.530384]
 [ 4.483216]
 [13.994648]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0.  3.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 10. 10.  8. 29. 11. 10.  0. 10.  3. 10.  8.
 11.  8.  0. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 10 11  8 10 11 10  8 29 10
 11 10  8 10  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [ 0.  3. 22.  0. 14.] 
adversary cards in discard: [1. 8. 4. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 34.08597183227539



action possibilites: [-1] 
expected returns: [[57.03844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 10. 10.  8. 29. 11. 10.  0. 10.  3. 10.  8.
 11.  8.  0. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 29 10 11  8 10 11 10  8 29 10 11 10  8
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [ 0.  3. 22.  0. 14.] 
adversary cards in discard: [1. 8. 4. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 32.0293083190918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[44.463737]
 [51.937496]
 [25.76956 ]
 [55.947906]
 [55.5431  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 10. 10.  8. 29. 11. 10.  0. 10.  3. 10.  8.
 11.  8.  0. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 29 10 11  8 10 11 10  8 29 10 11 10  8
 10  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  4. 10.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [ 0.  3. 22.  0. 14.] 
adversary cards in discard: [1. 8. 4. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.0384407043457



buy possibilites: [-1] 
expected returns: [[50.63889]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 11. 29. 11.  0.  0.  3. 10. 10.  8. 29. 11. 10.  0. 10.  3. 10.  8.
 11.  8.  0. 11.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 29 10 11  8 10 11 10  8 29 10 11 10  8
 10  8  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [ 0.  3. 22.  0. 14.] 
adversary cards in discard: [1. 8. 4. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -69 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 55.947906494140625






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 22.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 14.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 22.  0. 14.] 
cards in discard: [1. 8. 4. 3. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [10.  0. 11. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 29 10 11  8 10 11 10  8 29 10 11 10  8
 10  8  8] -> size -> 27 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14. 11.  0.  0.] 
cards in discard: [1. 8. 4. 3. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [10.  0. 11. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 29 10 11  8 10 11 10  8 29 10 11 10  8
 10  8  8] -> size -> 27 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14. 11.  0.  0.] 
cards in discard: [1. 8. 4. 3. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  2.  9. 10.] 
adversary cards in hand: [10.  0. 11. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 29 10 11  8 10 11 10  8 29 10 11 10  8
 10  8  8] -> size -> 27 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14. 11.  0.  0.] 
cards in discard: [ 1.  8.  4.  3.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  2.  9.  9.] 
adversary cards in hand: [10.  0. 11. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 29 10 11  8 10 11 10  8 29 10 11 10  8
 10  8  8] -> size -> 27 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [10.  0. 11. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.  8.] 
expected returns: [[43.505703]
 [35.933624]
 [50.330914]
 [35.933624]
 [43.856796]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 29 10 11  8 10 11 10  8 29 10 11 10  8
 10  8  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  2.  9.  9.] 
adversary cards in hand: [ 0.  8.  0. 29.  0.] 
adversary cards in discard: [ 1.  8.  4.  3.  3. 15. 22.  0.  3.  0. 14. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15] -> size -> 22 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.63888931274414



action possibilites: [-1] 
expected returns: [[51.552242]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  8.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 29 10 11  8 10 11 10  8 29 10 11 10  8
 10  8  8 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  8.  0. 29.  0.] 
adversary cards in discard: [ 1.  8.  4.  3.  3. 15. 22.  0.  3.  0. 14. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15] -> size -> 22 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 55.134517669677734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.368137]
 [24.34257 ]
 [54.39592 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  8.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 29 10 11  8 10 11 10  8 29 10 11 10  8
 10  8  8 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  8.  0. 29.  0.] 
adversary cards in discard: [ 1.  8.  4.  3.  3. 15. 22.  0.  3.  0. 14. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15] -> size -> 22 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.552242279052734






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 29.  0.] 
cards in discard: [ 1.  8.  4.  3.  3. 15. 22.  0.  3.  0. 14. 11.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  1.  9.  9.] 
adversary cards in hand: [10.  8.  8.  0.  3.] 
adversary cards in discard: [10. 11. 10.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 29 10 11  8 10 11 10  8 29 10 11 10  8
 10  8  8 10] -> size -> 28 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 1.] 
cards in discard: [ 1.  8.  4.  3.  3. 15. 22.  0.  3.  0. 14. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  1.  9.  9.] 
adversary cards in hand: [10.  8.  8.  0.  3.] 
adversary cards in discard: [10. 11. 10.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 29 10 11  8 10 11 10  8 29 10 11 10  8
 10  8  8 10] -> size -> 28 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 1.] 
cards in discard: [ 1.  8.  4.  3.  3. 15. 22.  0.  3.  0. 14. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  1.  9.  9.] 
adversary cards in hand: [10.  8.  8.  0.  3.] 
adversary cards in discard: [10. 11. 10.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 29 10 11  8 10 11 10  8 29 10 11 10  8
 10  8  8 10] -> size -> 28 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 1.] 
cards in discard: [ 1.  8.  4.  3.  3. 15. 22.  0.  3.  0. 14. 11.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  1.  9.  9.] 
adversary cards in hand: [10.  8.  8.  0.  3.] 
adversary cards in discard: [10. 11. 10.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 29 10 11  8 10 11 10  8 29 10 11 10  8
 10  8  8 10] -> size -> 28 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [10.  8.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
expected returns: [[86.19285]
 [76.60389]
 [86.57852]
 [86.57852]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.  0.  3.] 
cards in discard: [10. 11. 10.  0. 10.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 29 10 11  8 10 11 10  8 29 10 11 10  8
 10  8  8 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 1. 11.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1] -> size -> 23 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 54.395912170410156



action possibilites: [-1] 
expected returns: [[48.904926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [10. 11. 10.  0. 10.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 1. 11.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1] -> size -> 23 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 105.07837677001953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[42.53522 ]
 [23.117764]
 [52.114185]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [10. 11. 10.  0. 10.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 1. 11.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1] -> size -> 23 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.90492630004883






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 1. 11.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  1.  9.  9.] 
adversary cards in hand: [10. 11.  0. 11. 11.] 
adversary cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10] -> size -> 26 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  1.  9.  9.] 
adversary cards in hand: [10. 11.  0. 11. 11.] 
adversary cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10] -> size -> 26 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 1.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  0.  9.  9.] 
adversary cards in hand: [10. 11.  0. 11. 11.] 
adversary cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10] -> size -> 26 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  6.  9. 10.  0.  9.  9.] 
adversary cards in hand: [10. 11.  0. 11. 11.] 
adversary cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10] -> size -> 26 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1.] 
cards in discard: [10. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [10. 11.  0. 11. 11.] 
adversary cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10] -> size -> 26 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [10. 11.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 11.] 
expected returns: [[14.045057]
 [ 6.638452]
 [21.065157]
 [21.065157]
 [21.065157]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 11. 11.] 
cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [29.  0.  0.  3. 14.] 
adversary cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 52.114173889160156



action possibilites: [-1] 
expected returns: [[61.553623]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 11.] 
cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [29.  0.  0.  3. 14.] 
adversary cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -71 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 29.24429702758789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[51.24224 ]
 [32.515427]
 [61.500477]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11. 11.] 
cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [29.  0.  0.  3. 14.] 
adversary cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.55362319946289






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [29.  0.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3. 14.] 
cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [29.  0. 11.  3.  0.] 
adversary cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15. 11. 10.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10 15] -> size -> 27 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.] 
cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [29.  0. 11.  3.  0.] 
adversary cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15. 11. 10.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10 15] -> size -> 27 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [29.  3.  0.] 
adversary cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15. 11. 10.  0. 11. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10 15] -> size -> 27 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [29.  3.  0.] 
adversary cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15. 11. 10.  0. 11. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10 15] -> size -> 27 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3. 23.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [29.  3.  0.] 
adversary cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15. 11. 10.  0. 11. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10 15] -> size -> 27 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[39.545494]
 [53.639256]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.] 
cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15. 11. 10.  0. 11. 11. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [15.  8.  0.  0.  3.] 
adversary cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3. 23. 29. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23] -> size -> 26 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
  304    0] 
sum of rewards: 149 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 40.64268112182617



action possibilites: [-1.] 
expected returns: [[58.473965]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15. 11. 10.  0. 11. 11. 11.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [15.  8.  0.  0.  3.] 
adversary cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3. 23. 29. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23] -> size -> 26 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 44.79409408569336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[47.794155]
 [55.035877]
 [26.340878]
 [59.111965]
 [58.678776]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15. 11. 10.  0. 11. 11. 11.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  3. 10.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [15.  8.  0.  0.  3.] 
adversary cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3. 23. 29. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23] -> size -> 26 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 58.47396469116211



buy possibilites: [-1] 
expected returns: [[53.30422]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15. 11. 10.  0. 11. 11. 11.  0.  8.
  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10 15  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  2. 10.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [15.  8.  0.  0.  3.] 
adversary cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3. 23. 29. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23] -> size -> 26 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -119 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 59.11195755004883






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [15.  8.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  0.  3.] 
cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3. 23. 29. 14.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  2. 10.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [ 8. 29. 10. 29. 10.] 
adversary cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15. 11. 10.  0. 11. 11. 11.  0.  8.
  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10 15  8] -> size -> 28 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.  0.  3.] 
cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3. 23. 29. 14.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 29.  8. 10. 10.  4.  2. 10.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [ 8. 29. 10. 29. 10.] 
adversary cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15. 11. 10.  0. 11. 11. 11.  0.  8.
  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10 15  8] -> size -> 28 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.  0.  3.] 
cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3. 23. 29. 14.  0.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 29.  8. 10. 10.  4.  2. 10.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [ 8. 29. 10. 29. 10.] 
adversary cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15. 11. 10.  0. 11. 11. 11.  0.  8.
  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10 15  8] -> size -> 28 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [ 8. 29. 10. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10. 29. 10.] 
expected returns: [[43.029594]
 [43.39995 ]
 [57.684494]
 [35.425304]
 [57.684494]
 [35.425304]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 10. 29. 10.] 
cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15. 11. 10.  0. 11. 11. 11.  0.  8.
  8. 29.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10 15  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 29.  8. 10. 10.  4.  2. 10.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [ 8.  1.  0.  4. 22.] 
adversary cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3. 23. 29. 14.  0.  0.  3.  3. 15.  8.
  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.30421829223633



action possibilites: [-1.  8. 10. 10.] 
expected returns: [[73.25902 ]
 [73.59451 ]
 [66.055305]
 [66.055305]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.  0.] 
cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15. 11. 10.  0. 11. 11. 11.  0.  8.
  8. 29.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 10 11 10  8 29 10 11 10  8 10  8
  8 10 15  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 29.  8. 10. 10.  4.  2. 10.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [ 8.  1.  0.  4. 22.] 
adversary cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3. 23. 29. 14.  0.  0.  3.  3. 15.  8.
  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 48.421817779541016



action possibilites: [-1] 
expected returns: [[34.170895]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15. 11. 10.  0. 11. 11. 11.  0.  8.
  8. 29.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 29.  8. 10. 10.  4.  2. 10.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [ 8.  1.  0.  4. 22.] 
adversary cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3. 23. 29. 14.  0.  0.  3.  3. 15.  8.
  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -145 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 78.89081573486328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.939049 ]
 [30.979237 ]
 [ 8.3325405]
 [34.39487  ]
 [34.0911   ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15. 11. 10.  0. 11. 11. 11.  0.  8.
  8. 29.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 28. 29.  8. 10. 10.  4.  2. 10.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [ 8.  1.  0.  4. 22.] 
adversary cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3. 23. 29. 14.  0.  0.  3.  3. 15.  8.
  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.170894622802734



buy possibilites: [-1] 
expected returns: [[53.66388]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [10. 11. 10.  0. 10.  8.  8.  8.  0. 15. 11. 10.  0. 11. 11. 11.  0.  8.
  8. 29.  3.  0. 29.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 29.  8. 10. 10.  4.  1. 10.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [ 8.  1.  0.  4. 22.] 
adversary cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3. 23. 29. 14.  0.  0.  3.  3. 15.  8.
  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -129 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 34.39487838745117






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 8.  1.  0.  4. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  0.  4. 22.] 
cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3. 23. 29. 14.  0.  0.  3.  3. 15.  8.
  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 29.  8. 10. 10.  4.  1. 10.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [11.  0.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8] -> size -> 28 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  0.  4. 22.] 
cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3. 23. 29. 14.  0.  0.  3.  3. 15.  8.
  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 28. 29.  8. 10. 10.  4.  1. 10.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [11.  0.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8] -> size -> 28 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  0.  4. 22.] 
cards in discard: [10. 29. 10. 11.  1.  0.  0.  1.  3. 23. 29. 14.  0.  0.  3.  3. 15.  8.
  0.  0.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 29.  8. 10. 10.  4.  1. 10.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [11.  0.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8] -> size -> 28 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [11.  0.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[-5.842927]
 [ 2.056251]
 [ 2.056251]
 [-5.553794]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 29.  8. 10. 10.  4.  1. 10.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [29.  1.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1] -> size -> 28 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.66387939453125



action possibilites: [-1] 
expected returns: [[10.093416]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8.] 
cards in discard: [15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 29.  8. 10. 10.  4.  1. 10.  5.  9.  9.  0.  9.  7.] 
adversary cards in hand: [29.  1.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1] -> size -> 28 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -101 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 11.42669677734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[  2.516972]
 [  7.791248]
 [-12.370764]
 [ 11.250626]
 [ 10.886023]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  8.] 
cards in discard: [15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 28. 29.  8. 10. 10.  4.  1. 10.  5.  9.  9.  0.  9.  7.] 
adversary cards in hand: [29.  1.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1] -> size -> 28 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.093416213989258



buy possibilites: [-1] 
expected returns: [[36.531925]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  8.] 
cards in discard: [15.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 29.  8. 10. 10.  4.  0. 10.  5.  9.  9.  0.  9.  7.] 
adversary cards in hand: [29.  1.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1] -> size -> 28 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -149 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 11.25063705444336






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [29.  1.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 29.  8. 10. 10.  4.  0. 10.  5.  9.  9.  0.  9.  7.] 
adversary cards in hand: [11. 29. 15. 10. 10.] 
adversary cards in discard: [15.  8. 11.  0.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8] -> size -> 30 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 26. 30. 28. 29.  8. 10. 10.  4.  0. 10.  5.  9.  9.  0.  9.  7.] 
adversary cards in hand: [11. 29. 15. 10. 10.] 
adversary cards in discard: [15.  8. 11.  0.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8] -> size -> 30 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  1.  0.  0.] 
cards in discard: [23.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 28. 29.  8. 10. 10.  4.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [11. 29. 15. 10. 10.] 
adversary cards in discard: [15.  8. 11.  0.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8] -> size -> 30 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [11. 29. 15. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 15. 10. 10.] 
expected returns: [[57.20915 ]
 [64.26597 ]
 [70.47288 ]
 [52.138947]
 [49.31926 ]
 [49.31926 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 15. 10. 10.] 
cards in discard: [15.  8. 11.  0.  0. 11.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 29.  8. 10. 10.  4.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [10.  0.  0. 22.  3.] 
adversary cards in discard: [23. 29.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23] -> size -> 29 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.531925201416016



action possibilites: [-1. 11. 15. 10.] 
expected returns: [[55.71935 ]
 [66.10746 ]
 [48.279755]
 [44.13857 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 10.] 
cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 28. 29.  8. 10. 10.  4.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [10.  0.  0. 22.  3.] 
adversary cards in discard: [23. 29.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23] -> size -> 29 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 62.1570930480957



action possibilites: [-1] 
expected returns: [[69.37843]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.] 
cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 28. 29.  8. 10. 10.  4.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [10.  0.  0. 22.  3.] 
adversary cards in discard: [23. 29.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23] -> size -> 29 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -118 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 63.01472854614258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[58.26981 ]
 [36.43111 ]
 [69.227264]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.] 
cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 25. 30. 28. 29.  8. 10. 10.  4.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [10.  0.  0. 22.  3.] 
adversary cards in discard: [23. 29.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23] -> size -> 29 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 69.37843322753906






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [10.  0.  0. 22.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 22.  3.] 
cards in discard: [23. 29.  1.  1.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 29.  8. 10. 10.  4.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [11. 10.  8.  0.  8.] 
adversary cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1] -> size -> 31 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 22.  3.] 
cards in discard: [23. 29.  1.  1.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 25. 30. 28. 29.  8. 10. 10.  4.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [11. 10.  8.  0.  8.] 
adversary cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1] -> size -> 31 
adversary victory points: 1
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 10.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.  8.] 
expected returns: [[36.1546  ]
 [43.377987]
 [28.231617]
 [36.470272]
 [36.470272]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8.  0.  8.] 
cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 29.  8. 10. 10.  4.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 0.  4. 23.  0.  1.] 
adversary cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23] -> size -> 29 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 69.2272720336914



action possibilites: [-1] 
expected returns: [[50.525158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  8.] 
cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 29.  8. 10. 10.  4.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 0.  4. 23.  0.  1.] 
adversary cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23] -> size -> 29 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -138 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 41.211124420166016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[41.397503]
 [24.347244]
 [51.104267]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  8.] 
cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 24. 30. 28. 29.  8. 10. 10.  4.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 0.  4. 23.  0.  1.] 
adversary cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23] -> size -> 29 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.5251579284668






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0.  4. 23.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4. 23.  0.  1.] 
cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 29.  8. 10. 10.  4.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [11.  0.  3.  8.  8.] 
adversary cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1] -> size -> 32 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4.  0.  1. 11.] 
cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23] -> size -> 29 
action values: 1 
buys: 1 
player value: 1 
card supply: [28. 24. 30. 28. 29.  8. 10. 10.  4.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [11.  0.  3.  8.  8.] 
adversary cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1] -> size -> 32 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 0. 1.] 
cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 24. 30. 28. 29.  8. 10. 10.  3.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [11.  0.  3.  8.  8.] 
adversary cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1] -> size -> 32 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 1.] 
cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23 11] -> size -> 30 
action values: 0 
buys: 2 
player value: 5 
card supply: [28. 24. 30. 28. 29.  8. 10. 10.  3.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [11.  0.  3.  8.  8.] 
adversary cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1] -> size -> 32 
adversary victory points: 1
player victory points: 7 


buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 1.] 
cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23 11 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 24. 30. 28. 29.  8. 10. 10.  2.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [11.  0.  3.  8.  8.] 
adversary cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1] -> size -> 32 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 1.] 
cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23 11 11  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 24. 30. 28. 29.  8. 10. 10.  2.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [11.  0.  3.  8.  8.] 
adversary cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1] -> size -> 32 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [11.  0.  3.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
expected returns: [[38.20737]
 [46.35822]
 [38.55449]
 [38.55449]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  8.  8.] 
cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 28. 29.  8. 10. 10.  2.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 8.  0.  0. 29. 15.] 
adversary cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11. 11.  0. 23. 11.  0.  4.
  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23 11 11  0] -> size -> 32 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 51.10426330566406



action possibilites: [-1] 
expected returns: [[58.387547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 8.] 
cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 28. 29.  8. 10. 10.  2.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 8.  0.  0. 29. 15.] 
adversary cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11. 11.  0. 23. 11.  0.  4.
  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23 11 11  0] -> size -> 32 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -138 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 43.90781784057617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.243145]
 [20.391678]
 [57.623302]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 8.] 
cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 23. 30. 28. 29.  8. 10. 10.  2.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 8.  0.  0. 29. 15.] 
adversary cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11. 11.  0. 23. 11.  0.  4.
  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23 11 11  0] -> size -> 32 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.38754653930664






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 29. 15.] 
cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11. 11.  0. 23. 11.  0.  4.
  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10
 29 23  3  1 23 11 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 28. 29.  8. 10. 10.  2.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [10. 29.  8.  8.  0.] 
adversary cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.  1. 11.  0.  3.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1] -> size -> 33 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.] 
cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11. 11.  0. 23. 11.  0.  4.
  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29
 23  3  1 23 11 11  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 23. 30. 28. 29.  8. 10. 10.  2.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [10. 29.  8.  8.  0.] 
adversary cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.  1. 11.  0.  3.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1] -> size -> 33 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 29.] 
cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11. 11.  0. 23. 11.  0.  4.
  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29
 23  3  1 23 11 11  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 23. 30. 28. 29.  8. 10. 10.  2.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [10. 29.  8.  8.  0.] 
adversary cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.  1. 11.  0.  3.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1] -> size -> 33 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 29.] 
cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11. 11.  0. 23. 11.  0.  4.
  0.  1. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29
 23  3  1 23 11 11  0 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 23. 30. 28. 29.  8. 10. 10.  1.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [10. 29.  8.  8.  0.] 
adversary cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.  1. 11.  0.  3.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1] -> size -> 33 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [10. 29.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.  8.] 
expected returns: [[10.376312 ]
 [ 3.7434478]
 [21.331657 ]
 [10.624935 ]
 [10.624935 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  8.  8.  0.] 
cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.  1. 11.  0.  3.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 28. 29.  8. 10. 10.  1.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [14.  3.  3.  1. 10.] 
adversary cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11. 11.  0. 23. 11.  0.  4.
  0.  1. 11. 15.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29
 23  3  1 23 11 11  0 11] -> size -> 32 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 57.62329864501953



action possibilites: [-1.  8. 29.] 
expected returns: [[21.971085]
 [22.297169]
 [36.824375]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.] 
cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.  1. 11.  0.  3.  8.  8. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 23. 30. 28. 29.  8. 10. 10.  1.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [14.  3.  3.  1. 10.] 
adversary cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11. 11.  0. 23. 11.  0.  4.
  0.  1. 11. 15.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29
 23  3  1 23 11 11  0 11] -> size -> 32 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 14.445064544677734



action possibilites: [-1.  8.] 
expected returns: [[13.943022]
 [14.28315 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.  1. 11.  0.  3.  8.  8. 10.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 23. 30. 28. 29.  8. 10. 10.  1.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [14.  3.  3.  1. 10.] 
adversary cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11. 11.  0. 23. 11.  0.  4.
  0.  1. 11. 15.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29
 23  3  1 23 11 11  0 11] -> size -> 32 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -145 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 27.450870513916016



action possibilites: [-1] 
expected returns: [[18.416563]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.  1. 11.  0.  3.  8.  8. 10.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 23. 30. 28. 29.  8. 10. 10.  1.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [14.  3.  3.  1. 10.] 
adversary cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11. 11.  0. 23. 11.  0.  4.
  0.  1. 11. 15.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29
 23  3  1 23 11 11  0 11] -> size -> 32 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action 8.0
Learning step: 0
desired expected reward: 14.283153533935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 8.80912 ]
 [14.924454]
 [-9.01119 ]
 [18.11835 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  8. 11.  0.  0. 11.  8. 10. 10.  1. 29. 11. 15. 10.  1. 11. 10.  8.
  0.  8.  1. 11.  0.  3.  8.  8. 10.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 23. 30. 28. 29.  8. 10. 10.  1.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [14.  3.  3.  1. 10.] 
adversary cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11. 11.  0. 23. 11.  0.  4.
  0.  1. 11. 15.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29
 23  3  1 23 11 11  0 11] -> size -> 32 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.416563034057617






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [14.  3.  3.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  1. 10.] 
cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11. 11.  0. 23. 11.  0.  4.
  0.  1. 11. 15.  8.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29
 23  3  1 23 11 11  0 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 28. 29.  8. 10. 10.  1.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 0. 29.  8.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1] -> size -> 33 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3.  1. 10.] 
cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11. 11.  0. 23. 11.  0.  4.
  0.  1. 11. 15.  8.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29
 23  3  1 23 11 11  0 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 23. 30. 28. 29.  8. 10. 10.  1.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 0. 29.  8.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1] -> size -> 33 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3.  1. 10.] 
cards in discard: [23. 29.  1.  1.  0.  0. 10.  0.  0. 22.  3. 11. 11.  0. 23. 11.  0.  4.
  0.  1. 11. 15.  8.  0. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29
 23  3  1 23 11 11  0 11  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 27. 29.  8. 10. 10.  1.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 0. 29.  8.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1] -> size -> 33 
adversary victory points: 1
player victory points: 8 





Player: 0 
cards in hand: [ 0. 29.  8.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
expected returns: [[-14.726944 ]
 [ -6.1462736]
 [-14.526506 ]
 [-14.526506 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  8.  1.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 27. 29.  8. 10. 10.  1.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 8. 29.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29
 23  3  1 23 11 11  0 11  3] -> size -> 33 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 18.118345260620117



action possibilites: [-1.] 
expected returns: [[-0.36293554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [8. 8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 23. 30. 27. 29.  8. 10. 10.  1.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 8. 29.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29
 23  3  1 23 11 11  0 11  3] -> size -> 33 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -11.534402847290039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ -8.357279  ]
 [  5.113609  ]
 [ -2.7360644 ]
 [-18.279772  ]
 [-24.33025   ]
 [  0.45726776]
 [  7.142586  ]
 [ 24.978113  ]
 [ 13.09458   ]
 [-16.547571  ]
 [ -4.5008736 ]
 [-16.738703  ]
 [ -4.309741  ]
 [  0.40707016]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [8. 8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 23. 30. 27. 29.  8. 10. 10.  1.  0. 10.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 8. 29.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29
 23  3  1 23 11 11  0 11  3] -> size -> 33 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.36293554306030273



buy possibilites: [-1] 
expected returns: [[43.957676]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 8.  8. 25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 27. 29.  8. 10. 10.  1.  0.  9.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 8. 29.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29
 23  3  1 23 11 11  0 11  3] -> size -> 33 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
  250    0] 
sum of rewards: 55 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 24.978113174438477






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 8. 29.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29
 23  3  1 23 11 11  0 11  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 27. 29.  8. 10. 10.  1.  0.  9.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [11. 10. 10. 15.  8.] 
adversary cards in discard: [ 8.  8. 25. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1 25] -> size -> 34 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29 23  3
  1 23 11 11  0 11  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 27. 29.  8. 10. 10.  1.  0.  9.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [11. 10. 10. 15.  8.] 
adversary cards in discard: [ 8.  8. 25. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1 25] -> size -> 34 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29 23  3
  1 23 11 11  0 11  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 23. 30. 27. 29.  8. 10. 10.  1.  0.  9.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [11. 10. 10. 15.  8.] 
adversary cards in discard: [ 8.  8. 25. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1 25] -> size -> 34 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [11. 10. 10. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 15.  8.] 
expected returns: [[56.000942]
 [62.81618 ]
 [48.344196]
 [48.344196]
 [51.075855]
 [56.296844]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 15.  8.] 
cards in discard: [ 8.  8. 25. 29.  0.  1.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 27. 29.  8. 10. 10.  1.  0.  9.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 3.  3. 29. 10.  1.] 
adversary cards in discard: [ 8. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29 23  3
  1 23 11 11  0 11  3] -> size -> 31 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.95767593383789



action possibilites: [-1] 
expected returns: [[79.281425]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 15.  8.] 
cards in discard: [ 8.  8. 25. 29.  0.  1.  0.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1 25  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 27. 29.  8. 10. 10.  1.  0.  9.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 3.  3. 29. 10.  1.] 
adversary cards in discard: [ 8. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29 23  3
  1 23 11 11  0 11  3] -> size -> 31 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -138 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 60.76668930053711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[68.38232 ]
 [47.492268]
 [79.378365]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 15.  8.] 
cards in discard: [ 8.  8. 25. 29.  0.  1.  0.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1 25  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 22. 30. 27. 29.  8. 10. 10.  1.  0.  9.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 3.  3. 29. 10.  1.] 
adversary cards in discard: [ 8. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29 23  3
  1 23 11 11  0 11  3] -> size -> 31 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.28142547607422






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 29. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29. 10.  1.] 
cards in discard: [ 8. 29.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29 23  3
  1 23 11 11  0 11  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 27. 29.  8. 10. 10.  1.  0.  9.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 8.  8. 11. 10.  8.] 
adversary cards in discard: [ 8.  8. 25. 29.  0.  1.  0.  1. 11. 10. 10. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1 25  1] -> size -> 35 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 1.] 
cards in discard: [ 8. 29.  8.  3. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29 23  3
  1 23 11 11  0 11  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 22. 30. 27. 29.  8. 10. 10.  1.  0.  9.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 8.  8. 11. 10.  8.] 
adversary cards in discard: [ 8.  8. 25. 29.  0.  1.  0.  1. 11. 10. 10. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1 25  1] -> size -> 35 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1.] 
cards in discard: [ 8. 29.  8.  3. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29 23  3
  1 23 11 11  0 11  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 22. 30. 27. 29.  8. 10. 10.  1.  0.  9.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [ 8.  8. 11. 10.  8.] 
adversary cards in discard: [ 8.  8. 25. 29.  0.  1.  0.  1. 11. 10. 10. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1 25  1] -> size -> 35 
adversary victory points: 1
player victory points: 7 


Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 8 
Witch: 1 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 8.  8. 11. 10.  8.] 
cards in discard: [ 8.  8. 25. 29.  0.  1.  0.  1. 11. 10. 10. 15.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 11 29 11  8 11 10  8 29 10 11 10  8 10  8  8
 10 15  8  8 15  8  1  1  1 25  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 27. 29.  8. 10. 10.  0.  0.  9.  5.  9.  8.  0.  9.  7.] 
adversary cards in hand: [3. 1. 1.] 
adversary cards in discard: [ 8. 29.  8.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3 14  1  8 22  8  1 11  0  3 29  4 10  0 15  1 10 29 23  3
  1 23 11 11  0 11  3 11] -> size -> 32 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[      -5 -3000000        0     -180        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000185 

action type: buy - action -1.0
Learning step: -120010.578125
desired expected reward: -119931.203125



