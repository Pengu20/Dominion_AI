 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[339.07254]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -2  -60    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -567 

action type: buy - action -1
Learning step: -31.237812042236328
desired expected reward: 26.518444061279297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[322.30377]
 [325.07703]
 [325.41052]
 [321.34396]
 [329.11288]
 [325.9762 ]
 [326.30966]
 [337.9398 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.674872398376465
desired expected reward: 330.59686279296875



buy possibilites: [-1] 
expected returns: [[324.2753]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 1.0
Learning step: -8.1576566696167
desired expected reward: 316.9193420410156






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[351.81113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.367280006408691
desired expected reward: 315.90802001953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[340.7085 ]
 [344.2349 ]
 [344.67685]
 [339.50162]
 [344.7022 ]
 [349.40042]
 [345.39267]
 [351.3813 ]
 [344.22443]
 [345.8347 ]
 [347.79022]
 [361.06638]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.847189903259277
desired expected reward: 343.3299255371094



buy possibilites: [-1] 
expected returns: [[340.22467]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 6] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -24.97002601623535
desired expected reward: 314.5315856933594






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 6] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 6] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.  0.  0.  3.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 6] -> size -> 12 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[321.86072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -10.3668851852417
desired expected reward: 329.8577880859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[299.60318]
 [303.16748]
 [303.626  ]
 [298.39166]
 [303.65076]
 [308.41122]
 [304.3475 ]
 [310.41135]
 [303.17618]
 [304.806  ]
 [306.78134]
 [318.88727]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.8817720413208
desired expected reward: 314.3115234375



buy possibilites: [-1] 
expected returns: [[311.38098]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 19 

action type: buy - action 15.0
Learning step: -7.382995128631592
desired expected reward: 299.3983459472656






Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [15.  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [15.  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15] -> size -> 13 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[328.3495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [15.  1.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.789714813232422
desired expected reward: 302.5912780761719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[314.5075 ]
 [317.9981 ]
 [318.43433]
 [313.31256]
 [318.46445]
 [322.7541 ]
 [319.1472 ]
 [324.57678]
 [317.99066]
 [319.58344]
 [321.32242]
 [333.78665]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [15.  1.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.84915828704834
desired expected reward: 320.343505859375



buy possibilites: [-1] 
expected returns: [[333.03665]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [15.  1.  0.  0.  3.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -11.0 

action type: buy - action 8.0
Learning step: -9.01403522491455
desired expected reward: 310.1331481933594






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 8. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8] -> size -> 14 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[317.03235]
 [300.93286]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  3] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -10.729425430297852
desired expected reward: 322.3072204589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[295.6213 ]
 [299.80197]
 [294.36325]
 [300.55466]
 [316.6541 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  3] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -10.227396965026855
desired expected reward: 309.3442077636719



buy possibilites: [-1] 
expected returns: [[320.92053]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  3] -> size -> 13 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -334.0 

action type: buy - action 6.0
Learning step: -24.197452545166016
desired expected reward: 270.1658020019531






Player: 1 
cards in hand: [ 3.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  1.  6.] 
adversary cards in discard: [6. 0. 3. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6] -> size -> 15 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  3] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  1.  6.] 
adversary cards in discard: [6. 0. 3. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6] -> size -> 15 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  1.  6.] 
adversary cards in discard: [6. 0. 3. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6] -> size -> 15 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3] -> size -> 10 
action values: 1 
buys: 1 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  1.  6.] 
adversary cards in discard: [6. 0. 3. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6] -> size -> 15 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  3.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[331.27356]
 [319.95068]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  1.  6.] 
cards in discard: [6. 0. 3. 8. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3] -> size -> 10 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -9.834246635437012
desired expected reward: 311.0862731933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[312.88177]
 [315.99802]
 [316.3824 ]
 [311.81137]
 [320.55414]
 [317.01877]
 [317.4032 ]
 [330.5069 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  1.  6.] 
cards in discard: [6. 0. 3. 8. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3] -> size -> 10 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -10.60447883605957
desired expected reward: 322.4949951171875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6] -> size -> 15 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6] -> size -> 15 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.  8.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6] -> size -> 15 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[337.9301]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -9.542579650878906
desired expected reward: 310.49212646484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[315.97153]
 [319.41568]
 [319.8536 ]
 [314.79053]
 [319.88715]
 [324.48557]
 [320.56332]
 [326.42368]
 [319.42157]
 [321.00122]
 [322.90582]
 [335.52756]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -10.873781204223633
desired expected reward: 329.53314208984375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [6. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6] -> size -> 15 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [6. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6] -> size -> 15 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [6. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6] -> size -> 15 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [1. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[357.1596]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [6. 0. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 10.  3. 11.  0.] 
adversary cards in discard: [1. 0. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -9.895376205444336
desired expected reward: 325.6322021484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[336.96252]
 [341.4255 ]
 [341.99213]
 [335.43665]
 [342.03397]
 [347.7758 ]
 [342.87793]
 [349.9769 ]
 [341.4422 ]
 [343.42776]
 [345.80664]
 [360.16608]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [6. 0. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 10.  3. 11.  0.] 
adversary cards in discard: [1. 0. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -11.28931713104248
desired expected reward: 347.8664245605469



buy possibilites: [-1] 
expected returns: [[362.625]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [ 6.  0.  0.  0.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 10.  3. 11.  0.] 
adversary cards in discard: [1. 0. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 8 

action type: buy - action 14.0
Learning step: -8.51304817199707
desired expected reward: 332.92913818359375






Player: 1 
cards in hand: [ 3. 10.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3. 11.  0.] 
cards in discard: [1. 0. 8. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  6.  3.  8.] 
adversary cards in discard: [ 6.  0.  0.  0.  0. 14.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14] -> size -> 16 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  0.  0.] 
cards in discard: [1. 0. 8. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  6.  3.  8.] 
adversary cards in discard: [ 6.  0.  0.  0.  0. 14.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14] -> size -> 16 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 1.  0.  8.  3.  0.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  6.  3.  8.] 
adversary cards in discard: [ 6.  0.  0.  0.  0. 14.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14] -> size -> 16 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 1.  0.  8.  3.  0.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  6.  3.  8.] 
adversary cards in discard: [ 6.  0.  0.  0.  0. 14.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14] -> size -> 16 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 1.  0.  8.  3.  0.  0. 14.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  6.  3.  8.] 
adversary cards in discard: [ 6.  0.  0.  0.  0. 14.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14] -> size -> 16 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  6.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[295.92236]
 [279.96356]
 [277.13452]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6.  3.  8.] 
cards in discard: [ 6.  0.  0.  0.  0. 14.  1.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -12.84382152557373
desired expected reward: 349.78118896484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[274.0935 ]
 [272.66772]
 [299.05167]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6.  3.  8.] 
cards in discard: [ 6.  0.  0.  0.  0. 14.  1.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -9.518613815307617
desired expected reward: 286.4114074707031



buy possibilites: [-1] 
expected returns: [[285.3168]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6.  3.  8.] 
cards in discard: [ 6.  0.  0.  0.  0. 14.  1.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -54.0 

action type: buy - action 0.0
Learning step: -9.985047340393066
desired expected reward: 264.10845947265625






Player: 1 
cards in hand: [ 0. 10.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 11.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[305.67514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  1.  0.  8. 14.] 
adversary cards in discard: [11.  0. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -8.54116153717041
desired expected reward: 276.775634765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[290.24277]
 [293.26492]
 [293.64966]
 [289.20654]
 [293.67804]
 [297.7128 ]
 [294.2708 ]
 [299.41177]
 [293.26892]
 [294.65558]
 [296.32617]
 [307.39737]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  1.  0.  8. 14.] 
adversary cards in discard: [11.  0. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -9.849628448486328
desired expected reward: 297.91387939453125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  1.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  8. 14.] 
cards in discard: [11.  0. 10.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [0. 3. 6. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 8.] 
cards in discard: [11.  0. 10.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 3. 6. 1. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 8.] 
cards in discard: [11.  0. 10.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 3. 6. 1. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 8.] 
cards in discard: [11.  0. 10.  0.  0. 11. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 3. 6. 1. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[383.402]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 3. 6. 1. 0. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -20    0    0    0  -60    0    0    0    0    0 -600
   16    0] 
sum of rewards: -668 

action type: discard_down_to_3_cards - action 1
Learning step: -37.61865997314453
desired expected reward: 219.38827514648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[359.97064]
 [363.49875]
 [363.92093]
 [358.73993]
 [368.63458]
 [364.64502]
 [365.0671 ]
 [379.6764 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 3. 6. 1. 0. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -12.04626178741455
desired expected reward: 371.5843811035156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  3. 14. 15.  0.] 
adversary cards in discard: [0. 3. 6. 1. 0. 8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  3. 14. 15.  0.] 
adversary cards in discard: [0. 3. 6. 1. 0. 8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  3. 14. 15.  0.] 
adversary cards in discard: [0. 3. 6. 1. 0. 8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 6.  3. 14. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
expected returns: [[314.03708]
 [296.16016]
 [300.0345 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 14. 15.  0.] 
cards in discard: [0. 3. 6. 1. 0. 8. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0. 11.  0. 10.] 
adversary cards in discard: [0. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -13.260458946228027
desired expected reward: 366.4159240722656



action possibilites: [-1] 
expected returns: [[351.46252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 14.] 
cards in discard: [0. 3. 6. 1. 0. 8. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0. 11.  0. 10.] 
adversary cards in discard: [0. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 15.0
Learning step: -7.323238372802734
desired expected reward: 293.2996520996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[333.87027]
 [336.58423]
 [336.91315]
 [333.04535]
 [340.60742]
 [337.48053]
 [337.80948]
 [349.40793]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 14.] 
cards in discard: [0. 3. 6. 1. 0. 8. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0. 11.  0. 10.] 
adversary cards in discard: [0. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -10.07546329498291
desired expected reward: 341.3870544433594






Player: 1 
cards in hand: [11.  0. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0. 10.] 
cards in discard: [0. 3. 0. 3. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  0. 10.] 
cards in discard: [0. 3. 0. 3. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  0. 10.] 
cards in discard: [0. 3. 0. 3. 3. 0. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[318.5161]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8. 14.  1.  0.] 
adversary cards in discard: [ 0.  3.  0.  3.  3.  0.  8. 11.  0. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -11.621367454528809
desired expected reward: 340.9501037597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[298.7893 ]
 [302.26114]
 [302.70645]
 [297.61307]
 [302.73993]
 [307.37732]
 [303.42166]
 [309.33826]
 [302.28394]
 [303.8669 ]
 [305.79434]
 [318.52792]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8. 14.  1.  0.] 
adversary cards in discard: [ 0.  3.  0.  3.  3.  0.  8. 11.  0. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -10.253812789916992
desired expected reward: 310.0664978027344



buy possibilites: [-1] 
expected returns: [[298.44843]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  8.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8. 14.  1.  0.] 
adversary cards in discard: [ 0.  3.  0.  3.  3.  0.  8. 11.  0. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -11.0 

action type: buy - action 3.0
Learning step: -8.970232009887695
desired expected reward: 293.7361755371094






Player: 1 
cards in hand: [ 0.  8. 14.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  1.  0.] 
cards in discard: [ 0.  3.  0.  3.  3.  0.  8. 11.  0. 11.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  8.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  1.  3.  8. 15.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3] -> size -> 17 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 0.] 
cards in discard: [ 0.  3.  0.  3.  3.  0.  8. 11.  0. 11.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  8.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  8. 15.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3] -> size -> 17 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 0.] 
cards in discard: [ 0.  3.  0.  3.  3.  0.  8. 11.  0. 11.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  8.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  8. 15.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3] -> size -> 17 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 0.] 
cards in discard: [ 0.  3.  0.  3.  3.  0.  8. 11.  0. 11.  0. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  8. 15.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3] -> size -> 17 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [14.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 15.] 
expected returns: [[358.42673]
 [337.08246]
 [338.56494]
 [341.6894 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 15.] 
cards in discard: [3. 0. 0. 0. 0. 3. 1. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: discard_down_to_3_cards - action 9
Learning step: -5.147449493408203
desired expected reward: 241.3065185546875



action possibilites: [-1] 
expected returns: [[371.5366]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.] 
cards in discard: [3. 0. 0. 0. 0. 3. 1. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0. 14.] 
adversary cards in discard: [3. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action 14.0
Learning step: -8.084352493286133
desired expected reward: 327.7941589355469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[344.1296 ]
 [349.3164 ]
 [342.67633]
 [350.2857 ]
 [370.9719 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.] 
cards in discard: [3. 0. 0. 0. 0. 3. 1. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0. 14.] 
adversary cards in discard: [3. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -10.165639877319336
desired expected reward: 361.3709411621094



buy possibilites: [-1] 
expected returns: [[332.57706]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.] 
cards in discard: [3. 0. 0. 0. 0. 3. 1. 3. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0. 14.] 
adversary cards in discard: [3. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -304.0 

action type: buy - action 6.0
Learning step: -24.850833892822266
desired expected reward: 317.82550048828125






Player: 1 
cards in hand: [10.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 14.] 
cards in discard: [3. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  3.  1.  3.  6. 14.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [3. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 6.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  3.  1.  3.  6. 14.  8. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [3. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 6.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  3.  1.  3.  6. 14.  8. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [3. 8. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8 11  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 6.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  3.  1.  3.  6. 14.  8. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[248.21754]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [ 3.  0.  0.  0.  0.  3.  1.  3.  6. 14.  8. 15.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [11. 11. 11.  8.  1.] 
adversary cards in discard: [ 3.  8.  0. 14. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: discard_down_to_3_cards - action 2
Learning step: -7.080772399902344
desired expected reward: 219.77059936523438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[226.61925]
 [225.31825]
 [248.9861 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [ 3.  0.  0.  0.  0.  3.  1.  3.  6. 14.  8. 15.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [11. 11. 11.  8.  1.] 
adversary cards in discard: [ 3.  8.  0. 14. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -7.95999002456665
desired expected reward: 234.78651428222656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 11. 11.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.  8.  1.] 
cards in discard: [ 3.  8.  0. 14. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 11  1 14  0 11 14  0  8 11  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 3.  8.  0. 14. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 3.  8.  0. 14. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 6. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[277.7505 ]
 [267.10693]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  6 15  8  6 14  0  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0.  0.  3.  3.] 
adversary cards in discard: [ 3.  8.  0. 14. 10.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -7.458868503570557
desired expected reward: 241.5272216796875



action possibilites: [-1] 
expected returns: [[266.92523]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0.  0.  3.  3.] 
adversary cards in discard: [ 3.  8.  0. 14. 10.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 11
Learning step: -8.28635025024414
desired expected reward: 262.5570068359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[248.9611 ]
 [248.0611 ]
 [264.20306]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0.  0.  3.  3.] 
adversary cards in discard: [ 3.  8.  0. 14. 10.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: -8.304984092712402
desired expected reward: 258.6202392578125






Player: 1 
cards in hand: [14.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3.  3.] 
cards in discard: [ 3.  8.  0. 14. 10.  0.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0. 15.  0.  3.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6] -> size -> 15 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [ 3.  8.  0. 14. 10.  0.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0.  3.] 
adversary cards in discard: [ 8.  6. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6] -> size -> 15 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [ 3.  8.  0. 14. 10.  0.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0.  3.] 
adversary cards in discard: [ 8.  6. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6] -> size -> 15 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [ 3.  8.  0. 14. 10.  0.  8. 11.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0.  3.] 
adversary cards in discard: [ 8.  6. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6] -> size -> 15 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[225.49959]
 [215.4739 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.] 
cards in discard: [ 8.  6. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: discard_down_to_3_cards - action 3
Learning step: -5.274950981140137
desired expected reward: 164.50137329101562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[214.68158]
 [213.86806]
 [227.16762]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.] 
cards in discard: [ 8.  6. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -7.973065376281738
desired expected reward: 216.19471740722656



buy possibilites: [-1] 
expected returns: [[234.33908]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.] 
cards in discard: [ 8.  6. 15.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: -8.711450576782227
desired expected reward: 205.9701385498047






Player: 1 
cards in hand: [10.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [6. 3. 0. 1. 6.] 
adversary cards in discard: [ 8.  6. 15.  0.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [6. 3. 0. 1. 6.] 
adversary cards in discard: [ 8.  6. 15.  0.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [6. 3. 0. 1. 6.] 
adversary cards in discard: [ 8.  6. 15.  0.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10.  9.  7. 10.  9. 10.  9.] 
adversary cards in hand: [6. 3. 0. 1. 6.] 
adversary cards in discard: [ 8.  6. 15.  0.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[220.48604]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 1. 6.] 
cards in discard: [ 8.  6. 15.  0.  0. 14.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10.  9.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 14.  3.  0.  0.] 
adversary cards in discard: [29. 10.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29] -> size -> 19 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -8.546244621276855
desired expected reward: 225.79283142089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[203.82558]
 [207.22353]
 [207.64792]
 [202.66814]
 [212.23347]
 [208.36678]
 [208.79117]
 [223.19339]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 1. 6.] 
cards in discard: [ 8.  6. 15.  0.  0. 14.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10.  9.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 14.  3.  0.  0.] 
adversary cards in discard: [29. 10.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29] -> size -> 19 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -7.867466926574707
desired expected reward: 210.83074951171875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 14.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  3.  0.  0.] 
cards in discard: [29. 10.  0.  0.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10.  9.  7. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29. 10.  0.  0.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10.  9.  7. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29. 10.  0.  0.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10.  9.  7. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[271.62112]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [6. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10.  9.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  8.  0. 11.  0.] 
adversary cards in discard: [29. 10.  0.  0.  0.  0.  8. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29] -> size -> 19 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: discard_down_to_3_cards - action 3
Learning step: -7.402813911437988
desired expected reward: 228.33140563964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[256.51895]
 [260.08664]
 [255.42029]
 [260.74646]
 [274.0214 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [6. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10.  9.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  8.  0. 11.  0.] 
adversary cards in discard: [29. 10.  0.  0.  0.  0.  8. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29] -> size -> 19 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -9.400948524475098
desired expected reward: 263.2167053222656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  8.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 11.  0.] 
cards in discard: [29. 10.  0.  0.  0.  0.  8. 14.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10.  9.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0. 15.  8.  3.] 
adversary cards in discard: [6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [29. 10.  0.  0.  0.  0.  8. 14.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10.  9.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0. 15.  8.  3.] 
adversary cards in discard: [6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [29. 10.  0.  0.  0.  0.  8. 14.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 28. 30.  8.  7. 10.  7.  7. 10.  9.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0. 15.  8.  3.] 
adversary cards in discard: [6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [29. 10.  0.  0.  0.  0.  8. 14.  3.  3.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 30.  8.  7. 10.  7.  7. 10.  9.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0. 15.  8.  3.] 
adversary cards in discard: [6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [14.  0. 15.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.  8.] 
expected returns: [[279.8861 ]
 [270.2065 ]
 [272.3076 ]
 [270.92377]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 15.  8.  3.] 
cards in discard: [6. 0. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 30.  8.  7. 10.  7.  7. 10.  9.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -9.799667358398438
desired expected reward: 264.22174072265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[268.08673]
 [267.35947]
 [279.82098]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 15.  8.  3.] 
cards in discard: [6. 0. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 27. 30.  8.  7. 10.  7.  7. 10.  9.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -9.95588493347168
desired expected reward: 267.7176208496094



buy possibilites: [-1] 
expected returns: [[227.8858]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 15.  8.  3.] 
cards in discard: [6. 0. 0. 3. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 27. 30.  8.  6. 10.  7.  7. 10.  9.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -356.0 

action type: buy - action 6.0
Learning step: -26.040546417236328
desired expected reward: 241.31895446777344






Player: 1 
cards in hand: [ 0.  0. 11.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  1. 14.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 30.  8.  6. 10.  7.  7. 10.  9.  7. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 6. 1. 6.] 
adversary cards in discard: [ 6.  0.  0.  3.  0.  6. 14.  0. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6] -> size -> 17 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 14.] 
cards in discard: [14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 30.  8.  6. 10.  7.  7. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 6. 1. 6.] 
adversary cards in discard: [ 6.  0.  0.  3.  0.  6. 14.  0. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6] -> size -> 17 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 14.] 
cards in discard: [14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 27. 30.  8.  6. 10.  7.  7. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 6. 1. 6.] 
adversary cards in discard: [ 6.  0.  0.  3.  0.  6. 14.  0. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6] -> size -> 17 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 14.] 
cards in discard: [14.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 27. 30. 27. 30.  8.  6. 10.  7.  7. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 6. 1. 6.] 
adversary cards in discard: [ 6.  0.  0.  3.  0.  6. 14.  0. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6] -> size -> 17 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[163.50601]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 1. 6.] 
cards in discard: [ 6.  0.  0.  3.  0.  6. 14.  0. 15.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 30.  8.  6. 10.  7.  7. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [10. 29.  0.  0.  8.] 
adversary cards in discard: [14.  0. 11.  0.  0.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0] -> size -> 23 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -10.54960823059082
desired expected reward: 217.33619689941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[149.69888]
 [152.19034]
 [152.49242]
 [148.84421]
 [155.84421]
 [153.01917]
 [153.32126]
 [165.52463]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 1. 6.] 
cards in discard: [ 6.  0.  0.  3.  0.  6. 14.  0. 15.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 27. 30.  8.  6. 10.  7.  7. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [10. 29.  0.  0.  8.] 
adversary cards in discard: [14.  0. 11.  0.  0.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0] -> size -> 23 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -7.345813274383545
desired expected reward: 154.6400604248047



buy possibilites: [-1] 
expected returns: [[179.58133]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 1. 6.] 
cards in discard: [ 6.  0.  0.  3.  0.  6. 14.  0. 15.  8.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [10. 29.  0.  0.  8.] 
adversary cards in discard: [14.  0. 11.  0.  0.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0] -> size -> 23 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -54.0 

action type: buy - action 8.0
Learning step: -6.3103790283203125
desired expected reward: 146.70880126953125






Player: 1 
cards in hand: [10. 29.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  0.  8.] 
cards in discard: [14.  0. 11.  0.  0.  1. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 6. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8] -> size -> 18 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.] 
cards in discard: [14.  0. 11.  0.  0.  1. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 6. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8] -> size -> 18 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0.] 
cards in discard: [14.  0. 11.  0.  0.  1. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 6. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8] -> size -> 18 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0.] 
cards in discard: [14.  0. 11.  0.  0.  1. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [6. 6. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8] -> size -> 18 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [6. 6. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[195.85446]
 [179.76062]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [14.  0. 11.  0.  0.  1. 14.  0.  8. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0] -> size -> 23 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -7.495437145233154
desired expected reward: 172.0858917236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[175.71481]
 [174.48209]
 [196.51767]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [14.  0. 11.  0.  0.  1. 14.  0.  8. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0] -> size -> 23 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -8.368799209594727
desired expected reward: 187.25534057617188



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.  0. 11.  0.  0.  1. 14.  0.  8. 10. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 1. 6. 0.] 
adversary cards in discard: [6. 6. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8] -> size -> 18 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.  0. 11.  0.  0.  1. 14.  0.  8. 10. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 27. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 1. 6. 0.] 
adversary cards in discard: [6. 6. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8] -> size -> 18 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.  0. 11.  0.  0.  1. 14.  0.  8. 10. 29.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 5 
card supply: [21. 27. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 1. 6. 0.] 
adversary cards in discard: [6. 6. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8] -> size -> 18 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[249.23647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 6. 0.] 
cards in discard: [6. 6. 3. 8. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  3. 14.] 
adversary cards in discard: [14.  0. 11.  0.  0.  1. 14.  0.  8. 10. 29.  0.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -6.890298366546631
desired expected reward: 185.48252868652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[233.81644]
 [236.41562]
 [236.74327]
 [233.10571]
 [232.9366 ]
 [236.7922 ]
 [240.25725]
 [237.2954 ]
 [242.94041]
 [241.7497 ]
 [236.43233]
 [238.56337]
 [237.62305]
 [235.92917]
 [239.06656]
 [248.897  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 0.] 
cards in discard: [6. 6. 3. 8. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 27. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  3. 14.] 
adversary cards in discard: [14.  0. 11.  0.  0.  1. 14.  0.  8. 10. 29.  0.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -9.644183158874512
desired expected reward: 236.05996704101562



buy possibilites: [-1] 
expected returns: [[256.51263]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 0.] 
cards in discard: [6. 6. 3. 8. 0. 1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  3. 14.] 
adversary cards in discard: [14.  0. 11.  0.  0.  1. 14.  0.  8. 10. 29.  0.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.    0.   -1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -51.5 

action type: buy - action 1.0
Learning step: -8.624247550964355
desired expected reward: 227.7913818359375






Player: 1 
cards in hand: [ 3.  3.  3.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  3. 14.] 
cards in discard: [14.  0. 11.  0.  0.  1. 14.  0.  8. 10. 29.  0.  0.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 6. 0. 0. 3.] 
adversary cards in discard: [6. 6. 3. 8. 0. 1. 0. 0. 1. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8  1] -> size -> 19 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  3. 14.] 
cards in discard: [14.  0. 11.  0.  0.  1. 14.  0.  8. 10. 29.  0.  0.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 6. 0. 0. 3.] 
adversary cards in discard: [6. 6. 3. 8. 0. 1. 0. 0. 1. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8  1] -> size -> 19 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  3. 14.] 
cards in discard: [14.  0. 11.  0.  0.  1. 14.  0.  8. 10. 29.  0.  0.  0.  0.  0.  0.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 6. 0. 0. 3.] 
adversary cards in discard: [6. 6. 3. 8. 0. 1. 0. 0. 1. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8  1] -> size -> 19 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [3. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[266.16928]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 3.] 
cards in discard: [6. 6. 3. 8. 0. 1. 0. 0. 1. 6. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -9.67469596862793
desired expected reward: 246.8379364013672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[247.36168]
 [250.88771]
 [246.3066 ]
 [251.55696]
 [266.1747 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 3.] 
cards in discard: [6. 6. 3. 8. 0. 1. 0. 0. 1. 6. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -10.236372947692871
desired expected reward: 254.2496795654297



buy possibilites: [-1] 
expected returns: [[234.64412]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 3.] 
cards in discard: [6. 6. 3. 8. 0. 1. 0. 0. 1. 6. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 26. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -86.0 

action type: buy - action 0.0
Learning step: -11.388590812683105
desired expected reward: 235.9730682373047






Player: 1 
cards in hand: [ 0.  0. 14.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 14. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0] -> size -> 20 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 14. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0] -> size -> 20 
adversary victory points: -1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 15.] 
expected returns: [[144.64488]
 [134.80177]
 [134.08543]
 [136.23132]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 14. 15.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [14.  8.  0. 10.  0.] 
adversary cards in discard: [ 0.  0. 14.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -11.455326080322266
desired expected reward: 223.1887969970703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[131.98126]
 [134.35008]
 [131.25262]
 [134.8048 ]
 [144.70586]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 14. 15.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 27. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [14.  8.  0. 10.  0.] 
adversary cards in discard: [ 0.  0. 14.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -6.758811950683594
desired expected reward: 134.81338500976562



buy possibilites: [-1] 
expected returns: [[168.55202]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 14. 15.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [14.  8.  0. 10.  0.] 
adversary cards in discard: [ 0.  0. 14.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -37 

action type: buy - action 3.0
Learning step: -4.775084018707275
desired expected reward: 129.5749969482422






Player: 1 
cards in hand: [14.  8.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  0. 10.  0.] 
cards in discard: [ 0.  0. 14.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 6. 3. 3.] 
adversary cards in discard: [ 3.  0.  0.  8. 14. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3] -> size -> 21 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  0. 10.  0.] 
cards in discard: [ 0.  0. 14.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 26. 30.  8.  6. 10.  7.  6. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 6. 3. 3.] 
adversary cards in discard: [ 3.  0.  0.  8. 14. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3] -> size -> 21 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  0. 10.  0.] 
cards in discard: [ 0.  0. 14.  0.  8.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  6. 10.  7.  5. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 6. 3. 3.] 
adversary cards in discard: [ 3.  0.  0.  8. 14. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3] -> size -> 21 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [8. 0. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[172.44609]
 [161.76216]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 3. 3.] 
cards in discard: [ 3.  0.  0.  8. 14. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  6. 10.  7.  5. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [14. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -6.919589519500732
desired expected reward: 161.63243103027344



action possibilites: [-1] 
expected returns: [[150.72273]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [ 3.  0.  0.  8. 14. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  6. 10.  7.  5. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [14. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8] -> size -> 26 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: trash_cards_n_from_hand - action 4
Learning step: -6.056090831756592
desired expected reward: 146.8909454345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[140.24818]
 [139.42146]
 [154.32466]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 3.  0.  0.  8. 14. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  6. 10.  7.  5. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [14. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8] -> size -> 26 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -6.005380153656006
desired expected reward: 144.71734619140625



buy possibilites: [-1] 
expected returns: [[182.50542]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 3.  0.  0.  8. 14. 15.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 26. 30.  8.  6. 10.  7.  5. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [14. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8] -> size -> 26 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action 0.0
Learning step: -6.206037521362305
desired expected reward: 134.04214477539062






Player: 1 
cards in hand: [14. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  0.  0.  0.] 
cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 26. 30.  8.  6. 10.  7.  5. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [1. 0. 6. 1. 6.] 
adversary cards in discard: [ 3.  0.  0.  8. 14. 15.  0.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0] -> size -> 20 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 26. 30. 26. 30.  8.  6. 10.  7.  5. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [1. 0. 1.] 
adversary cards in discard: [ 3.  0.  0.  8. 14. 15.  0.  8.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0] -> size -> 20 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 26. 30. 26. 30.  8.  6. 10.  7.  5. 10.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [1. 0. 1.] 
adversary cards in discard: [ 3.  0.  0.  8. 14. 15.  0.  8.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0] -> size -> 20 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 26. 30.  8.  6. 10.  7.  5.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [1. 0. 1.] 
adversary cards in discard: [ 3.  0.  0.  8. 14. 15.  0.  8.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0] -> size -> 20 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[173.82439]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1.] 
cards in discard: [ 3.  0.  0.  8. 14. 15.  0.  8.  6.  3.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 26. 30.  8.  6. 10.  7.  5.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0. 25. 14. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8 25] -> size -> 27 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: discard_down_to_3_cards - action 3
Learning step: -5.088935852050781
desired expected reward: 119.20789337158203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[150.95724]
 [152.25917]
 [152.429  ]
 [150.58684]
 [150.50082]
 [152.47136]
 [154.71294]
 [152.80136]
 [156.46884]
 [155.69363]
 [152.22646]
 [153.60776]
 [152.99939]
 [151.97481]
 [153.93777]
 [160.17801]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1.] 
cards in discard: [ 3.  0.  0.  8. 14. 15.  0.  8.  6.  3.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 26. 30. 26. 30.  8.  6. 10.  7.  5.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0. 25. 14. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8 25] -> size -> 27 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -7.278546333312988
desired expected reward: 152.37518310546875



buy possibilites: [-1] 
expected returns: [[134.36916]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1.] 
cards in discard: [ 3.  0.  0.  8. 14. 15.  0.  8.  6.  3.  6.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 25. 30. 26. 30.  8.  6. 10.  7.  5.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0. 25. 14. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8 25] -> size -> 27 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.    0.   -1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -51.5 

action type: buy - action 1.0
Learning step: -7.164653301239014
desired expected reward: 145.09451293945312






Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0. 25. 14. 11.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 26. 30.  8.  6. 10.  7.  5.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [ 3.  0.  0.  8. 14. 15.  0.  8.  6.  3.  6.  6.  1.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1] -> size -> 21 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0. 25. 14. 11.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 25. 30. 26. 30.  8.  6. 10.  7.  5.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [ 3.  0.  0.  8. 14. 15.  0.  8.  6.  3.  6.  6.  1.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1] -> size -> 21 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0. 25. 14. 11.  0.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8 25  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [ 3.  0.  0.  8. 14. 15.  0.  8.  6.  3.  6.  6.  1.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1] -> size -> 21 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[171.22757]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [ 3.  0.  0.  8. 14. 15.  0.  8.  6.  3.  6.  6.  1.  1.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  1.  0.  3.] 
adversary cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0. 25. 14. 11.  0.  0.  0.  8.
  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8 25  8] -> size -> 28 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -5.66583776473999
desired expected reward: 128.7033233642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[165.43369]
 [167.31383]
 [167.53561]
 [164.79184]
 [170.07689]
 [167.94864]
 [168.17041]
 [176.23943]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [ 3.  0.  0.  8. 14. 15.  0.  8.  6.  3.  6.  6.  1.  1.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 25. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  1.  0.  3.] 
adversary cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0. 25. 14. 11.  0.  0.  0.  8.
  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8 25  8] -> size -> 28 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -7.510295391082764
desired expected reward: 163.71726989746094



buy possibilites: [-1] 
expected returns: [[181.74577]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [ 3.  0.  0.  8. 14. 15.  0.  8.  6.  3.  6.  6.  1.  1.  0.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  1.  0.  3.] 
adversary cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0. 25. 14. 11.  0.  0.  0.  8.
  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8 25  8] -> size -> 28 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -38 

action type: buy - action 1.0
Learning step: -6.176410675048828
desired expected reward: 161.1374053955078






Player: 1 
cards in hand: [ 0. 29.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  0.  3.] 
cards in discard: [ 0.  0. 14.  0.  8.  8. 14.  8.  0. 10.  0. 25. 14. 11.  0.  0.  0.  8.
  3.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8 25  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [15.  3.  6.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1] -> size -> 22 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8 25  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 24. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [15.  3.  6.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1] -> size -> 22 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8 25  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [18. 24. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [15.  3.  6.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1] -> size -> 22 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [15.  3.  6.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[166.87791]
 [157.02074]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  6.  1.  6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [29.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8 25  8] -> size -> 28 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -8.30247974395752
desired expected reward: 173.44329833984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[148.96129]
 [151.7107 ]
 [148.13756]
 [152.24072]
 [164.51054]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  6.  1.  6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 24. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [29.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8 25  8] -> size -> 28 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -7.393255710601807
desired expected reward: 155.16114807128906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [29.  0.  1.  0.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0
  0  8 25  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [15.  3.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1] -> size -> 22 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.  0.  1.  0.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [15.  3.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1] -> size -> 22 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  0.  1.  0.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 24. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [15.  3.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1] -> size -> 22 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  0.  1.  0.  3.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25
  8  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 24. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [15.  3.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1] -> size -> 22 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[207.77437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [15.  3.  6.  1.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  8.] 
adversary cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25
  8  0] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -5.903611183166504
desired expected reward: 158.60690307617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[193.0903 ]
 [196.08984]
 [196.46796]
 [192.08334]
 [200.52821]
 [197.11682]
 [197.49493]
 [209.96497]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [15.  3.  6.  1.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 24. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  8.] 
adversary cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25
  8  0] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -8.02416706085205
desired expected reward: 197.39427185058594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  3.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  8.] 
cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25
  8  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [8. 1. 0. 6. 0.] 
adversary cards in discard: [15.  3.  6.  1.  6.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1] -> size -> 22 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [8. 1. 0. 6. 0.] 
adversary cards in discard: [15.  3.  6.  1.  6.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1] -> size -> 22 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 24. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [8. 1. 0. 6. 0.] 
adversary cards in discard: [15.  3.  6.  1.  6.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1] -> size -> 22 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [8. 1. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[187.51155]
 [175.59203]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 6. 0.] 
cards in discard: [15.  3.  6.  1.  6.  3.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  8.  8.] 
adversary cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.  8.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0] -> size -> 22 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -8.20640754699707
desired expected reward: 201.75857543945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[176.09515]
 [178.71481]
 [179.04778]
 [175.21806]
 [179.10803]
 [182.61076]
 [179.61923]
 [184.12236]
 [178.74493]
 [179.9522 ]
 [181.40353]
 [191.14357]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 6. 0.] 
cards in discard: [15.  3.  6.  1.  6.  3.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 24. 30. 26. 30.  8.  6. 10.  7.  4.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  8.  8.] 
adversary cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.  8.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0] -> size -> 22 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -6.940286159515381
desired expected reward: 178.75543212890625



buy possibilites: [-1] 
expected returns: [[158.57942]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 6. 0.] 
cards in discard: [15.  3.  6.  1.  6.  3.  3.  0.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 24. 30. 26. 30.  8.  6. 10.  7.  3.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  8.  8.] 
adversary cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.  8.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0] -> size -> 22 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -34.0 

action type: buy - action 8.0
Learning step: -7.112924098968506
desired expected reward: 172.5063018798828






Player: 1 
cards in hand: [ 0. 14.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  8.  8.] 
cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 26. 30.  8.  6. 10.  7.  3.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [14.  6.  1.  0.  8.] 
adversary cards in discard: [15.  3.  6.  1.  6.  3.  3.  0.  0.  0.  8.  8.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8] -> size -> 23 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 24. 30. 26. 30.  8.  6. 10.  7.  3.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [14.  6.  1.] 
adversary cards in discard: [15.  3.  6.  1.  6.  3.  3.  0.  0.  0.  8.  8.  1.  0.  6.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8] -> size -> 23 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 24. 30. 26. 30.  8.  6. 10.  7.  3.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [14.  6.  1.] 
adversary cards in discard: [15.  3.  6.  1.  6.  3.  3.  0.  0.  0.  8.  8.  1.  0.  6.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8] -> size -> 23 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 4 
card supply: [16. 24. 30. 26. 30.  8.  6. 10.  7.  3.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [14.  6.  1.] 
adversary cards in discard: [15.  3.  6.  1.  6.  3.  3.  0.  0.  0.  8.  8.  1.  0.  6.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8] -> size -> 23 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [14.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[103.70972 ]
 [ 99.537415]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  1.] 
cards in discard: [15.  3.  6.  1.  6.  3.  3.  0.  0.  0.  8.  8.  1.  0.  6.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  6. 10.  7.  3.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 14.  0. 14. 11.] 
adversary cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.  8.  0. 14.  0.  0.  8.  8.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0] -> size -> 23 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[   -5     0    -1   -30     0     0     0     0     0     0     0     0
     0 -1200    47     0] 
sum of rewards: -1189 

action type: discard_down_to_3_cards - action 9
Learning step: -63.44477462768555
desired expected reward: 62.508731842041016



action possibilites: [-1] 
expected returns: [[91.97511]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1.] 
cards in discard: [15.  3.  6.  1.  6.  3.  3.  0.  0.  0.  8.  8.  1.  0.  6.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 24. 30. 26. 30.  8.  6. 10.  7.  3.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.] 
adversary cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.  8.  0. 14.  0.  0.  8.  8. 14. 14.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0] -> size -> 23 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action 14.0
Learning step: -3.7074315547943115
desired expected reward: 95.83000183105469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[76.225204]
 [78.72163 ]
 [79.04414 ]
 [75.393265]
 [79.100624]
 [82.44867 ]
 [79.592094]
 [83.887985]
 [78.76339 ]
 [79.91462 ]
 [81.29745 ]
 [90.59727 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1.] 
cards in discard: [15.  3.  6.  1.  6.  3.  3.  0.  0.  0.  8.  8.  1.  0.  6.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 24. 30. 26. 30.  8.  6. 10.  7.  3.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.] 
adversary cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.  8.  0. 14.  0.  0.  8.  8. 14. 14.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0] -> size -> 23 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1
Learning step: -3.509511947631836
desired expected reward: 88.4655990600586






Player: 1 
cards in hand: [ 3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.] 
cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.  8.  0. 14.  0.  0.  8.  8. 14. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  6. 10.  7.  3.  9.  9.  6. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8] -> size -> 23 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.  8.  0. 14.  0.  0.  8.  8. 14. 14.
 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  6. 10.  7.  3.  9.  9.  6. 10.  9. 10.  8.] 
adversary cards in hand: [0. 6. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8] -> size -> 23 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [29.  0.  1.  0.  3.  0.  0.  8.  0.  8.  0. 14.  0.  0.  8.  8. 14. 14.
 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 26. 30.  8.  6. 10.  7.  3.  9.  9.  6. 10.  9. 10.  8.] 
adversary cards in hand: [0. 6. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8] -> size -> 23 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [0. 6. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[126.2791  ]
 [115.593414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 1. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  6. 10.  7.  3.  9.  9.  6. 10.  9. 10.  8.] 
adversary cards in hand: [14.  0.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15] -> size -> 24 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -3.2930362224578857
desired expected reward: 80.75910186767578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[110.82033 ]
 [113.43043 ]
 [113.74324 ]
 [109.938286]
 [113.80988 ]
 [117.25533 ]
 [114.3192  ]
 [118.65065 ]
 [113.42726 ]
 [114.632034]
 [116.07759 ]
 [125.71324 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 1. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 24. 30. 26. 30.  8.  6. 10.  7.  3.  9.  9.  6. 10.  9. 10.  8.] 
adversary cards in hand: [14.  0.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15] -> size -> 24 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -5.331753253936768
desired expected reward: 118.77899169921875



buy possibilites: [-1] 
expected returns: [[123.272766]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 1. 0.] 
cards in discard: [16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  6.  9.  7.  3.  9.  9.  6. 10.  9. 10.  8.] 
adversary cards in hand: [14.  0.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15] -> size -> 24 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -4 

action type: buy - action 16.0
Learning step: -3.116856575012207
desired expected reward: 110.6930160522461






Player: 1 
cards in hand: [14.  0.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  6.  9.  7.  3.  9.  9.  6. 10.  9. 10.  8.] 
adversary cards in hand: [0. 8. 6. 6. 3.] 
adversary cards in discard: [16.  0.  6.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16] -> size -> 24 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 24. 30. 26. 30.  8.  6.  9.  7.  3.  9.  9.  6. 10.  9. 10.  8.] 
adversary cards in hand: [6. 6. 3.] 
adversary cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16] -> size -> 24 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 24. 30. 26. 30.  8.  6.  9.  7.  3.  9.  9.  6. 10.  9. 10.  8.] 
adversary cards in hand: [6. 6. 3.] 
adversary cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16] -> size -> 24 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 25.] 
cards in discard: [22.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  6.  9.  7.  3.  9.  9.  6. 10.  9.  9.  8.] 
adversary cards in hand: [6. 6. 3.] 
adversary cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16] -> size -> 24 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[144.75642]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3.] 
cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  6.  9.  7.  3.  9.  9.  6. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  8. 14.  0. 14.] 
adversary cards in discard: [22. 14.  0.  0.  0. 25.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22] -> size -> 25 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: discard_down_to_3_cards - action 5
Learning step: -1.5997055768966675
desired expected reward: 58.583431243896484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[126.44545 ]
 [125.622604]
 [141.84991 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  6.  9.  7.  3.  9.  9.  6. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  8. 14.  0. 14.] 
adversary cards in discard: [22. 14.  0.  0.  0. 25.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22] -> size -> 25 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -5.894993782043457
desired expected reward: 136.74729919433594



buy possibilites: [-1] 
expected returns: [[165.7205]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  5.  9.  7.  3.  9.  9.  6. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  8. 14.  0. 14.] 
adversary cards in discard: [22. 14.  0.  0.  0. 25.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22] -> size -> 25 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -40    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -347 

action type: buy - action 6.0
Learning step: -19.902420043945312
desired expected reward: 105.72019958496094






Player: 1 
cards in hand: [ 0.  8. 14.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  0. 14.] 
cards in discard: [22. 14.  0.  0.  0. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  5.  9.  7.  3.  9.  9.  6. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 6. 1. 3.] 
adversary cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16
  6] -> size -> 25 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 14.] 
cards in discard: [22. 14.  0.  0.  0. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 24. 30. 26. 30.  8.  5.  9.  7.  3.  9.  9.  6. 10.  9.  9.  8.] 
adversary cards in hand: [0. 6. 3.] 
adversary cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.  6.  6.  6.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16
  6] -> size -> 25 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 14.] 
cards in discard: [22. 14.  0.  0.  0. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 24. 30. 26. 30.  8.  5.  9.  7.  3.  9.  9.  6. 10.  9.  9.  8.] 
adversary cards in hand: [0. 6. 3.] 
adversary cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.  6.  6.  6.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16
  6] -> size -> 25 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 14.] 
cards in discard: [22. 14.  0.  0.  0. 25. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  5.  9.  7.  3.  9.  9.  6. 10.  9.  9.  7.] 
adversary cards in hand: [0. 6. 3.] 
adversary cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.  6.  6.  6.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16
  6] -> size -> 25 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[156.78685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.  6.  6.  6.  3.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  5.  9.  7.  3.  9.  9.  6. 10.  9.  9.  7.] 
adversary cards in hand: [ 8. 11.  1. 15.  8.] 
adversary cards in discard: [22. 14.  0.  0.  0. 25. 15. 14.  0.  8.  0. 14.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15] -> size -> 26 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: discard_down_to_3_cards - action 0
Learning step: -2.046828508377075
desired expected reward: 62.443817138671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[142.38846]
 [141.3074 ]
 [160.06535]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.  6.  6.  6.  3.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 26. 30.  8.  5.  9.  7.  3.  9.  9.  6. 10.  9.  9.  7.] 
adversary cards in hand: [ 8. 11.  1. 15.  8.] 
adversary cards in discard: [22. 14.  0.  0.  0. 25. 15. 14.  0.  8.  0. 14.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15] -> size -> 26 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -6.765834331512451
desired expected reward: 150.02101135253906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 11.  1. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  1. 15.  8.] 
cards in discard: [22. 14.  0.  0.  0. 25. 15. 14.  0.  8.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  5.  9.  7.  3.  9.  9.  6. 10.  9.  9.  7.] 
adversary cards in hand: [ 1. 14.  8. 15.  0.] 
adversary cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.  6.  6.  6.  3.  0.  1.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16
  6] -> size -> 25 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  1.  8.] 
cards in discard: [22. 14.  0.  0.  0. 25. 15. 14.  0.  8.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  5.  9.  7.  3.  9.  9.  6. 10.  9.  9.  7.] 
adversary cards in hand: [ 1. 14.  8. 15.  0.] 
adversary cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.  6.  6.  6.  3.  0.  1.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16
  6] -> size -> 25 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  1.  8.] 
cards in discard: [22. 14.  0.  0.  0. 25. 15. 14.  0.  8.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 24. 30. 26. 30.  8.  5.  9.  7.  3.  9.  9.  6. 10.  9.  9.  7.] 
adversary cards in hand: [ 1. 14.  8. 15.  0.] 
adversary cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.  6.  6.  6.  3.  0.  1.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16
  6] -> size -> 25 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  1.  8.] 
cards in discard: [22. 14.  0.  0.  0. 25. 15. 14.  0.  8.  0. 14.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 30.  8.  5.  9.  7.  3.  9.  9.  6. 10.  9.  9.  7.] 
adversary cards in hand: [ 1. 14.  8. 15.  0.] 
adversary cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.  6.  6.  6.  3.  0.  1.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16
  6] -> size -> 25 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 1. 14.  8. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 15.] 
expected returns: [[112.63237 ]
 [100.91417 ]
 [101.714035]
 [103.32589 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  8. 15.  0.] 
cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.  6.  6.  6.  3.  0.  1.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 30.  8.  5.  9.  7.  3.  9.  9.  6. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [22. 14.  0.  0.  0. 25. 15. 14.  0.  8.  0. 14.  3. 15.  8. 11.  1.  8.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -8.436055183410645
desired expected reward: 151.62928771972656



action possibilites: [-1] 
expected returns: [[41.769062]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  8.] 
cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.  6.  6.  6.  3.  0.  1.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 24. 30. 25. 30.  8.  5.  9.  7.  3.  9.  9.  6. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [22. 14.  0.  0.  0. 25. 15. 14.  0.  8.  0. 14.  3. 15.  8. 11.  1.  8.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action 15.0
Learning step: -6.0764899253845215
desired expected reward: 97.2493896484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[30.848278]
 [32.55678 ]
 [32.753506]
 [30.380741]
 [30.275549]
 [32.80088 ]
 [35.147   ]
 [33.146267]
 [37.001842]
 [36.18015 ]
 [32.53628 ]
 [33.982086]
 [33.34518 ]
 [32.194393]
 [34.32985 ]
 [40.90074 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  8.] 
cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.  6.  6.  6.  3.  0.  1.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 24. 30. 25. 30.  8.  5.  9.  7.  3.  9.  9.  6. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [22. 14.  0.  0.  0. 25. 15. 14.  0.  8.  0. 14.  3. 15.  8. 11.  1.  8.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -3.1244513988494873
desired expected reward: 38.64461135864258



buy possibilites: [-1] 
expected returns: [[66.59421]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  8.] 
cards in discard: [16.  0.  6.  8.  1.  0.  0.  8.  6.  6.  6.  3.  0.  1.  0.  6.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 25. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [22. 14.  0.  0.  0. 25. 15. 14.  0.  8.  0. 14.  3. 15.  8. 11.  1.  8.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -50.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -29.0 

action type: buy - action 29.0
Learning step: -1.7606381177902222
desired expected reward: 34.41951370239258






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [22. 14.  0.  0.  0. 25. 15. 14.  0.  8.  0. 14.  3. 15.  8. 11.  1.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  9.  7.] 
adversary cards in hand: [14.  8.  1.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6
 29] -> size -> 25 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [22. 14.  0.  0.  0. 25. 15. 14.  0.  8.  0. 14.  3. 15.  8. 11.  1.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 24. 30. 25. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  9.  7.] 
adversary cards in hand: [14.  8.  1.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6
 29] -> size -> 25 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [22. 14.  0.  0.  0. 25. 15. 14.  0.  8.  0. 14.  3. 15.  8. 11.  1.  8.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 24. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  9.  7.] 
adversary cards in hand: [14.  8.  1.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6
 29] -> size -> 25 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [14.  8.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[147.4628 ]
 [138.08344]
 [138.67502]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  1.  0.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  9.  7.] 
adversary cards in hand: [14.  0.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -3.4986705780029297
desired expected reward: 63.09553527832031



action possibilites: [-1] 
expected returns: [[132.81061]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 24. 30. 24. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  9.  7.] 
adversary cards in hand: [14.  8. 29.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action 14.0
Learning step: -6.004821300506592
desired expected reward: 130.1058807373047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[125.302185]
 [127.85092 ]
 [128.16255 ]
 [124.602615]
 [124.44699 ]
 [128.23296 ]
 [131.62692 ]
 [128.72586 ]
 [134.2868  ]
 [133.1077  ]
 [127.85834 ]
 [129.95493 ]
 [129.03746 ]
 [127.36545 ]
 [130.4478  ]
 [139.93869 ]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 24. 30. 24. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  9.  7.] 
adversary cards in hand: [14.  8. 29.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: -5.995832920074463
desired expected reward: 126.81477355957031



buy possibilites: [-1] 
expected returns: [[83.509705]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 3.] 
cards in discard: [22.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6
 29 22] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [14.  8. 29.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0  50   0] 
sum of rewards: 3 

action type: buy - action 22.0
Learning step: -4.339303493499756
desired expected reward: 123.02613067626953






Player: 1 
cards in hand: [14.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 29.] 
cards in discard: [0. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [16.  0.  6.  3.  1.] 
adversary cards in discard: [22. 14.  8.  1.  0.  3.] 
adversary owned cards: [ 0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6
 29 22] -> size -> 26 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 29.] 
cards in discard: [0. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [16.  0.  6.  3.  1.] 
adversary cards in discard: [22. 14.  8.  1.  0.  3.] 
adversary owned cards: [ 0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6
 29 22] -> size -> 26 
adversary victory points: -2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [16.  0.  6.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[75.71251 ]
 [70.024025]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  3.  1.] 
cards in discard: [22. 14.  8.  1.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6
 29 22] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [14.  0. 25.  8. 22.] 
adversary cards in discard: [ 0.  0. 14.  8. 29.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3] -> size -> 28 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -5.863631248474121
desired expected reward: 77.64607238769531



action possibilites: [-1] 
expected returns: [[87.43921]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [22. 14.  8.  1.  0.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 23. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [14.  0. 25.  8. 22.] 
adversary cards in discard: [ 0.  0. 14.  8. 29.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3] -> size -> 28 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -32 

action type: gain_card_n - action 2
Learning step: -3.2968521118164062
desired expected reward: 69.98783111572266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[71.26643 ]
 [70.376526]
 [88.22463 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [22. 14.  8.  1.  0.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 23. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [14.  0. 25.  8. 22.] 
adversary cards in discard: [ 0.  0. 14.  8. 29.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3] -> size -> 28 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -4.356914043426514
desired expected reward: 83.0822982788086



buy possibilites: [-1] 
expected returns: [[103.52258]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [22. 14.  8.  1.  0.  3.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 24. 30. 23. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [14.  0. 25.  8. 22.] 
adversary cards in discard: [ 0.  0. 14.  8. 29.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3] -> size -> 28 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -66.0 

action type: buy - action 0.0
Learning step: -4.534063816070557
desired expected reward: 66.73236846923828






Player: 1 
cards in hand: [14.  0. 25.  8. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 25.  8. 22.] 
cards in discard: [ 0.  0. 14.  8. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 23. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 8.  0.  8. 29.  6.] 
adversary cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0] -> size -> 27 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 25.  8. 22.] 
cards in discard: [ 0.  0. 14.  8. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 24. 30. 23. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 8.  0.  8. 29.  6.] 
adversary cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0] -> size -> 27 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 25.  8. 22.] 
cards in discard: [ 0.  0. 14.  8. 29.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 24. 30. 23. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 8.  0.  8. 29.  6.] 
adversary cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0] -> size -> 27 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  8. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
expected returns: [[53.837227]
 [46.205482]
 [46.205482]
 [49.1801  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 29.  6.] 
cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 23. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 0. 14.  3.  0.  0.] 
adversary cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0] -> size -> 29 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -6.837767124176025
desired expected reward: 96.684814453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.989952]
 [43.419952]
 [53.950256]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  8. 29.  6.] 
cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 24. 30. 23. 30.  8.  5.  9.  7.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 0. 14.  3.  0.  0.] 
adversary cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0] -> size -> 29 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -4.3780646324157715
desired expected reward: 49.45916748046875



buy possibilites: [-1] 
expected returns: [[24.919657]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  8. 29.  6.] 
cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 24. 30. 23. 30.  8.  4.  9.  7.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 0. 14.  3.  0.  0.] 
adversary cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0] -> size -> 29 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -60.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -367.0 

action type: buy - action 6.0
Learning step: -19.96030616760254
desired expected reward: 23.459657669067383






Player: 1 
cards in hand: [ 0. 14.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0.  0.] 
cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 23. 30.  8.  4.  9.  7.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 6.  6.  1. 15.  0.] 
adversary cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.  6.  8.  0.  8. 29.  6.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6] -> size -> 28 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 24. 30. 23. 30.  8.  4.  9.  7.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 6.  6. 15.] 
adversary cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.  6.  8.  0.  8. 29.  6.
  1.  0.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6] -> size -> 28 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 24. 30. 23. 30.  8.  4.  9.  7.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 6.  6. 15.] 
adversary cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.  6.  8.  0.  8. 29.  6.
  1.  0.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6] -> size -> 28 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 24. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 6.  6. 15.] 
adversary cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.  6.  8.  0.  8. 29.  6.
  1.  0.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6] -> size -> 28 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 6.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[61.34758 ]
 [56.017815]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 15.] 
cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.  6.  8.  0.  8. 29.  6.
  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22. 11. 14.  0.  3.  0.  0.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0 11] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: discard_down_to_3_cards - action 3
Learning step: -4.262388706207275
desired expected reward: 40.810813903808594



action possibilites: [-1] 
expected returns: [[77.13676]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.  6.  8.  0.  8. 29.  6.
  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22. 11. 14.  0.  3.  0.  0.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0 11] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action 15.0
Learning step: -3.415314197540283
desired expected reward: 52.602508544921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[64.35238 ]
 [63.646942]
 [77.04117 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.  6.  8.  0.  8. 29.  6.
  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 24. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22. 11. 14.  0.  3.  0.  0.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0 11] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: -4.60081148147583
desired expected reward: 72.53594207763672



buy possibilites: [-1] 
expected returns: [[85.74754]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.  6.  8.  0.  8. 29.  6.
  1.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22. 11. 14.  0.  3.  0.  0.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0 11] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action 0.0
Learning step: -4.945560455322266
desired expected reward: 59.40681076049805






Player: 1 
cards in hand: [0. 3. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22. 11. 14.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [1. 6. 3. 0. 0.] 
adversary cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.  6.  8.  0.  8. 29.  6.
  1.  0.  0. 15.  6.  6.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0] -> size -> 29 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22. 11. 14.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 24. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [1. 6. 3. 0. 0.] 
adversary cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.  6.  8.  0.  8. 29.  6.
  1.  0.  0. 15.  6.  6.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0] -> size -> 29 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22. 11. 14.  0.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0 11  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [1. 6. 3. 0. 0.] 
adversary cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.  6.  8.  0.  8. 29.  6.
  1.  0.  0. 15.  6.  6.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0] -> size -> 29 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [1. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[61.07883]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 3. 0. 0.] 
cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.  6.  8.  0.  8. 29.  6.
  1.  0.  0. 15.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [11.  3. 15.  0.  1.] 
adversary cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22. 11. 14.  0.  3.  0.  0.  0.
  0.  3.  3.  8.  0.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0 11  0] -> size -> 31 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -6.263103485107422
desired expected reward: 79.48443603515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[49.81846 ]
 [51.35333 ]
 [51.548233]
 [49.3098  ]
 [51.5898  ]
 [53.64047 ]
 [51.885616]
 [54.533108]
 [51.371647]
 [52.08053 ]
 [52.931595]
 [58.670654]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 3. 0. 0.] 
cards in discard: [22. 14.  8.  1.  0.  3.  3.  0. 16.  0.  6.  3.  6.  8.  0.  8. 29.  6.
  1.  0.  0. 15.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [11.  3. 15.  0.  1.] 
adversary cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22. 11. 14.  0.  3.  0.  0.  0.
  0.  3.  3.  8.  0.] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0 11  0] -> size -> 31 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -5.175818920135498
desired expected reward: 55.903011322021484



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  3. 15.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 15.  0.  1.] 
cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22. 11. 14.  0.  3.  0.  0.  0.
  0.  3.  3.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0 11  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 0. 15.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0] -> size -> 29 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 15.  0.  1.] 
cards in discard: [ 0.  0. 14.  8. 29.  0. 14.  0. 25.  8. 22. 11. 14.  0.  3.  0.  0.  0.
  0.  3.  3.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0 11  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 0. 15.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0] -> size -> 29 
adversary victory points: -2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[113.346825]
 [106.151344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 0.  0.  0. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0 11  0] -> size -> 31 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -3.785947561264038
desired expected reward: 54.88471221923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[107.9219  ]
 [109.866875]
 [110.08961 ]
 [107.26007 ]
 [112.71362 ]
 [110.516594]
 [110.73934 ]
 [119.015366]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 0.  0.  0. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0 11  0] -> size -> 31 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -6.456719875335693
desired expected reward: 106.89010620117188



buy possibilites: [-1] 
expected returns: [[87.12861]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6.  0.  0.] 
cards in discard: [1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 0.  0.  0. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0 11  0] -> size -> 31 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -49 

action type: buy - action 1.0
Learning step: -5.982950687408447
desired expected reward: 103.8839340209961






Player: 1 
cards in hand: [ 0.  0.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  0 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15
 22 15  3  3  0 11  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [6. 3. 0. 6. 0.] 
adversary cards in discard: [ 1.  0. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1] -> size -> 30 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  3 14 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15 22
 15  3  3  0 11  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 23. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [6. 3. 0. 6. 0.] 
adversary cards in discard: [ 1.  0. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1] -> size -> 30 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  3 14 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15 22
 15  3  3  0 11  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 23. 30. 23. 30.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [6. 3. 0. 6. 0.] 
adversary cards in discard: [ 1.  0. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1] -> size -> 30 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [4.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  3 14 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15 22
 15  3  3  0 11  0  4] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 23. 29.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [6. 3. 0. 6. 0.] 
adversary cards in discard: [ 1.  0. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1] -> size -> 30 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.131424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 6. 0.] 
cards in discard: [ 1.  0. 15.  6.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 23. 29.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [14.  8. 14. 14.  0.] 
adversary cards in discard: [ 4. 15.  0.  0.  8.] 
adversary owned cards: [ 8  3 14 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15 22
 15  3  3  0 11  0  4] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -8.505973815917969
desired expected reward: 78.62263488769531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[18.233734]
 [20.224503]
 [17.641651]
 [20.607079]
 [29.775438]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6. 0.] 
cards in discard: [ 1.  0. 15.  6.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 23. 30. 23. 29.  8.  4.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [14.  8. 14. 14.  0.] 
adversary cards in discard: [ 4. 15.  0.  0.  8.] 
adversary owned cards: [ 8  3 14 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15 22
 15  3  3  0 11  0  4] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -5.860867500305176
desired expected reward: 25.270557403564453



buy possibilites: [-1] 
expected returns: [[79.0529]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6. 0.] 
cards in discard: [ 1.  0. 15.  6.  0.  0.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 23. 30. 23. 29.  8.  3.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [14.  8. 14. 14.  0.] 
adversary cards in discard: [ 4. 15.  0.  0.  8.] 
adversary owned cards: [ 8  3 14 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15 22
 15  3  3  0 11  0  4] -> size -> 31 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -100.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -408.0 

action type: buy - action 6.0
Learning step: -19.503393173217773
desired expected reward: -1.8617420196533203






Player: 1 
cards in hand: [14.  8. 14. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 14. 14.  0.] 
cards in discard: [ 4. 15.  0.  0.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15 22
 15  3  3  0 11  0  4] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 23. 29.  8.  3.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [3. 6. 0. 1. 1.] 
adversary cards in discard: [ 1.  0. 15.  6.  0.  0.  6.  6.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1  6] -> size -> 31 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 14.  0.] 
cards in discard: [ 4. 15.  0.  0.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3 14 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15 22
 15  3  3  0 11  0  4] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 23. 30. 23. 29.  8.  3.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [3. 6. 0.] 
adversary cards in discard: [ 1.  0. 15.  6.  0.  0.  6.  6.  3.  0.  6.  0.  1.  1.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1  6] -> size -> 31 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14. 14.  0.] 
cards in discard: [ 4. 15.  0.  0.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3 14 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15 22
 15  3  3  0 11  0  4] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 23. 30. 23. 29.  8.  3.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [3. 6. 0.] 
adversary cards in discard: [ 1.  0. 15.  6.  0.  0.  6.  6.  3.  0.  6.  0.  1.  1.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1  6] -> size -> 31 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[159.73439]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0.] 
cards in discard: [ 1.  0. 15.  6.  0.  0.  6.  6.  3.  0.  6.  0.  1.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 23. 29.  8.  3.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [15.  8.  0.  3.  3.] 
adversary cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.] 
adversary owned cards: [ 8  3 14 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15 22
 15  3  3  0 11  0  4] -> size -> 31 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: discard_down_to_3_cards - action 3
Learning step: -1.8166592121124268
desired expected reward: -1.603005051612854





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[142.33281]
 [141.36223]
 [159.243  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [ 1.  0. 15.  6.  0.  0.  6.  6.  3.  0.  6.  0.  1.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 23. 30. 23. 29.  8.  3.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [15.  8.  0.  3.  3.] 
adversary cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.] 
adversary owned cards: [ 8  3 14 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15 22
 15  3  3  0 11  0  4] -> size -> 31 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action -1.0
Learning step: -9.973685264587402
desired expected reward: 149.76071166992188



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15.  8.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  3.  3.] 
cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14 14  0  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 15 22
 15  3  3  0 11  0  4] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 23. 29.  8.  3.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [16. 29.  3. 22.  1.] 
adversary cards in discard: [ 1.  0. 15.  6.  0.  0.  6.  6.  3.  0.  6.  0.  1.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1  6] -> size -> 31 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 23. 29.  8.  3.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [16. 29.  3. 22.  1.] 
adversary cards in discard: [ 1.  0. 15.  6.  0.  0.  6.  6.  3.  0.  6.  0.  1.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1  6] -> size -> 31 
adversary victory points: -3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 23. 30. 23. 29.  8.  3.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [16. 29.  3. 22.  1.] 
adversary cards in discard: [ 1.  0. 15.  6.  0.  0.  6.  6.  3.  0.  6.  0.  1.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1  6] -> size -> 31 
adversary victory points: -3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 23. 29.  8.  3.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [16. 29.  3. 22.  1.] 
adversary cards in discard: [ 1.  0. 15.  6.  0.  0.  6.  6.  3.  0.  6.  0.  1.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1  6] -> size -> 31 
adversary victory points: -3
player victory points: 6 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [16. 29.  3. 22.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 22.] 
expected returns: [[143.07439]
 [131.02213]
 [135.63472]
 [130.28847]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  3. 22.  1.] 
cards in discard: [ 1.  0. 15.  6.  0.  0.  6.  6.  3.  0.  6.  0.  1.  1.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
 22  3  0  6  0  1  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 23. 29.  8.  3.  9.  6.  3.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.  8.  3.] 
adversary owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0] -> size -> 29 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: buy - action -1.0
Learning step: -9.761219024658203
desired expected reward: 149.48178100585938



action possibilites: [-1] 
expected returns: [[152.26581]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.] 
cards in discard: [ 1.  0. 15.  6.  0.  0.  6.  6.  3.  0.  6.  0.  1.  1.  3.  6.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 23. 29.  8.  3.  9.  6.  2.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.  8.  3.] 
adversary owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0] -> size -> 29 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -74 

action type: gain_card_n - action 8
Learning step: -10.766690254211426
desired expected reward: 199.0867156982422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[138.60875]
 [140.7423 ]
 [137.96758]
 [141.1694 ]
 [150.81152]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1.] 
cards in discard: [ 1.  0. 15.  6.  0.  0.  6.  6.  3.  0.  6.  0.  1.  1.  3.  6.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 23. 30. 23. 29.  8.  3.  9.  6.  2.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.  8.  3.] 
adversary owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0] -> size -> 29 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1
Learning step: -8.251200675964355
desired expected reward: 144.0146026611328



buy possibilites: [-1] 
expected returns: [[162.00784]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1.] 
cards in discard: [ 1.  0. 15.  6.  0.  0.  6.  6.  3.  0.  6.  0.  1.  1.  3.  6.  0.  8.
  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  2.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.  8.  3.] 
adversary owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0] -> size -> 29 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -59 

action type: buy - action 3.0
Learning step: -5.767073631286621
desired expected reward: 123.47792053222656






Player: 1 
cards in hand: [ 3.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  2.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [8. 8. 6. 3. 6.] 
adversary cards in discard: [ 1.  0. 15.  6.  0.  0.  6.  6.  3.  0.  6.  0.  1.  1.  3.  6.  0.  8.
  3. 16. 29.  3.  1.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3] -> size -> 32 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  2.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [8. 8. 6. 3. 6.] 
adversary cards in discard: [ 1.  0. 15.  6.  0.  0.  6.  6.  3.  0.  6.  0.  1.  1.  3.  6.  0.  8.
  3. 16. 29.  3.  1.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3] -> size -> 32 
adversary victory points: -2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [8. 8. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[109.53416]
 [ 95.00804]
 [ 95.00804]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 6. 3. 6.] 
cards in discard: [ 1.  0. 15.  6.  0.  0.  6.  6.  3.  0.  6.  0.  1.  1.  3.  6.  0.  8.
  3. 16. 29.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  2.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 0.  0.  8. 22. 25.] 
adversary cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.  8.  3.  3.  0. 11.  0.  0.] 
adversary owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0] -> size -> 29 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -10.127776145935059
desired expected reward: 151.88006591796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 91.40223]
 [ 90.4084 ]
 [110.19276]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 6. 3. 6.] 
cards in discard: [ 1.  0. 15.  6.  0.  0.  6.  6.  3.  0.  6.  0.  1.  1.  3.  6.  0.  8.
  3. 16. 29.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  2.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 0.  0.  8. 22. 25.] 
adversary cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.  8.  3.  3.  0. 11.  0.  0.] 
adversary owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0] -> size -> 29 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -7.535785675048828
desired expected reward: 101.99836730957031



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  8. 22. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 22. 25.] 
cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.  8.  3.  3.  0. 11.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  2.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3] -> size -> 32 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 22. 25.] 
cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.  8.  3.  3.  0. 11.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  2.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3] -> size -> 32 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 22. 25.] 
cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.  8.  3.  3.  0. 11.  0.  0.
  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  1.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3] -> size -> 32 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[81.63541]
 [74.21279]
 [73.68275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  1.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 3. 29.  1.  0. 11.] 
adversary cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.  8.  3.  3.  0. 11.  0.  0.
  8.  0.  0.  8. 22. 25.] 
adversary owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8] -> size -> 30 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -8.097940444946289
desired expected reward: 102.09481811523438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[74.11942 ]
 [75.87601 ]
 [73.59404 ]
 [76.22716 ]
 [83.334076]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  1.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 3. 29.  1.  0. 11.] 
adversary cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.  8.  3.  3.  0. 11.  0.  0.
  8.  0.  0.  8. 22. 25.] 
adversary owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8] -> size -> 30 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -6.654988765716553
desired expected reward: 74.98043823242188



buy possibilites: [-1] 
expected returns: [[50.202126]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0.  0. 14.] 
cards in discard: [8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  0.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 3. 29.  1.  0. 11.] 
adversary cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.  8.  3.  3.  0. 11.  0.  0.
  8.  0.  0.  8. 22. 25.] 
adversary owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8] -> size -> 30 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -79 

action type: buy - action 8.0
Learning step: -6.631810188293457
desired expected reward: 69.59535217285156






Player: 1 
cards in hand: [ 3. 29.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1.  0. 11.] 
cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.  8.  3.  3.  0. 11.  0.  0.
  8.  0.  0.  8. 22. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  0.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 6.  8. 15.  1.  3.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3  8] -> size -> 33 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  1.  0. 11.] 
cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.  8.  3.  3.  0. 11.  0.  0.
  8.  0.  0.  8. 22. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  0.  9.  8.  6. 10.  9.  8.  7.] 
adversary cards in hand: [ 6.  8. 15.  1.  3.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3  8] -> size -> 33 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  1.  0. 11.] 
cards in discard: [ 4. 15.  0.  0.  8. 14.  8. 14. 14.  0.  0.  8.  3.  3.  0. 11.  0.  0.
  8.  0.  0.  8. 22. 25. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 6.  8. 15.  1.  3.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3  8] -> size -> 33 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 6.  8. 15.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[40.88066 ]
 [33.990852]
 [35.048977]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 15.  1.  3.] 
cards in discard: [ 8.  3.  8.  0.  0. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 3.  0. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8 10] -> size -> 31 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -6.00242805480957
desired expected reward: 44.19969940185547



action possibilites: [-1] 
expected returns: [[80.46397]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 1. 3.] 
cards in discard: [ 8.  3.  8.  0.  0. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 3.  0. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8 10] -> size -> 31 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action 15.0
Learning step: -3.2920098304748535
desired expected reward: 31.75697135925293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[71.80173 ]
 [73.376366]
 [71.33568 ]
 [81.07281 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 1. 3.] 
cards in discard: [ 8.  3.  8.  0.  0. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 3.  0. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8 10] -> size -> 31 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -5.646887302398682
desired expected reward: 74.81707763671875






Player: 1 
cards in hand: [ 3.  0. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 22. 29.  8.  3.  9.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [16.  3.  0.  1.  3.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3  8] -> size -> 33 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 22. 29.  8.  2.  9.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [16.  3.  0.  1.  3.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3  8  6] -> size -> 34 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 23. 30. 22. 29.  8.  2.  9.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [16.  3.  0.  1.  3.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3  8  6] -> size -> 34 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0. 8.] 
cards in discard: [3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8 10  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 23. 30. 21. 29.  8.  2.  9.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [16.  3.  0.  1.  3.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6.] 
adversary owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3  8  6] -> size -> 34 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [16.  3.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[98.766014]
 [90.5523  ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  1.  3.] 
cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29
  3  0  6  0  1  6  8  3  8  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 21. 29.  8.  2.  9.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 8.  3. 11. 29. 14.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8 10  3] -> size -> 32 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -408 

action type: buy - action -1.0
Learning step: -22.291584014892578
desired expected reward: 58.78121566772461



action possibilites: [-1] 
expected returns: [[128.03946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3.] 
cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 21. 29.  8.  2.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 8.  3. 11. 29. 14.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8 10  3] -> size -> 32 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -83 

action type: gain_card_n - action 4
Learning step: -3.8087525367736816
desired expected reward: 46.98405075073242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[103.46516 ]
 [106.34431 ]
 [106.71484 ]
 [102.51402 ]
 [110.650566]
 [107.72308 ]
 [120.729454]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3.] 
cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 23. 30. 21. 29.  8.  2.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 8.  3. 11. 29. 14.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8 10  3] -> size -> 32 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -99 

action type: take_action - action -1
Learning step: -8.817604064941406
desired expected reward: 119.22185516357422



buy possibilites: [-1] 
expected returns: [[68.869896]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3.] 
cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 23. 30. 21. 29.  8.  1.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 8.  3. 11. 29. 14.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8 10  3] -> size -> 32 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -120.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -410.0 

action type: buy - action 6.0
Learning step: -24.076128005981445
desired expected reward: 78.4378890991211






Player: 1 
cards in hand: [ 8.  3. 11. 29. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11. 29. 14.] 
cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 14  8 11  0  1 29  0  3 14  0  0  0  0  8 25  8  0  0 22 15  3  3
  0 11  0  4  0  8 10  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 21. 29.  8.  1.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6] -> size -> 35 
adversary victory points: -5
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  8 11  0  1  0 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0
  4  0  8 10  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 21. 29.  8.  1.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6] -> size -> 35 
adversary victory points: -5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  8 11  0  1  0 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0
  4  0  8 10  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 23. 30. 21. 29.  8.  1.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6] -> size -> 35 
adversary victory points: -5
player victory points: 6 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [6. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[43.23699 ]
 [38.483147]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 21. 29.  8.  1.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 8. 14. 15.  0. 14.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.] 
adversary owned cards: [ 8 14  8 11  0  1  0 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0
  4  0  8 10  3] -> size -> 29 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -120 

action type: buy - action -1
Learning step: -8.505492210388184
desired expected reward: 60.364402770996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[29.69878 ]
 [30.464348]
 [29.470795]
 [34.022015]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 23. 30. 21. 29.  8.  1.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 8. 14. 15.  0. 14.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.] 
adversary owned cards: [ 8 14  8 11  0  1  0 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0
  4  0  8 10  3] -> size -> 29 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -120 

action type: take_action - action -1.0
Learning step: -7.090491771697998
desired expected reward: 29.118396759033203



buy possibilites: [-1] 
expected returns: [[40.15488]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.
  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 23. 30. 21. 29.  8.  0.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 8. 14. 15.  0. 14.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.] 
adversary owned cards: [ 8 14  8 11  0  1  0 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0
  4  0  8 10  3] -> size -> 29 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -120.    0.    0.    0.    0.    0.    0.    0.   -1.
    0. -300.    0.    0.] 
sum of rewards: -432.0 

action type: buy - action 6.0
Learning step: -22.170055389404297
desired expected reward: 7.300731658935547






Player: 1 
cards in hand: [ 8. 14. 15.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 15. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 15.  0. 14.] 
cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8 11  0  1  0 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0
  4  0  8 10  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 21. 29.  8.  0.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [6. 0. 8. 6. 6.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.
  6.  6.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6] -> size -> 36 
adversary victory points: -6
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14.] 
cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 11  1  0 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0
  8 10  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 21. 29.  8.  0.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [6. 0. 8. 6. 6.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.
  6.  6.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6] -> size -> 36 
adversary victory points: -6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 14.] 
cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 11  1  0 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0
  8 10  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 23. 30. 21. 29.  8.  0.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [6. 0. 8. 6. 6.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.
  6.  6.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6] -> size -> 36 
adversary victory points: -6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 14.] 
cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 11  1  0 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0
  8 10  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 23. 30. 21. 29.  8.  0.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [6. 0. 8. 6. 6.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.
  6.  6.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6] -> size -> 36 
adversary victory points: -6
player victory points: 6 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [6. 0. 8. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[47.05541 ]
 [38.317047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 6. 6.] 
cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.
  6.  6.  0.  8.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 23. 30. 21. 29.  8.  0.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 0.  1. 11.  0.  8.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.  0.  8. 15. 14.] 
adversary owned cards: [ 8  8 11  1  0 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0
  8 10  3  0] -> size -> 28 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -131 

action type: buy - action -1
Learning step: -7.563019752502441
desired expected reward: 32.591861724853516





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[35.390568]
 [46.79067 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 6. 6.] 
cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.
  6.  6.  0.  8.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 23. 30. 21. 29.  8.  0.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 0.  1. 11.  0.  8.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.  0.  8. 15. 14.] 
adversary owned cards: [ 8  8 11  1  0 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0
  8 10  3  0] -> size -> 28 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -131 

action type: take_action - action -1.0
Learning step: -7.9335036277771
desired expected reward: 39.12190246582031



buy possibilites: [-1] 
expected returns: [[49.62705]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 6. 6.] 
cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.
  6.  6.  0.  8.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 23. 30. 21. 29.  8.  0.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 0.  1. 11.  0.  8.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.  0.  8. 15. 14.] 
adversary owned cards: [ 8  8 11  1  0 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0
  8 10  3  0] -> size -> 28 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -120.    0.    0.    0.  -30.    0.    0.    0.   -2.
    0.    0.    0.    0.] 
sum of rewards: -163.0 

action type: buy - action 0.0
Learning step: -8.8029203414917
desired expected reward: 26.587650299072266






Player: 1 
cards in hand: [ 0.  1. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.  0.  8.] 
cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.  0.  8. 15. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 11  1  0 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0
  8 10  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 21. 29.  8.  0.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [0. 1. 6. 6. 0.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.
  6.  6.  0.  8.  0.  3.  0.  6.  0.  8.  6.  6.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0] -> size -> 37 
adversary victory points: -6
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.  0.  8. 15. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 21. 29.  8.  0.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [0. 1. 6. 6. 0.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.
  6.  6.  0.  8.  0.  3.  0.  6.  0.  8.  6.  6.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0] -> size -> 37 
adversary victory points: -6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.  0.  8. 15. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 23. 30. 21. 29.  8.  0.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [0. 1. 6. 6. 0.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.
  6.  6.  0.  8.  0.  3.  0.  6.  0.  8.  6.  6.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0] -> size -> 37 
adversary victory points: -6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.  0.  8. 15. 14.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 23. 30. 20. 29.  8.  0.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [0. 1. 6. 6. 0.] 
adversary cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.
  6.  6.  0.  8.  0.  3.  0.  6.  0.  8.  6.  6.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0] -> size -> 37 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [0. 1. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[92.85814]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 6. 0.] 
cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.
  6.  6.  0.  8.  0.  3.  0.  6.  0.  8.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 20. 29.  8.  0.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [22.  0.  8. 10.  4.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.  0.  8. 15. 14.  3.  8.  1.  0.] 
adversary owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3] -> size -> 27 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1
Learning step: -7.442044258117676
desired expected reward: 42.18500518798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[81.36159 ]
 [83.391266]
 [83.639984]
 [83.70699 ]
 [86.514885]
 [87.77929 ]
 [83.41188 ]
 [84.37082 ]
 [85.53911 ]
 [93.614815]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 6. 0.] 
cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.
  6.  6.  0.  8.  0.  3.  0.  6.  0.  8.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 23. 30. 20. 29.  8.  0.  8.  6.  0.  9.  8.  6. 10.  8.  8.  7.] 
adversary cards in hand: [22.  0.  8. 10.  4.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.  0.  8. 15. 14.  3.  8.  1.  0.] 
adversary owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3] -> size -> 27 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: take_action - action -1.0
Learning step: -9.707927703857422
desired expected reward: 83.15020751953125



buy possibilites: [-1] 
expected returns: [[91.02532]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 6. 0.] 
cards in discard: [ 8.  3.  8.  0.  0. 14. 15.  6.  8.  1.  3.  6. 16.  6. 16.  0.  1.  3.
  6.  6.  0.  8.  0.  3.  0.  6.  0.  8.  6.  6. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 20. 29.  8.  0.  8.  6.  0.  9.  8.  5. 10.  8.  8.  7.] 
adversary cards in hand: [22.  0.  8. 10.  4.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.  0.  8. 15. 14.  3.  8.  1.  0.] 
adversary owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3] -> size -> 27 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0   -3    0    0
   32    0] 
sum of rewards: -112 

action type: buy - action 14.0
Learning step: -7.7225236892700195
desired expected reward: 75.68934631347656






Player: 1 
cards in hand: [22.  0.  8. 10.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  8. 10.  4.] 
cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.  0.  8. 15. 14.  3.  8.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 20. 29.  8.  0.  8.  6.  0.  9.  8.  5. 10.  8.  8.  7.] 
adversary cards in hand: [ 6.  8. 14.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14] -> size -> 38 
adversary victory points: -6
player victory points: 7 


action possibilites: [-1. 22.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  8.  4.  3.] 
cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.  0.  8. 15. 14.  3.  8.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 20. 29.  8.  0.  8.  6.  0.  9.  8.  5. 10.  8.  8.  7.] 
adversary cards in hand: [ 6.  8. 14.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14] -> size -> 38 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.  8.  4.  3.] 
cards in discard: [ 3. 25.  3.  0.  0.  0.  0.  8.  8. 11.  0.  8. 15. 14.  3.  8.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 23. 30. 20. 29.  8.  0.  8.  6.  0.  9.  8.  5. 10.  8.  8.  7.] 
adversary cards in hand: [ 6.  8. 14.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14] -> size -> 38 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 6.  8. 14.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 29.] 
expected returns: [[10.017333]
 [ 8.031557]
 [ 7.879295]
 [ 8.794097]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 14.  1. 29.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 20. 29.  8.  0.  8.  6.  0.  9.  8.  5. 10.  8.  8.  7.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3] -> size -> 27 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1
Learning step: -11.395463943481445
desired expected reward: 79.6298599243164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[6.6842265]
 [7.208594 ]
 [9.440946 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 14.  1. 29.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 23. 30. 20. 29.  8.  0.  8.  6.  0.  9.  8.  5. 10.  8.  8.  7.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3] -> size -> 27 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: take_action - action -1.0
Learning step: -7.362814426422119
desired expected reward: 2.654524326324463



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 20. 29.  8.  0.  8.  6.  0.  9.  8.  5. 10.  8.  8.  7.] 
adversary cards in hand: [6. 3. 6. 6. 1.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14] -> size -> 38 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 9. 23. 30. 20. 29.  8.  0.  8.  6.  0.  9.  8.  5. 10.  8.  8.  7.] 
adversary cards in hand: [6. 3. 6. 6. 1.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14] -> size -> 38 
adversary victory points: -6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 23. 30. 20. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [6. 3. 6. 6. 1.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14] -> size -> 38 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [6. 3. 6. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[16.365463]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 6. 1.] 
cards in discard: [ 6.  8. 14.  1. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 20. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [29.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3 29] -> size -> 28 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1.0
Learning step: -7.153824806213379
desired expected reward: 2.287125587463379





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[15.8138895]
 [15.82792  ]
 [16.073147 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 6. 1.] 
cards in discard: [ 6.  8. 14.  1. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 23. 30. 20. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [29.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3 29] -> size -> 28 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: take_action - action -1.0
Learning step: -7.509091377258301
desired expected reward: 8.856371879577637



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 15.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  0.  0.] 
cards in discard: [29.  0.  1.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 20. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [0. 8. 3. 8. 3.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14] -> size -> 38 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0.  0.] 
cards in discard: [29.  0.  1.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 23. 30. 20. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [0. 8. 3. 8. 3.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14] -> size -> 38 
adversary victory points: -6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0.  0.] 
cards in discard: [29.  0.  1.  0.  0.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3 29  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 20. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [0. 8. 3. 8. 3.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14] -> size -> 38 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [0. 8. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[42.567627]
 [39.343456]
 [39.343456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 8. 3.] 
cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 20. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [ 0. 25.  0.  4. 22.] 
adversary cards in discard: [29.  0.  1.  0.  0.  0.  1.  3. 15.  0.  0.  0.] 
adversary owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3 29  1] -> size -> 29 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1.0
Learning step: -6.927381992340088
desired expected reward: 9.14576530456543





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[39.16329 ]
 [43.369846]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 8. 3.] 
cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 22. 30. 20. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [ 0. 25.  0.  4. 22.] 
adversary cards in discard: [29.  0.  1.  0.  0.  0.  1.  3. 15.  0.  0.  0.] 
adversary owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3 29  1] -> size -> 29 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: take_action - action -1.0
Learning step: -8.233379364013672
desired expected reward: 34.33424377441406



buy possibilites: [-1] 
expected returns: [[8.672128]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 8. 3.] 
cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 22. 30. 20. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [ 0. 25.  0.  4. 22.] 
adversary cards in discard: [29.  0.  1.  0.  0.  0.  1.  3. 15.  0.  0.  0.] 
adversary owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3 29  1] -> size -> 29 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -130.    0.    0.    0.  -30.    0.    0.    0.   -4.
    0.    0.    0.    0.] 
sum of rewards: -175.0 

action type: buy - action 0.0
Learning step: -10.513041496276855
desired expected reward: 28.650249481201172






Player: 1 
cards in hand: [ 0. 25.  0.  4. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  4. 22.] 
cards in discard: [29.  0.  1.  0.  0.  0.  1.  3. 15.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3 29  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 20. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [ 0. 15.  6.  6.  6.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0] -> size -> 39 
adversary victory points: -6
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  4.  3. 14.  8.] 
cards in discard: [29.  0.  1.  0.  0.  0.  1.  3. 15.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3 29  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 20. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [ 0. 15.  6.  6.  6.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0] -> size -> 39 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  4.  3. 14.  8.] 
cards in discard: [29.  0.  1.  0.  0.  0.  1.  3. 15.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3 29  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 22. 30. 20. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [ 0. 15.  6.  6.  6.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0] -> size -> 39 
adversary victory points: -6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  4.  3. 14.  8.] 
cards in discard: [29.  0.  1.  0.  0.  0.  1.  3. 15.  0.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3 29  1  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 19. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [ 0. 15.  6.  6.  6.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0] -> size -> 39 
adversary victory points: -6
player victory points: 8 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  6.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[47.361057]
 [44.471992]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6.  6.  6.] 
cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 19. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [ 0. 11.  3.  8.  8.] 
adversary cards in discard: [29.  0.  1.  0.  0.  0.  1.  3. 15.  0.  0.  0.  3. 22.  0. 25.  0.  4.
  3. 14.  8.] 
adversary owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3 29  1  3] -> size -> 30 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -151 

action type: buy - action -1
Learning step: -6.939150333404541
desired expected reward: 1.7329773902893066





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[38.01146 ]
 [42.214676]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6.  6.  6.] 
cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 22. 30. 19. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [ 0. 11.  3.  8.  8.] 
adversary cards in discard: [29.  0.  1.  0.  0.  0.  1.  3. 15.  0.  0.  0.  3. 22.  0. 25.  0.  4.
  3. 14.  8.] 
adversary owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3 29  1  3] -> size -> 30 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -151 

action type: take_action - action -1.0
Learning step: -8.721084594726562
desired expected reward: 33.08131790161133



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11.  3.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  8.  8.] 
cards in discard: [29.  0.  1.  0.  0.  0.  1.  3. 15.  0.  0.  0.  3. 22.  0. 25.  0.  4.
  3. 14.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1 14  0  0  0  0  8 25  8  0  0 22 15  3  3  0 11  0  4  0  8 10
  3  0  3 29  1  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 19. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [6. 6. 1. 8. 0.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0] -> size -> 39 
adversary victory points: -6
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.  0.  1.  0.  0.  0.  1.  3. 15.  0.  0.  0.  3. 22.  0. 25.  0.  4.
  3. 14.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1 14  0  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29
  1  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 19. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [6. 6. 1. 8. 0.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0] -> size -> 39 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.  1.  0.  0.  0.  1.  3. 15.  0.  0.  0.  3. 22.  0. 25.  0.  4.
  3. 14.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1 14  0  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29
  1  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 22. 30. 19. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [6. 6. 1. 8. 0.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0] -> size -> 39 
adversary victory points: -6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.  1.  0.  0.  0.  1.  3. 15.  0.  0.  0.  3. 22.  0. 25.  0.  4.
  3. 14.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1 14  0  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29
  1  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [6. 6. 1. 8. 0.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0] -> size -> 39 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [6. 6. 1. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[26.973595]
 [20.812874]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 1. 8. 0.] 
cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [ 3.  3. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 14  0  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29
  1  3  0] -> size -> 27 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1.0
Learning step: -8.59896469116211
desired expected reward: 33.6157112121582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[17.844975]
 [19.0082  ]
 [19.166084]
 [20.929533]
 [19.620733]
 [25.453053]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 1. 8. 0.] 
cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  8.  8.  7.] 
adversary cards in hand: [ 3.  3. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 14  0  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29
  1  3  0] -> size -> 27 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: take_action - action -1.0
Learning step: -7.900951385498047
desired expected reward: 19.07265281677246



buy possibilites: [-1] 
expected returns: [[1.6869228]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 1. 8. 0.] 
cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 3.  3. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 14  0  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29
  1  3  0] -> size -> 27 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0   -5    0    0
   18    0] 
sum of rewards: -128 

action type: buy - action 10.0
Learning step: -7.343080997467041
desired expected reward: 12.277656555175781






Player: 1 
cards in hand: [ 3.  3. 10.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  8.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14  0  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29
  1  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 0.  8.  0. 16.  0.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6. 10.  6.  6.  1.  8.  0.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10] -> size -> 40 
adversary victory points: -6
player victory points: 7 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  1 14  0  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29
  1  3  0] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 0.  8.  0. 16.  0.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6. 10.  6.  6.  1.  8.  0.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10] -> size -> 40 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  1 14  0  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29
  1  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 0.  8.  0. 16.  0.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6. 10.  6.  6.  1.  8.  0.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10] -> size -> 40 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[15.359016]
 [11.254637]
 [11.088371]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 16.  0.] 
cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6. 10.  6.  6.  1.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [10.  3.  3.  8.  8.  0.] 
adversary owned cards: [ 8  1 14  0  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29
  1  3  0] -> size -> 27 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1
Learning step: -6.829675197601318
desired expected reward: -5.142752647399902





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[10.582901]
 [11.435106]
 [11.537619]
 [12.751846]
 [11.83758 ]
 [15.93305 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 16.  0.] 
cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6. 10.  6.  6.  1.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  6.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [10.  3.  3.  8.  8.  0.] 
adversary owned cards: [ 8  1 14  0  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29
  1  3  0] -> size -> 27 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: take_action - action -1.0
Learning step: -7.512013912200928
desired expected reward: 7.847004413604736



buy possibilites: [-1] 
expected returns: [[10.397495]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 16.  0.] 
cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6. 10.  6.  6.  1.  8.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [10.  3.  3.  8.  8.  0.] 
adversary owned cards: [ 8  1 14  0  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29
  1  3  0] -> size -> 27 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0   -6    0    0
   18    0] 
sum of rewards: -129 

action type: buy - action 11.0
Learning step: -6.853649139404297
desired expected reward: 5.898199081420898






Player: 1 
cards in hand: [3. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [10.  3.  3.  8.  8.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14  0  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29
  1  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 3.  0.  6.  0. 16.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6. 10.  6.  6.  1.  8.  0. 11.  0.  8.  0. 16.  0.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
adversary victory points: -6
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [10.  3.  3.  8.  8.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 3.  0.  6.  0. 16.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6. 10.  6.  6.  1.  8.  0. 11.  0.  8.  0. 16.  0.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [10.  3.  3.  8.  8.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 3.  0.  6.  0. 16.] 
adversary cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6. 10.  6.  6.  1.  8.  0. 11.  0.  8.  0. 16.  0.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  6.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[12.84404  ]
 [ 8.1918545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6.  0. 16.] 
cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6. 10.  6.  6.  1.  8.  0. 11.  0.  8.  0. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [25.  8.  0.  0. 14.] 
adversary cards in discard: [10.  3.  3.  8.  8.  0.  8.  3.  3.  0.] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0] -> size -> 26 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1
Learning step: -7.314968109130859
desired expected reward: 3.0825271606445312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 7.088642]
 [ 8.156942]
 [12.84404 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6.  0. 16.] 
cards in discard: [ 6.  8. 14.  1. 29.  6.  3.  6.  6.  1.  0.  0.  8.  3.  8.  3.  0. 15.
  6.  6.  6. 10.  6.  6.  1.  8.  0. 11.  0.  8.  0. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [25.  8.  0.  0. 14.] 
adversary cards in discard: [10.  3.  3.  8.  8.  0.  8.  3.  3.  0.] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0] -> size -> 26 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: take_action - action -1.0
Learning step: -7.454216003417969
desired expected reward: 5.389825820922852



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [25.  8.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 14.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  0.  0. 14.] 
cards in discard: [10.  3.  3.  8.  8.  0.  8.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 0.  8.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
adversary victory points: -6
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 14.  0. 15.] 
cards in discard: [10.  3.  3.  8.  8.  0.  8.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 0.  8.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 14.  0. 15.] 
cards in discard: [10.  3.  3.  8.  8.  0.  8.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 0.  8.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[-1.2343718]
 [-1.2343718]
 [-1.2343718]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 14.  1.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 1.  0.  1.  0. 29.] 
adversary cards in discard: [10.  3.  3.  8.  8.  0.  8.  3.  3.  0. 25.  8.  0.  0. 14.  0. 15.] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0] -> size -> 26 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1.0
Learning step: -7.719975471496582
desired expected reward: 5.124066352844238



action possibilites: [-1] 
expected returns: [[106.41973]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 1.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 0.  0. 29.] 
adversary cards in discard: [10.  3.  3.  8.  8.  0.  8.  3.  3.  0. 25.  8.  0.  0. 14.  0. 15.  1.
  1.] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0] -> size -> 26 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -121 

action type: take_action - action 14.0
Learning step: -3.593837022781372
desired expected reward: -4.828208923339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[101.544495]
 [102.982155]
 [101.69855 ]
 [103.17211 ]
 [101.17407 ]
 [103.223656]
 [105.18152 ]
 [106.713615]
 [106.032234]
 [103.01955 ]
 [104.21281 ]
 [103.70093 ]
 [102.73223 ]
 [104.500114]
 [110.00175 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 1.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 0.  0. 29.] 
adversary cards in discard: [10.  3.  3.  8.  8.  0.  8.  3.  3.  0. 25.  8.  0.  0. 14.  0. 15.  1.
  1.] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0] -> size -> 26 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -121 

action type: take_action - action -1
Learning step: -8.984000205993652
desired expected reward: 97.43572998046875






Player: 1 
cards in hand: [ 0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.] 
cards in discard: [10.  3.  3.  8.  8.  0.  8.  3.  3.  0. 25.  8.  0.  0. 14.  0. 15.  1.
  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [0. 6. 0. 3. 3.] 
adversary cards in discard: [14.  0.  8.  0.  1.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
adversary victory points: -6
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10.  3.  3.  8.  8.  0.  8.  3.  3.  0. 25.  8.  0.  0. 14.  0. 15.  1.
  1.  0.  4.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [0. 6. 0. 3. 3.] 
adversary cards in discard: [14.  0.  8.  0.  1.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  3.  3.  8.  8.  0.  8.  3.  3.  0. 25.  8.  0.  0. 14.  0. 15.  1.
  1.  0.  4.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [0. 6. 0. 3. 3.] 
adversary cards in discard: [14.  0.  8.  0.  1.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
adversary victory points: -6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  3.  3.  8.  8.  0.  8.  3.  3.  0. 25.  8.  0.  0. 14.  0. 15.  1.
  1.  0.  4.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [0. 6. 0. 3. 3.] 
adversary cards in discard: [14.  0.  8.  0.  1.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[32.626427]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [14.  0.  8.  0.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 8.  0.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0] -> size -> 27 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1.0
Learning step: -11.815993309020996
desired expected reward: 98.18575286865234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[21.761183]
 [22.838015]
 [30.102446]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [14.  0.  8.  0.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 8.  0.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0] -> size -> 27 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: take_action - action -1.0
Learning step: -8.080241203308105
desired expected reward: 24.546184539794922



buy possibilites: [-1] 
expected returns: [[32.415085]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [14.  0.  8.  0.  1.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 8.  0.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0] -> size -> 27 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -130.    0.    0.    0.  -30.    0.    0.    0.   -7.
    0.    0.    0.    0.] 
sum of rewards: -178.0 

action type: buy - action 0.0
Learning step: -9.258719444274902
desired expected reward: 12.502463340759277






Player: 1 
cards in hand: [ 8.  0.  0.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 22.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [6. 0. 8. 8. 3.] 
adversary cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11  0] -> size -> 42 
adversary victory points: -6
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 29.  0.  8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [6. 0. 8. 8. 3.] 
adversary cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11  0] -> size -> 42 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 29.  0.  8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [6. 0. 8. 8. 3.] 
adversary cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11  0] -> size -> 42 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [6. 0. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[8.169275]
 [5.083076]
 [5.083076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 8. 3.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [15.  3.  1.  4.  3.] 
adversary cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0] -> size -> 27 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1
Learning step: -8.517093658447266
desired expected reward: 23.897991180419922





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[0.29187465]
 [3.3765483 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 8. 3.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [15.  3.  1.  4.  3.] 
adversary cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0] -> size -> 27 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: take_action - action -1.0
Learning step: -7.212497234344482
desired expected reward: -2.895115852355957



buy possibilites: [-1] 
expected returns: [[33.361954]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 8. 3.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [15.  3.  1.  4.  3.] 
adversary cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0] -> size -> 27 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -130.    0.    0.    0.  -30.    0.    0.    0.   -8.
    0.    0.    0.    0.] 
sum of rewards: -179.0 

action type: buy - action 0.0
Learning step: -8.213950157165527
desired expected reward: -7.922072887420654






Player: 1 
cards in hand: [15.  3.  1.  4.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  1.  4.  3.] 
cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 0.  8.  6. 14.  0.] 
adversary cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0] -> size -> 43 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  1.  4.  3.] 
cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 0.  8.  6. 14.  0.] 
adversary cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0] -> size -> 43 
adversary victory points: -6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  1.  4.  3.] 
cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 0.  8.  6. 14.  0.] 
adversary cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.] 
adversary owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0] -> size -> 43 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  6. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[17.692356]
 [13.120615]
 [12.877201]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6. 14.  0.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6 15  8  6 14  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3
  0  6  0  1  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [25.  0.  1.  0.  3.] 
adversary cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.  0. 15.  3.  1.  4.  3.] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0  0] -> size -> 28 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1
Learning step: -8.365869522094727
desired expected reward: 24.996084213256836



action possibilites: [-1] 
expected returns: [[71.32894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3  0  6  0
  1  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [25.  0.  1.  0.  3.] 
adversary cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.  0. 15.  3.  1.  4.  3.] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0  0] -> size -> 28 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -121 

action type: trash_cards_n_from_hand - action 11
Learning step: -5.207549095153809
desired expected reward: 10.041451454162598





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[61.345833]
 [69.86626 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3  0  6  0
  1  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [25.  0.  1.  0.  3.] 
adversary cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.  0. 15.  3.  1.  4.  3.] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0  0] -> size -> 28 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -121 

action type: take_action - action -1
Learning step: -8.106882095336914
desired expected reward: 63.22206115722656






Player: 1 
cards in hand: [25.  0.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  1.  0.  3.] 
cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.  0. 15.  3.  1.  4.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [16.  6. 10. 16.  0.] 
adversary cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6.] 
adversary owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3  0  6  0
  1  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0] -> size -> 40 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  1.  0.  3.] 
cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.  0. 15.  3.  1.  4.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 22. 30. 19. 29.  8.  0.  8.  5.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [16.  6. 10. 16.  0.] 
adversary cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6.] 
adversary owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3  0  6  0
  1  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0] -> size -> 40 
adversary victory points: -6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  1.  0.  3.] 
cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.  0. 15.  3.  1.  4.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0  0 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [16.  6. 10. 16.  0.] 
adversary cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6.] 
adversary owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3  0  6  0
  1  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0] -> size -> 40 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [16.  6. 10. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 16.] 
expected returns: [[42.46128 ]
 [36.733906]
 [36.990063]
 [36.733906]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6. 10. 16.  0.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8 16  6 29  3  0  6  0
  1  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  7.  5. 10.  7.  8.  7.] 
adversary cards in hand: [ 0.  0. 14.  0.  8.] 
adversary cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.  0. 15.  3.  1.  4.  3. 11. 25.  0.  1.
  0.  3.] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0  0 11] -> size -> 29 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1.0
Learning step: -9.64993953704834
desired expected reward: 60.21631622314453



action possibilites: [-1] 
expected returns: [[46.724014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8  6 29  3  0  6  0  1
  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  7.  5. 10.  6.  8.  7.] 
adversary cards in hand: [ 0.  0. 14.  0.  8.] 
adversary cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.  0. 15.  3.  1.  4.  3. 11. 25.  0.  1.
  0.  3.] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0  0 11] -> size -> 29 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0   20    0    0    0    0   -5    0    0
    9    0] 
sum of rewards: -117 

action type: gain_card_n - action 11
Learning step: -8.140678405761719
desired expected reward: 58.698699951171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[37.57343 ]
 [43.746017]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8  6 29  3  0  6  0  1
  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  7.  5. 10.  6.  8.  7.] 
adversary cards in hand: [ 0.  0. 14.  0.  8.] 
adversary cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.  0. 15.  3.  1.  4.  3. 11. 25.  0.  1.
  0.  3.] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0  0 11] -> size -> 29 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -121 

action type: take_action - action -1
Learning step: -7.447139263153076
desired expected reward: 39.27687454223633



buy possibilites: [-1] 
expected returns: [[25.882256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8  6 29  3  0  6  0  1
  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0 10  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  7.  5. 10.  6.  8.  7.] 
adversary cards in hand: [ 0.  0. 14.  0.  8.] 
adversary cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.  0. 15.  3.  1.  4.  3. 11. 25.  0.  1.
  0.  3.] 
adversary owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0  0 11] -> size -> 29 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -130.    0.    0.   20.  -30.    0.    0.    0.   -6.
    0.    0.    0.    0.] 
sum of rewards: -157.0 

action type: buy - action 0.0
Learning step: -9.146320343017578
desired expected reward: 28.427101135253906






Player: 1 
cards in hand: [ 0.  0. 14.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.  8.] 
cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.  0. 15.  3.  1.  4.  3. 11. 25.  0.  1.
  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14  0  0  8 25  8  0  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1
  3  0  0  0 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  7.  5. 10.  6.  8.  7.] 
adversary cards in hand: [11.  6.  6.  3.  6.] 
adversary cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6. 10.  0. 16.  6. 10.  0.] 
adversary owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8  6 29  3  0  6  0  1
  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0 10  0] -> size -> 41 
adversary victory points: -6
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.  0. 15.  3.  1.  4.  3. 11. 25.  0.  1.
  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  8 25  8  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1  3  0  0  0
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  7.  5. 10.  6.  8.  7.] 
adversary cards in hand: [11.  6.  6.  3.  6.] 
adversary cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6. 10.  0. 16.  6. 10.  0.] 
adversary owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8  6 29  3  0  6  0  1
  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0 10  0] -> size -> 41 
adversary victory points: -6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [22.  8.  0.  0.  0. 29.  0.  8.  0. 15.  3.  1.  4.  3. 11. 25.  0.  1.
  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  8 25  8  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1  3  0  0  0
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  7.  5. 10.  6.  8.  7.] 
adversary cards in hand: [11.  6.  6.  3.  6.] 
adversary cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6. 10.  0. 16.  6. 10.  0.] 
adversary owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8  6 29  3  0  6  0  1
  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0 10  0] -> size -> 41 
adversary victory points: -6
player victory points: 7 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [11.  6.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[50.93457 ]
 [43.925922]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  6.  3.  6.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6. 10.  0. 16.  6. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8  6 29  3  0  6  0  1
  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0 10  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  7.  5. 10.  6.  8.  7.] 
adversary cards in hand: [ 3.  0.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8 25  8  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1  3  0  0  0
 11] -> size -> 25 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: buy - action -1
Learning step: -7.249433994293213
desired expected reward: 18.632822036743164



action possibilites: [-1] 
expected returns: [[13.741153]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 6.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6. 10.  0. 16.  6. 10.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8  6 29  3  0  6  0  1
  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0 10  0 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  6.  5. 10.  6.  8.  7.] 
adversary cards in hand: [ 3.  0.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8 25  8  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1  3  0  0  0
 11] -> size -> 25 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0   20    0    0    0    0   -7    0    0
   16    0] 
sum of rewards: -112 

action type: gain_card_n - action 5
Learning step: -7.267205238342285
desired expected reward: 32.26041793823242





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.017409]
 [13.741146]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 6.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6. 10.  0. 16.  6. 10.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8  6 29  3  0  6  0  1
  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0 10  0 29] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  6.  5. 10.  6.  8.  7.] 
adversary cards in hand: [ 3.  0.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8 25  8  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1  3  0  0  0
 11] -> size -> 25 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -121 

action type: take_action - action -1
Learning step: -6.462491035461426
desired expected reward: 7.278661727905273



buy possibilites: [-1] 
expected returns: [[6.6634474]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 6.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6. 10.  0. 16.  6. 10.  0. 29.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8  6 29  3  0  6  0  1
  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0 10  0 29  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  6.  5. 10.  6.  8.  7.] 
adversary cards in hand: [ 3.  0.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8 25  8  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1  3  0  0  0
 11] -> size -> 25 
adversary victory points: 7
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -130    0    0   20  -30    0    0    0   -8    0    0
    0    0] 
sum of rewards: -159 

action type: buy - action 0.0
Learning step: -7.738173961639404
desired expected reward: -8.976157188415527






Player: 1 
cards in hand: [ 3.  0.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8 25  8  0 22 15  3  0  0  4  0  8 10  3  0  3 29  1  3  0  0  0
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  6.  5. 10.  6.  8.  7.] 
adversary cards in hand: [ 0.  6.  6. 29.  1.] 
adversary cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6. 10.  0. 16.  6. 10.  0. 29.  0. 11.  6.  6.  3.  6.] 
adversary owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8  6 29  3  0  6  0  1
  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0 10  0 29  0] -> size -> 43 
adversary victory points: -6
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  8 25  8  0 22 15  0  0  4  0  8  0  3 29  1  3  0  0  0 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  6.  5. 10.  6.  8.  7.] 
adversary cards in hand: [ 0.  6.  6. 29.  1.] 
adversary cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6. 10.  0. 16.  6. 10.  0. 29.  0. 11.  6.  6.  3.  6.] 
adversary owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8  6 29  3  0  6  0  1
  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0 10  0 29  0] -> size -> 43 
adversary victory points: -6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  8 25  8  0 22 15  0  0  4  0  8  0  3 29  1  3  0  0  0 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  6.  5. 10.  6.  8.  7.] 
adversary cards in hand: [ 0.  6.  6. 29.  1.] 
adversary cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6. 10.  0. 16.  6. 10.  0. 29.  0. 11.  6.  6.  3.  6.] 
adversary owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8  6 29  3  0  6  0  1
  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0 10  0 29  0] -> size -> 43 
adversary victory points: -6
player victory points: 5 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  6. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[39.393074]
 [34.398636]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 29.  1.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6. 10.  0. 16.  6. 10.  0. 29.  0. 11.  6.  6.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8  6 29  3  0  6  0  1
  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0 10  0 29  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  6.  5. 10.  6.  8.  7.] 
adversary cards in hand: [ 3. 11. 29.  1.  1.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 8  1  8 25  8  0 22 15  0  0  4  0  8  0  3 29  1  3  0  0  0 11] -> size -> 22 
adversary victory points: 5
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -121 

action type: buy - action -1
Learning step: -5.533420085906982
desired expected reward: 1.1300272941589355



action possibilites: [-1.] 
expected returns: [[86.11832]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6. 10.  0. 16.  6. 10.  0. 29.  0. 11.  6.  6.  3.  6.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8  6 29  3  0  6  0  1
  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0 10  0 29  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  6.  5. 10.  6.  8.  7.] 
adversary cards in hand: [ 3. 11. 29.  1.  1.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 8  1  8 25  8  0 22 15  0  0  4  0  8  0  3 29  1  3  0  0  0 11] -> size -> 22 
adversary victory points: 5
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -101 

action type: discard_n_cards - action 0
Learning step: -4.552591323852539
desired expected reward: 24.252479553222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[75.543945]
 [86.11833 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6. 10.  0. 16.  6. 10.  0. 29.  0. 11.  6.  6.  3.  6.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8  6 29  3  0  6  0  1
  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0 10  0 29  0] -> size -> 43 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 1. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  6.  5. 10.  6.  8.  7.] 
adversary cards in hand: [ 3. 11. 29.  1.  1.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 8  1  8 25  8  0 22 15  0  0  4  0  8  0  3 29  1  3  0  0  0 11] -> size -> 22 
adversary victory points: 5
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -101 

action type: take_action - action -1.0
Learning step: -7.4957275390625
desired expected reward: 78.62258911132812



Player 1 won the game! 



Player 0 bought cards:
Copper: 13 
Silver: 5 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 9 

Remodel: 1 
Workshop: 1 
Chapel: 4 
Witch: 0 
Poacher: 1 
Militia: 2 
Market: 0 
Village: 1 
Library: 1 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [6. 6. 6.] 
cards in discard: [14.  0.  8.  0.  1.  0.  0.  6.  0.  3.  3.  0.  6.  0.  8.  8.  3.  8.
  6. 10.  0. 16.  6. 10.  0. 29.  0. 11.  6.  6.  3.  6.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 6 15  8  6  0  3  6  0  6  8  1  0  3  0  1  1  8  6 29  3  0  6  0  1
  6  8  3  8  6 16  6  6  0 14  0 10 11  0  0 10  0 29  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 22. 30. 19. 29.  8.  0.  8.  4.  0.  9.  6.  5. 10.  6.  8.  7.] 
adversary cards in hand: [ 3. 11. 29.  1.  1.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 8  1  8 25  8  0 22 15  0  0  4  0  8  0  3 29  1  3  0  0  0 11] -> size -> 22 
adversary victory points: 5
player victory points: -6 

Reward from previous game state: 
[  -5 -500   -6 -110    0    0   20  -30    0    0    0   -9    0    0
    0    0] 
sum of rewards: -640 

action type: buy - action 0.0
Learning step: -35.777198791503906
desired expected reward: 39.766746520996094



