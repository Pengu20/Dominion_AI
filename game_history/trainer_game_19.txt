 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.597294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   0   0   0   0  40   0   0   0   0  -4   0   0  16   0] 
sum of rewards: 547 

action type: gain_card_n - action 8
Learning step: 15.697633743286133
desired expected reward: 39.44320297241211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.787704]
 [21.811   ]
 [21.248857]
 [19.403242]
 [23.28654 ]
 [22.825386]
 [22.263245]
 [22.864481]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6076017022132874
desired expected reward: 22.383012771606445



buy possibilites: [-1] 
expected returns: [[22.765732]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.06955593079328537
desired expected reward: 23.216981887817383






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.42631]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5531935095787048
desired expected reward: 22.21253776550293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.16059 ]
 [26.183886]
 [25.621744]
 [23.776127]
 [25.641726]
 [27.659422]
 [27.19827 ]
 [27.879335]
 [25.812756]
 [26.636126]
 [26.836054]
 [27.237364]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6698700785636902
desired expected reward: 25.975698471069336



buy possibilites: [-1] 
expected returns: [[29.827183]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.2868053615093231
desired expected reward: 28.166141510009766






Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[28.422552]
 [29.064522]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7392476797103882
desired expected reward: 29.087934494018555



action possibilites: [-1.] 
expected returns: [[31.022083]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.10502243041992188
desired expected reward: 29.253454208374023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[29.20648 ]
 [30.22978 ]
 [28.644339]
 [29.667637]
 [28.383106]
 [27.822018]
 [29.68762 ]
 [31.705315]
 [31.244158]
 [32.748596]
 [31.925226]
 [29.858644]
 [29.325401]
 [30.682016]
 [28.302107]
 [30.881943]
 [31.283257]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.15910102427005768
desired expected reward: 30.86298179626465



buy possibilites: [-1] 
expected returns: [[29.262781]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 11.0
Learning step: -0.05890016257762909
desired expected reward: 31.646411895751953






Player: 1 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.061106]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7322660088539124
desired expected reward: 28.530515670776367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.247759]
 [26.70891 ]
 [24.863295]
 [28.28544 ]
 [28.324533]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.709297239780426
desired expected reward: 27.444738388061523



buy possibilites: [-1] 
expected returns: [[26.659475]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.6575082540512085
desired expected reward: 25.59025001525879






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 3. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 3. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8.  3.  3.  3.  0.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[27.737787]
 [28.159845]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  8. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6535763144493103
desired expected reward: 26.00589942932129



action possibilites: [-1] 
expected returns: [[29.151052]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  8. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 5
Learning step: 0.23402108252048492
desired expected reward: 26.636186599731445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[27.575266]
 [28.598564]
 [28.03642 ]
 [26.190804]
 [30.074102]
 [29.612947]
 [29.050806]
 [29.652042]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  8. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.12114549428224564
desired expected reward: 29.0299072265625



buy possibilites: [-1] 
expected returns: [[30.059313]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  8. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.4137536883354187
desired expected reward: 30.142723083496094






Player: 1 
cards in hand: [ 3. 15.  8. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8. 14.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [11. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 14.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [11. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 14.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [11. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[32.41912]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [11. 11. 11.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 8.  3. 15. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7102575302124023
desired expected reward: 29.349056243896484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[30.681759]
 [31.694347]
 [31.133917]
 [29.862211]
 [29.311333]
 [31.154213]
 [33.149513]
 [32.697357]
 [34.182404]
 [33.362858]
 [31.317377]
 [30.786825]
 [32.136925]
 [29.774233]
 [32.329964]
 [32.706177]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [11. 11. 11.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 8.  3. 15. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7881960272789001
desired expected reward: 31.73769760131836



buy possibilites: [-1] 
expected returns: [[33.610817]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [11. 11. 11.  0.  0.  3.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 8.  3. 15. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 3.0 

action type: buy - action 14.0
Learning step: -0.49660778045654297
desired expected reward: 30.820770263671875






Player: 1 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 8.  3. 15. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 11. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 8.  3. 15. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 11. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 8.  3. 15. 14.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  8. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 11. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[29.319126]
 [29.762459]
 [29.9758  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  8. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8448283672332764
desired expected reward: 32.765987396240234



action possibilites: [-1. 11. 11.] 
expected returns: [[30.655983]
 [31.099318]
 [31.099318]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  8. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.12736186385154724
desired expected reward: 29.96141815185547



action possibilites: [-1] 
expected returns: [[33.247173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 11.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  7. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  4  0] 
sum of rewards: 39 

action type: gain_card_n - action 6
Learning step: 0.7011922597885132
desired expected reward: 27.964630126953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.376781]
 [31.828936]
 [30.006355]
 [33.39238 ]
 [33.401203]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 11.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  7. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.3915368318557739
desired expected reward: 33.638710021972656



buy possibilites: [-1] 
expected returns: [[31.0043]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 11.] 
cards in discard: [8. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6.  7. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15  8] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -265.0 

action type: buy - action 6.0
Learning step: -8.52464485168457
desired expected reward: 21.481708526611328






Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6.  7. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [11. 11. 14.  3.  0.] 
adversary cards in discard: [ 8.  6. 29. 11.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6] -> size -> 19 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6.  7. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [11. 11. 14.  3.  0.] 
adversary cards in discard: [ 8.  6. 29. 11.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6] -> size -> 19 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  6.  7. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [11. 11. 14.  3.  0.] 
adversary cards in discard: [ 8.  6. 29. 11.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6] -> size -> 19 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [11. 11. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 14.] 
expected returns: [[32.060627]
 [32.50396 ]
 [32.50396 ]
 [30.671822]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 14.  3.  0.] 
cards in discard: [ 8.  6. 29. 11.  0.  3.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  6.  7. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  0.  8.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7427653074264526
desired expected reward: 30.261533737182617



action possibilites: [-1] 
expected returns: [[27.496777]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  3.  0.] 
cards in discard: [ 8.  6. 29. 11.  0.  3.  3. 11.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  0.  8.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 6
Learning step: -0.0037920570466667414
desired expected reward: 28.74648094177246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.765314]
 [24.420422]
 [27.75198 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  3.  0.] 
cards in discard: [ 8.  6. 29. 11.  0.  3.  3. 11.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  0.  8.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.0983985885977745
desired expected reward: 27.398378372192383



buy possibilites: [-1] 
expected returns: [[25.435833]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  3.  0.] 
cards in discard: [ 8.  6. 29. 11.  0.  3.  3. 11.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  0.  8.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: -0.05588315799832344
desired expected reward: 25.709430694580078






Player: 1 
cards in hand: [ 3. 15.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  0.  8.] 
cards in discard: [0. 8. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8 15  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  6. 29. 11.  0.  3.  3. 11.  8.  0. 11. 11. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0] -> size -> 21 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [0. 8. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 14  3  8 15  8  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  6. 29. 11.  0.  3.  3. 11.  8.  0. 11. 11. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0] -> size -> 21 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [0. 8. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 14  3  8 15  8  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  6. 29. 11.  0.  3.  3. 11.  8.  0. 11. 11. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0] -> size -> 21 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[29.89843]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  6. 29. 11.  0.  3.  3. 11.  8.  0. 11. 11. 14.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  3  8 15  8  0] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5988081097602844
desired expected reward: 24.837024688720703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[27.792044]
 [28.795258]
 [28.236044]
 [26.976465]
 [26.434195]
 [28.256907]
 [30.231697]
 [29.7877  ]
 [31.25577 ]
 [30.440191]
 [28.412905]
 [27.885326]
 [29.228483]
 [26.882113]
 [29.41612 ]
 [29.76869 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  6. 29. 11.  0.  3.  3. 11.  8.  0. 11. 11. 14.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  3  8 15  8  0] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7256484627723694
desired expected reward: 28.69703483581543



buy possibilites: [-1] 
expected returns: [[32.628025]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  6. 29. 11.  0.  3.  3. 11.  8.  0. 11. 11. 14.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  3  8 15  8  0] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 1.0
Learning step: -0.5362634658813477
desired expected reward: 28.258995056152344






Player: 1 
cards in hand: [ 0.  0.  3. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  3  8 15  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [11.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1] -> size -> 22 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  3  8 15  8  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [11.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1] -> size -> 22 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.  3.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  3  8 15  8  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [11.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1] -> size -> 22 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [11.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[26.992239]
 [27.455244]
 [27.455244]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [ 0.  0.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  3  8 15  8  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8407944440841675
desired expected reward: 31.7872314453125



action possibilites: [-1] 
expected returns: [[28.014711]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  0.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [ 0.  0.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  3  8 15  8  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.1708010584115982
desired expected reward: 28.282581329345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.067474]
 [24.70962 ]
 [28.044123]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  0.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [ 0.  0.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  3  8 15  8  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.11084924638271332
desired expected reward: 27.90386199951172






Player: 1 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [ 0.  0.  0.  3. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  3  8 15  8  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [11. 14. 29.  0.  8.] 
adversary cards in discard: [10. 11.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10] -> size -> 23 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0.  0.  0.  3. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 14  3  8 15  8  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [11. 14. 29.  0.  8.] 
adversary cards in discard: [10. 11.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10] -> size -> 23 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  0.  0.  3. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 14  3  8 15  8  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [11. 14. 29.  0.  8.] 
adversary cards in discard: [10. 11.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10] -> size -> 23 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  0.  0.  3. 14.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 14  3  8 15  8  0  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [11. 14. 29.  0.  8.] 
adversary cards in discard: [10. 11.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10] -> size -> 23 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [11. 14. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 29.  8.] 
expected returns: [[24.864729]
 [25.327736]
 [23.508944]
 [25.53623 ]
 [24.883736]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14. 29.  0.  8.] 
cards in discard: [10. 11.  3. 11.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 14  3  8 15  8  0  0  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7283540368080139
desired expected reward: 27.31576919555664



action possibilites: [-1. 11. 14.  8.  8.] 
expected returns: [[26.465275]
 [26.92828 ]
 [25.109488]
 [26.48428 ]
 [26.48428 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  0.  8.  8.] 
cards in discard: [10. 11.  3. 11.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 14  3  8 15  8  0  0  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.04100692644715309
desired expected reward: 25.573280334472656



action possibilites: [-1] 
expected returns: [[31.844423]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  8.] 
cards in discard: [10. 11.  3. 11.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [ 0. 15.] 
adversary owned cards: [ 0  0  0  0  3 14  3  8 15  8  0  0  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 14.0
Learning step: 0.631081759929657
desired expected reward: 25.740570068359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[29.999949]
 [31.003159]
 [30.443945]
 [28.642096]
 [30.46481 ]
 [32.439598]
 [31.9956  ]
 [32.648094]
 [30.620808]
 [31.436386]
 [31.624022]
 [31.976595]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  8.] 
cards in discard: [10. 11.  3. 11.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  6. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [ 0. 15.] 
adversary owned cards: [ 0  0  0  0  3 14  3  8 15  8  0  0  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.42453476786613464
desired expected reward: 32.268959045410156



buy possibilites: [-1] 
expected returns: [[37.065258]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  8.] 
cards in discard: [10. 11.  3. 11.  3.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  6. 10.  8.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [ 0. 15.] 
adversary owned cards: [ 0  0  0  0  3 14  3  8 15  8  0  0  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 29.0
Learning step: 1.4197423458099365
desired expected reward: 34.06783676147461






Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [ 0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  8 15  8  0  0  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  6. 10.  8.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  1.] 
adversary cards in discard: [10. 11.  3. 11.  3.  0. 29. 29. 14. 11.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29] -> size -> 24 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [ 0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  8 15  8  0  0  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  6. 10.  8.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  1.] 
adversary cards in discard: [10. 11.  3. 11.  3.  0. 29. 29. 14. 11.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29] -> size -> 24 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[25.434118]
 [25.888367]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  1.] 
cards in discard: [10. 11.  3. 11.  3.  0. 29. 29. 14. 11.  0.  8.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  6. 10.  8.  8. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 15.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 14  3  8 15  8  0  0  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.9915888905525208
desired expected reward: 36.07366943359375



action possibilites: [-1] 
expected returns: [[32.952793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [10. 11.  3. 11.  3.  0. 29. 29. 14. 11.  0.  8.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  6. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 15.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 14  3  8 15  8  0  0  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.27197083830833435
desired expected reward: 26.73975372314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[31.269705]
 [32.253883]
 [31.705286]
 [30.469572]
 [29.937592]
 [31.725727]
 [33.68707 ]
 [33.24307 ]
 [34.711143]
 [33.89556 ]
 [31.878777]
 [31.361181]
 [32.683853]
 [30.377   ]
 [32.871487]
 [33.22406 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [10. 11.  3. 11.  3.  0. 29. 29. 14. 11.  0.  8.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  6. 10.  8.  8. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 15.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 14  3  8 15  8  0  0  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.19516055285930634
desired expected reward: 32.757633209228516



buy possibilites: [-1] 
expected returns: [[32.082256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [10. 11.  3. 11.  3.  0. 29. 29. 14. 11.  0.  8.  8. 10. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  6. 10.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 15.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 14  3  8 15  8  0  0  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 23.0 

action type: buy - action 14.0
Learning step: 0.07559984177350998
desired expected reward: 31.954374313354492






Player: 1 
cards in hand: [8. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [ 0. 15.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  8 15  8  0  0  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  6. 10.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10. 11.  3. 11.  3.  0. 29. 29. 14. 11.  0.  8.  8. 10. 14. 11.  0.  0.
  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14] -> size -> 26 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 0. 15.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 14  3  8 15  8  0  0  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  6. 10.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10. 11.  3. 11.  3.  0. 29. 29. 14. 11.  0.  8.  8. 10. 14. 11.  0.  0.
  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14] -> size -> 26 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0. 15.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 14  3  8 15  8  0  0  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  6. 10.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10. 11.  3. 11.  3.  0. 29. 29. 14. 11.  0.  8.  8. 10. 14. 11.  0.  0.
  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14] -> size -> 26 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.06558]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 11.  3. 11.  3.  0. 29. 29. 14. 11.  0.  8.  8. 10. 14. 11.  0.  0.
  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  6. 10.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  3.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 14  3  8 15  8  0  0  3] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8385810256004333
desired expected reward: 31.243675231933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[24.602526]
 [25.542326]
 [25.013723]
 [23.328955]
 [25.035675]
 [26.884676]
 [26.473482]
 [27.0794  ]
 [25.177843]
 [25.944874]
 [26.117645]
 [26.427845]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 11.  3. 11.  3.  0. 29. 29. 14. 11.  0.  8.  8. 10. 14. 11.  0.  0.
  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  6. 10.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  3.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 14  3  8 15  8  0  0  3] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6603263020515442
desired expected reward: 25.424118041992188



buy possibilites: [-1] 
expected returns: [[27.18392]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 11.  3. 11.  3.  0. 29. 29. 14. 11.  0.  8.  8. 10. 14. 11.  0.  0.
  0.  1.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  5. 10.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  3.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 14  3  8 15  8  0  0  3] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -0.598773181438446
desired expected reward: 25.874704360961914






Player: 1 
cards in hand: [ 8.  3.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3.  0. 14.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 14  3  8 15  8  0  0  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  5. 10.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  8.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8] -> size -> 27 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  3.  0. 14.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 14  3  8 15  8  0  0  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  5. 10.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  8.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8] -> size -> 27 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [11.  0.  8.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[31.491728]
 [31.976063]
 [31.540071]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  0.  6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  5. 10.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  0.  8.] 
adversary cards in discard: [ 8.  3.  3.  0. 14.] 
adversary owned cards: [ 0  0  3 14  3  8 15  8  0  0  3] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6316896080970764
desired expected reward: 26.552230834960938



action possibilites: [-1] 
expected returns: [[33.783195]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 6.] 
cards in discard: [14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  5. 10.  8.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  0.  8.] 
adversary cards in discard: [ 8.  3.  3.  0. 14.] 
adversary owned cards: [ 0  0  3 14  3  8 15  8  0  0  3] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0.33677437901496887
desired expected reward: 31.935081481933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[32.206467]
 [32.64246 ]
 [30.856098]
 [34.190266]
 [34.14192 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 6.] 
cards in discard: [14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  5. 10.  8.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  0.  8.] 
adversary cards in discard: [ 8.  3.  3.  0. 14.] 
adversary owned cards: [ 0  0  3 14  3  8 15  8  0  0  3] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.21611377596855164
desired expected reward: 33.567081451416016






Player: 1 
cards in hand: [ 0.  3. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  0.  8.] 
cards in discard: [ 8.  3.  3.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 14  3  8 15  8  0  0  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  5. 10.  8.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29. 29.] 
adversary cards in discard: [14. 11.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14] -> size -> 28 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8.] 
cards in discard: [ 8.  3.  3.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 14  3  8 15  8  0  0  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  5. 10.  8.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29. 29.] 
adversary cards in discard: [14. 11.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14] -> size -> 28 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [ 8.  3.  3.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 14  3  8 15  8  0  0  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  5. 10.  8.  6. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29. 29.] 
adversary cards in discard: [14. 11.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14] -> size -> 28 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [ 8.  3.  3.  0. 14. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 14  3  8 15  8  0  0  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  5. 10.  8.  5. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29. 29.] 
adversary cards in discard: [14. 11.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14] -> size -> 28 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[29.187372]
 [29.864998]
 [29.864998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29. 29.] 
cards in discard: [14. 11.  0.  8.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  5. 10.  8.  5. 10.  8. 10.  9.] 
adversary cards in hand: [15. 14.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 14  3  8 15  8  0  0  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.8618696331977844
desired expected reward: 33.28004837036133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.470772]
 [27.898432]
 [26.146208]
 [29.416641]
 [29.369204]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29. 29.] 
cards in discard: [14. 11.  0.  8.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  6.  5. 10.  8.  5. 10.  8. 10.  9.] 
adversary cards in hand: [15. 14.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 14  3  8 15  8  0  0  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7301477789878845
desired expected reward: 28.52414894104004



buy possibilites: [-1] 
expected returns: [[31.528164]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29. 29.] 
cards in discard: [14. 11.  0.  8.  0.  6.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  8. 10.  6.  5. 10.  8.  5. 10.  8. 10.  9.] 
adversary cards in hand: [15. 14.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 14  3  8 15  8  0  0  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.603340148925781
desired expected reward: 16.54286766052246






Player: 1 
cards in hand: [15. 14.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14  3  8 15  8  0  0  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8. 10.  6.  5. 10.  8.  5. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14. 11. 11. 10.] 
adversary cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6] -> size -> 29 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 14  3  8 15  8  0  0  3 14] -> size -> 10 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  8. 10.  6.  5. 10.  8.  5. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14. 11. 11. 10.] 
adversary cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6] -> size -> 29 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 14  3  8 15  8  0  0  3 14] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  8. 10.  6.  5. 10.  8.  5. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14. 11. 11. 10.] 
adversary cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6] -> size -> 29 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  3.] 
cards in discard: [11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 14  3  8 15  8  0  0  3 14 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8. 10.  5.  5. 10.  8.  5. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14. 11. 11. 10.] 
adversary cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6] -> size -> 29 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0. 14. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 11. 10.] 
expected returns: [[35.26636 ]
 [33.94095 ]
 [35.750698]
 [35.750698]
 [34.754204]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 11. 11. 10.] 
cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8. 10.  5.  5. 10.  8.  5. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 14.  8.  0.  0.] 
adversary cards in discard: [11. 15. 14.  8.  3.] 
adversary owned cards: [ 3 14  3  8 15  8  0  0  3 14 11] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7256568074226379
desired expected reward: 30.802507400512695



action possibilites: [-1. 14. 11. 11.] 
expected returns: [[36.94598 ]
 [35.620567]
 [37.430317]
 [37.430317]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 11. 11.  0.] 
cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8. 10.  5.  5. 10.  8.  5. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 14.  8.  0.  0.] 
adversary cards in discard: [11. 15. 14.  8.  3.] 
adversary owned cards: [ 3 14  3  8 15  8  0  0  3 14 11] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.2053796648979187
desired expected reward: 34.58063507080078



action possibilites: [-1. 14. 11.] 
expected returns: [[38.114605]
 [36.78919 ]
 [38.59894 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 11.  0.] 
cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8. 10.  5.  5. 10.  8.  5. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 14.  8.  0.  0.] 
adversary cards in discard: [11. 15. 14.  8.  3.] 
adversary owned cards: [ 3 14  3  8 15  8  0  0  3 14 11] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 10
Learning step: 0.835950493812561
desired expected reward: 37.266448974609375



action possibilites: [-1] 
expected returns: [[28.679625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.] 
cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29. 15. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 14.  8.  0.  0.] 
adversary cards in discard: [11. 15. 14.  8.  3.] 
adversary owned cards: [ 3 14  3  8 15  8  0  0  3 14 11] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  9  0] 
sum of rewards: 64 

action type: gain_card_n - action 9
Learning step: 1.047195315361023
desired expected reward: 40.20665740966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.014078]
 [27.428839]
 [25.70833 ]
 [28.93171 ]
 [28.847923]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.] 
cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29. 15. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 14.  8.  0.  0.] 
adversary cards in discard: [11. 15. 14.  8.  3.] 
adversary owned cards: [ 3 14  3  8 15  8  0  0  3 14 11] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 1.0820916891098022
desired expected reward: 29.761716842651367



buy possibilites: [-1] 
expected returns: [[24.89485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.] 
cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29. 15. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 28. 30.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 14.  8.  0.  0.] 
adversary cards in discard: [11. 15. 14.  8.  3.] 
adversary owned cards: [ 3 14  3  8 15  8  0  0  3 14 11] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 60.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 55.0 

action type: buy - action 0.0
Learning step: 1.10097336769104
desired expected reward: 28.115055084228516






Player: 1 
cards in hand: [ 3. 14.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  8.  0.  0.] 
cards in discard: [11. 15. 14.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  8 15  8  0  0  3 14 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [ 8.  0. 14.  0.  1.] 
adversary cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29. 15. 10.  0. 10. 11. 11.
  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0] -> size -> 32 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  8.  0.  0.] 
cards in discard: [11. 15. 14.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  8 15  8  0  0  3 14 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 28. 30.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [ 8.  0. 14.  0.  1.] 
adversary cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29. 15. 10.  0. 10. 11. 11.
  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0] -> size -> 32 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  8.  0.  0.] 
cards in discard: [11. 15. 14.  8.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [ 8.  0. 14.  0.  1.] 
adversary cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29. 15. 10.  0. 10. 11. 11.
  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0] -> size -> 32 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 14.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[36.05264 ]
 [36.13906 ]
 [34.760925]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 14.  0.  1.] 
cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29. 15. 10.  0. 10. 11. 11.
  0. 14.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  8.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5214861035346985
desired expected reward: 24.373363494873047



action possibilites: [-1] 
expected returns: [[35.11876]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 1.] 
cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29. 15. 10.  0. 10. 11. 11.
  0. 14.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 27. 30.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 15.  3.] 
adversary cards in discard: [3. 8.] 
adversary owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: -0.22408080101013184
desired expected reward: 34.53684616088867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[33.44104 ]
 [34.421402]
 [32.88367 ]
 [33.86403 ]
 [32.635933]
 [32.109383]
 [33.88941 ]
 [35.81973 ]
 [35.39674 ]
 [36.827755]
 [36.02035 ]
 [34.03426 ]
 [33.507282]
 [34.83937 ]
 [32.526928]
 [35.01462 ]
 [35.31131 ]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 1.] 
cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29. 15. 10.  0. 10. 11. 11.
  0. 14.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 29. 30. 27. 30.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 15.  3.] 
adversary cards in discard: [3. 8.] 
adversary owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.23837962746620178
desired expected reward: 34.88037872314453



buy possibilites: [-1] 
expected returns: [[34.62342]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 1.] 
cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29. 15. 10.  0. 10. 11. 11.
  0. 14.  0.  4.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0  4] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 15.  3.] 
adversary cards in discard: [3. 8.] 
adversary owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 27.5 

action type: buy - action 4.0
Learning step: 0.20946796238422394
desired expected reward: 32.845401763916016






Player: 1 
cards in hand: [ 3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.] 
cards in discard: [3. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 10.  3. 11.  0.] 
adversary cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29. 15. 10.  0. 10. 11. 11.
  0. 14.  0.  4. 14.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0  4] -> size -> 33 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [3. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 10.  3. 11.  0.] 
adversary cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29. 15. 10.  0. 10. 11. 11.
  0. 14.  0.  4. 14.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0  4] -> size -> 33 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [3. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 10.  3. 11.  0.] 
adversary cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29. 15. 10.  0. 10. 11. 11.
  0. 14.  0.  4. 14.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0  4] -> size -> 33 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[28.9093  ]
 [28.995718]
 [28.43196 ]
 [29.423576]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3. 11.  0.] 
cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29. 15. 10.  0. 10. 11. 11.
  0. 14.  0.  4. 14.  8.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0  4] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11. 14.  0.  3.] 
adversary cards in discard: [ 3.  8. 15.  3.  3.] 
adversary owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8838159441947937
desired expected reward: 33.73960494995117



action possibilites: [-1.  8. 11.] 
expected returns: [[30.309927]
 [30.396347]
 [30.824205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.  0.  3.] 
cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29. 15. 10.  0. 10. 11. 11.
  0. 14.  0.  4. 14.  8.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0  4] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11. 14.  0.  3.] 
adversary cards in discard: [ 3.  8. 15.  3.  3.] 
adversary owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.08194272965192795
desired expected reward: 28.350019454956055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.38072 ]
 [27.033762]
 [30.272478]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11.  0.  3.] 
cards in discard: [14. 11.  0.  8.  0.  6.  6.  0.  0.  3. 29. 29. 15. 10.  0. 10. 11. 11.
  0. 14.  0.  4. 14.  8.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0  4] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11. 14.  0.  3.] 
adversary cards in discard: [ 3.  8. 15.  3.  3.] 
adversary owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.15580210089683533
desired expected reward: 30.154125213623047






Player: 1 
cards in hand: [ 0. 11. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 14.  0.  3.] 
cards in discard: [ 3.  8. 15.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [ 8.  0.  0. 29.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0  4] -> size -> 33 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [ 3.  8. 15.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0  4] -> size -> 33 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [ 3.  8. 15.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  5. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0  4] -> size -> 33 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [ 3.  8. 15.  3.  3. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  4. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0  4] -> size -> 33 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[28.676163]
 [28.762587]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [29.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29
 10 14  8 14  6 15 10  0  4] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  4. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  8. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -600
  140    0] 
sum of rewards: -465 

action type: discard_down_to_3_cards - action 2
Learning step: -14.411656379699707
desired expected reward: 11.044987678527832



action possibilites: [-1] 
expected returns: [[30.142252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  4. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  8. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.06401842087507248
desired expected reward: 27.619718551635742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.456968]
 [27.110008]
 [30.34873 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  4. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  8. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.14997121691703796
desired expected reward: 29.992280960083008






Player: 1 
cards in hand: [ 3.  0.  8. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 14.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3  8 15  8  0  0  3 14 11  3 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  4. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  0.  3.] 
adversary cards in discard: [29.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4] -> size -> 31 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  8  0  0  3 14 11  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  4. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  0.  3.] 
adversary cards in discard: [29.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4] -> size -> 31 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  8  0  0  3 14 11  3 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  4. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  0.  3.] 
adversary cards in discard: [29.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4] -> size -> 31 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[32.34854 ]
 [32.862816]
 [32.862816]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  3.] 
cards in discard: [29.  6.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  4. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 15. 11. 14.  3.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 3  3 15  8  0  0  3 14 11  3 14] -> size -> 11 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.716090977191925
desired expected reward: 29.632638931274414



action possibilites: [-1] 
expected returns: [[32.46989]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [29.  6.  8. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  4. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 15. 11. 14.  3.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 3  3 15  8  0  0  3 14 11  3 14] -> size -> 11 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.07137439399957657
desired expected reward: 33.05669021606445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[30.800287]
 [31.218508]
 [29.45978 ]
 [32.768185]
 [32.646317]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [29.  6.  8. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  5. 10.  8.  4. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 15. 11. 14.  3.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 3  3 15  8  0  0  3 14 11  3 14] -> size -> 11 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.1917031854391098
desired expected reward: 32.2781867980957



buy possibilites: [-1] 
expected returns: [[32.099495]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [29.  6.  8. 10.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4 10  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 15. 11. 14.  3.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 3  3 15  8  0  0  3 14 11  3 14] -> size -> 11 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.043999213725328445
desired expected reward: 32.81218338012695






Player: 1 
cards in hand: [ 3. 15. 11. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 11. 14.  3.] 
cards in discard: [8. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0  0  3 14 11  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 10. 11.] 
adversary cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4 10  8] -> size -> 33 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 11. 14.  3.] 
cards in discard: [8. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0  0  3 14 11  3 14] -> size -> 11 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 10. 11.] 
adversary cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4 10  8] -> size -> 33 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 11. 14.  3.] 
cards in discard: [8. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 10. 11.] 
adversary cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4 10  8] -> size -> 33 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 8.  6.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[31.166147]
 [31.288017]
 [30.721832]
 [31.706238]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0. 10. 11.] 
cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4 10  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 11.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7842301726341248
desired expected reward: 31.315265655517578



action possibilites: [-1] 
expected returns: [[29.957146]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0. 10.] 
cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4 10  8 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 11.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 10
Learning step: 0.3231257498264313
desired expected reward: 31.037267684936523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.19489 ]
 [26.880245]
 [30.005268]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  0. 10.] 
cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4 10  8 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 11.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.14747817814350128
desired expected reward: 29.809667587280273






Player: 1 
cards in hand: [ 3. 11.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 8. 11.  0. 15. 14.] 
adversary cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4 10  8 15] -> size -> 34 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 8. 11. 15.] 
adversary cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4 10  8 15] -> size -> 34 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 8. 11. 15.] 
adversary cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4 10  8 15] -> size -> 34 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 8. 11. 15.] 
adversary cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4 10  8 15] -> size -> 34 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 15.] 
expected returns: [[24.624336]
 [24.742477]
 [25.14787 ]
 [24.359081]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 15.] 
cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14
  8 14  6 15 10  0  4 10  8 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  8. 15. 14.] 
adversary cards in discard: [ 0. 14.  3. 11.  0.  3.] 
adversary owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -600
  173    0] 
sum of rewards: -432 

action type: discard_down_to_3_cards - action 4
Learning step: -13.415229797363281
desired expected reward: 10.44063949584961



action possibilites: [-1] 
expected returns: [[28.164463]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  8. 15. 14.] 
adversary cards in discard: [ 0. 14.  3. 11.  0.  3.] 
adversary owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 2
Learning step: 0.08063598722219467
desired expected reward: 22.25033187866211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.38437 ]
 [25.043867]
 [28.2304  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  8. 15. 14.] 
adversary cards in discard: [ 0. 14.  3. 11.  0.  3.] 
adversary owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.11260585486888885
desired expected reward: 28.051856994628906



buy possibilites: [-1] 
expected returns: [[26.81947]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.
  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  8. 15. 14.] 
adversary cards in discard: [ 0. 14.  3. 11.  0.  3.] 
adversary owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: -0.059926699846982956
desired expected reward: 26.324443817138672






Player: 1 
cards in hand: [ 0.  3.  8. 15. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 15. 14.] 
cards in discard: [ 0. 14.  3. 11.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  0. 29. 14.] 
adversary cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0] -> size -> 33 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8. 15. 14.] 
cards in discard: [ 0. 14.  3. 11.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  0. 29. 14.] 
adversary cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0] -> size -> 33 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0. 29. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 14.] 
expected returns: [[23.061443]
 [22.630754]
 [23.778202]
 [21.841965]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 29. 14.] 
cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.
  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  7.] 
adversary cards in hand: [15. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7128939032554626
desired expected reward: 26.10657501220703



action possibilites: [-1. 10. 14.] 
expected returns: [[24.532932]
 [24.09364 ]
 [23.289165]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 14.  0.] 
cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.
  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  7.] 
adversary cards in hand: [15. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.010462875477969646
desired expected reward: 23.767738342285156



action possibilites: [-1] 
expected returns: [[22.673483]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.
  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  7.] 
adversary cards in hand: [15.  0.  0.] 
adversary cards in discard: [11.  3.] 
adversary owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 14.0
Learning step: 0.5914916396141052
desired expected reward: 23.880657196044922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[21.000408]
 [21.948948]
 [21.398289]
 [20.21149 ]
 [19.705359]
 [21.428411]
 [23.298996]
 [22.901115]
 [24.277657]
 [23.488737]
 [21.561537]
 [21.037373]
 [22.350458]
 [20.088835]
 [22.510075]
 [22.753836]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.
  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  8.  4. 10.  6. 10.  7.] 
adversary cards in hand: [15.  0.  0.] 
adversary cards in discard: [11.  3.] 
adversary owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.6045083403587341
desired expected reward: 23.277990341186523



buy possibilites: [-1] 
expected returns: [[27.602175]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.
  0.  8. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  7.  4. 10.  6. 10.  7.] 
adversary cards in hand: [15.  0.  0.] 
adversary cards in discard: [11.  3.] 
adversary owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 43.0 

action type: buy - action 29.0
Learning step: 0.8751606941223145
desired expected reward: 24.363895416259766






Player: 1 
cards in hand: [15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.] 
cards in discard: [11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0  0  3 14 11  3 14  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  7.  4. 10.  6. 10.  7.] 
adversary cards in hand: [14.  0.  0.  3.  1.] 
adversary cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.
  0.  8. 29. 29. 14.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29] -> size -> 34 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  7.  4. 10.  6. 10.  7.] 
adversary cards in hand: [14.  0.  0.  3.  1.] 
adversary cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.
  0.  8. 29. 29. 14.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29] -> size -> 34 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  4. 10.  7.  4. 10.  6. 10.  7.] 
adversary cards in hand: [14.  0.  0.  3.  1.] 
adversary cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.
  0.  8. 29. 29. 14.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29] -> size -> 34 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  3. 10.  7.  4. 10.  6. 10.  7.] 
adversary cards in hand: [14.  0.  0.  3.  1.] 
adversary cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.
  0.  8. 29. 29. 14.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29] -> size -> 34 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [14.  0.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[26.587797]
 [25.35774 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3.  1.] 
cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.
  0.  8. 29. 29. 14.  3. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  3. 10.  7.  4. 10.  6. 10.  7.] 
adversary cards in hand: [0. 3. 3. 8. 3.] 
adversary cards in discard: [11.  3.  8. 15.  0.] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7040596008300781
desired expected reward: 26.898115158081055



action possibilites: [-1] 
expected returns: [[25.73145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.
  0.  8. 29. 29. 14.  3. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  3. 10.  7.  4. 10.  6. 10.  7.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [11.  3.  8. 15.  0.  3.  8.] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: -0.04055196791887283
desired expected reward: 25.317188262939453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[23.902735]
 [24.862368]
 [23.345654]
 [24.305285]
 [23.104563]
 [22.592527]
 [24.33577 ]
 [26.228247]
 [25.8257  ]
 [27.229809]
 [26.420193]
 [24.470444]
 [23.940147]
 [25.268618]
 [22.98051 ]
 [25.430077]
 [25.676691]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.
  0.  8. 29. 29. 14.  3. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 6 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  3. 10.  7.  4. 10.  6. 10.  7.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [11.  3.  8. 15.  0.  3.  8.] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.0572713278234005
desired expected reward: 25.674177169799805



buy possibilites: [-1] 
expected returns: [[25.77051]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [29.  6.  8. 10.  8. 11.  0. 11.  0.  3. 15. 11.  8.  6.  0. 10.  0. 14.
  0.  8. 29. 29. 14.  3. 10.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  3. 10.  6.  4. 10.  6. 10.  7.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [11.  3.  8. 15.  0.  3.  8.] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 23.0 

action type: buy - action 29.0
Learning step: 0.16798444092273712
desired expected reward: 26.588178634643555






Player: 1 
cards in hand: [0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [11.  3.  8. 15.  0.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  3. 10.  6.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 1.  3. 10. 10.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29] -> size -> 35 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [11.  3.  8. 15.  0.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  3. 10.  6.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 1.  3. 10. 10.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29] -> size -> 35 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 10. 10.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[24.891918]
 [24.47891 ]
 [24.47891 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10. 10.  4.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  3. 10.  6.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  8.  0. 14. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6638559103012085
desired expected reward: 25.106653213500977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.223598]
 [23.626146]
 [21.913391]
 [25.154459]
 [25.002531]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10. 10.  4.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  3. 10.  6.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  8.  0. 14. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6447893381118774
desired expected reward: 24.268529891967773



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  8.  0. 14. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 14. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  3. 10.  6.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 6. 29.  8.  0. 11.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29] -> size -> 35 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  3. 10.  6.  4. 10.  6. 10.  7.] 
adversary cards in hand: [29.  8. 11.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29] -> size -> 35 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  3. 10.  6.  4. 10.  6. 10.  7.] 
adversary cards in hand: [29.  8. 11.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29] -> size -> 35 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 14.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  2. 10.  6.  4. 10.  6. 10.  7.] 
adversary cards in hand: [29.  8. 11.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29] -> size -> 35 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [29.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
expected returns: [[28.932642]
 [29.69084 ]
 [29.084574]
 [29.495062]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 11.] 
cards in discard: [ 1.  3. 10. 10.  4.  6.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  2. 10.  6.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  8. 11.  0.] 
adversary cards in discard: [ 8. 14.  3.  8.  0. 14.] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -600
  176    0] 
sum of rewards: -429 

action type: discard_down_to_3_cards - action 5
Learning step: -13.276581764221191
desired expected reward: 10.556269645690918



action possibilites: [-1] 
expected returns: [[26.5279]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.] 
cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  2. 10.  5.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  8. 11.  0.] 
adversary cards in discard: [ 8. 14.  3.  8.  0. 14.] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -1  0  0 16  0] 
sum of rewards: 30 

action type: gain_card_n - action 7
Learning step: 0.3770890533924103
desired expected reward: 27.092220306396484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.832027]
 [23.536976]
 [26.60568 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.] 
cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  5.  2. 10.  5.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  8. 11.  0.] 
adversary cards in discard: [ 8. 14.  3.  8.  0. 14.] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.0800359696149826
desired expected reward: 26.447864532470703



buy possibilites: [-1] 
expected returns: [[22.26681]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.] 
cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  8. 10.  5.  2. 10.  5.  4. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  8. 11.  0.] 
adversary cards in discard: [ 8. 14.  3.  8.  0. 14.] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -2  0  0  0  0] 
sum of rewards: 13 

action type: buy - action 0.0
Learning step: -0.12115933746099472
desired expected reward: 24.71086883544922






Player: 1 
cards in hand: [ 3.  0.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 11.  0.] 
cards in discard: [ 8. 14.  3.  8.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  8. 10.  5.  2. 10.  5.  4. 10.  6. 10.  7.] 
adversary cards in hand: [10. 14. 11.  0. 10.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0] -> size -> 37 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [ 8. 14.  3.  8.  0. 14. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  8. 10.  5.  2. 10.  5.  4. 10.  5. 10.  7.] 
adversary cards in hand: [10. 14. 11.  0. 10.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0] -> size -> 37 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [ 8. 14.  3.  8.  0. 14. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 27. 29.  8.  8. 10.  5.  2. 10.  5.  4. 10.  5. 10.  7.] 
adversary cards in hand: [10. 14. 11.  0. 10.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0] -> size -> 37 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [ 8. 14.  3.  8.  0. 14. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  8. 10.  5.  1. 10.  5.  4. 10.  5. 10.  7.] 
adversary cards in hand: [10. 14. 11.  0. 10.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0] -> size -> 37 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [10. 14. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 11. 10.] 
expected returns: [[30.112928]
 [29.696772]
 [28.882874]
 [30.675344]
 [29.696772]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14. 11.  0. 10.] 
cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  8. 10.  5.  1. 10.  5.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 8.  8.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5031573176383972
desired expected reward: 21.763652801513672



action possibilites: [-1] 
expected returns: [[24.065825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  0. 10.] 
cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  8. 10.  4.  1. 10.  5.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 8.  8.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -3  0  0  9  0] 
sum of rewards: 21 

action type: gain_card_n - action 5
Learning step: 0.04293147847056389
desired expected reward: 28.03491973876953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.442425]
 [21.206285]
 [24.091446]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  0. 10.] 
cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 27. 29.  8.  8. 10.  4.  1. 10.  5.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 8.  8.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.03171026334166527
desired expected reward: 24.034114837646484






Player: 1 
cards in hand: [ 8.  8.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3.  3. 15.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  8. 10.  4.  1. 10.  5.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 3. 15. 29.  0.  6.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11] -> size -> 38 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  8. 10.  4.  1. 10.  5.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 3. 15. 29.  0.  6.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11] -> size -> 38 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  8. 10.  4.  1. 10.  5.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 3. 15. 29.  0.  6.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11] -> size -> 38 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3. 3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 29.  8.  8. 10.  4.  1. 10.  5.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 3. 15. 29.  0.  6.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11] -> size -> 38 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 3. 15. 29.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[26.82602 ]
 [26.597164]
 [27.59012 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 29.  0.  6.] 
cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 29.  8.  8. 10.  4.  1. 10.  5.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 8. 14.  3. 11.  3.] 
adversary cards in discard: [ 0. 15.  8.  8.  3.  3.] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5879668593406677
desired expected reward: 23.50347900390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.05585 ]
 [23.743223]
 [26.806993]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 29.  0.  6.] 
cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 27. 29.  8.  8. 10.  4.  1. 10.  5.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 8. 14.  3. 11.  3.] 
adversary cards in discard: [ 0. 15.  8.  8.  3.  3.] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6867889165878296
desired expected reward: 26.139232635498047



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 14.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  3. 11.  3.] 
cards in discard: [ 0. 15.  8.  8.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10  8  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 29.  8.  8. 10.  4.  1. 10.  5.  4. 10.  5. 10.  7.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.
  3. 15. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11] -> size -> 38 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  3.  3.] 
cards in discard: [ 0. 15.  8.  8.  3.  3. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10  8  0 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 29.  8.  8. 10.  4.  1. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.
  3. 15. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11] -> size -> 38 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  3.  3.] 
cards in discard: [ 0. 15.  8.  8.  3.  3. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10  8  0 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 29. 30. 27. 29.  8.  8. 10.  4.  1. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.
  3. 15. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11] -> size -> 38 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[29.397629]
 [29.575203]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.
  3. 15. 29.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 29.  8.  8. 10.  4.  1. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 8. 14.  0. 10.  0.] 
adversary cards in discard: [ 0. 15.  8.  8.  3.  3. 29. 11.  8. 14.  3.  3.] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10  8  0 29] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6444158554077148
desired expected reward: 26.162574768066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[27.636301]
 [28.606092]
 [28.038248]
 [26.308596]
 [29.98708 ]
 [29.585129]
 [29.017284]
 [29.407555]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.
  3. 15. 29.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 29. 30. 27. 29.  8.  8. 10.  4.  1. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 8. 14.  0. 10.  0.] 
adversary cards in discard: [ 0. 15.  8.  8.  3.  3. 29. 11.  8. 14.  3.  3.] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10  8  0 29] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7289403676986694
desired expected reward: 28.66868782043457



buy possibilites: [-1] 
expected returns: [[30.60749]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.
  3. 15. 29.  0.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 26. 29.  8.  8. 10.  4.  1. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 8. 14.  0. 10.  0.] 
adversary cards in discard: [ 0. 15.  8.  8.  3.  3. 29. 11.  8. 14.  3.  3.] 
adversary owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10  8  0 29] -> size -> 18 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -4.  0.  0.  2.  0.] 
sum of rewards: -7.0 

action type: buy - action 3.0
Learning step: -0.7297687530517578
desired expected reward: 27.30847930908203






Player: 1 
cards in hand: [ 8. 14.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0. 10.  0.] 
cards in discard: [ 0. 15.  8.  8.  3.  3. 29. 11.  8. 14.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  0  3 14 11  3 14  0  0  8  8 10  8  0 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  8. 10.  4.  1. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [14.  8. 29. 29.  0.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.
  3. 15. 29.  0.  6.  3.  0.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3] -> size -> 39 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.] 
cards in discard: [ 0. 15.  8.  8.  3.  3. 29. 11.  8. 14.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  8. 10.  4.  1. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [14.  8. 29. 29.  0.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.
  3. 15. 29.  0.  6.  3.  0.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3] -> size -> 39 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.] 
cards in discard: [ 0. 15.  8.  8.  3.  3. 29. 11.  8. 14.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  8. 10.  4.  1. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [14.  8. 29. 29.  0.] 
adversary cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.
  3. 15. 29.  0.  6.  3.  0.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3] -> size -> 39 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [14.  8. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 29. 29.] 
expected returns: [[19.39436 ]
 [18.206715]
 [19.56991 ]
 [20.158459]
 [20.158459]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 29. 29.  0.] 
cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.
  3. 15. 29.  0.  6.  3.  0.  3.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  8. 10.  4.  1. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 8.  8. 14. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29] -> size -> 16 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.862112283706665
desired expected reward: 29.745378494262695



action possibilites: [-1. 14.  8. 29.  8.] 
expected returns: [[22.487595]
 [21.299948]
 [22.663143]
 [23.256191]
 [22.663143]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 29.  0.  8.] 
cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.
  3. 15. 29.  0.  6.  3.  0.  3.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 26. 29.  8.  8. 10.  4.  1. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 8.  8. 14. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29] -> size -> 16 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.08286586403846741
desired expected reward: 20.24132537841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.736448]
 [21.133823]
 [19.42382 ]
 [22.663143]
 [22.487595]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 29.  0.  8.] 
cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.
  3. 15. 29.  0.  6.  3.  0.  3.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 26. 29.  8.  8. 10.  4.  1. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 8.  8. 14. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29] -> size -> 16 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.0017922020051628351
desired expected reward: 22.489383697509766



buy possibilites: [-1] 
expected returns: [[20.381222]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 29.  0.  8.] 
cards in discard: [ 1.  3. 10. 10.  4.  6.  0. 29.  0. 11. 29.  8. 11. 11. 10. 14.  0. 10.
  3. 15. 29.  0.  6.  3.  0.  3.  8.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 26. 29.  8.  7. 10.  4.  1. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 8.  8. 14. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -5.
    0. -300.    0.    0.] 
sum of rewards: -290.0 

action type: buy - action 6.0
Learning step: -9.06871223449707
desired expected reward: 10.355108261108398






Player: 1 
cards in hand: [ 8.  8. 14. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 14. 10.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  7. 10.  4.  1. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [10. 11.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6] -> size -> 40 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 14. 10.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 26. 29.  8.  7. 10.  4.  1. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [10. 11.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6] -> size -> 40 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [10. 11.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 14.] 
expected returns: [[25.537548]
 [25.147278]
 [26.117073]
 [24.336273]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  7. 10.  4.  1. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  3.  3. 14. 15.] 
adversary cards in discard: [ 8.  8. 14. 10.  0.] 
adversary owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.49420657753944397
desired expected reward: 19.887014389038086



action possibilites: [-1] 
expected returns: [[26.617607]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 14.] 
cards in discard: [8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  7. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  3.  3. 14. 15.] 
adversary cards in discard: [ 8.  8. 14. 10.  0.] 
adversary owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -6  0  0  4  0] 
sum of rewards: 13 

action type: gain_card_n - action 6
Learning step: -0.0036896895617246628
desired expected reward: 22.435462951660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[25.026873]
 [25.428822]
 [23.699165]
 [26.798128]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 14.] 
cards in discard: [8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 26. 29.  8.  7. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  3.  3. 14. 15.] 
adversary cards in discard: [ 8.  8. 14. 10.  0.] 
adversary owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.08025088906288147
desired expected reward: 26.537355422973633






Player: 1 
cards in hand: [ 3.  3.  3. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 14. 15.] 
cards in discard: [ 8.  8. 14. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  7. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [29.  0. 29. 14. 29.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8] -> size -> 41 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 15.] 
cards in discard: [ 8.  8. 14. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 26. 29.  8.  7. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 29. 29.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8] -> size -> 41 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 15.] 
cards in discard: [ 8.  8. 14. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 26. 29.  8.  7. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 29. 29.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8] -> size -> 41 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 15.] 
cards in discard: [ 8.  8. 14. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 29. 30. 26. 29.  8.  7. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 29. 29.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8] -> size -> 41 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[18.428905]
 [19.193884]
 [19.193884]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 26. 29.  8.  7. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [29.  8.  8.  0.  3.] 
adversary cards in discard: [ 8.  8. 14. 10.  0.  0. 14.  3.  3.  3. 15.] 
adversary owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0   -6    0 -900
  172    0] 
sum of rewards: -739 

action type: discard_down_to_3_cards - action 0
Learning step: -22.479354858398438
desired expected reward: -5.521020889282227



action possibilites: [-1. 29.  8.] 
expected returns: [[24.33569 ]
 [25.111696]
 [24.526428]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 26. 29.  8.  7. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [29.  8.  8.  0.  3.] 
adversary cards in discard: [ 8.  8. 14. 10.  0.  0. 14.  3.  3.  3. 15.] 
adversary owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 0
Learning step: 0.20763833820819855
desired expected reward: 16.948400497436523



action possibilites: [-1.  8.] 
expected returns: [[29.439219]
 [29.62996 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 29. 30. 26. 29.  8.  7. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [29.  8.  8.  0.  3.] 
adversary cards in discard: [ 8.  8. 14. 10.  0.  0. 14.  3.  3.  3. 15.] 
adversary owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 0
Learning step: 0.6813433170318604
desired expected reward: 23.313678741455078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[27.671675]
 [28.06395 ]
 [26.362303]
 [29.402493]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8] -> size -> 41 
action values: 1 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 26. 29.  8.  7. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [29.  8.  8.  0.  3.] 
adversary cards in discard: [ 8.  8. 14. 10.  0.  0. 14.  3.  3.  3. 15.] 
adversary owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.4627196490764618
desired expected reward: 29.901935577392578



buy possibilites: [-1] 
expected returns: [[23.704762]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 29. 30. 26. 29.  8.  6. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [29.  8.  8.  0.  3.] 
adversary cards in discard: [ 8.  8. 14. 10.  0.  0. 14.  3.  3.  3. 15.] 
adversary owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   40.    0.    0.    0.    0.   -7.
    0. -300.    0.    0.] 
sum of rewards: -272.0 

action type: buy - action 6.0
Learning step: -8.701969146728516
desired expected reward: 17.66033172607422






Player: 1 
cards in hand: [29.  8.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  8.  0.  3.] 
cards in discard: [ 8.  8. 14. 10.  0.  0. 14.  3.  3.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  8  3 14 11  3 14  0  8  8 10  8  0 29  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 26. 29.  8.  6. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 6.  0.  8. 10. 15.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6] -> size -> 42 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.] 
cards in discard: [ 8.  8. 14. 10.  0.  0. 14.  3.  3.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  3 14 11  3 14  0  8  8 10  8  0 29  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 26. 29.  8.  6. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 6.  0.  8. 10. 15.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6] -> size -> 42 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.] 
cards in discard: [ 8.  8. 14. 10.  0.  0. 14.  3.  3.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  3 14 11  3 14  0  8  8 10  8  0 29  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 29. 30. 26. 29.  8.  6. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 6.  0.  8. 10. 15.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6] -> size -> 42 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.] 
cards in discard: [ 8.  8. 14. 10.  0.  0. 14.  3.  3.  3. 15.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  3 14 11  3 14  0  8  8 10  8  0 29  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 26. 29.  8.  6. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 6.  0.  8. 10. 15.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6] -> size -> 42 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  8. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 15.] 
expected returns: [[25.186256]
 [25.365925]
 [24.836294]
 [24.982733]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8. 10. 15.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 26. 29.  8.  6. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [10.  0. 14.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  3 14 11  3 14  0  8  8 10  8  0 29  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5970948338508606
desired expected reward: 23.107666015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.541801]
 [22.308708]
 [25.171713]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  8. 10. 15.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 29. 30. 26. 29.  8.  6. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [10.  0. 14.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15  3 14 11  3 14  0  8  8 10  8  0 29  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6538648009300232
desired expected reward: 24.532392501831055



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  0. 14.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 14.  8. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3 14 11  3 14  0  8  8 10  8  0 29  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 26. 29.  8.  6. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  4. 11. 10. 14.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6] -> size -> 42 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  3  3 14  0  8  8 10  8  0 29  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 26. 29.  8.  6. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  4. 11. 10. 14.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6] -> size -> 42 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  3  3 14  0  8  8 10  8  0 29  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 29. 30. 26. 29.  8.  6. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  4. 11. 10. 14.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6] -> size -> 42 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15  3  3 14  0  8  8 10  8  0 29  0  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 29. 30. 26. 29.  8.  6. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  4. 11. 10. 14.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6] -> size -> 42 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 0.  4. 11. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 14.] 
expected returns: [[25.334072]
 [25.91709 ]
 [24.9624  ]
 [24.172857]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4. 11. 10. 14.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 26. 29.  8.  6. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 14.  3.  8. 15.] 
adversary cards in discard: [ 0.  8. 10.  0.] 
adversary owned cards: [ 3  3 15  3  3 14  0  8  8 10  8  0 29  0  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6399139761924744
desired expected reward: 24.53179931640625



action possibilites: [-1. 11. 14. 29.] 
expected returns: [[24.570559]
 [25.142197]
 [23.422642]
 [25.331367]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4. 11. 14. 29.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 26. 29.  8.  6. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 14.  3.  8. 15.] 
adversary cards in discard: [ 0.  8. 10.  0.] 
adversary owned cards: [ 3  3 15  3  3 14  0  8  8 10  8  0 29  0  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.038895949721336365
desired expected reward: 24.923503875732422



action possibilites: [-1. 11. 14. 29.] 
expected returns: [[22.704506]
 [23.276144]
 [21.556587]
 [23.465315]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 11. 14. 29.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6] -> size -> 42 
action values: 2 
buys: 0 
player value: 1 
card supply: [17. 29. 30. 26. 29.  8.  6. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 14.  3.  8. 15.] 
adversary cards in discard: [ 0.  8. 10.  0.] 
adversary owned cards: [ 3  3 15  3  3 14  0  8  8 10  8  0 29  0  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 3
Learning step: 0.5926357507705688
desired expected reward: 23.850862503051758



action possibilites: [-1. 14.] 
expected returns: [[21.95568 ]
 [20.809116]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 14.  3.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6] -> size -> 42 
action values: 2 
buys: 0 
player value: 2 
card supply: [17. 29. 30. 26. 29.  8.  6. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 14.  3.  8. 15.] 
adversary cards in discard: [ 0.  8. 10.  0.] 
adversary owned cards: [ 3  3 15  3  3 14  0  8  8 10  8  0 29  0  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: discard_n_cards - action 0
Learning step: 1.2454921007156372
desired expected reward: 22.2530574798584



action possibilites: [-1.] 
expected returns: [[17.205372]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 3.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 29. 29. 14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 4 
card supply: [17. 29. 30. 26. 29.  8.  6. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 14. 15.] 
adversary cards in discard: [ 0.  8. 10.  0.  3.  8.] 
adversary owned cards: [ 3  3 15  3  3 14  0  8  8 10  8  0 29  0  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 14.0
Learning step: 1.8082562685012817
desired expected reward: 22.617372512817383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[15.667052]
 [16.519457]
 [16.015753]
 [14.497145]
 [16.049866]
 [17.733322]
 [17.905973]
 [16.167046]
 [16.880917]
 [17.019453]
 [17.203218]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 29. 29. 14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6] -> size -> 42 
action values: 1 
buys: 1 
player value: 4 
card supply: [17. 29. 30. 26. 29.  8.  6. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 14. 15.] 
adversary cards in discard: [ 0.  8. 10.  0.  3.  8.] 
adversary owned cards: [ 3  3 15  3  3 14  0  8  8 10  8  0 29  0  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 1.9101629257202148
desired expected reward: 19.115535736083984



buy possibilites: [-1] 
expected returns: [[16.57838]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 29. 29. 14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 4 
card supply: [17. 29. 30. 26. 29.  8.  5. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 14. 15.] 
adversary cards in discard: [ 0.  8. 10.  0.  3.  8.] 
adversary owned cards: [ 3  3 15  3  3 14  0  8  8 10  8  0 29  0  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   80.    0.    0.    0.    0.   -8.
    0. -300.    0.    0.] 
sum of rewards: -233.0 

action type: buy - action 6.0
Learning step: -7.25084114074707
desired expected reward: 7.246304512023926






Player: 1 
cards in hand: [ 0. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 15.] 
cards in discard: [ 0.  8. 10.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  3 14  0  8  8 10  8  0 29  0  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 26. 29.  8.  5. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 11.  6.  0. 10.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6] -> size -> 43 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [ 0.  8. 10.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15  3  3 14  8  8 10  8  0 29  0  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 29. 30. 26. 29.  8.  5. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 11.  6.  0. 10.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6] -> size -> 43 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 0.  8. 10.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15  3  3 14  8  8 10  8  0 29  0  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 29. 30. 26. 29.  8.  5. 10.  4.  0. 10.  4.  4. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 11.  6.  0. 10.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6] -> size -> 43 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 0.  8. 10.  0.  3.  8. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15  3  3 14  8  8 10  8  0 29  0  0  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 26. 29.  8.  5. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 11.  6.  0. 10.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6] -> size -> 43 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[29.831467]
 [30.41925 ]
 [29.47608 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0. 10.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 26. 29.  8.  5. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [ 0.  8. 10.  0.  3.  8. 10. 15. 14.] 
adversary owned cards: [ 3  3 15  3  3 14  8  8 10  8  0 29  0  0  0 10] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3322359621524811
desired expected reward: 16.246145248413086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[28.137428]
 [28.521984]
 [26.845795]
 [29.831467]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  0. 10.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 29. 30. 26. 29.  8.  5. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [ 0.  8. 10.  0.  3.  8. 10. 15. 14.] 
adversary owned cards: [ 3  3 15  3  3 14  8  8 10  8  0 29  0  0  0 10] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7442908883094788
desired expected reward: 29.087175369262695



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [ 0.  8. 10.  0.  3.  8. 10. 15. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15  3  3 14  8  8 10  8  0 29  0  0  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 26. 29.  8.  5. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [0. 3. 3. 1. 8.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.  0. 11.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6] -> size -> 43 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 0.  8. 10.  0.  3.  8. 10. 15. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0  0 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 26. 29.  8.  5. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [0. 3. 3. 1. 8.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.  0. 11.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6] -> size -> 43 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0.  8. 10.  0.  3.  8. 10. 15. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0  0 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 29. 30. 26. 29.  8.  5. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [0. 3. 3. 1. 8.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.  0. 11.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6] -> size -> 43 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0.  8. 10.  0.  3.  8. 10. 15. 14.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0  0 10  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 26. 29.  8.  5. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [0. 3. 3. 1. 8.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.  0. 11.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6] -> size -> 43 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[26.820309]
 [27.02428 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1. 8.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.  0. 11.  6.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 26. 29.  8.  5. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0. 15. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0  0 10  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.762045681476593
desired expected reward: 29.069421768188477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[25.110075]
 [26.057724]
 [25.497744]
 [23.807932]
 [27.416424]
 [26.45959 ]
 [26.82031 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 8.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.  0. 11.  6.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 29. 30. 26. 29.  8.  5. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0. 15. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0  0 10  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6796309351921082
desired expected reward: 26.14067840576172



buy possibilites: [-1] 
expected returns: [[23.607397]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 8.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.  0. 11.  6.  0. 10.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6] -> size -> 44 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 29. 30. 26. 29.  8.  4. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0. 15. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0  0 10  0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -9.
    0. -300.    0.    0.] 
sum of rewards: -314.0 

action type: buy - action 6.0
Learning step: -9.886360168457031
desired expected reward: 13.921573638916016






Player: 1 
cards in hand: [10.  0. 15. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15. 29.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0  0 10  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 26. 29.  8.  4. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.  0. 11.  6.  0. 10.  6.  0.  3.
  3.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6] -> size -> 44 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0  0 10  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 26. 29.  8.  4. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.  0. 11.  6.  0. 10.  6.  0.  3.
  3.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6] -> size -> 44 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 4 
card supply: [16. 29. 30. 26. 29.  8.  4. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.  0. 11.  6.  0. 10.  6.  0.  3.
  3.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6] -> size -> 44 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 29. 30. 26. 29.  8.  4. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.  0. 11.  6.  0. 10.  6.  0.  3.
  3.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6] -> size -> 44 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 28. 30. 26. 29.  8.  4. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.  0. 11.  6.  0. 10.  6.  0.  3.
  3.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6] -> size -> 44 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [0. 8. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[27.587116]
 [27.791088]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0. 3.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.  0. 11.  6.  0. 10.  6.  0.  3.
  3.  1.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11  0 11 11 14  8  6  8  0  1 10 29 10 14  8
 14  6 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  4. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [14.  3.  0. 10.  8.] 
adversary cards in discard: [10.  1. 29. 15.  3.  0.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5672721862792969
desired expected reward: 23.040124893188477



action possibilites: [-1] 
expected returns: [[13.363252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.  0. 11.  6.  0. 10.  6.  0.  3.
  3.  1.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  4. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [14.  3.  0. 10.  8.] 
adversary cards in discard: [10.  1. 29. 15.  3.  0.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 7
Learning step: -0.17315568029880524
desired expected reward: 25.27583885192871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[11.836535]
 [12.183087]
 [10.674673]
 [13.363252]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 11. 10.  0.  0. 14. 29. 14.  0. 11.  6. 29. 29.  8.  6.  0.  8. 10.
 15.  0. 11.  6. 10. 29. 29. 14.  4.  3.  0. 11.  6.  0. 10.  6.  0.  3.
  3.  1.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 26. 29.  8.  4. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [14.  3.  0. 10.  8.] 
adversary cards in discard: [10.  1. 29. 15.  3.  0.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.17808611690998077
desired expected reward: 13.541337966918945






Player: 1 
cards in hand: [14.  3.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0. 10.  8.] 
cards in discard: [10.  1. 29. 15.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  4. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  8. 11.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6] -> size -> 42 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  8.] 
cards in discard: [10.  1. 29. 15.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 28. 30. 26. 29.  8.  4. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [8. 8. 8.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6] -> size -> 42 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  8.] 
cards in discard: [10.  1. 29. 15.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 28. 30. 26. 29.  8.  4. 10.  4.  0. 10.  4.  4. 10.  4. 10.  7.] 
adversary cards in hand: [8. 8. 8.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6] -> size -> 42 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  8.] 
cards in discard: [10.  1. 29. 15.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  4. 10.  4.  0. 10.  4.  4. 10.  3. 10.  7.] 
adversary cards in hand: [8. 8. 8.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6] -> size -> 42 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [8. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
expected returns: [[26.710207]
 [26.914177]
 [26.914177]
 [26.914177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8.] 
cards in discard: [ 0. 11.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  4. 10.  4.  0. 10.  4.  4. 10.  3. 10.  7.] 
adversary cards in hand: [3. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1 10] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0    -7
     0 -1500   183     0] 
sum of rewards: -1329 

action type: discard_down_to_3_cards - action 1
Learning step: -40.087520599365234
desired expected reward: -23.435237884521484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.044605]
 [23.727488]
 [26.772102]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 8.] 
cards in discard: [ 0. 11.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6] -> size -> 42 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  4. 10.  4.  0. 10.  4.  4. 10.  3. 10.  7.] 
adversary cards in hand: [3. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1 10] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6832088232040405
desired expected reward: 26.0152587890625



buy possibilites: [-1] 
expected returns: [[20.05219]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 8.] 
cards in discard: [ 0. 11.  6.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  3. 10.  4.  0. 10.  4.  4. 10.  3. 10.  7.] 
adversary cards in hand: [3. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1 10] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0   -8    0 -300
    0    0] 
sum of rewards: -313 

action type: buy - action 6.0
Learning step: -9.891275405883789
desired expected reward: 13.836214065551758






Player: 1 
cards in hand: [3. 0. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 8. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  3. 10.  4.  0. 10.  4.  4. 10.  3. 10.  7.] 
adversary cards in hand: [29. 11.  3.  3. 15.] 
adversary cards in discard: [ 0. 11.  6.  8.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6] -> size -> 43 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 8. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 28. 30. 26. 29.  8.  3. 10.  4.  0. 10.  4.  4. 10.  3. 10.  7.] 
adversary cards in hand: [29. 11.  3.  3. 15.] 
adversary cards in discard: [ 0. 11.  6.  8.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6] -> size -> 43 
adversary victory points: 0
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [29. 11.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 15.] 
expected returns: [[25.060455]
 [25.847345]
 [25.653198]
 [24.857807]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3.  3. 15.] 
cards in discard: [ 0. 11.  6.  8.  8.  8.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  3. 10.  4.  0. 10.  4.  4. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 15.  3.  0.  1.] 
adversary cards in discard: [3. 0. 8. 8. 3.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1 10] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4843067526817322
desired expected reward: 19.56788444519043



action possibilites: [-1. 15. 11.] 
expected returns: [[23.589935]
 [23.388838]
 [24.162638]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15. 11.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 26. 29.  8.  3. 10.  4.  0. 10.  4.  4. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 15.  3.  0.  1.] 
adversary cards in discard: [3. 0. 8. 8. 3.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1 10] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 0
Learning step: 0.034470003098249435
desired expected reward: 22.216718673706055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.942144]
 [20.69111 ]
 [23.600477]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15. 11.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6] -> size -> 43 
action values: 1 
buys: 1 
player value: 1 
card supply: [16. 28. 30. 26. 29.  8.  3. 10.  4.  0. 10.  4.  4. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 15.  3.  0.  1.] 
adversary cards in discard: [3. 0. 8. 8. 3.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1 10] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.02268253266811371
desired expected reward: 23.567251205444336



buy possibilites: [-1] 
expected returns: [[17.673386]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15. 11.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 15.  3.  0.  1.] 
adversary cards in discard: [3. 0. 8. 8. 3.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1 10] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -9.
    0. -300.    0.    0.] 
sum of rewards: -294.0 

action type: buy - action 6.0
Learning step: -9.255162239074707
desired expected reward: 11.435948371887207






Player: 1 
cards in hand: [ 0. 15.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0.  1.] 
cards in discard: [3. 0. 8. 8. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0  0 10  0  1 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4. 10.  3. 10.  7.] 
adversary cards in hand: [ 6. 29. 10. 14. 29.] 
adversary cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6] -> size -> 44 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1.] 
cards in discard: [3. 0. 8. 8. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4. 10.  3. 10.  7.] 
adversary cards in hand: [ 6. 29. 10. 14. 29.] 
adversary cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6] -> size -> 44 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [3. 0. 8. 8. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [16. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4. 10.  3. 10.  7.] 
adversary cards in hand: [ 6. 29. 10. 14. 29.] 
adversary cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6] -> size -> 44 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [ 3.  0.  8.  8.  3. 23.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [ 6. 29. 10. 14. 29.] 
adversary cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6] -> size -> 44 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 6. 29. 10. 14. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 14. 29.] 
expected returns: [[12.209722]
 [12.89785 ]
 [11.889355]
 [11.198491]
 [12.89785 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 10. 14. 29.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [10. 10. 14. 29.  8.] 
adversary cards in discard: [ 3.  0.  8.  8.  3. 23. 15.  3.  0.  1.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5504794120788574
desired expected reward: 17.122905731201172



action possibilites: [-1. 10. 14. 29.] 
expected returns: [[15.567735]
 [15.245235]
 [14.541796]
 [16.260067]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 14. 29.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [10. 10. 14. 29.  8.] 
adversary cards in discard: [ 3.  0.  8.  8.  3. 23. 15.  3.  0.  1.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 3
Learning step: 0.2820954918861389
desired expected reward: 11.330157279968262



action possibilites: [-1. 14. 14.] 
expected returns: [[16.598795]
 [15.572857]
 [15.572857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14. 14.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 2 
card supply: [16. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [10. 10. 14. 29.  8.] 
adversary cards in discard: [ 3.  0.  8.  8.  3. 23. 15.  3.  0.  1.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 2
Learning step: 0.8121755123138428
desired expected reward: 14.35772705078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[15.047312 ]
 [15.394194 ]
 [13.8872795]
 [16.573381 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14. 14.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6] -> size -> 44 
action values: 1 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [10. 10. 14. 29.  8.] 
adversary cards in discard: [ 3.  0.  8.  8.  3. 23. 15.  3.  0.  1.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.7147347331047058
desired expected reward: 17.31352996826172






Player: 1 
cards in hand: [10. 10. 14. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 14. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 14. 29.  8.] 
cards in discard: [ 3.  0.  8.  8.  3. 23. 15.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [ 8.  8. 14.  0.  6.] 
adversary cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6] -> size -> 44 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 14. 29.  8.] 
cards in discard: [ 3.  0.  8.  8.  3. 23. 15.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [ 8.  8. 14.  0.  6.] 
adversary cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6] -> size -> 44 
adversary victory points: -1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 8.  8. 14.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
expected returns: [[16.126228]
 [16.303705]
 [16.303705]
 [15.078328]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 14.  0.  6.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [14. 10.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.47895851731300354
desired expected reward: 16.094423294067383



action possibilites: [-1] 
expected returns: [[18.35946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 6.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [14. 10. 10.] 
adversary cards in discard: [ 3. 10.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.19042447209358215
desired expected reward: 15.268754005432129





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[16.73441 ]
 [17.643684]
 [17.108513]
 [15.485463]
 [18.941698]
 [18.032421]
 [18.38022 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 6.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [14. 10. 10.] 
adversary cards in discard: [ 3. 10.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.08578542619943619
desired expected reward: 18.44524574279785



buy possibilites: [-1] 
expected returns: [[19.006353]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 6.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [14. 10. 10.] 
adversary cards in discard: [ 3. 10.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -10.   0.   0.
   0.   0.] 
sum of rewards: 5.0 

action type: buy - action 0.0
Learning step: -0.1524655669927597
desired expected reward: 16.58194351196289






Player: 1 
cards in hand: [14. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10. 10.] 
cards in discard: [ 3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [10.  6.  0. 10.  0.] 
adversary cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0] -> size -> 45 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10. 10.] 
cards in discard: [ 3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [10.  6.  0. 10.  0.] 
adversary cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0] -> size -> 45 
adversary victory points: -1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [10.  6.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[15.6918545]
 [15.362467 ]
 [15.362467 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0. 10.  0.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [ 3.  8. 23.  8.  1.] 
adversary cards in discard: [ 3. 10. 14. 10. 10.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5572707056999207
desired expected reward: 18.44908332824707



action possibilites: [-1. 10.] 
expected returns: [[16.9009  ]
 [16.536415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  0.  4.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0] -> size -> 45 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [ 3.  8. 23.  8.  1.] 
adversary cards in discard: [ 3. 10. 14. 10. 10.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.16583435237407684
desired expected reward: 15.528300285339355





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[15.28315 ]
 [15.643197]
 [14.098211]
 [16.9009  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  0.  4.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [ 3.  8. 23.  8.  1.] 
adversary cards in discard: [ 3. 10. 14. 10. 10.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.10850835591554642
desired expected reward: 17.009408950805664






Player: 1 
cards in hand: [ 3.  8. 23.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 23.  8.  1.] 
cards in discard: [ 3. 10. 14. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [11. 29.  0.  1.  0.] 
adversary cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6. 10.  6.  0. 10.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0] -> size -> 45 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 23.  8.  1.] 
cards in discard: [ 3. 10. 14. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [11. 29.  0.  1.  0.] 
adversary cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6. 10.  6.  0. 10.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0] -> size -> 45 
adversary victory points: -1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [11. 29.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[9.272192]
 [9.776559]
 [9.948723]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  1.  0.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6. 10.  6.  0. 10.  0.  4.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 26. 29.  8.  2. 10.  4.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [15.  0. 29.  3.  8.] 
adversary cards in discard: [ 3. 10. 14. 10. 10.  3.  8. 23.  8.  1.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.554941713809967
desired expected reward: 16.345958709716797



action possibilites: [-1] 
expected returns: [[13.325375]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  0.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6. 10.  6.  0. 10.  0.  4. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 26. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [15.  0. 29.  3.  8.] 
adversary cards in discard: [ 3. 10. 14. 10. 10.  3.  8. 23.  8.  1.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -11   0   0   9   0] 
sum of rewards: 13 

action type: gain_card_n - action 5
Learning step: 0.2917362451553345
desired expected reward: 8.23107624053955





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[11.722403]
 [12.595715]
 [12.087791]
 [10.521921]
 [12.11598 ]
 [13.847775]
 [14.026076]
 [12.251267]
 [12.974466]
 [13.124578]
 [13.325373]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  1.  0.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6. 10.  6.  0. 10.  0.  4. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 28. 30. 26. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [15.  0. 29.  3.  8.] 
adversary cards in discard: [ 3. 10. 14. 10. 10.  3.  8. 23.  8.  1.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1855284720659256
desired expected reward: 13.510903358459473






Player: 1 
cards in hand: [15.  0. 29.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 29.  3.  8.] 
cards in discard: [ 3. 10. 14. 10. 10.  3.  8. 23.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29  0 10  0  1 10 23] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 26. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [ 0. 29.  0. 10.  6.] 
adversary cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6. 10.  6.  0. 10.  0.  4. 11. 11. 29.  0.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11] -> size -> 46 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  8.] 
cards in discard: [ 3. 10. 14. 10. 10.  3.  8. 23.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 28. 30. 26. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [ 0. 29.  0. 10.  6.] 
adversary cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6. 10.  6.  0. 10.  0.  4. 11. 11. 29.  0.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11] -> size -> 46 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  8.] 
cards in discard: [ 3. 10. 14. 10. 10.  3.  8. 23.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 28. 30. 26. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [ 0. 29.  0. 10.  6.] 
adversary cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6. 10.  6.  0. 10.  0.  4. 11. 11. 29.  0.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11] -> size -> 46 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  8.] 
cards in discard: [ 3. 10. 14. 10. 10.  3.  8. 23.  8.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 28. 30. 26. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [ 0. 29.  0. 10.  6.] 
adversary cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6. 10.  6.  0. 10.  0.  4. 11. 11. 29.  0.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11] -> size -> 46 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[10.030137]
 [10.738756]
 [ 9.677328]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 10.  6.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6. 10.  6.  0. 10.  0.  4. 11. 11. 29.  0.
  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [29. 15. 10. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4419604241847992
desired expected reward: 12.883414268493652



action possibilites: [-1. 10.] 
expected returns: [[17.011335]
 [16.634672]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6. 10.  6.  0. 10.  0.  4. 11. 11. 29.  0.
  1.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 28. 30. 26. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [29. 15. 10. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.3481026589870453
desired expected reward: 9.645914077758789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[15.290522]
 [16.228037]
 [15.682788]
 [14.010857]
 [15.713051]
 [17.572187]
 [17.763601]
 [15.858309]
 [16.634672]
 [16.795824]
 [17.011335]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6. 10.  6.  0. 10.  0.  4. 11. 11. 29.  0.
  1.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 28. 30. 26. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [29. 15. 10. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.11331939697265625
desired expected reward: 17.124652862548828



buy possibilites: [-1] 
expected returns: [[16.714191]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 0. 11.  6.  8.  8.  8. 11.  6. 29.  3.  3. 15. 11.  0. 10. 29. 29.  6.
 14. 14.  0. 14.  8.  8.  0.  6. 10.  6.  0. 10.  0.  4. 11. 11. 29.  0.
  1.  0.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 28. 30. 25. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [29. 15. 10. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -12.   0.   0.
   2.   0.] 
sum of rewards: 5.0 

action type: buy - action 3.0
Learning step: -0.14498458802700043
desired expected reward: 15.537802696228027






Player: 1 
cards in hand: [29. 15. 10. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 10. 14.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [6. 3. 8. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3] -> size -> 47 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15. 10. 14.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 25. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [6. 3. 8. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3] -> size -> 47 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15. 10. 14.  0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 25. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [6. 3. 8. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3] -> size -> 47 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [6. 3. 8. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[22.437912]
 [22.606497]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 3. 6.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14  6
 10  0  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 25. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [ 8. 10.  3.  3.  8.] 
adversary cards in discard: [ 0. 29. 15. 10. 14.  0.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4147655665874481
desired expected reward: 16.29942512512207



action possibilites: [-1] 
expected returns: [[16.200373]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14 10  0
  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 25. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [ 8. 10.  3.  3.  8.] 
adversary cards in discard: [ 0. 29. 15. 10. 14.  0.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 3
Learning step: -0.011523570865392685
desired expected reward: 21.042724609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.697821]
 [13.469393]
 [16.350666]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14 10  0
  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 28. 30. 25. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [ 8. 10.  3.  3.  8.] 
adversary cards in discard: [ 0. 29. 15. 10. 14.  0.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.12297528982162476
desired expected reward: 16.323347091674805



buy possibilites: [-1] 
expected returns: [[19.203691]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [0.] 
cards in deck: 42 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14 10  0
  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 25. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [ 8. 10.  3.  3.  8.] 
adversary cards in discard: [ 0. 29. 15. 10. 14.  0.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -11   0   0   0   0] 
sum of rewards: 4 

action type: buy - action 0.0
Learning step: -0.11929584294557571
desired expected reward: 14.578524589538574






Player: 1 
cards in hand: [ 8. 10.  3.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.  3.  8.] 
cards in discard: [ 0. 29. 15. 10. 14.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 25. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [ 6.  0.  4. 11.  0.] 
adversary cards in discard: [0. 8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14 10  0
  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0] -> size -> 46 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.  3.  8.] 
cards in discard: [ 0. 29. 15. 10. 14.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 28. 30. 25. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [ 6.  0.  4. 11.  0.] 
adversary cards in discard: [0. 8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14 10  0
  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0] -> size -> 46 
adversary victory points: 0
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  4. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[25.08289]
 [25.64374]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  4. 11.  0.] 
cards in discard: [0. 8. 3. 6.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14 10  0
  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 25. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  3. 10.  7.] 
adversary cards in hand: [23.  3.  0. 10.  8.] 
adversary cards in discard: [ 0. 29. 15. 10. 14.  0.  8. 10.  3.  3.  8.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.45920705795288086
desired expected reward: 18.744483947753906



action possibilites: [-1] 
expected returns: [[26.9047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 4. 0.] 
cards in discard: [ 0.  8.  3.  6. 10.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14 10  0
  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 25. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [23.  3.  0. 10.  8.] 
adversary cards in discard: [ 0. 29. 15. 10. 14.  0.  8. 10.  3.  3.  8.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -12   0   0   9   0] 
sum of rewards: 12 

action type: gain_card_n - action 8
Learning step: -0.10620763897895813
desired expected reward: 24.850692749023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[25.302588]
 [25.697105]
 [24.032711]
 [27.02787 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 4. 0.] 
cards in discard: [ 0.  8.  3.  6. 10.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14 10  0
  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 28. 30. 25. 29.  8.  2. 10.  3.  0. 10.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [23.  3.  0. 10.  8.] 
adversary cards in discard: [ 0. 29. 15. 10. 14.  0.  8. 10.  3.  3.  8.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.08605585247278214
desired expected reward: 26.81864356994629



buy possibilites: [-1] 
expected returns: [[20.228]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 4. 0.] 
cards in discard: [ 0.  8.  3.  6. 10.  6.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14 10  0
  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 28. 30. 25. 29.  8.  1. 10.  3.  0. 10.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [23.  3.  0. 10.  8.] 
adversary cards in discard: [ 0. 29. 15. 10. 14.  0.  8. 10.  3.  3.  8.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0] -> size -> 17 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.  -13.
    0. -300.    0.    0.] 
sum of rewards: -298.0 

action type: buy - action 6.0
Learning step: -9.448587417602539
desired expected reward: 14.584123611450195






Player: 1 
cards in hand: [23.  3.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  0. 10.  8.] 
cards in discard: [ 0. 29. 15. 10. 14.  0.  8. 10.  3.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 25. 29.  8.  1. 10.  3.  0. 10.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 8.  0. 15. 10.  8.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14 10  0
  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6] -> size -> 48 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  0. 10.  8.] 
cards in discard: [ 0. 29. 15. 10. 14.  0.  8. 10.  3.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 28. 30. 25. 29.  8.  1. 10.  3.  0. 10.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 8.  0. 15. 10.  8.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14 10  0
  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6] -> size -> 48 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  0. 10.  8.] 
cards in discard: [ 0. 29. 15. 10. 14.  0.  8. 10.  3.  3.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 25. 29.  8.  1. 10.  3.  0. 10.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 8.  0. 15. 10.  8.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14 10  0
  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6] -> size -> 48 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 15. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.  8.] 
expected returns: [[12.221905 ]
 [12.354957 ]
 [12.0271435]
 [11.883077 ]
 [12.354957 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15. 10.  8.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14 10  0
  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  1. 10.  3.  0. 10.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 8. 14.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6286799907684326
desired expected reward: 19.599321365356445



action possibilites: [-1.  8. 15.  8. 14.] 
expected returns: [[13.016349]
 [13.150247]
 [12.820331]
 [13.150247]
 [11.996144]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  8. 14.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11 14  8  8  0  1 10 29 10 14  8 14 10  0
  4 10  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6] -> size -> 48 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  1. 10.  3.  0. 10.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 8. 14.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.22886721789836884
desired expected reward: 12.111944198608398



action possibilites: [-1. 15.] 
expected returns: [[21.53307 ]
 [21.315622]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  1. 10.  3.  0. 10.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 8. 14.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.9505966901779175
desired expected reward: 11.770170211791992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.90585 ]
 [18.661024]
 [21.590443]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 25. 29.  8.  1. 10.  3.  0. 10.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 8. 14.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.6177884340286255
desired expected reward: 22.150854110717773






Player: 1 
cards in hand: [ 8. 14.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  3.  1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  1. 10.  3.  0. 10.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 0. 29.  0.  6. 10.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6] -> size -> 46 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 28. 30. 25. 29.  8.  1. 10.  3.  0. 10.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [29.  0.  6.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6] -> size -> 46 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 28. 30. 25. 29.  8.  1. 10.  3.  0. 10.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [29.  0.  6.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6] -> size -> 46 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 1.] 
cards in discard: [25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  1. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [29.  0.  6.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6] -> size -> 46 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [29.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[13.32348 ]
 [13.978677]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  1. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [10.  3.  0. 15. 29.] 
adversary cards in discard: [25. 14.  8.  0.  3.  1.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0   -11
     0 -2100   172     0] 
sum of rewards: -1944 

action type: discard_down_to_3_cards - action 0
Learning step: -58.47306442260742
desired expected reward: -48.57005310058594



action possibilites: [-1.] 
expected returns: [[16.841434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 25. 29.  8.  1. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [10.  3.  0. 15. 29.] 
adversary cards in discard: [25. 14.  8.  0.  3.  1.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 2
Learning step: 0.287139892578125
desired expected reward: 11.610312461853027





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[15.203692 ]
 [15.5551195]
 [14.061226 ]
 [16.777895 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 30. 25. 29.  8.  1. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [10.  3.  0. 15. 29.] 
adversary cards in discard: [25. 14.  8.  0.  3.  1.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.10934623330831528
desired expected reward: 16.950780868530273



buy possibilites: [-1] 
expected returns: [[16.887547]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 28. 30. 25. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [10.  3.  0. 15. 29.] 
adversary cards in discard: [25. 14.  8.  0.  3.  1.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25] -> size -> 19 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.  -12.
    0. -300.    0.    0.] 
sum of rewards: -297.0 

action type: buy - action 6.0
Learning step: -9.15451717376709
desired expected reward: 4.906708717346191






Player: 1 
cards in hand: [10.  3.  0. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 15. 29.] 
cards in discard: [25. 14.  8.  0.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [11.  8.  0.  6.  3.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 47 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1. 15. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15. 29. 10.] 
cards in discard: [25. 14.  8.  0.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [11.  8.  0.  6.  3.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 47 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15. 29. 10.] 
cards in discard: [25. 14.  8.  0.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 25. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [11.  8.  0.  6.  3.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 47 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15. 29. 10.] 
cards in discard: [25. 14.  8.  0.  3.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 28. 30. 25. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [11.  8.  0.  6.  3.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 47 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [11.  8.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[8.858108]
 [9.35109 ]
 [8.994016]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  6.  3.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  6  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 25. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 0. 23.  8.  3. 10.] 
adversary cards in discard: [25. 14.  8.  0.  3.  1.  0. 10.  3.  0. 15. 29. 10.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0] -> size -> 20 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5608201026916504
desired expected reward: 16.32672691345215



action possibilites: [-1] 
expected returns: [[9.421766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 25. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 0. 23.  8.  3. 10.] 
adversary cards in discard: [25. 14.  8.  0.  3.  1.  0. 10.  3.  0. 15. 29. 10.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0] -> size -> 20 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 3
Learning step: 0.3266914486885071
desired expected reward: 7.73459529876709





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[7.8892965]
 [9.421765 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 28. 30. 25. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 0. 23.  8.  3. 10.] 
adversary cards in discard: [25. 14.  8.  0.  3.  1.  0. 10.  3.  0. 15. 29. 10.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0] -> size -> 20 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.25983917713165283
desired expected reward: 9.681605339050293






Player: 1 
cards in hand: [ 0. 23.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 10.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  8.  3. 10.] 
cards in discard: [25. 14.  8.  0.  3.  1.  0. 10.  3.  0. 15. 29. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 25. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [10.  0. 29.  0. 11.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 10.  0.] 
cards in discard: [25. 14.  8.  0.  3.  1.  0. 10.  3.  0. 15. 29. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0] -> size -> 20 
action values: 1 
buys: 1 
player value: 1 
card supply: [10. 28. 30. 25. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [10.  0. 29.  0. 11.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3. 10.  0.] 
cards in discard: [25. 14.  8.  0.  3.  1.  0. 10.  3.  0. 15. 29. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0] -> size -> 20 
action values: 0 
buys: 2 
player value: 3 
card supply: [10. 28. 30. 25. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [10.  0. 29.  0. 11.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
adversary victory points: -1
player victory points: 3 


buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3. 10.  0.] 
cards in discard: [25. 14.  8.  0.  3.  1.  0. 10.  3.  0. 15. 29. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 28. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [10.  0. 29.  0. 11.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [10.  0. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[13.25999 ]
 [12.899437]
 [13.918799]
 [13.74722 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  0. 11.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 3. 25. 14.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2903900742530823
desired expected reward: 9.131376266479492



action possibilites: [-1. 10. 11.] 
expected returns: [[11.277123]
 [10.920869]
 [11.758546]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  6.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 28. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 3. 25. 14.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.19397319853305817
desired expected reward: 12.720574378967285





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.718125]
 [11.277123]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  6.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
action values: 1 
buys: 1 
player value: 1 
card supply: [10. 28. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 3. 25. 14.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.2235483080148697
desired expected reward: 11.500670433044434






Player: 1 
cards in hand: [ 3. 25. 14.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.  8.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 14.  3.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 8. 11.  6.  3. 10.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.  0.  0. 29. 10. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  3.  8.  1. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 8. 11.  6.  3. 10.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.  0.  0. 29. 10. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  3.  8.  1. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 28. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 8. 11.  6.  3. 10.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.  0.  0. 29. 10. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  6.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[13.441009]
 [13.561117]
 [13.913072]
 [13.092336]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  6.  3. 10.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.  0.  0. 29. 10. 11.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [25.  3. 14.  3.  8.  1. 10.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3456804156303406
desired expected reward: 10.931442260742188



action possibilites: [-1.  8. 11. 29.] 
expected returns: [[12.639954]
 [12.758797]
 [13.10703 ]
 [13.271508]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  6.  3. 29.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.  0.  0. 29. 10. 11.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [25.  3. 14.  3.  8.  1. 10.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.1938323825597763
desired expected reward: 13.286168098449707



action possibilites: [-1.] 
expected returns: [[11.180497]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.  0.  0. 29. 10. 11.  6.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
action values: 2 
buys: 0 
player value: 1 
card supply: [10. 28. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [25.  3. 14.  3.  8.  1. 10.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 9
Learning step: 0.7602508068084717
desired expected reward: 14.331731796264648





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 9.671315]
 [10.017349]
 [11.180497]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.  0.  0. 29. 10. 11.  6.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 28. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [25.  3. 14.  3.  8.  1. 10.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.8244978189468384
desired expected reward: 12.004995346069336






Player: 1 
cards in hand: [29.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [25.  3. 14.  3.  8.  1. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 0. 14. 29. 11. 29.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.  0.  0. 29. 10. 11.  6.  8. 11. 10. 29.
  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [25.  3. 14.  3.  8.  1. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 28. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 0. 14. 29. 11. 29.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.  0.  0. 29. 10. 11.  6.  8. 11. 10. 29.
  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [25.  3. 14.  3.  8.  1. 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 0. 14. 29. 11. 29.] 
adversary cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.  0.  0. 29. 10. 11.  6.  8. 11. 10. 29.
  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 0. 14. 29. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29. 11. 29.] 
expected returns: [[15.822268]
 [14.708584]
 [16.522387]
 [16.340038]
 [16.522387]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 29. 11. 29.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.  0.  0. 29. 10. 11.  6.  8. 11. 10. 29.
  6.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [15.  8.  3.  8.  0.] 
adversary cards in discard: [25.  3. 14.  3.  8.  1. 10.  1. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3164595663547516
desired expected reward: 10.86403751373291



action possibilites: [-1. 14. 11. 29.] 
expected returns: [[13.576964]
 [12.473644]
 [14.086217]
 [14.265575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11. 29.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.  0.  0. 29. 10. 11.  6.  8. 11. 10. 29.
  6.  3.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [15.  8.  3.  8.  0.] 
adversary cards in discard: [25.  3. 14.  3.  8.  1. 10.  1. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 0
Learning step: 0.1693163365125656
desired expected reward: 14.332197189331055





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.924889]
 [13.576964]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11. 29.] 
cards in discard: [ 0.  8.  3.  6. 10.  6. 11.  6.  0.  4.  0. 10.  8.  0. 15.  0. 10. 14.
  6. 29.  0.  6.  8. 11.  0.  3.  0.  0. 29. 10. 11.  6.  8. 11. 10. 29.
  6.  3.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
action values: 1 
buys: 1 
player value: 1 
card supply: [10. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [15.  8.  3.  8.  0.] 
adversary cards in discard: [25.  3. 14.  3.  8.  1. 10.  1. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.17831046879291534
desired expected reward: 13.755274772644043






Player: 1 
cards in hand: [15.  8.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  3.  8.  0.] 
cards in discard: [25.  3. 14.  3.  8.  1. 10.  1. 29.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [29.  4. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.] 
cards in discard: [25.  3. 14.  3.  8.  1. 10.  1. 29.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [29.  4. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.] 
cards in discard: [25.  3. 14.  3.  8.  1. 10.  1. 29.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [29.  4. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.] 
cards in discard: [25.  3. 14.  3.  8.  1. 10.  1. 29.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [29.  4. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [29.  4. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.] 
expected returns: [[18.959421]
 [19.620213]
 [18.581013]
 [19.071009]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  4. 10.  8.  0.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  0. 23. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0] -> size -> 22 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3578271269798279
desired expected reward: 13.279375076293945



action possibilites: [-1. 29.  8.] 
expected returns: [[18.482574]
 [19.162512]
 [18.597378]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  4.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  0. 23. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0] -> size -> 22 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.09028976410627365
desired expected reward: 18.671302795410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[16.676756]
 [17.062988]
 [18.350872]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  4.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  0. 23. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0] -> size -> 22 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.07991334795951843
desired expected reward: 18.562488555908203



buy possibilites: [-1] 
expected returns: [[14.896657]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  4.  8.  0.  0.] 
cards in discard: [0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  0. 23. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0] -> size -> 22 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -12.   0.   0.
   0.   0.] 
sum of rewards: 3.0 

action type: buy - action 0.0
Learning step: -0.2538878321647644
desired expected reward: 16.422870635986328






Player: 1 
cards in hand: [ 0.  0. 23. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10. 10.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 23. 10. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 3. 10.  6. 10. 11.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0] -> size -> 47 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [23.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0] -> size -> 22 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 8. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 3. 10.  6. 10. 11.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0] -> size -> 47 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0] -> size -> 22 
action values: 2 
buys: 1 
player value: 1 
card supply: [ 8. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 3. 10.  6. 10. 11.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0] -> size -> 47 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [23. 10. 10.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0] -> size -> 22 
action values: 3 
buys: 1 
player value: 1 
card supply: [ 8. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 3. 10.  6. 10. 11.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0] -> size -> 47 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.] 
cards in discard: [3. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23. 10. 10. 29.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0] -> size -> 22 
action values: 3 
buys: 1 
player value: 2 
card supply: [ 8. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 3. 10.  6. 10. 11.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0] -> size -> 47 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [3. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23. 10. 10. 29. 25.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0] -> size -> 22 
action values: 2 
buys: 1 
player value: 2 
card supply: [ 8. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 3. 10.  6. 10. 11.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0] -> size -> 47 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [3. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23. 10. 10. 29. 25.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0] -> size -> 22 
action values: 0 
buys: 2 
player value: 7 
card supply: [ 8. 27. 30. 24. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 3. 10.  6. 10. 11.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0] -> size -> 47 
adversary victory points: -1
player victory points: 3 


buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [3. 3. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23. 10. 10. 29. 25.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 8. 27. 30. 23. 29.  8.  0. 10.  3.  0.  9.  4.  4.  9.  2. 10.  7.] 
adversary cards in hand: [ 3. 10.  6. 10. 11.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0] -> size -> 47 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [ 3.  3.  3. 23.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23. 10. 10. 29. 25.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0  3 23] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 23. 29.  8.  0. 10.  3.  0.  9.  4.  4.  8.  2. 10.  7.] 
adversary cards in hand: [ 3. 10.  6. 10. 11.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0] -> size -> 47 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  6. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[14.699685]
 [14.319587]
 [14.319587]
 [15.193004]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6. 10. 11.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 23. 29.  8.  0. 10.  3.  0.  9.  4.  4.  8.  2. 10.  7.] 
adversary cards in hand: [15. 10.  0.  1.  8.] 
adversary cards in discard: [ 3.  3.  3. 23. 23. 10. 10. 29. 25.  0.  0.  1.  0.] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0  3 23] -> size -> 24 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.44207748770713806
desired expected reward: 14.45457935333252



action possibilites: [-1. 10. 11.] 
expected returns: [[15.447915]
 [15.061963]
 [15.946361]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10. 11.  3.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0] -> size -> 47 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 23. 29.  8.  0. 10.  3.  0.  9.  4.  4.  8.  2. 10.  7.] 
adversary cards in hand: [15. 10.  0.  1.  8.] 
adversary cards in discard: [ 3.  3.  3. 23. 23. 10. 10. 29. 25.  0.  0.  1.  0.] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0  3 23] -> size -> 24 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.18397724628448486
desired expected reward: 14.50356388092041



action possibilites: [-1. 10.] 
expected returns: [[15.780615]
 [15.400073]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.  3.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.] 
cards in deck: 34 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 23. 29.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [15. 10.  0.  1.  8.] 
adversary cards in discard: [ 3.  3.  3. 23. 23. 10. 10. 29. 25.  0.  0.  1.  0.] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0  3 23] -> size -> 24 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0 -13   0   0  16   0] 
sum of rewards: 38 

action type: gain_card_n - action 6
Learning step: 0.9264516830444336
desired expected reward: 13.514668464660645



action possibilites: [-1.] 
expected returns: [[15.455716]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 6.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.] 
cards in deck: 33 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14] -> size -> 48 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 23. 29.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [15. 10.  0.  1.  8.] 
adversary cards in discard: [ 3.  3.  3. 23. 23. 10. 10. 29. 25.  0.  0.  1.  0.] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0  3 23] -> size -> 24 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 10.0
Learning step: 1.350282907485962
desired expected reward: 16.750354766845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.863359]
 [15.499162]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 6.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.] 
cards in deck: 33 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14] -> size -> 48 
action values: 2 
buys: 1 
player value: 0 
card supply: [ 8. 27. 30. 23. 29.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [15. 10.  0.  1.  8.] 
adversary cards in discard: [ 3.  3.  3. 23. 23. 10. 10. 29. 25.  0.  0.  1.  0.] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0  3 23] -> size -> 24 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 1.3421993255615234
desired expected reward: 16.797916412353516



buy possibilites: [-1] 
expected returns: [[17.175236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 6.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0] -> size -> 49 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 29.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [15. 10.  0.  1.  8.] 
adversary cards in discard: [ 3.  3.  3. 23. 23. 10. 10. 29. 25.  0.  0.  1.  0.] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0  3 23] -> size -> 24 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0 -14   0   0   0   0] 
sum of rewards: 41 

action type: buy - action 0.0
Learning step: 0.9944391250610352
desired expected reward: 14.857799530029297






Player: 1 
cards in hand: [15. 10.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  1.  8.] 
cards in discard: [ 3.  3.  3. 23. 23. 10. 10. 29. 25.  0.  0.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  3 14  8  8 10  8 29 10  0  1 10 23  0  0  0 25  0  3  1  0  3 23] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 29.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 0.  8.  8. 14.  0.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0] -> size -> 49 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  8.] 
cards in discard: [ 3.  3.  3. 23. 23. 10. 10. 29. 25.  0.  0.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 27. 30. 23. 29.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 0.  8.  8. 14.  0.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0] -> size -> 49 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  8.] 
cards in discard: [ 3.  3.  3. 23. 23. 10. 10. 29. 25.  0.  0.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 27. 30. 23. 29.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 0.  8.  8. 14.  0.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0] -> size -> 49 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  8.] 
cards in discard: [ 3.  3.  3. 23. 23. 10. 10. 29. 25.  0.  0.  1.  0.  4.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 0.  8.  8. 14.  0.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0] -> size -> 49 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  8. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
expected returns: [[14.358249]
 [14.468484]
 [14.468484]
 [13.286408]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 14.  0.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [ 3.  3.  3. 23. 23. 10. 10. 29. 25.  0.  0.  1.  0.  4. 15. 10.  1.  8.] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5160518288612366
desired expected reward: 16.659183502197266



action possibilites: [-1] 
expected returns: [[13.47362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 27. 30. 23. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 3.  3.  3. 23. 23. 10. 10. 29. 25.  0.  0.  1.  0.  4. 15. 10.  1.  8.
  8.  8.] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.1928807497024536
desired expected reward: 13.479289054870605





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[11.948647]
 [12.761383]
 [12.300733]
 [12.31428 ]
 [13.939596]
 [14.103724]
 [12.457625]
 [13.122921]
 [13.273435]
 [13.480097]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0] -> size -> 49 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 27. 30. 23. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 3.  3.  3. 23. 23. 10. 10. 29. 25.  0.  0.  1.  0.  4. 15. 10.  1.  8.
  8.  8.] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.18435925245285034
desired expected reward: 13.657979965209961






Player: 1 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  3.  3. 23. 23. 10. 10. 29. 25.  0.  0.  1.  0.  4. 15. 10.  1.  8.
  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [29.  8.  6.  0.  0.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0] -> size -> 49 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  3.  3. 23. 23. 10. 10. 29. 25.  0.  0.  1.  0.  4. 15. 10.  1.  8.
  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 27. 30. 23. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [29.  8.  6.  0.  0.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0] -> size -> 49 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  3.  3. 23. 23. 10. 10. 29. 25.  0.  0.  1.  0.  4. 15. 10.  1.  8.
  8.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [29.  8.  6.  0.  0.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0] -> size -> 49 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [29.  8.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[10.914048]
 [11.540507]
 [11.019799]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  6.  0.  0.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 23. 14.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3] -> size -> 25 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4364396631717682
desired expected reward: 13.043658256530762





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 9.378091]
 [ 9.730178]
 [10.914048]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  6.  0.  0.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 27. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 23. 14.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3] -> size -> 25 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.37043941020965576
desired expected reward: 10.543607711791992



buy possibilites: [-1] 
expected returns: [[8.485223]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  6.  0.  0.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 27. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 23. 14.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3] -> size -> 25 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -15.   0.   0.
   0.   0.] 
sum of rewards: -20.0 

action type: buy - action 0.0
Learning step: -0.7972404360771179
desired expected reward: 8.747269630432129






Player: 1 
cards in hand: [ 3.  0.  0. 23. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 14.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 23. 14.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [29. 15. 29.  0. 14.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0] -> size -> 50 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [23.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3] -> size -> 25 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 6. 27. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [29. 15. 29.  0. 14.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0] -> size -> 50 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 27. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [29. 29.  0.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0] -> size -> 50 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3] -> size -> 25 
action values: 0 
buys: 2 
player value: 5 
card supply: [ 6. 27. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [29. 29.  0.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0] -> size -> 50 
adversary victory points: -1
player victory points: 8 


buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [29. 29.  0.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0] -> size -> 50 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [1. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3  1  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [29. 29.  0.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0] -> size -> 50 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[8.175017]
 [8.76019 ]
 [8.76019 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [23. 10.  3.  0.  0.] 
adversary cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3  1  0] -> size -> 27 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0   -15
     0 -2100   163     0] 
sum of rewards: -1957 

action type: discard_down_to_3_cards - action 1
Learning step: -58.822444915771484
desired expected reward: -52.06284713745117





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[6.750346]
 [8.175017]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [23. 10.  3.  0.  0.] 
adversary cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3  1  0] -> size -> 27 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3153964579105377
desired expected reward: 7.859621047973633



buy possibilites: [-1] 
expected returns: [[8.559651]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [23. 10.  3.  0.  0.] 
adversary cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3  1  0] -> size -> 27 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -16.   0.   0.
   0.   0.] 
sum of rewards: -21.0 

action type: buy - action 0.0
Learning step: -0.7426339983940125
desired expected reward: 6.007711887359619






Player: 1 
cards in hand: [23. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 10.  3.  0.  0.] 
cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3  1  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 6.  6.  6.  0. 11.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0] -> size -> 51 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23. 10.  3.  0.  0.] 
cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3  1  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 6.  6.  6.  0. 11.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0] -> size -> 51 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23. 10.  3.  0.  0.] 
cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3  1  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 6.  6.  6.  0. 11.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0] -> size -> 51 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[17.45444 ]
 [17.926407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  6.  0. 11.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 0.  3. 10. 15.  8.] 
adversary cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.  0. 23. 10.  3.  0.  0.] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3  1  0  0] -> size -> 28 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.22054453194141388
desired expected reward: 8.339106559753418





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.879798]
 [17.45444 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  6.  0. 11.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0] -> size -> 51 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 0.  3. 10. 15.  8.] 
adversary cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.  0. 23. 10.  3.  0.  0.] 
adversary owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3  1  0  0] -> size -> 28 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.49697500467300415
desired expected reward: 16.95746421813965



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3. 10. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 15.  8.] 
cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.  0. 23. 10.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  3 14  8  8 10  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4
  3  1  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [10. 29. 10.  6.  0.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.  6.  6.  6.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0] -> size -> 51 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.] 
cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.  0. 23. 10.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  3 14  8  8  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4  3
  1  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [10. 29. 10.  6.  0.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.  6.  6.  6.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0] -> size -> 51 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.] 
cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.  0. 23. 10.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  3 14  8  8  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4  3
  1  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [10. 29. 10.  6.  0.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.  6.  6.  6.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0] -> size -> 51 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.] 
cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.  0. 23. 10.  3.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  3 14  8  8  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4  3
  1  0  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [10. 29. 10.  6.  0.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.  6.  6.  6.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0] -> size -> 51 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [10. 29. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[16.864267]
 [16.50581 ]
 [17.491209]
 [16.50581 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.  6.  0.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.  6.  6.  6.
  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 3.  1. 10. 29.  8.] 
adversary cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.  0. 23. 10.  3.  0.  0.  0.  8.  0.  3.
 15.] 
adversary owned cards: [15  3  3 14  8  8  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4  3
  1  0  0  0] -> size -> 28 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.49543073773384094
desired expected reward: 16.959009170532227



action possibilites: [-1. 10. 10.] 
expected returns: [[11.549171]
 [11.199338]
 [11.199338]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.  6.  6.  6.
  0. 11.  6.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 3.  1. 10. 29.  8.] 
adversary cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.  0. 23. 10.  3.  0.  0.  0.  8.  0.  3.
 15.] 
adversary owned cards: [15  3  3 14  8  8  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4  3
  1  0  0  0] -> size -> 28 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.08512389659881592
desired expected reward: 16.224567413330078



action possibilites: [-1. 10.] 
expected returns: [[11.90912 ]
 [11.557924]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.  6.  6.  6.
  0. 11.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0] -> size -> 51 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 3.  1. 10. 29.  8.] 
adversary cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.  0. 23. 10.  3.  0.  0.  0.  8.  0.  3.
 15.] 
adversary owned cards: [15  3  3 14  8  8  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4  3
  1  0  0  0] -> size -> 28 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0.8375906348228455
desired expected reward: 12.036928176879883



action possibilites: [-1.] 
expected returns: [[12.266931]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.  6.  6.  6.
  0. 11.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0] -> size -> 51 
action values: 3 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 3.  1. 10. 29.  8.] 
adversary cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.  0. 23. 10.  3.  0.  0.  0.  8.  0.  3.
 15.] 
adversary owned cards: [15  3  3 14  8  8  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4  3
  1  0  0  0] -> size -> 28 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 10.0
Learning step: 1.4320651292800903
desired expected reward: 12.989989280700684





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[10.749633]
 [11.55404 ]
 [11.099719]
 [11.109781]
 [12.722928]
 [12.882108]
 [11.25504 ]
 [11.914369]
 [12.063403]
 [12.266932]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.  6.  6.  6.
  0. 11.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0] -> size -> 51 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 26. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 3.  1. 10. 29.  8.] 
adversary cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.  0. 23. 10.  3.  0.  0.  0.  8.  0.  3.
 15.] 
adversary owned cards: [15  3  3 14  8  8  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4  3
  1  0  0  0] -> size -> 28 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 1.4078435897827148
desired expected reward: 13.674774169921875



buy possibilites: [-1] 
expected returns: [[10.987675]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.  6.  6.  6.
  0. 11.  6.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 25. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [ 3.  1. 10. 29.  8.] 
adversary cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.  0. 23. 10.  3.  0.  0.  0.  8.  0.  3.
 15.] 
adversary owned cards: [15  3  3 14  8  8  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4  3
  1  0  0  0] -> size -> 28 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.   60.    0.    0.    0.    0.  -17.
   0.    0.    4.5   0. ] 
sum of rewards: 42.5 

action type: buy - action 1.0
Learning step: 1.043749451637268
desired expected reward: 12.597789764404297






Player: 1 
cards in hand: [ 3.  1. 10. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 10. 29.  8.] 
cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.  0. 23. 10.  3.  0.  0.  0.  8.  0.  3.
 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  3 14  8  8  8 29 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4  3
  1  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [11.  0.  3. 11. 11.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.  6.  6.  6.
  0. 11.  6.  1.  1. 29. 10. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0  1] -> size -> 52 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 10.] 
cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.  0. 23. 10.  3.  0.  0.  0.  8.  0.  3.
 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  3 14  8  8  8 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4  3  1
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [11.  0.  3. 11. 11.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.  6.  6.  6.
  0. 11.  6.  1.  1. 29. 10. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0  1] -> size -> 52 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 10.] 
cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.  0. 23. 10.  3.  0.  0.  0.  8.  0.  3.
 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  3 14  8  8  8 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4  3  1
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 25. 30. 22. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [11.  0.  3. 11. 11.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.  6.  6.  6.
  0. 11.  6.  1.  1. 29. 10. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0  1] -> size -> 52 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 10.] 
cards in discard: [ 1.  0. 23. 14.  3.  0.  0.  3.  0. 23. 10.  3.  0.  0.  0.  8.  0.  3.
 15.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  3 14  8  8  8 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4  3  1
  0  0  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 21. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [11.  0.  3. 11. 11.] 
adversary cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.  6.  6.  6.
  0. 11.  6.  1.  1. 29. 10. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0  1] -> size -> 52 
adversary victory points: -1
player victory points: 9 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [11.  0.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
expected returns: [[16.728605]
 [17.226873]
 [17.226873]
 [17.226873]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 11. 11.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.  6.  6.  6.
  0. 11.  6.  1.  1. 29. 10. 10.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0  1] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 21. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [10.  1.  4. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  3 14  8  8  8 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4  3  1
  0  0  0  3] -> size -> 28 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.29979443550109863
desired expected reward: 10.687880516052246





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.0776205]
 [16.728605 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 11. 11.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.  6.  6.  6.
  0. 11.  6.  1.  1. 29. 10. 10.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 25. 30. 21. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [10.  1.  4. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  3 14  8  8  8 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4  3  1
  0  0  0  3] -> size -> 28 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4831419587135315
desired expected reward: 16.24546241760254



buy possibilites: [-1] 
expected returns: [[16.481459]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 11. 11.] 
cards in discard: [ 0. 10. 29.  4.  8.  0.  0. 14.  0. 10. 11. 10.  3.  6.  3.  6. 14.  0.
  8.  8.  0.  0. 29.  8.  6.  0.  0. 15. 14.  0. 29. 29.  0.  6.  6.  6.
  0. 11.  6.  1.  1. 29. 10. 10.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0  1  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 25. 30. 21. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [10.  1.  4. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  3 14  8  8  8 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4  3  1
  0  0  0  3] -> size -> 28 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -18.   0.   0.
   0.   0.] 
sum of rewards: -23.0 

action type: buy - action 0.0
Learning step: -0.9590766429901123
desired expected reward: 13.778656959533691






Player: 1 
cards in hand: [10.  1.  4. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  4. 25.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  3 14  8  8  8 10  1 10 23  0  0  0 25  0  3  1  0  3 23  4  3  1
  0  0  0  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 21. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [0. 8. 0. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0  1  0] -> size -> 53 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  3 14  8  8  8 10 10 23  0  0  0 25  0  3  1  0  3 23  3  1  0  0
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 21. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [0. 8. 0. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0  1  0] -> size -> 53 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 25.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  3 14  8  8  8 10 10 23  0  0  0 25  0  3  1  0  3 23  3  1  0  0
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 25. 30. 21. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [0. 8. 0. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0  1  0] -> size -> 53 
adversary victory points: -1
player victory points: 6 


Player 1 won the game! 



Player 0 bought cards:
Copper: 12 
Silver: 2 
Gold: 0 
Estate: 2 
Duchy: 1 
Province: 0 
Curse: 10 

Remodel: 0 
Workshop: 3 
Chapel: 2 
Witch: 0 
Poacher: 4 
Militia: 2 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 8. 0. 0. 4.] 
cards in discard: [] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11  0 11 11  8  0  1 10 29 10 14  8 14 10  0  4 10
  8 15  0 29 29 29  0 11  3  8  6  6  6  6  6  0 11  3  0 10  6  6  0 14
  0  0  0  1  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 21. 28.  8.  0. 10.  3.  0.  9.  4.  3.  8.  2. 10.  7.] 
adversary cards in hand: [10. 25.] 
adversary cards in discard: [0.] 
adversary owned cards: [15  3  3 14  8  8  8 10 10 23  0  0  0 25  0  3  1  0  3 23  3  1  0  0
  0  3  0] -> size -> 27 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1
Learning step: -15.644442558288574
desired expected reward: 0.8370161056518555



