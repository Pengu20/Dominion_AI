 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[52.14319]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -120        0        0       20        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000105 

action type: buy - action 0.0
Learning step: -119995.515625
desired expected reward: -120212.6015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 41.704987]
 [ 82.51377 ]
 [ 56.019794]
 [-23.971731]
 [ 82.1013  ]
 [ 67.33075 ]
 [ 41.28097 ]
 [ 51.321857]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 53.03199768066406



buy possibilites: [-1] 
expected returns: [[59.245712]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 82.51374816894531






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[59.763077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.24571228027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 50.27255 ]
 [ 91.86499 ]
 [ 65.10323 ]
 [-18.116001]
 [ 82.11791 ]
 [ 91.51632 ]
 [ 76.648155]
 [107.82836 ]
 [  8.079048]
 [ 49.94033 ]
 [ 49.210686]
 [ 60.65152 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 60.32103729248047



buy possibilites: [-1] 
expected returns: [[36.667927]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1.  0.  3.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 107.82832336425781






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[52.761505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.66792678833008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 43.920834 ]
 [ 81.398544 ]
 [ 56.956673 ]
 [  7.3122506]
 [-14.431997 ]
 [ 72.39808  ]
 [ 80.998566 ]
 [ 67.34929  ]
 [136.93968  ]
 [ 96.05461  ]
 [  6.99649  ]
 [ 47.57962  ]
 [ 43.480732 ]
 [ 11.694336 ]
 [ 42.737694 ]
 [ 52.43202  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 52.00870132446289



buy possibilites: [-1] 
expected returns: [[63.979294]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 215 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 136.93966674804688






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [25.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [25.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3 3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [25.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 57.78151]
 [100.28994]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [25.  0.  1.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3 3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 63.97929382324219



action possibilites: [-1.] 
expected returns: [[85.41423]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [25.  0.  1.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3 3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 98.93782043457031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 76.361305]
 [113.725914]
 [ 89.81802 ]
 [ 38.712746]
 [ 15.040119]
 [105.000305]
 [113.56066 ]
 [100.103935]
 [166.68187 ]
 [128.17342 ]
 [ 38.573486]
 [ 80.5229  ]
 [ 76.196045]
 [ 43.424942]
 [ 75.62655 ]
 [ 86.359955]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [25.  0.  1.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 28. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3 3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 85.41423034667969



buy possibilites: [-1] 
expected returns: [[92.56444]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [25.  0.  1.  3.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10. 10. 10.  8.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3 3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 205 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 166.68186950683594






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3 3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10. 10. 10.  8.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 29.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25] -> size -> 14 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3 3] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8. 10. 10. 10. 10.  8.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 29.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25] -> size -> 14 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3 3 3] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 27. 30.  8. 10. 10. 10. 10.  8.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 29.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25] -> size -> 14 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 1. 29.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[ 42.857903]
 [ 84.54749 ]
 [122.15915 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8. 10. 10. 10. 10.  8.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3 3 3] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 92.56443786621094



action possibilites: [-1] 
expected returns: [[29.338089]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  9. 10. 10. 10.  8.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3 3 3 6] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 120.9088134765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 19.268368]
 [ 56.897774]
 [ 33.000908]
 [-18.2947  ]
 [-41.818344]
 [ 48.13231 ]
 [ 56.94346 ]
 [ 43.210922]
 [109.71828 ]
 [ 71.642654]
 [-18.222685]
 [ 23.803238]
 [ 19.314043]
 [-13.374325]
 [ 18.881844]
 [ 30.386097]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 27. 30.  8.  9. 10. 10. 10.  8.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3 3 3 6] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.338088989257812



buy possibilites: [-1] 
expected returns: [[31.89809]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0.  3.  0.  0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  9. 10. 10. 10.  7.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3 3 3 6] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 175 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 109.7182846069336






Player: 1 
cards in hand: [0. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3 3 3 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  9. 10. 10. 10.  7.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 25.  0.  3.] 
adversary cards in discard: [25. 25.  1. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25] -> size -> 15 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3 3 3 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 27. 30.  8.  9. 10. 10. 10.  7.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 25.  0.  3.] 
adversary cards in discard: [25. 25.  1. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25] -> size -> 15 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [ 6. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 27. 30.  8.  9. 10.  9. 10.  7.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 25.  0.  3.] 
adversary cards in discard: [25. 25.  1. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25] -> size -> 15 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[23.316288]
 [85.253845]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.  0.  3.] 
cards in discard: [25. 25.  1. 29.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  9. 10.  9. 10.  7.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.898090362548828



action possibilites: [-1] 
expected returns: [[58.686264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0. 0.] 
cards in discard: [25. 25.  1. 29.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  8. 10.  9. 10.  7.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 84.87042236328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 51.44538 ]
 [ 86.27976 ]
 [ 63.27845 ]
 [  4.3823  ]
 [ 77.83124 ]
 [ 86.370926]
 [ 73.085266]
 [100.53619 ]
 [ 22.281816]
 [ 51.756294]
 [ 51.585495]
 [ 61.767128]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0. 0.] 
cards in discard: [25. 25.  1. 29.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 27. 30.  8.  8. 10.  9. 10.  7.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.68626403808594



buy possibilites: [-1] 
expected returns: [[75.60592]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0. 0.] 
cards in discard: [25. 25.  1. 29.  0.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  8. 10.  9. 10.  7.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 83 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 100.53619384765625






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  1.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  8. 10.  9. 10.  7.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1. 25.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  1.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 27. 30.  8.  8. 10.  9. 10.  7.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1. 25.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  1.  6. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  8. 10.  9. 10.  7.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  1. 25.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 25.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[10.487682]
 [88.2012  ]
 [88.2012  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25.  0. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  8. 10.  9. 10.  7.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.60591888427734



action possibilites: [-1] 
expected returns: [[33.118683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 25.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  7. 10.  9. 10.  7.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 3. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 87.08236694335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 29.520737 ]
 [ 61.29557  ]
 [ 41.438572 ]
 [ -2.3719583]
 [-22.179441 ]
 [ 53.93123  ]
 [ 61.71035  ]
 [ 49.79255  ]
 [111.03798  ]
 [ 74.08518  ]
 [ -1.9571548]
 [ 33.956352 ]
 [ 29.935535 ]
 [  2.1815171]
 [ 29.817677 ]
 [ 40.749413 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 25.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 27. 30.  8.  7. 10.  9. 10.  7.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 3. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.118682861328125



buy possibilites: [-1] 
expected returns: [[66.855316]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 25.  0.  3.] 
cards in discard: [25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  7. 10.  9. 10.  6.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 3. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 111.03799438476562






Player: 1 
cards in hand: [1. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 3. 0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  7. 10.  9. 10.  6.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [25. 25.  0.  1.  0. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 3. 0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 27. 30.  8.  7. 10.  9. 10.  6.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [25. 25.  0.  1.  0. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 3. 0.] 
cards in discard: [6. 1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 27. 30.  8.  7. 10.  9. 10.  6.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [25. 25.  0.  1.  0. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 71.140854]
 [100.371124]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [25. 25.  0.  1.  0. 25.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 27. 30.  8.  7. 10.  9. 10.  6.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [6. 1. 1. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.85531616210938



action possibilites: [-1. 29.] 
expected returns: [[66.89616 ]
 [98.130226]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [25. 25.  0.  1.  0. 25.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 27. 30.  8.  7. 10.  9. 10.  6.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [6. 1. 1. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 96.99687194824219



action possibilites: [-1.] 
expected returns: [[107.39411]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [25. 25.  0.  1.  0. 25.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 27. 30. 27. 30.  8.  7. 10.  9. 10.  6.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [6. 1. 1. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 98.13020324707031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[104.134254]
 [132.03531 ]
 [ 87.57092 ]
 [114.17316 ]
 [ 77.6357  ]
 [ 61.072334]
 [125.45586 ]
 [132.19896 ]
 [121.75935 ]
 [173.30713 ]
 [143.24112 ]
 [ 77.83102 ]
 [107.56747 ]
 [104.32959 ]
 [ 81.264656]
 [104.133804]
 [112.72014 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [25. 25.  0.  1.  0. 25.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 27. 30. 27. 30.  8.  7. 10.  9. 10.  6.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [6. 1. 1. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 107.39411163330078



buy possibilites: [-1] 
expected returns: [[142.20657]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [25. 25.  0.  1.  0. 25.  0.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 27. 30.  8.  7. 10.  9. 10.  5.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [6. 1. 1. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 97.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 173.30712890625






Player: 1 
cards in hand: [ 0. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [6. 1. 1. 3. 3. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 27. 30.  8.  7. 10.  9. 10.  5.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25] -> size -> 18 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [6. 1. 1. 3. 3. 3. 0. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8.  7. 10.  9. 10.  5.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [6. 1. 1. 3. 3. 3. 0. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 26. 30.  8.  7. 10.  9. 10.  5.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [6. 1. 1. 3. 3. 3. 0. 3. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 25. 30.  8.  7. 10.  9. 10.  5.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25] -> size -> 18 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[32.788788]
 [97.6125  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 25. 30.  8.  7. 10.  9. 10.  5.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [ 6.  1.  1.  3.  3.  3.  0.  3.  3. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 142.20657348632812



action possibilites: [-1] 
expected returns: [[66.36121]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 29. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 25. 30.  8.  6. 10.  9. 10.  5.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [ 6.  1.  1.  3.  3.  3.  0.  3.  3. 11.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 96.05613708496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[58.58155 ]
 [69.98973 ]
 [ 9.809502]
 [77.80041 ]
 [69.95756 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 29. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 27. 30. 25. 30.  8.  6. 10.  9. 10.  5.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [ 6.  1.  1.  3.  3.  3.  0.  3.  3. 11.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.36121368408203



buy possibilites: [-1] 
expected returns: [[99.31781]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 29. 25.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 25. 30.  8.  6. 10.  9.  9.  5.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [ 6.  1.  1.  3.  3.  3.  0.  3.  3. 11.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 77.80040740966797






Player: 1 
cards in hand: [0. 6. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [ 6.  1.  1.  3.  3.  3.  0.  3.  3. 11.  0.  0.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 25. 30.  8.  6. 10.  9.  9.  5.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 25.  3.  0.  0.  3. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [ 6.  1.  1.  3.  3.  3.  0.  3.  3. 11.  0.  0.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 27. 30. 25. 30.  8.  6. 10.  9.  9.  5.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 25.  3.  0.  0.  3. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [ 6.  1.  1.  3.  3.  3.  0.  3.  3. 11.  0.  0.  3.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 25. 30.  8.  6. 10.  9.  9.  5.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 25.  3.  0.  0.  3. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[41.00801]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8. 25.  3.  0.  0.  3. 29. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 25. 30.  8.  6. 10.  9.  9.  5.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  3.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 99.31781005859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[33.450108]
 [61.981613]
 [43.518616]
 [-4.850374]
 [55.076427]
 [62.059914]
 [51.197502]
 [73.643814]
 [ 9.73262 ]
 [33.64065 ]
 [33.44386 ]
 [42.0618  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8. 25.  3.  0.  0.  3. 29. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 25. 30.  8.  6. 10.  9.  9.  5.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  3.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 37.548118591308594



buy possibilites: [-1] 
expected returns: [[68.419876]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8. 25.  3.  0.  0.  3. 29. 25. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 25. 30.  8.  6. 10.  9.  9.  5.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  3.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 73.64381408691406






Player: 1 
cards in hand: [ 6.  3.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 25. 30.  8.  6. 10.  9.  9.  5.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25. 25.  0. 25.] 
adversary cards in discard: [ 8. 25.  3.  0.  0.  3. 29. 25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 25. 30.  8.  6. 10.  9.  9.  5.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25. 25.  0. 25.] 
adversary cards in discard: [ 8. 25.  3.  0.  0.  3. 29. 25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 25. 30.  8.  6. 10.  9.  9.  5.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25. 25.  0. 25.] 
adversary cards in discard: [ 8. 25.  3.  0.  0.  3. 29. 25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [29. 25. 25.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25. 25.] 
expected returns: [[ 66.808784]
 [ 92.46408 ]
 [116.74789 ]
 [116.74789 ]
 [116.74789 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 25.  0. 25.] 
cards in discard: [ 8. 25.  3.  0.  0.  3. 29. 25. 29.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 25. 30.  8.  6. 10.  9.  9.  5.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 1.] 
adversary cards in discard: [10.  6.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 68.41987609863281



action possibilites: [-1] 
expected returns: [[87.80044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0. 25.  0.  1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 25. 30.  8.  5. 10.  9.  9.  5.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 1.] 
adversary cards in discard: [10.  6.  3.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 116.49032592773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 81.86918 ]
 [109.25953 ]
 [ 91.60893 ]
 [ 41.07556 ]
 [102.37954 ]
 [109.87986 ]
 [ 98.714485]
 [121.46542 ]
 [ 57.26129 ]
 [ 82.47682 ]
 [ 82.566185]
 [ 92.18029 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  0. 25.  0.  1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 25. 30.  8.  5. 10.  9.  9.  5.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 1.] 
adversary cards in discard: [10.  6.  3.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.8004379272461



buy possibilites: [-1] 
expected returns: [[115.08948]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  0. 25.  0.  1.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 25. 30.  8.  5. 10.  9.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 1.] 
adversary cards in discard: [10.  6.  3.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 121.46539306640625






Player: 1 
cards in hand: [3. 3. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 1.] 
cards in discard: [10.  6.  3.  0.  3.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 25. 30.  8.  5. 10.  9.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 25.  3.  0.] 
adversary cards in discard: [29. 25. 29. 25.  0. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 1.] 
cards in discard: [10.  6.  3.  0.  3.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 25. 30.  8.  5. 10.  9.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 25.  3.  0.] 
adversary cards in discard: [29. 25. 29. 25.  0. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 1.] 
cards in discard: [10.  6.  3.  0.  3.  3.  6.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  5. 10.  9.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 25.  3.  0.] 
adversary cards in discard: [29. 25. 29. 25.  0. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[108.989586]
 [160.01627 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.  3.  0.] 
cards in discard: [29. 25. 29. 25.  0. 25.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  5. 10.  9.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0.  1. 11.  3.] 
adversary cards in discard: [10.  6.  3.  0.  3.  3.  6.  1.  3.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 115.0894775390625



action possibilites: [-1] 
expected returns: [[85.147705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0. 8.] 
cards in discard: [29. 25. 29. 25.  0. 25.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  4. 10.  9.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0.  1. 11.  3.] 
adversary cards in discard: [10.  6.  3.  0.  3.  3.  6.  1.  3.  3.  0.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 158.05999755859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 72.75041]
 [100.03353]
 [ 83.03575]
 [ 28.05392]
 [100.44815]
 [ 90.16279]
 [ 73.16505]
 [ 82.65939]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0. 8.] 
cards in discard: [29. 25. 29. 25.  0. 25.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 25. 30.  8.  4. 10.  9.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0.  1. 11.  3.] 
adversary cards in discard: [10.  6.  3.  0.  3.  3.  6.  1.  3.  3.  0.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 85.147705078125



buy possibilites: [-1] 
expected returns: [[67.79227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0. 8.] 
cards in discard: [29. 25. 29. 25.  0. 25.  0.  1. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  4. 10.  8.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0.  1. 11.  3.] 
adversary cards in discard: [10.  6.  3.  0.  3.  3.  6.  1.  3.  3.  0.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 100.44810485839844






Player: 1 
cards in hand: [ 6.  0.  1. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  1. 11.  3.] 
cards in discard: [10.  6.  3.  0.  3.  3.  6.  1.  3.  3.  0.  3.  1.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  4. 10.  8.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 25.  3.  0.] 
adversary cards in discard: [29. 25. 29. 25.  0. 25.  0.  1. 11. 25.  3.  0.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11] -> size -> 22 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 3.] 
cards in discard: [10.  6.  3.  0.  3.  3.  6.  1.  3.  3.  0.  3.  1.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  3. 10.  8.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 25.  3.  0.] 
adversary cards in discard: [29. 25. 29. 25.  0. 25.  0.  1. 11. 25.  3.  0.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11] -> size -> 22 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 3.] 
cards in discard: [10.  6.  3.  0.  3.  3.  6.  1.  3.  3.  0.  3.  1.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 25. 30.  8.  3. 10.  8.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 25.  3.  0.] 
adversary cards in discard: [29. 25. 29. 25.  0. 25.  0.  1. 11. 25.  3.  0.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11] -> size -> 22 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 3.] 
cards in discard: [10.  6.  3.  0.  3.  3.  6.  1.  3.  3.  0.  3.  1.  6.  6. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  3. 10.  7.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 25.  3.  0.] 
adversary cards in discard: [29. 25. 29. 25.  0. 25.  0.  1. 11. 25.  3.  0.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11] -> size -> 22 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [29.  0. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[ 70.8501  ]
 [ 96.56055 ]
 [120.231476]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  3.  0.] 
cards in discard: [29. 25. 29. 25.  0. 25.  0.  1. 11. 25.  3.  0.  3.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  3. 10.  7.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [10.  6.  3.  0.  3.  3.  6.  1.  3.  3.  0.  3.  1.  6.  6. 11. 11.  6.
  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11] -> size -> 29 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.79226684570312



action possibilites: [-1] 
expected returns: [[56.589737]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  2. 10.  7.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [10.  6.  3.  0.  3.  3.  6.  1.  3.  3.  0.  3.  1.  6.  6. 11. 11.  6.
  0.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6] -> size -> 30 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 120.23146057128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[46.546707]
 [73.11715 ]
 [56.56129 ]
 [ 2.484776]
 [73.57839 ]
 [63.48548 ]
 [47.07458 ]
 [56.74363 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 25. 30.  8.  2. 10.  7.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [10.  6.  3.  0.  3.  3.  6.  1.  3.  3.  0.  3.  1.  6.  6. 11. 11.  6.
  0.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6] -> size -> 30 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.58973693847656



buy possibilites: [-1] 
expected returns: [[46.360428]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  0. 29.] 
cards in discard: [11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  2. 10.  6.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [10.  6.  3.  0.  3.  3.  6.  1.  3.  3.  0.  3.  1.  6.  6. 11. 11.  6.
  0.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6] -> size -> 30 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 73.57838439941406






Player: 1 
cards in hand: [0. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [10.  6.  3.  0.  3.  3.  6.  1.  3.  3.  0.  3.  1.  6.  6. 11. 11.  6.
  0.  1.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  2. 10.  6.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3. 25.] 
adversary cards in discard: [11. 25. 29.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [10.  6.  3.  0.  3.  3.  6.  1.  3.  3.  0.  3.  1.  6.  6. 11. 11.  6.
  0.  1.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 25. 30.  8.  2. 10.  6.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3. 25.] 
adversary cards in discard: [11. 25. 29.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [10.  6.  3.  0.  3.  3.  6.  1.  3.  3.  0.  3.  1.  6.  6. 11. 11.  6.
  0.  1.  3.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 24. 30.  8.  2. 10.  6.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3. 25.] 
adversary cards in discard: [11. 25. 29.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[38.2805  ]
 [63.043953]
 [88.98276 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3. 25.] 
cards in discard: [11. 25. 29.  0.  3.  0.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 24. 30.  8.  2. 10.  6.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3] -> size -> 31 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.36042785644531



action possibilites: [-1] 
expected returns: [[41.139114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3. 29.  0.] 
cards in discard: [11. 25. 29.  0.  3.  0.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 24. 30.  8.  1. 10.  6.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6] -> size -> 32 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 88.98274230957031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[35.903175]
 [61.697617]
 [45.93933 ]
 [-7.655269]
 [62.017036]
 [52.824852]
 [36.257072]
 [45.380024]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3. 29.  0.] 
cards in discard: [11. 25. 29.  0.  3.  0.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 24. 30.  8.  1. 10.  6.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6] -> size -> 32 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.13911437988281



buy possibilites: [-1] 
expected returns: [[46.695114]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3. 29.  0.] 
cards in discard: [11. 25. 29.  0.  3.  0.  0. 29. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 24. 30.  8.  1. 10.  5.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6] -> size -> 32 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 62.01701354980469






Player: 1 
cards in hand: [6. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 24. 30.  8.  1. 10.  5.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 25.  3. 11.  0.] 
adversary cards in discard: [11. 25. 29.  0.  3.  0.  0. 29. 11. 25. 29.  0.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11] -> size -> 24 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 24. 30.  8.  1. 10.  5.  9.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 25.  3. 11.  0.] 
adversary cards in discard: [11. 25. 29.  0.  3.  0.  0. 29. 11. 25. 29.  0.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11] -> size -> 24 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 0.] 
cards in discard: [6. 8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 24. 30.  8.  1. 10.  5.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 25.  3. 11.  0.] 
adversary cards in discard: [11. 25. 29.  0.  3.  0.  0. 29. 11. 25. 29.  0.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11] -> size -> 24 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 8. 25.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 11.] 
expected returns: [[17.093292]
 [25.311256]
 [66.205536]
 [33.679394]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  3. 11.  0.] 
cards in discard: [11. 25. 29.  0.  3.  0.  0. 29. 11. 25. 29.  0.  0.  3. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 24. 30.  8.  1. 10.  5.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [6. 8. 6. 6. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.69511413574219



action possibilites: [-1] 
expected returns: [[37.438225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.  0. 25.  1.] 
cards in discard: [11. 25. 29.  0.  3.  0.  0. 29. 11. 25. 29.  0.  0.  3. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 24. 30.  8.  0. 10.  5.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [6. 8. 6. 6. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 66.20548248291016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[32.044224]
 [53.328094]
 [39.820213]
 [53.364788]
 [45.5888  ]
 [32.080917]
 [38.382675]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11.  0. 25.  1.] 
cards in discard: [11. 25. 29.  0.  3.  0.  0. 29. 11. 25. 29.  0.  0.  3. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 24. 30.  8.  0. 10.  5.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [6. 8. 6. 6. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.43822479248047



buy possibilites: [-1] 
expected returns: [[19.050955]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11.  0. 25.  1.] 
cards in discard: [11. 25. 29.  0.  3.  0.  0. 29. 11. 25. 29.  0.  0.  3. 29.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 24. 30.  8.  0. 10.  4.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [6. 8. 6. 6. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 53.364776611328125






Player: 1 
cards in hand: [3. 6. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 0. 3.] 
cards in discard: [6. 8. 6. 6. 6. 0. 0. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 24. 30.  8.  0. 10.  4.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 3.] 
cards in discard: [6. 8. 6. 6. 6. 0. 0. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 26. 30. 24. 30.  8.  0. 10.  4.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11. 25.] 
expected returns: [[-12.509487 ]
 [ 10.792831 ]
 [ 10.792831 ]
 [  1.6420426]
 [ 35.17392  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 11. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 24. 30.  8.  0. 10.  4.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  3. 11. 11.] 
adversary cards in discard: [6. 8. 6. 6. 6. 0. 0. 6. 3. 6. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.050954818725586



action possibilites: [-1] 
expected returns: [[18.044895]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 11. 25.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 24. 30.  8.  0. 10.  4.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  3. 11. 11.] 
adversary cards in discard: [6. 8. 6. 6. 6. 0. 0. 6. 3. 6. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.17390823364258





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[10.966246]
 [19.252739]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29. 11. 25.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 26. 30. 24. 30.  8.  0. 10.  4.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  3. 11. 11.] 
adversary cards in discard: [6. 8. 6. 6. 6. 0. 0. 6. 3. 6. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.04489517211914






Player: 1 
cards in hand: [10.  3.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 11. 11.] 
cards in discard: [6. 8. 6. 6. 6. 0. 0. 6. 3. 6. 3. 0. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 24. 30.  8.  0. 10.  4.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25. 29. 25.  0.  0.] 
adversary cards in discard: [25.  0. 29. 29. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 11.  0.] 
cards in discard: [6. 8. 6. 6. 6. 0. 0. 6. 3. 6. 3. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 24. 30.  8.  0. 10.  4.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25. 29. 25.  0.  0.] 
adversary cards in discard: [25.  0. 29. 29. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  0.] 
cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 24. 30.  8.  0. 10.  3.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25. 29. 25.  0.  0.] 
adversary cards in discard: [25.  0. 29. 29. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 11. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 23. 30.  8.  0. 10.  3.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25. 29. 25.  0.  0.] 
adversary cards in discard: [25.  0. 29. 29. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 11. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 26. 30. 23. 30.  8.  0. 10.  3.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25. 29. 25.  0.  0.] 
adversary cards in discard: [25.  0. 29. 29. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 11. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 23. 30.  8.  0. 10.  3.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25. 29. 25.  0.  0.] 
adversary cards in discard: [25.  0. 29. 29. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [25. 29. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[ 6.3394685]
 [54.3683   ]
 [30.22874  ]
 [54.3683   ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25.  0.  0.] 
cards in discard: [25.  0. 29. 29. 11. 25.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 23. 30.  8.  0. 10.  3.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 1. 3. 6. 0.] 
adversary cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 19.25273323059082



action possibilites: [-1] 
expected returns: [[29.33651]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  0.  0.  0.] 
cards in discard: [25.  0. 29. 29. 11. 25.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 23. 30.  8.  0. 10.  3.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 1. 3. 6. 0.] 
adversary cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 54.36827850341797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 15.759075]
 [ 48.255928]
 [ 28.530758]
 [ 40.79658 ]
 [ 49.359802]
 [ 36.58813 ]
 [ 61.957375]
 [-15.302158]
 [ 16.86295 ]
 [ 17.194693]
 [ 30.561771]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  0.  0.  0.  0.] 
cards in discard: [25.  0. 29. 29. 11. 25.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 23. 30.  8.  0. 10.  3.  8.  5.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 1. 3. 6. 0.] 
adversary cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.336509704589844



buy possibilites: [-1] 
expected returns: [[87.67763]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  0.  0.  0.  0.] 
cards in discard: [25.  0. 29. 29. 11. 25.  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 23. 30.  8.  0. 10.  3.  8.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 1. 3. 6. 0.] 
adversary cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 233 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 61.9573974609375






Player: 1 
cards in hand: [1. 1. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3. 6. 0.] 
cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 23. 30.  8.  0. 10.  3.  8.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 29. 25. 11.  1.] 
adversary cards in discard: [25.  0. 29. 29. 11. 25.  3. 29. 25. 29. 25.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29] -> size -> 26 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 6. 0.] 
cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 26. 30. 23. 30.  8.  0. 10.  3.  8.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 29. 25. 11.  1.] 
adversary cards in discard: [25.  0. 29. 29. 11. 25.  3. 29. 25. 29. 25.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29] -> size -> 26 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 6. 0.] 
cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0. 23.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 23. 30.  8.  0. 10.  3.  8.  5.  5. 10.  9.  9. 10. 10.] 
adversary cards in hand: [11. 29. 25. 11.  1.] 
adversary cards in discard: [25.  0. 29. 29. 11. 25.  3. 29. 25. 29. 25.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29] -> size -> 26 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11. 29. 25. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25. 11.] 
expected returns: [[54.72592 ]
 [67.04729 ]
 [74.708206]
 [94.48949 ]
 [67.04729 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 25. 11.  1.] 
cards in discard: [25.  0. 29. 29. 11. 25.  3. 29. 25. 29. 25.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 23. 30.  8.  0. 10.  3.  8.  5.  5. 10.  9.  9. 10. 10.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0. 23.  1.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23] -> size -> 38 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 87.67762756347656



action possibilites: [-1] 
expected returns: [[101.97383]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 11.  1.  3.  3.] 
cards in discard: [25.  0. 29. 29. 11. 25.  3. 29. 25. 29. 25.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 23. 30.  8.  0. 10.  3.  8.  5.  5. 10.  9.  9. 10. 10.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0. 23.  1.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23] -> size -> 38 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 94.48950958251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 94.343895]
 [103.43863 ]
 [109.899864]
 [102.65321 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 11.  1.  3.  3.] 
cards in discard: [25.  0. 29. 29. 11. 25.  3. 29. 25. 29. 25.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 23. 30.  8.  0. 10.  3.  8.  5.  5. 10.  9.  9. 10. 10.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0. 23.  1.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23] -> size -> 38 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.97383117675781



buy possibilites: [-1] 
expected returns: [[95.128006]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 11.  1.  3.  3.] 
cards in discard: [25.  0. 29. 29. 11. 25.  3. 29. 25. 29. 25.  0.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 23. 30.  8.  0. 10.  3.  7.  5.  5. 10.  9.  9. 10. 10.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0. 23.  1.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23] -> size -> 38 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 109.89987182617188






Player: 1 
cards in hand: [0. 6. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0. 23.  1.  1.  3.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 23. 30.  8.  0. 10.  3.  7.  5.  5. 10.  9.  9. 10. 10.] 
adversary cards in hand: [11.  8. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8] -> size -> 27 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0. 23.  1.  1.  3.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 23. 30.  8.  0. 10.  3.  7.  5.  5. 10.  9.  9. 10. 10.] 
adversary cards in hand: [11.  8. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8] -> size -> 27 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0. 23.  1.  1.  3.  6.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 22. 30.  8.  0. 10.  3.  7.  5.  5. 10.  9.  9. 10. 10.] 
adversary cards in hand: [11.  8. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8] -> size -> 27 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [11.  8. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[29.9295  ]
 [45.453545]
 [36.174118]
 [45.453545]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 22. 30.  8.  0. 10.  3.  7.  5.  5. 10.  9.  9. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 6.] 
adversary cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0. 23.  1.  1.  3.  6.  0.  3.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 95.12800598144531



action possibilites: [-1] 
expected returns: [[59.61676]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.] 
cards in discard: [15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 22. 30.  8.  0. 10.  3.  7.  5.  5. 10.  9.  9. 10.  9.] 
adversary cards in hand: [1. 0. 3. 3. 6.] 
adversary cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0. 23.  1.  1.  3.  6.  0.  3.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 61.028564453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[51.02021 ]
 [60.491943]
 [66.95468 ]
 [60.517876]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.] 
cards in discard: [15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 22. 30.  8.  0. 10.  3.  7.  5.  5. 10.  9.  9. 10.  9.] 
adversary cards in hand: [1. 0. 3. 3. 6.] 
adversary cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0. 23.  1.  1.  3.  6.  0.  3.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.61676025390625



buy possibilites: [-1] 
expected returns: [[48.626064]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.] 
cards in discard: [15.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 22. 30.  8.  0. 10.  3.  6.  5.  5. 10.  9.  9. 10.  9.] 
adversary cards in hand: [1. 0. 3. 3. 6.] 
adversary cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0. 23.  1.  1.  3.  6.  0.  3.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 66.95470428466797






Player: 1 
cards in hand: [1. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 6.] 
cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0. 23.  1.  1.  3.  6.  0.  3.  0.  6.  6.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 22. 30.  8.  0. 10.  3.  6.  5.  5. 10.  9.  9. 10.  9.] 
adversary cards in hand: [25. 25. 25.  1.  0.] 
adversary cards in discard: [15.  8. 11.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8] -> size -> 29 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 6.] 
cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0. 23.  1.  1.  3.  6.  0.  3.  0.  6.  6.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 22. 30.  8.  0. 10.  3.  6.  5.  5. 10.  9.  9. 10.  9.] 
adversary cards in hand: [25. 25. 25.  1.  0.] 
adversary cards in discard: [15.  8. 11.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8] -> size -> 29 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 6.] 
cards in discard: [ 6.  8.  6.  6.  6.  0.  0.  6.  3.  6.  3.  0.  3. 11.  3.  0. 10. 11.
 11.  3.  3.  0. 23.  1.  1.  3.  6.  0.  3.  0.  6.  6.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 22. 30.  8.  0. 10.  2.  6.  5.  5. 10.  9.  9. 10.  9.] 
adversary cards in hand: [25. 25. 25.  1.  0.] 
adversary cards in discard: [15.  8. 11.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8] -> size -> 29 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [25. 25. 25.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[11.587301]
 [56.75764 ]
 [56.75764 ]
 [56.75764 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 25.  1.  0.] 
cards in discard: [15.  8. 11.  8. 11.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 22. 30.  8.  0. 10.  2.  6.  5.  5. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 6.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11] -> size -> 40 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.62606430053711



action possibilites: [-1] 
expected returns: [[35.706688]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  1.  0.  0.  8.] 
cards in discard: [15.  8. 11.  8. 11.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 22. 30.  8.  0. 10.  2.  6.  5.  5. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 6.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11] -> size -> 40 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 56.75761413574219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[27.31121 ]
 [51.09893 ]
 [36.075   ]
 [45.483185]
 [51.562344]
 [42.321056]
 [61.01986 ]
 [ 6.772906]
 [27.746609]
 [27.759373]
 [36.342354]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25.  1.  0.  0.  8.] 
cards in discard: [15.  8. 11.  8. 11.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 22. 30.  8.  0. 10.  2.  6.  5.  5. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 6.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11] -> size -> 40 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.706687927246094



buy possibilites: [-1] 
expected returns: [[74.88522]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25.  1.  0.  0.  8.] 
cards in discard: [15.  8. 11.  8. 11.  0.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 22. 30.  8.  0. 10.  2.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 6.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11] -> size -> 40 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 61.01983642578125






Player: 1 
cards in hand: [ 6.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 22. 30.  8.  0. 10.  2.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [15.  8. 11.  8. 11.  0.  0. 29. 25. 25. 25.  1.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29] -> size -> 30 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 22. 30.  8.  0. 10.  1.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [15.  8. 11.  8. 11.  0.  0. 29. 25. 25. 25.  1.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29] -> size -> 30 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 22. 30.  8.  0. 10.  1.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [15.  8. 11.  8. 11.  0.  0. 29. 25. 25. 25.  1.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29] -> size -> 30 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [11.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 22. 30.  8.  0. 10.  1.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [15.  8. 11.  8. 11.  0.  0. 29. 25. 25. 25.  1.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29] -> size -> 30 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[37.50151]
 [50.61785]
 [58.47187]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0. 29.] 
cards in discard: [15.  8. 11.  8. 11.  0.  0. 29. 25. 25. 25.  1.  0.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 22. 30.  8.  0. 10.  1.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  6.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0] -> size -> 42 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.88522338867188



action possibilites: [-1. 11. 25.] 
expected returns: [[ 61.62113]
 [ 75.40817]
 [106.17186]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 25.] 
cards in discard: [15.  8. 11.  8. 11.  0.  0. 29. 25. 25. 25.  1.  0.  0.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 22. 30.  8.  0. 10.  1.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  6.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0] -> size -> 42 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 50.46759033203125



action possibilites: [-1] 
expected returns: [[62.14997]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 29.  3.] 
cards in discard: [15.  8. 11.  8. 11.  0.  0. 29. 25. 25. 25.  1.  0.  0.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 22. 30.  8.  0. 10.  1.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  6.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0] -> size -> 42 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 106.17188262939453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[55.655872]
 [80.833466]
 [64.31104 ]
 [80.93241 ]
 [71.34706 ]
 [55.71104 ]
 [62.777008]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 29.  3.] 
cards in discard: [15.  8. 11.  8. 11.  0.  0. 29. 25. 25. 25.  1.  0.  0.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 22. 30.  8.  0. 10.  1.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  6.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0] -> size -> 42 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.14997100830078



buy possibilites: [-1] 
expected returns: [[111.68162]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 29.  3.] 
cards in discard: [15.  8. 11.  8. 11.  0.  0. 29. 25. 25. 25.  1.  0.  0.  8.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 22. 30.  8.  0. 10.  0.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  6.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0] -> size -> 42 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 149 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 80.93241882324219






Player: 1 
cards in hand: [11.  0.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0.  6.] 
cards in discard: [11.  0. 11.  6.  0.  3.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 22. 30.  8.  0. 10.  0.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [29. 25. 29.  0.  3.] 
adversary cards in discard: [15.  8. 11.  8. 11.  0.  0. 29. 25. 25. 25.  1.  0.  0.  8.  3. 11. 29.
 25.  0. 11.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11] -> size -> 31 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  0.  6.] 
cards in discard: [11.  0. 11.  6.  0.  3.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 22. 30.  8.  0. 10.  0.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [29. 25. 29.  0.  3.] 
adversary cards in discard: [15.  8. 11.  8. 11.  0.  0. 29. 25. 25. 25.  1.  0.  0.  8.  3. 11. 29.
 25.  0. 11.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11] -> size -> 31 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  0.  6.] 
cards in discard: [11.  0. 11.  6.  0.  3.  0.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 21. 30.  8.  0. 10.  0.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [29. 25. 29.  0.  3.] 
adversary cards in discard: [15.  8. 11.  8. 11.  0.  0. 29. 25. 25. 25.  1.  0.  0.  8.  3. 11. 29.
 25.  0. 11.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11] -> size -> 31 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [29. 25. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[49.53882]
 [72.70305]
 [94.55439]
 [72.70305]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29.  0.  3.] 
cards in discard: [15.  8. 11.  8. 11.  0.  0. 29. 25. 25. 25.  1.  0.  0.  8.  3. 11. 29.
 25.  0. 11.  0. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 21. 30.  8.  0. 10.  0.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [10.  3.  3.  6. 11.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3] -> size -> 43 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 111.6816177368164



action possibilites: [-1] 
expected returns: [[38.45655]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  3. 29. 11.] 
cards in discard: [15.  8. 11.  8. 11.  0.  0. 29. 25. 25. 25.  1.  0.  0.  8.  3. 11. 29.
 25.  0. 11.  0. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 21. 30.  8.  0. 10.  0.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [10.  3.  3.  6. 11.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3] -> size -> 43 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 94.55438232421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[33.32325]
 [39.23226]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0.  3. 29. 11.] 
cards in discard: [15.  8. 11.  8. 11.  0.  0. 29. 25. 25. 25.  1.  0.  0.  8.  3. 11. 29.
 25.  0. 11.  0. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 21. 30.  8.  0. 10.  0.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [10.  3.  3.  6. 11.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3] -> size -> 43 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.45655059814453






Player: 1 
cards in hand: [10.  3.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  6. 11.] 
cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 21. 30.  8.  0. 10.  0.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [25.  8.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11] -> size -> 31 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  6. 11.] 
cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3] -> size -> 43 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 26. 30. 21. 30.  8.  0. 10.  0.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [25.  8.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11] -> size -> 31 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  6. 11.] 
cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [25.  8.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11] -> size -> 31 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [25.  8.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 11.] 
expected returns: [[ 53.514008]
 [107.09251 ]
 [ 60.360886]
 [ 70.38731 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 6. 3.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 39.23223876953125



action possibilites: [-1] 
expected returns: [[58.170593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 11.  0. 25.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 6. 3.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 107.09246826171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[50.100716]
 [59.20919 ]
 [65.37198 ]
 [59.532608]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 11.  0. 25.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  6.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 6. 3.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.17059326171875



buy possibilites: [-1] 
expected returns: [[74.257355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 11.  0. 25.] 
cards in discard: [8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 6. 3.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 65.37196350097656






Player: 1 
cards in hand: [3. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 3.] 
cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [25. 11. 11.  3.  0.] 
adversary cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 3.] 
cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [25. 11. 11.  3.  0.] 
adversary cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [25. 11. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11.] 
expected returns: [[53.551044]
 [99.39311 ]
 [67.65873 ]
 [67.65873 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 11.  3.  0.] 
cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  6. 11.  3.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.25735473632812



action possibilites: [-1] 
expected returns: [[49.283844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  0. 29. 11.] 
cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  6. 11.  3.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 99.39312744140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[39.69491 ]
 [48.767532]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  3.  0. 29. 11.] 
cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  6. 11.  3.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.283843994140625






Player: 1 
cards in hand: [ 0.  8.  6. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6. 11.  3.] 
cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 8. 25.  0.  8. 15.] 
adversary cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25. 25. 11. 11.  3.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  6. 11.  3.] 
cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 8. 25.  0.  8. 15.] 
adversary cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25. 25. 11. 11.  3.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 8. 25.  0.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.  8. 15.] 
expected returns: [[35.440746]
 [41.9388  ]
 [82.86576 ]
 [41.9388  ]
 [28.134777]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  0.  8. 15.] 
cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25. 25. 11. 11.  3.  0. 29. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [23.  3.  6.  1.  1.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.  0.  8.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 48.76753234863281



action possibilites: [-1] 
expected returns: [[20.658941]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 15. 29. 25.] 
cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25. 25. 11. 11.  3.  0. 29. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [23.  3.  6.  1.  1.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.  0.  8.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 82.86576843261719





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.842772]
 [20.796585]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  8. 15. 29. 25.] 
cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25. 25. 11. 11.  3.  0. 29. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [23.  3.  6.  1.  1.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.  0.  8.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.6589412689209






Player: 1 
cards in hand: [23.  3.  6.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  6.  1.  1.] 
cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.  0.  8.  6. 11.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 29.  0. 11.] 
adversary cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25. 25. 11. 11.  3.  0. 29. 11. 25.  8.  0.
  8. 15. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 1. 1. 3.] 
cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.  0.  8.  6. 11.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
action values: 1 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 29.  0. 11.] 
adversary cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25. 25. 11. 11.  3.  0. 29. 11. 25.  8.  0.
  8. 15. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 1. 3.] 
cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.  0.  8.  6. 11.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0] -> size -> 44 
action values: 0 
buys: 2 
player value: 5 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 29.  0. 11.] 
adversary cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25. 25. 11. 11.  3.  0. 29. 11. 25.  8.  0.
  8. 15. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
adversary victory points: 3
player victory points: 2 


buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 1. 3.] 
cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.  0.  8.  6. 11.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 29.  0. 11.] 
adversary cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25. 25. 11. 11.  3.  0. 29. 11. 25.  8.  0.
  8. 15. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 1. 3.] 
cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.  0.  8.  6. 11.  3. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 20. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 29.  0. 11.] 
adversary cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25. 25. 11. 11.  3.  0. 29. 11. 25.  8.  0.
  8. 15. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[39.38775 ]
 [64.408676]
 [55.60022 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.  0. 11.] 
cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25. 25. 11. 11.  3.  0. 29. 11. 25.  8.  0.
  8. 15. 29. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 20. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  8. 10.  9.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.  0.  8.  6. 11.  3. 10.  3. 23.  3.  6.  1.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.79660987854004



action possibilites: [-1. 11. 29.] 
expected returns: [[35.702637]
 [50.38379 ]
 [58.699814]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 29.] 
cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25. 25. 11. 11.  3.  0. 29. 11. 25.  8.  0.
  8. 15. 29. 25.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 20. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  8. 10.  9.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.  0.  8.  6. 11.  3. 10.  3. 23.  3.  6.  1.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 55.6597900390625



action possibilites: [-1.] 
expected returns: [[54.7128]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25. 25. 11. 11.  3.  0. 29. 11. 25.  8.  0.
  8. 15. 29. 25.  0.  0. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 20. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  8. 10.  9.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.  0.  8.  6. 11.  3. 10.  3. 23.  3.  6.  1.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 50.2703857421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[49.73338 ]
 [69.82045 ]
 [57.167618]
 [65.15491 ]
 [62.532288]
 [77.8038  ]
 [29.642372]
 [49.879482]
 [49.72942 ]
 [56.257954]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25. 25. 11. 11.  3.  0. 29. 11. 25.  8.  0.
  8. 15. 29. 25.  0.  0. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 20. 30.  8.  0. 10.  0.  5.  5.  4. 10.  9.  8. 10.  9.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.  0.  8.  6. 11.  3. 10.  3. 23.  3.  6.  1.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 54.712799072265625



buy possibilites: [-1] 
expected returns: [[72.794975]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 8. 25.  8.  3.  0. 11.  0. 25. 25. 11. 11.  3.  0. 29. 11. 25.  8.  0.
  8. 15. 29. 25.  0.  0. 11.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 20. 30.  8.  0. 10.  0.  5.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.  0.  8.  6. 11.  3. 10.  3. 23.  3.  6.  1.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 77.80376434326172






Player: 1 
cards in hand: [6. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.  0.  8.  6. 11.  3. 10.  3. 23.  3.  6.  1.  1.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 20. 30.  8.  0. 10.  0.  5.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29] -> size -> 33 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [11.  0. 11.  6.  0.  3.  0.  3. 11.  0.  6.  0.  6.  0. 10.  3.  3.  6.
 11.  3.  0.  3.  6.  3.  0.  8.  6. 11.  3. 10.  3. 23.  3.  6.  1.  1.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 20. 30.  8.  0. 10.  0.  5.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29] -> size -> 33 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[28.706436]
 [53.269447]
 [53.269447]
 [53.269447]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 20. 30.  8.  0. 10.  0.  5.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.79497528076172



action possibilites: [-1. 29. 25.] 
expected returns: [[ 88.24263]
 [107.83112]
 [127.36371]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.] 
cards in discard: [ 0. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 20. 30.  8.  0. 10.  0.  5.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 42.97601318359375



action possibilites: [-1] 
expected returns: [[91.200745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 25.] 
cards in discard: [ 0. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 20. 30.  8.  0. 10.  0.  5.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 127.36370849609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[83.27069]
 [91.24628]
 [96.48613]
 [91.89971]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29. 25.] 
cards in discard: [ 0. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 20. 30.  8.  0. 10.  0.  5.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.20074462890625



buy possibilites: [-1] 
expected returns: [[114.36749]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29. 25.] 
cards in discard: [ 0. 29.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 20. 30.  8.  0. 10.  0.  4.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 96.48611450195312






Player: 1 
cards in hand: [10.  3.  0.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  6.  1.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 20. 30.  8.  0. 10.  0.  4.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  3. 29. 29.] 
adversary cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8] -> size -> 34 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 1. 6.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3] -> size -> 46 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 20. 30.  8.  0. 10.  0.  4.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  3. 29. 29.] 
adversary cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8] -> size -> 34 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 1. 6.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 20. 30.  8.  0. 10.  0.  4.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  3. 29. 29.] 
adversary cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8] -> size -> 34 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 1. 6.] 
cards in discard: [3.] 
cards in deck: 40 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 19. 30.  8.  0. 10.  0.  4.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  3. 29. 29.] 
adversary cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8] -> size -> 34 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  3. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
expected returns: [[68.542816]
 [75.01995 ]
 [91.08253 ]
 [91.08253 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3. 29. 29.] 
cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 19. 30.  8.  0. 10.  0.  4.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  1.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3] -> size -> 47 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 114.36749267578125



action possibilites: [-1. 25.] 
expected returns: [[ 65.0157  ]
 [108.349625]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25.] 
cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 19. 30.  8.  0. 10.  0.  4.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  1.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3] -> size -> 47 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 82.67280578613281



action possibilites: [-1] 
expected returns: [[124.77753]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.] 
cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 19. 30.  8.  0. 10.  0.  4.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  1.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3] -> size -> 47 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 108.3496322631836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[119.15459]
 [127.03311]
 [132.76468]
 [125.91571]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 11.] 
cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 19. 30.  8.  0. 10.  0.  4.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  1.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3] -> size -> 47 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 124.77752685546875



buy possibilites: [-1] 
expected returns: [[113.36132]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 11.] 
cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 19. 30.  8.  0. 10.  0.  3.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  1.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3] -> size -> 47 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 21 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 132.76470947265625






Player: 1 
cards in hand: [ 3. 10.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.  1.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 19. 30.  8.  0. 10.  0.  3.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 8. 25. 11.  0.  1.] 
adversary cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8. 29. 25.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8] -> size -> 35 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  3.  1.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 19. 30.  8.  0. 10.  0.  3.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 8. 25. 11.  0.  1.] 
adversary cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8. 29. 25.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8] -> size -> 35 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 8. 25. 11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 11.] 
expected returns: [[106.00286]
 [111.66101]
 [150.60817]
 [119.35998]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 11.  0.  1.] 
cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8. 29. 25.  3.  3.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 19. 30.  8.  0. 10.  0.  3.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [11.  0. 11.  3.  6.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3] -> size -> 47 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 113.36132049560547



action possibilites: [-1] 
expected returns: [[114.583984]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  1.  0.  0.] 
cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8. 29. 25.  3.  3.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 19. 30.  8.  0. 10.  0.  3.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [11.  0. 11.  3.  6.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3] -> size -> 47 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 150.6081085205078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[111.343025]
 [133.5398  ]
 [119.51532 ]
 [ 89.33467 ]
 [128.30414 ]
 [125.36131 ]
 [165.27072 ]
 [142.57445 ]
 [ 89.574814]
 [114.3282  ]
 [111.58316 ]
 [ 92.42911 ]
 [111.47386 ]
 [118.861725]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  1.  0.  0.] 
cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8. 29. 25.  3.  3.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 26. 30. 19. 30.  8.  0. 10.  0.  3.  5.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [11.  0. 11.  3.  6.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3] -> size -> 47 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 114.583984375



buy possibilites: [-1] 
expected returns: [[148.7015]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  1.  0.  0.] 
cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8. 29. 25.  3.  3.  0. 11.
 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [11.  0. 11.  3.  6.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3] -> size -> 47 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -10   0   0 250   0] 
sum of rewards: 225 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 165.27073669433594






Player: 1 
cards in hand: [11.  0. 11.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  3.  6.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  8.  0. 11.] 
adversary cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8. 29. 25.  3.  3.  0. 11.
 25. 25.  8. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25] -> size -> 36 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  6.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  8.  0. 11.] 
adversary cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8. 29. 25.  3.  3.  0. 11.
 25. 25.  8. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25] -> size -> 36 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  6.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 3. 15.  8.  0. 11.] 
adversary cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8. 29. 25.  3.  3.  0. 11.
 25. 25.  8. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25] -> size -> 36 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 11.] 
expected returns: [[32.64157 ]
 [27.008469]
 [38.400856]
 [45.501812]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8.  0. 11.] 
cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8. 29. 25.  3.  3.  0. 11.
 25. 25.  8. 11.  0.  1.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [23.  3. 11.  8.  3.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1] -> size -> 48 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 148.70150756835938



action possibilites: [-1] 
expected returns: [[-10.731514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8.  0.] 
cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8. 29. 25.  3.  3.  0. 11.
 25. 25.  8. 11.  0.  1.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [23.  3. 11.  8.  3.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1] -> size -> 48 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -20   0   0  27   0] 
sum of rewards: -8 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 45.5001220703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-16.259228]
 [ -9.64986 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  8.  0.] 
cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8. 29. 25.  3.  3.  0. 11.
 25. 25.  8. 11.  0.  1.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 24. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [23.  3. 11.  8.  3.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1] -> size -> 48 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.731513977050781






Player: 1 
cards in hand: [23.  3. 11.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3. 11.  8.  3.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  8. 10.  9.] 
adversary cards in hand: [25. 11. 29. 11.  8.] 
adversary cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8. 29. 25.  3.  3.  0. 11.
 25. 25.  8. 11.  0.  1.  0.  0.  1. 11.  3. 15.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1] -> size -> 37 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  8.  3.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  7. 10.  9.] 
adversary cards in hand: [25. 11. 29. 11.  8.] 
adversary cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8. 29. 25.  3.  3.  0. 11.
 25. 25.  8. 11.  0.  1.  0.  0.  1. 11.  3. 15.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1] -> size -> 37 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  8.  3.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10] -> size -> 49 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 24. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  7. 10.  9.] 
adversary cards in hand: [25. 11. 29. 11.  8.] 
adversary cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8. 29. 25.  3.  3.  0. 11.
 25. 25.  8. 11.  0.  1.  0.  0.  1. 11.  3. 15.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1] -> size -> 37 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  8.  3.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  7. 10.  9.] 
adversary cards in hand: [25. 11. 29. 11.  8.] 
adversary cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8. 29. 25.  3.  3.  0. 11.
 25. 25.  8. 11.  0.  1.  0.  0.  1. 11.  3. 15.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1] -> size -> 37 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [25. 11. 29. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29. 11.  8.] 
expected returns: [[ 6.0418153]
 [42.27022  ]
 [17.297554 ]
 [24.244831 ]
 [17.297554 ]
 [11.006758 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 29. 11.  8.] 
cards in discard: [ 0. 29.  8. 29. 25. 29.  0. 29. 25.  8. 29.  8. 29. 25.  3.  3.  0. 11.
 25. 25.  8. 11.  0.  1.  0.  0.  1. 11.  3. 15.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0] -> size -> 50 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -9.649833679199219



action possibilites: [-1] 
expected returns: [[113.576385]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 11.  8.  8.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0] -> size -> 50 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 42.27021026611328





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[105.84532]
 [114.05381]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 11.  8.  8.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 24. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0] -> size -> 50 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 113.57638549804688






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 29.  1.  8.] 
adversary cards in discard: [25. 11. 29. 11.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1] -> size -> 37 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 24. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 29.  1.  8.] 
adversary cards in discard: [25. 11. 29. 11.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1] -> size -> 37 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 8.  3. 29.  1.  8.] 
adversary cards in discard: [25. 11. 29. 11.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1] -> size -> 37 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 8.  3. 29.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
expected returns: [[20.033756]
 [29.269215]
 [45.830276]
 [29.269215]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29.  1.  8.] 
cards in discard: [25. 11. 29. 11.  8.  8.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [6. 6. 0. 3. 0.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10] -> size -> 51 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 114.0538101196289



action possibilites: [-1.  8. 25.] 
expected returns: [[40.46001 ]
 [49.400906]
 [96.18222 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 25.] 
cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [6. 6. 0. 3. 0.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10] -> size -> 51 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 37.143028259277344



action possibilites: [-1] 
expected returns: [[74.2432]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 11. 25.] 
cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [6. 6. 0. 3. 0.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10] -> size -> 51 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 96.18222045898438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[66.706955]
 [88.324524]
 [74.959206]
 [80.52267 ]
 [67.157364]
 [75.1618  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 11. 25.] 
cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [6. 6. 0. 3. 0.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10] -> size -> 51 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.24320220947266



buy possibilites: [-1] 
expected returns: [[31.615093]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 11. 25.] 
cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [6. 6. 0. 3. 0.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10] -> size -> 51 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0 -30   0   0  54   0] 
sum of rewards: 29 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 88.32450866699219






Player: 1 
cards in hand: [6. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 3. 0.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  0. 11. 11.] 
adversary cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1] -> size -> 38 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 0.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 23. 30. 19. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  0. 11. 11.] 
adversary cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1] -> size -> 38 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 0.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 18. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  0. 11. 11.] 
adversary cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1] -> size -> 38 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11.] 
expected returns: [[ 2.6098561]
 [54.662537 ]
 [16.898445 ]
 [16.898445 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 11. 11.] 
cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 18. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [11.  1.  6.  0.  0.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3] -> size -> 52 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.615093231201172



action possibilites: [-1] 
expected returns: [[31.484154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11. 29.  0.] 
cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 18. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [11.  1.  6.  0.  0.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3] -> size -> 52 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 54.66252899169922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[26.039349]
 [50.061066]
 [34.826794]
 [41.328876]
 [26.094616]
 [33.2707  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 11. 29.  0.] 
cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 30. 18. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [11.  1.  6.  0.  0.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3] -> size -> 52 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.484153747558594



buy possibilites: [-1] 
expected returns: [[50.672596]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 11. 29.  0.] 
cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [11.  1.  6.  0.  0.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3] -> size -> 52 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0 -40   0   0  54   0] 
sum of rewards: -31 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 50.061073303222656






Player: 1 
cards in hand: [11.  1.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  6.  0.  0.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 3. 29. 25. 25. 15.] 
adversary cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.  1. 25.
  0.  0. 11. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  6.  0.  0.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3] -> size -> 52 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  3.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 3. 29. 25. 25. 15.] 
adversary cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.  1. 25.
  0.  0. 11. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  6.  0.  0.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8] -> size -> 53 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  2.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 3. 29. 25. 25. 15.] 
adversary cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.  1. 25.
  0.  0. 11. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 25. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25. 15.] 
expected returns: [[-21.074013 ]
 [  3.5334725]
 [ 27.113853 ]
 [ 27.113853 ]
 [-27.783848 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 25. 25. 15.] 
cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.  1. 25.
  0.  0. 11. 11. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  2.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [3. 3. 3. 6. 3.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.  8. 11.  1.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8] -> size -> 53 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.6725959777832



action possibilites: [-1] 
expected returns: [[-24.696789]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 25. 15. 29.  3.] 
cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.  1. 25.
  0.  0. 11. 11. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  2.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [3. 3. 3. 6. 3.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.  8. 11.  1.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8] -> size -> 53 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 27.113868713378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-30.015461]
 [-23.839745]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 25. 15. 29.  3.] 
cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.  1. 25.
  0.  0. 11. 11. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  2.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [3. 3. 3. 6. 3.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.  8. 11.  1.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8] -> size -> 53 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -24.696788787841797






Player: 1 
cards in hand: [3. 3. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 6. 3.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.  8. 11.  1.  6.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  2.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [29.  0.  0.  8.  0.] 
adversary cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.  1. 25.
  0.  0. 11. 11. 29.  0. 25.  3. 29. 25. 15. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 6. 3.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.  8. 11.  1.  6.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8] -> size -> 53 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  2.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [29.  0.  0.  8.  0.] 
adversary cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.  1. 25.
  0.  0. 11. 11. 29.  0. 25.  3. 29. 25. 15. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[49.09369 ]
 [75.43487 ]
 [55.942642]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  8.  0.] 
cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.  1. 25.
  0.  0. 11. 11. 29.  0. 25.  3. 29. 25. 15. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  2.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 6.  6. 11.  3.  6.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.  8. 11.  1.  6.  0.  0.  3.  3.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8] -> size -> 53 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -23.839786529541016



action possibilites: [-1.] 
expected returns: [[53.600273]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.  1. 25.
  0.  0. 11. 11. 29.  0. 25.  3. 29. 25. 15. 29.  3.  8.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  2.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 6.  6. 11.  3.  6.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.  8. 11.  1.  6.  0.  0.  3.  3.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8] -> size -> 53 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 65.10468292236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[45.72207 ]
 [74.58406 ]
 [56.398834]
 [68.47185 ]
 [64.605896]
 [84.599525]
 [15.395798]
 [45.570133]
 [45.10829 ]
 [53.6003  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.  1. 25.
  0.  0. 11. 11. 29.  0. 25.  3. 29. 25. 15. 29.  3.  8.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  2.  4.  3. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 6.  6. 11.  3.  6.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.  8. 11.  1.  6.  0.  0.  3.  3.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8] -> size -> 53 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 53.60027313232422



buy possibilites: [-1] 
expected returns: [[26.156391]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25. 11. 29. 11.  8.  8.  0.  3.  8.  1. 29. 25.  1.  8. 11. 25.  1. 25.
  0.  0. 11. 11. 29.  0. 25.  3. 29. 25. 15. 29.  3.  8.  1. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  2.  4.  2. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 6.  6. 11.  3.  6.] 
adversary cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.  8. 11.  1.  6.  0.  0.  3.  3.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8] -> size -> 53 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0 -50   0   0 128   0] 
sum of rewards: 33 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 84.59950256347656






Player: 1 
cards in hand: [ 6.  6. 11.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 11.  3.  6.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.  8. 11.  1.  6.  0.  0.  3.  3.  3.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  2.  4.  2. 10.  9.  6. 10.  9.] 
adversary cards in hand: [25. 11.  1. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1 29] -> size -> 40 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 6.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.  8. 11.  1.  6.  0.  0.  3.  3.  3.  6.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8 29] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  2.  4.  1. 10.  9.  6. 10.  9.] 
adversary cards in hand: [25. 11.  1. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1 29] -> size -> 40 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 6.] 
cards in discard: [ 3. 10.  3.  0.  6.  1.  6.  3. 10.  0.  3.  1.  1. 11.  0. 11.  3.  6.
 10.  0. 11. 23.  3.  8.  3. 10.  3.  0.  0.  0.  0.  3.  6.  6.  0.  3.
  0.  8. 11.  1.  6.  0.  0.  3.  3.  3.  6.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8 29] -> size -> 54 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  2.  4.  1. 10.  9.  6. 10.  9.] 
adversary cards in hand: [25. 11.  1. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1 29] -> size -> 40 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [25. 11.  1. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.  8.] 
expected returns: [[ 67.42705]
 [108.76025]
 [ 79.12993]
 [ 86.90154]
 [ 71.76865]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  1. 29.  8.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  2.  4.  1. 10.  9.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8 29] -> size -> 54 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.156391143798828



action possibilites: [-1] 
expected returns: [[85.87179]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 29.  8.  8.  8.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  2.  4.  1. 10.  9.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8 29] -> size -> 54 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 108.76029205322266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[78.601204]
 [86.69496 ]
 [92.06735 ]
 [87.26872 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 29.  8.  8.  8.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1 29] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  2.  4.  1. 10.  9.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8 29] -> size -> 54 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 85.87178802490234



buy possibilites: [-1] 
expected returns: [[89.825165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 29.  8.  8.  8.] 
cards in discard: [8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1 29  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  1.  4.  1. 10.  9.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8 29] -> size -> 54 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0 -60   0   0  16   0] 
sum of rewards: -89 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 92.06734466552734






Player: 1 
cards in hand: [8. 3. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 6. 1.] 
cards in discard: [] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3  6 11  6 10  6  1  3  3  6  0
  6  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1
 10  0 10  3  8 29] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  1.  4.  1. 10.  9.  6. 10.  9.] 
adversary cards in hand: [25.  0. 11.  3.  0.] 
adversary cards in discard: [ 8. 25. 11.  1. 29.  8.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1 29  8] -> size -> 41 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1.] 
cards in discard: [] 
cards in deck: 49 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3 11  6 10  6  1  3  3  6  0  6
  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1 10
  0 10  3  8 29] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  1.  4.  1. 10.  9.  6. 10.  9.] 
adversary cards in hand: [25.  0. 11.  3.  0.] 
adversary cards in discard: [ 8. 25. 11.  1. 29.  8.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1 29  8] -> size -> 41 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [] 
cards in deck: 49 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3 11  6 10  6  1  3  3  6  0  6
  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1 10
  0 10  3  8 29] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  1.  4.  1. 10.  9.  6. 10.  9.] 
adversary cards in hand: [25.  0. 11.  3.  0.] 
adversary cards in discard: [ 8. 25. 11.  1. 29.  8.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1 29  8] -> size -> 41 
adversary victory points: 3
player victory points: 6 


Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 3 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 7 
Witch: 6 
Poacher: 8 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [25.  0. 11.  3.  0.] 
cards in discard: [ 8. 25. 11.  1. 29.  8.  8.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 25 25 29 25 25  8 29 29 11 11 11
 11 29  8 15  8 29 11  8 29  8  8 25  1  1  1 29  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 18. 30.  8.  0. 10.  0.  0.  4.  1. 10.  9.  6. 10.  9.] 
adversary cards in hand: [3. 0. 1.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3  3  3 11  6 10  6  1  3  3  6  0  6
  1  6  6 11  6  3  6  8  6 11  3  0 23  3 11 11  0  3  0 10  3  3  1 10
  0 10  3  8 29  8] -> size -> 54 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000095 

action type: buy - action -1
Learning step: -120007.390625
desired expected reward: -119917.5625



