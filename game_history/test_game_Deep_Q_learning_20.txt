 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[108.964516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -270        0        0       40        0
        0        0        0     -100        0     -300        0        0] 
sum of rewards: -3000635 

action type: buy - action 6.0
Learning step: -120025.65625
desired expected reward: -120019.140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[104.29304 ]
 [107.210754]
 [105.997116]
 [101.04172 ]
 [106.85134 ]
 [109.67047 ]
 [107.873726]
 [111.50433 ]
 [104.61003 ]
 [106.64157 ]
 [107.529945]
 [107.41252 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 109.47718811035156



buy possibilites: [-1] 
expected returns: [[106.60363]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 111.50434875488281






Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[116.36989]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 106.60363006591797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[113.050125]
 [116.168785]
 [114.87234 ]
 [109.69436 ]
 [118.67732 ]
 [116.85509 ]
 [115.558655]
 [116.40712 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 117.00584411621094



buy possibilites: [-1] 
expected returns: [[113.6737]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 118.67733001708984






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  3.  0.  3.  3.  0. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[122.810265]
 [126.90793 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0. 23.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 113.67369842529297



action possibilites: [-1.] 
expected returns: [[119.61471]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0. 23.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 128.02203369140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[112.70085 ]
 [116.42538 ]
 [111.154655]
 [114.879166]
 [110.13008 ]
 [108.58389 ]
 [115.961266]
 [119.417046]
 [117.23871 ]
 [124.21178 ]
 [121.65289 ]
 [113.121765]
 [115.56883 ]
 [115.69252 ]
 [111.84432 ]
 [116.846275]
 [116.76976 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0. 23.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 119.61470794677734



buy possibilites: [-1] 
expected returns: [[132.6672]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0. 23.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 47.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 124.21176147460938






Player: 1 
cards in hand: [ 0. 23.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  3.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  3.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  0.  0.  0.] 
cards in discard: [15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10.  9. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  3.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[132.05115]
 [134.41353]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  3.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10.  9. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [15.  0. 23.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 132.66720581054688



action possibilites: [-1] 
expected returns: [[149.2014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10.  9.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [15.  0. 23.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 143.29605102539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[144.70929]
 [146.88692]
 [140.71848]
 [149.26178]
 [148.69238]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10.  9.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [15.  0. 23.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 149.20140075683594



buy possibilites: [-1] 
expected returns: [[126.71025]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  9. 10.  9.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [15.  0. 23.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 149.2617645263672






Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [15.  0. 23.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  9. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [15.  0. 23.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  9. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [15.  0. 23.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  9. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[116.53403]
 [120.98446]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  9. 10.  9.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 126.71025085449219



action possibilites: [-1.] 
expected returns: [[115.36213]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  9. 10.  9.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 122.6587142944336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[110.365845]
 [113.47592 ]
 [112.185295]
 [106.9337  ]
 [113.08677 ]
 [115.97262 ]
 [114.15316 ]
 [117.84268 ]
 [110.72102 ]
 [112.862526]
 [113.831116]
 [113.78351 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  9. 10.  9.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 115.36212921142578



buy possibilites: [-1] 
expected returns: [[145.73714]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  8. 10.  9.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 117.84268188476562






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  8. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  8. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  8. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[122.87328]
 [125.34917]
 [121.96309]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11. 10.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  8. 10.  9.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 23.  0.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 145.7371368408203



action possibilites: [-1] 
expected returns: [[143.85693]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 23.  0.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 127.52352905273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[140.19583]
 [142.21399]
 [136.37059]
 [144.40001]
 [143.93454]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 23.  0.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 143.85693359375



buy possibilites: [-1] 
expected returns: [[135.2168]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9.  8.  9.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 23.  0.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 144.4000244140625






Player: 1 
cards in hand: [ 3.  0. 23.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 23.  0.  0.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9.  8.  9.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 23.  0.  0.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9.  8.  9.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8] -> size -> 18 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[110.66199]
 [111.08841]
 [117.81129]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9.  8.  9.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 135.216796875



action possibilites: [-1] 
expected returns: [[130.77481]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  8.  9.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 119.31278991699219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[127.1164 ]
 [130.41927]
 [129.04622]
 [123.44796]
 [133.07669]
 [131.14687]
 [129.7738 ]
 [130.6621 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  8.  9.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 130.77481079101562



buy possibilites: [-1] 
expected returns: [[137.25436]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  0.  3. 29.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  8.  8.  9.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 133.07667541503906






Player: 1 
cards in hand: [ 0.  0.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  8.  8.  9.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [29.  0.  8. 11.  0.] 
adversary cards in discard: [11. 25.  0.  8.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  8.  8.  9.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [29.  0.  8. 11.  0.] 
adversary cards in discard: [11. 25.  0.  8.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [6. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  8.  7.  9.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [29.  0.  8. 11.  0.] 
adversary cards in discard: [11. 25.  0.  8.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [29.  0.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
expected returns: [[125.445496]
 [129.46695 ]
 [125.9321  ]
 [127.55501 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8. 11.  0.] 
cards in discard: [11. 25.  0.  8.  0.  0.  3. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  8.  7.  9.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 137.25436401367188



action possibilites: [-1.  8. 11. 10.] 
expected returns: [[113.26129]
 [113.69416]
 [115.43516]
 [112.4543 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  0. 10.] 
cards in discard: [11. 25.  0.  8.  0.  0.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  8.  7.  9.  8. 10.  9.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 130.0380859375



action possibilites: [-1] 
expected returns: [[138.2734]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10.] 
cards in discard: [11. 25.  0.  8.  0.  0.  3. 29. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  8.  7.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 116.6807632446289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[136.64708]
 [140.02147]
 [138.6157 ]
 [132.92647]
 [142.74287]
 [140.77425]
 [139.3685 ]
 [140.19455]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 10.] 
cards in discard: [11. 25.  0.  8.  0.  0.  3. 29. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  8.  7.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 138.27340698242188



buy possibilites: [-1] 
expected returns: [[143.15073]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 10.] 
cards in discard: [11. 25.  0.  8.  0.  0.  3. 29. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  7.  7.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 142.74288940429688






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 6.  8.  0.  0.  0. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  7.  7.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [11. 25.  0.  8.  0.  0.  3. 29. 10. 11. 29. 11.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 6.  8.  0.  0.  0. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  7.  7.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [11. 25.  0.  8.  0.  0.  3. 29. 10. 11. 29. 11.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 6.  8.  0.  0.  0. 15.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  7.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [11. 25.  0.  8.  0.  0.  3. 29. 10. 11. 29. 11.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[137.77968]
 [137.03238]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  3.] 
cards in discard: [11. 25.  0.  8.  0.  0.  3. 29. 10. 11. 29. 11.  0.  8.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  7.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [23.  0.  0.  3.  0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 15.  3.  3.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 143.15072631835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[135.46742]
 [137.23613]
 [132.07625]
 [139.1782 ]
 [138.65909]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  3.] 
cards in discard: [11. 25.  0.  8.  0.  0.  3. 29. 10. 11. 29. 11.  0.  8.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11 10 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  7.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [23.  0.  0.  3.  0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 15.  3.  3.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 137.34158325195312



buy possibilites: [-1] 
expected returns: [[155.32544]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  3.] 
cards in discard: [11. 25.  0.  8.  0.  0.  3. 29. 10. 11. 29. 11.  0.  8.  0. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11 10 11  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  6.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [23.  0.  0.  3.  0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 15.  3.  3.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 139.17822265625






Player: 1 
cards in hand: [23.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  0.  3.  0.] 
cards in discard: [ 6.  8.  0.  0.  0. 15.  3.  3.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  6.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11 10 11  8] -> size -> 22 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3] -> size -> 18 
action values: 1 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  6.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11 10 11  8] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3] -> size -> 18 
action values: 0 
buys: 2 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  6.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11 10 11  8] -> size -> 22 
adversary victory points: 3
player victory points: 4 


buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  5.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11 10 11  8] -> size -> 22 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [8. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  4.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11 10 11  8] -> size -> 22 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[137.1601 ]
 [137.72377]
 [135.91878]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 29 10  8 11 10 11  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  4.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 15.  8.] 
adversary cards in discard: [ 8.  8. 23.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 155.325439453125



action possibilites: [-1] 
expected returns: [[127.85199]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  4.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 15.  8.] 
adversary cards in discard: [ 8.  8. 23.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 140.97738647460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[123.873436]
 [120.72879 ]
 [126.93338 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  4.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 15.  8.] 
adversary cards in discard: [ 8.  8. 23.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 127.85198974609375






Player: 1 
cards in hand: [ 3.  3.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 15.  8.] 
cards in discard: [ 8.  8. 23.  0.  0.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  4.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [10.  3. 11.  8.  3.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8] -> size -> 19 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8.] 
cards in discard: [ 8.  8. 23.  0.  0.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  4.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [10.  3. 11.  8.  3.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8] -> size -> 19 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8.] 
cards in discard: [ 8.  8. 23.  0.  0.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  4.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [10.  3. 11.  8.  3.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8] -> size -> 19 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [10.  3. 11.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
expected returns: [[137.12083]
 [136.45296]
 [139.2857 ]
 [137.6355 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.  8.  3.] 
cards in discard: [ 8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  4.  9.  8. 10.  9.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  8. 23.  0.  0.  3.  0.  6. 15.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 126.93338012695312



action possibilites: [-1] 
expected returns: [[131.54991]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  3.] 
cards in discard: [ 8. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  4.  9.  8. 10.  9.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  8. 23.  0.  0.  3.  0.  6. 15.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 140.1408233642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[128.64848]
 [124.89116]
 [132.20374]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.  3.] 
cards in discard: [ 8. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  4.  9.  8. 10.  9.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  8. 23.  0.  0.  3.  0.  6. 15.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 131.54991149902344






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  8. 23.  0.  0.  3.  0.  6. 15.  3.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  4.  9.  8. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [ 8. 10. 10. 11. 10.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10] -> size -> 20 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  8. 23.  0.  0.  3.  0.  6. 15.  3.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  4.  9.  8. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [ 8. 10. 10. 11. 10.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10] -> size -> 20 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  8. 23.  0.  0.  3.  0.  6. 15.  3.  3.  8. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  4.  9.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [ 8. 10. 10. 11. 10.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10] -> size -> 20 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[130.23804]
 [130.82709]
 [132.98912]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 11.] 
cards in discard: [ 8. 10. 10. 11. 10.  3.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  4.  9.  8. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 8. 15.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8 15] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 132.20375061035156



action possibilites: [-1] 
expected returns: [[142.19595]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 8. 10. 10. 11. 10.  3.  8.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  4.  9.  8. 10.  9.  5. 10.  8.] 
adversary cards in hand: [ 8. 15.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8 15] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 135.2336883544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[138.75844]
 [142.04486]
 [140.63159]
 [135.52829]
 [144.78098]
 [142.80077]
 [141.38748]
 [142.22299]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 8. 10. 10. 11. 10.  3.  8.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  7.  4.  9.  8. 10.  9.  5. 10.  8.] 
adversary cards in hand: [ 8. 15.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8 15] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 142.19595336914062



buy possibilites: [-1] 
expected returns: [[146.71805]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 8. 10. 10. 11. 10.  3.  8.  3. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  6.  4.  9.  8. 10.  9.  5. 10.  8.] 
adversary cards in hand: [ 8. 15.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8 15] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 144.78094482421875






Player: 1 
cards in hand: [ 8. 15.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 23 15  0  0  6  8  3  8  8 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  6.  4.  9.  8. 10.  9.  5. 10.  8.] 
adversary cards in hand: [29. 29. 10.  0. 25.] 
adversary cards in discard: [ 8. 10. 10. 11. 10.  3.  8.  3. 10. 11. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11] -> size -> 22 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  6.  4.  9.  8. 10.  9.  5. 10.  8.] 
adversary cards in hand: [29. 29. 10.  0. 25.] 
adversary cards in discard: [ 8. 10. 10. 11. 10.  3.  8.  3. 10. 11. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11] -> size -> 22 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  6.  4.  9.  8. 10.  9.  5. 10.  8.] 
adversary cards in hand: [29. 29. 10.  0. 25.] 
adversary cards in discard: [ 8. 10. 10. 11. 10.  3.  8.  3. 10. 11. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11] -> size -> 22 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [29. 29. 10.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10. 25.] 
expected returns: [[175.4324 ]
 [179.3112 ]
 [179.3112 ]
 [174.66486]
 [181.33783]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 10.  0. 25.] 
cards in discard: [ 8. 10. 10. 11. 10.  3.  8.  3. 10. 11. 11.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  6.  4.  9.  8. 10.  9.  5. 10.  8.] 
adversary cards in hand: [ 8.  3.  6. 23.  3.] 
adversary cards in discard: [ 8. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 146.71804809570312



action possibilites: [-1] 
expected returns: [[155.32693]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 10.  0. 11.  0.] 
cards in discard: [ 8. 10. 10. 11. 10.  3.  8.  3. 10. 11. 11.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8. 10.  6.  4.  9.  8. 10.  9.  5. 10.  8.] 
adversary cards in hand: [ 8.  3.  6. 23.  3.] 
adversary cards in discard: [ 8. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 181.7196807861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[152.40744]
 [154.83762]
 [147.79753]
 [157.47757]
 [156.88559]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 10.  0. 11.  0.] 
cards in discard: [ 8. 10. 10. 11. 10.  3.  8.  3. 10. 11. 11.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  8. 10.  6.  4.  9.  8. 10.  9.  5. 10.  8.] 
adversary cards in hand: [ 8.  3.  6. 23.  3.] 
adversary cards in discard: [ 8. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 155.32693481445312



buy possibilites: [-1] 
expected returns: [[166.9779]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 10.  0. 11.  0.] 
cards in discard: [ 8. 10. 10. 11. 10.  3.  8.  3. 10. 11. 11.  0.  0.  0.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8. 10.  6.  3.  9.  8. 10.  9.  5. 10.  8.] 
adversary cards in hand: [ 8.  3.  6. 23.  3.] 
adversary cards in discard: [ 8. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 157.47760009765625






Player: 1 
cards in hand: [ 8.  3.  6. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  6. 23.  3.] 
cards in discard: [ 8. 15.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8. 10.  6.  3.  9.  8. 10.  9.  5. 10.  8.] 
adversary cards in hand: [11.  0.  8. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6. 3. 0.] 
cards in discard: [ 8. 15.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6] -> size -> 19 
action values: 1 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  8. 10.  6.  3.  9.  8. 10.  9.  5. 10.  8.] 
adversary cards in hand: [11.  0.  8. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 3. 0.] 
cards in discard: [ 8. 15.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6] -> size -> 19 
action values: 0 
buys: 2 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  8. 10.  6.  3.  9.  8. 10.  9.  5. 10.  8.] 
adversary cards in hand: [11.  0.  8. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 3. 0.] 
cards in discard: [ 8. 15.  3.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  6.  3.  9.  8. 10.  9.  5. 10.  8.] 
adversary cards in hand: [11.  0.  8. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8] -> size -> 23 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [11.  0.  8. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[136.39441]
 [139.13351]
 [136.95338]
 [139.13351]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 11.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  6.  3.  9.  8. 10.  9.  5. 10.  8.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [ 8. 15.  3.  6.  3. 23.  8.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 166.9779052734375



action possibilites: [-1] 
expected returns: [[110.59877]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  3.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  6.  3.  9.  8. 10.  9.  4. 10.  8.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [ 8. 15.  3.  6.  3. 23.  8.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 138.97732543945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[109.252815]
 [105.59922 ]
 [112.7919  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  3.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  6.  3.  9.  8. 10.  9.  4. 10.  8.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [ 8. 15.  3.  6.  3. 23.  8.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 110.59877014160156






Player: 1 
cards in hand: [15.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  3.  0.] 
cards in discard: [ 8. 15.  3.  6.  3. 23.  8.  3.  6.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  6.  3.  9.  8. 10.  9.  4. 10.  8.] 
adversary cards in hand: [ 0. 11. 25. 10. 10.] 
adversary cards in discard: [10. 11.  0.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10] -> size -> 24 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8. 15.  3.  6.  3. 23.  8.  3.  6.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  6.  3.  9.  8. 10.  9.  4. 10.  8.] 
adversary cards in hand: [ 0. 11. 25. 10. 10.] 
adversary cards in discard: [10. 11.  0.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10] -> size -> 24 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8. 15.  3.  6.  3. 23.  8.  3.  6.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 27. 30.  8.  8. 10.  6.  3.  9.  8. 10.  9.  4. 10.  8.] 
adversary cards in hand: [ 0. 11. 25. 10. 10.] 
adversary cards in discard: [10. 11.  0.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10] -> size -> 24 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8. 15.  3.  6.  3. 23.  8.  3.  6.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 5 
card supply: [27. 30. 30. 27. 30.  8.  8. 10.  6.  3.  9.  8. 10.  9.  4. 10.  8.] 
adversary cards in hand: [ 0. 11. 25. 10. 10.] 
adversary cards in discard: [10. 11.  0.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10] -> size -> 24 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 25. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10. 10.] 
expected returns: [[107.23329 ]
 [109.276375]
 [112.8115  ]
 [106.54046 ]
 [106.54046 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25. 10. 10.] 
cards in discard: [10. 11.  0.  8. 11.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  8. 10.  6.  3.  9.  8. 10.  9.  4. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 112.79188537597656



action possibilites: [-1] 
expected returns: [[149.02469]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 10.  0.  8.] 
cards in discard: [10. 11.  0.  8. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  6.  3.  9.  8. 10.  9.  4. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 111.13761901855469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[147.39343]
 [149.5604 ]
 [143.30283]
 [151.93124]
 [151.3071 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10. 10.  0.  8.] 
cards in discard: [10. 11.  0.  8. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  6.  3.  9.  8. 10.  9.  4. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 149.02468872070312



buy possibilites: [-1] 
expected returns: [[146.14166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10. 10.  0.  8.] 
cards in discard: [10. 11.  0.  8. 11.  3.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  6.  2.  9.  8. 10.  9.  4. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 151.93124389648438






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  6.  2.  9.  8. 10.  9.  4. 10.  8.] 
adversary cards in hand: [29.  8. 10.  0. 11.] 
adversary cards in discard: [10. 11.  0.  8. 11.  3.  8. 25.  0. 11. 10. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10
  8] -> size -> 25 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  6.  2.  9.  8. 10.  9.  4. 10.  8.] 
adversary cards in hand: [29.  8. 10.  0. 11.] 
adversary cards in discard: [10. 11.  0.  8. 11.  3.  8. 25.  0. 11. 10. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10
  8] -> size -> 25 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 6. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  6.  2.  9.  8. 10.  9.  3. 10.  8.] 
adversary cards in hand: [29.  8. 10.  0. 11.] 
adversary cards in discard: [10. 11.  0.  8. 11.  3.  8. 25.  0. 11. 10. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10
  8] -> size -> 25 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29.  8. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10. 11.] 
expected returns: [[140.55698]
 [144.59177]
 [141.06735]
 [139.82082]
 [142.81375]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 10.  0. 11.] 
cards in discard: [10. 11.  0.  8. 11.  3.  8. 25.  0. 11. 10. 10.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  6.  2.  9.  8. 10.  9.  3. 10.  8.] 
adversary cards in hand: [ 3.  3.  3.  0. 15.] 
adversary cards in discard: [ 6. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6 10] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 146.14166259765625



action possibilites: [-1.  8. 10. 11. 10.] 
expected returns: [[160.99243]
 [161.63916]
 [159.95393]
 [164.00603]
 [159.95393]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 11. 10.] 
cards in discard: [10. 11.  0.  8. 11.  3.  8. 25.  0. 11. 10. 10.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  6.  2.  9.  8. 10.  9.  3. 10.  8.] 
adversary cards in hand: [ 3.  3.  3.  0. 15.] 
adversary cards in discard: [ 6. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6 10] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 144.59176635742188



action possibilites: [-1] 
expected returns: [[156.05222]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 10.] 
cards in discard: [10. 11.  0.  8. 11.  3.  8. 25.  0. 11. 10. 10.  0.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10
  8 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  6.  2.  9.  8. 10.  9.  2. 10.  8.] 
adversary cards in hand: [ 3.  3.  3.  0. 15.] 
adversary cards in discard: [ 6. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6 10] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 165.68905639648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[153.37135]
 [155.48633]
 [149.47868]
 [157.79553]
 [157.2207 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0. 10.] 
cards in discard: [10. 11.  0.  8. 11.  3.  8. 25.  0. 11. 10. 10.  0.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10
  8 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  6.  2.  9.  8. 10.  9.  2. 10.  8.] 
adversary cards in hand: [ 3.  3.  3.  0. 15.] 
adversary cards in discard: [ 6. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6 10] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 156.05221557617188



buy possibilites: [-1] 
expected returns: [[177.93948]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0. 10.] 
cards in discard: [10. 11.  0.  8. 11.  3.  8. 25.  0. 11. 10. 10.  0.  8. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10
  8 10  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  2. 10.  8.] 
adversary cards in hand: [ 3.  3.  3.  0. 15.] 
adversary cards in discard: [ 6. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6 10] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 21 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 157.7955322265625






Player: 1 
cards in hand: [ 3.  3.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 15.] 
cards in discard: [ 6. 10.  0.  0.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  2. 10.  8.] 
adversary cards in hand: [29.  3. 10.  0.  8.] 
adversary cards in discard: [10. 11.  0.  8. 11.  3.  8. 25.  0. 11. 10. 10.  0.  8. 10.  8. 29. 11.
  8. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10
  8 10  8] -> size -> 27 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  0. 15.] 
cards in discard: [ 6. 10.  0.  0.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  2. 10.  8.] 
adversary cards in hand: [29.  3. 10.  0.  8.] 
adversary cards in discard: [10. 11.  0.  8. 11.  3.  8. 25.  0. 11. 10. 10.  0.  8. 10.  8. 29. 11.
  8. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10
  8 10  8] -> size -> 27 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  0. 15.] 
cards in discard: [ 6. 10.  0.  0.  3.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  2. 10.  8.] 
adversary cards in hand: [29.  3. 10.  0.  8.] 
adversary cards in discard: [10. 11.  0.  8. 11.  3.  8. 25.  0. 11. 10. 10.  0.  8. 10.  8. 29. 11.
  8. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10
  8 10  8] -> size -> 27 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [29.  3. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.] 
expected returns: [[143.96478]
 [149.5283 ]
 [142.8932 ]
 [144.6169 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10.  0.  8.] 
cards in discard: [10. 11.  0.  8. 11.  3.  8. 25.  0. 11. 10. 10.  0.  8. 10.  8. 29. 11.
  8. 10.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10
  8 10  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  2. 10.  8.] 
adversary cards in hand: [ 8.  3. 15.  0.  8.] 
adversary cards in discard: [ 6. 10.  0.  0.  3.  0.  0.  0.  3.  3.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6 10  0] -> size -> 23 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 177.93948364257812



action possibilites: [-1. 10.  8.  8.] 
expected returns: [[109.20885]
 [108.34216]
 [109.77101]
 [109.77101]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  8.  8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 25 10  8 29 10  8 11 10 11  8 10 10 11  8 10
  8 10  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  2. 10.  8.] 
adversary cards in hand: [ 8.  3. 15.  0.  8.] 
adversary cards in discard: [ 6. 10.  0.  0.  3.  0.  0.  0.  3.  3.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6 10  0] -> size -> 23 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 149.5283203125



action possibilites: [-1] 
expected returns: [[112.08569]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11 25 10 29 10  8 11 10 11  8 10 10 11  8 10  8 10
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  2. 10.  8.] 
adversary cards in hand: [ 8.  3. 15.  0.  8.] 
adversary cards in discard: [ 6. 10.  0.  0.  3.  0.  0.  0.  3.  3.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6 10  0] -> size -> 23 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 113.28013610839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[111.10055]
 [107.30403]
 [114.75962]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11 25 10 29 10  8 11 10 11  8 10 10 11  8 10  8 10
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  2. 10.  8.] 
adversary cards in hand: [ 8.  3. 15.  0.  8.] 
adversary cards in discard: [ 6. 10.  0.  0.  3.  0.  0.  0.  3.  3.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6 10  0] -> size -> 23 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.085693359375






Player: 1 
cards in hand: [ 8.  3. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 15.  0.  8.] 
cards in discard: [ 6. 10.  0.  0.  3.  0.  0.  0.  3.  3.  3.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8  8 15  6  3  0  6 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  2. 10.  8.] 
adversary cards in hand: [11. 11. 11. 29. 11.] 
adversary cards in discard: [29.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 25 10 29 10  8 11 10 11  8 10 10 11  8 10  8 10
  8] -> size -> 25 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.] 
cards in discard: [ 6. 10.  0.  0.  3.  0.  0.  0.  3.  3.  3.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  2. 10.  8.] 
adversary cards in hand: [11. 11. 11. 29. 11.] 
adversary cards in discard: [29.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 25 10 29 10  8 11 10 11  8 10 10 11  8 10  8 10
  8] -> size -> 25 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.] 
cards in discard: [ 6. 10.  0.  0.  3.  0.  0.  0.  3.  3.  3.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  2. 10.  8.] 
adversary cards in hand: [11. 11. 11. 29. 11.] 
adversary cards in discard: [29.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 25 10 29 10  8 11 10 11  8 10 10 11  8 10  8 10
  8] -> size -> 25 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11. 11. 11. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 29. 11.] 
expected returns: [[133.26149]
 [135.81743]
 [135.81743]
 [135.81743]
 [137.87135]
 [135.81743]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 29. 11.] 
cards in discard: [29.  8.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11 25 10 29 10  8 11 10 11  8 10 10 11  8 10  8 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  2. 10.  8.] 
adversary cards in hand: [ 6.  0.  3.  6. 23.] 
adversary cards in discard: [ 6. 10.  0.  0.  3.  0.  0.  0.  3.  3.  3.  0. 15.  8.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 114.75962829589844



action possibilites: [-1. 11. 11. 11. 11.  8.] 
expected returns: [[118.63696 ]
 [120.955635]
 [120.955635]
 [120.955635]
 [120.955635]
 [119.097534]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 11.  8.] 
cards in discard: [29.  8.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11 25 10 29 10  8 11 10 11  8 10 10 11  8 10  8 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  2. 10.  8.] 
adversary cards in hand: [ 6.  0.  3.  6. 23.] 
adversary cards in discard: [ 6. 10.  0.  0.  3.  0.  0.  0.  3.  3.  3.  0. 15.  8.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 136.9485321044922



action possibilites: [-1] 
expected returns: [[122.50534]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.  8.] 
cards in discard: [29.  8.  3. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11 25 10 29 10  8 11 10 11  8 10 10 11  8 10  8 10
  8 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 6.  0.  3.  6. 23.] 
adversary cards in discard: [ 6. 10.  0.  0.  3.  0.  0.  0.  3.  3.  3.  0. 15.  8.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 122.3179931640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[119.058105]
 [114.96819 ]
 [123.012314]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 11.  8.] 
cards in discard: [29.  8.  3. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11 25 10 29 10  8 11 10 11  8 10 10 11  8 10  8 10
  8 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 6.  0.  3.  6. 23.] 
adversary cards in discard: [ 6. 10.  0.  0.  3.  0.  0.  0.  3.  3.  3.  0. 15.  8.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.50534057617188






Player: 1 
cards in hand: [ 6.  0.  3.  6. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  6. 23.] 
cards in discard: [ 6. 10.  0.  0.  3.  0.  0.  0.  3.  3.  3.  0. 15.  8.  3. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [10.  0.  8.  0.  3.] 
adversary cards in discard: [29.  8.  3. 10. 10. 29. 11. 11. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 25 10 29 10  8 11 10 11  8 10 10 11  8 10  8 10
  8 10] -> size -> 26 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  6. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0] -> size -> 22 
action values: 1 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [10.  0.  8.  0.  3.] 
adversary cards in discard: [29.  8.  3. 10. 10. 29. 11. 11. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 25 10 29 10  8 11 10 11  8 10 10 11  8 10  8 10
  8 10] -> size -> 26 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  6. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0] -> size -> 22 
action values: 0 
buys: 2 
player value: 2 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [10.  0.  8.  0.  3.] 
adversary cards in discard: [29.  8.  3. 10. 10. 29. 11. 11. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 25 10 29 10  8 11 10 11  8 10 10 11  8 10  8 10
  8 10] -> size -> 26 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [10.  0.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[131.61409]
 [130.81607]
 [132.11775]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  0.  3.] 
cards in discard: [29.  8.  3. 10. 10. 29. 11. 11. 11. 11.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11 25 10 29 10  8 11 10 11  8 10 10 11  8 10  8 10
  8 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [23.  6.  0.  3.  6. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 123.0123062133789



action possibilites: [-1] 
expected returns: [[102.572395]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.  8.  3. 10. 10. 29. 11. 11. 11. 11.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 29 11 25 29 10  8 11 10 11  8 10 10 11  8 10  8 10  8 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [23.  6.  0.  3.  6. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 135.15834045410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[100.451904]
 [ 97.85309 ]
 [102.83815 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  8.  3. 10. 10. 29. 11. 11. 11. 11.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 29 11 25 29 10  8 11 10 11  8 10 10 11  8 10  8 10  8 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [23.  6.  0.  3.  6. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.57239532470703






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [23.  6.  0.  3.  6. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [10.  0.  8. 10. 10.] 
adversary cards in discard: [29.  8.  3. 10. 10. 29. 11. 11. 11. 11.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  3 29 11 25 29 10  8 11 10 11  8 10 10 11  8 10  8 10  8 10] -> size -> 23 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [23.  6.  0.  3.  6. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [10.  0.  8. 10. 10.] 
adversary cards in discard: [29.  8.  3. 10. 10. 29. 11. 11. 11. 11.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  3 29 11 25 29 10  8 11 10 11  8 10 10 11  8 10  8 10  8 10] -> size -> 23 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [23.  6.  0.  3.  6. 15.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [10.  0.  8. 10. 10.] 
adversary cards in discard: [29.  8.  3. 10. 10. 29. 11. 11. 11. 11.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  3 29 11 25 29 10  8 11 10 11  8 10 10 11  8 10  8 10  8 10] -> size -> 23 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [10.  0.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 10.] 
expected returns: [[115.315796]
 [114.40334 ]
 [115.83141 ]
 [114.40334 ]
 [114.40334 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 10. 10.] 
cards in discard: [29.  8.  3. 10. 10. 29. 11. 11. 11. 11.  8.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 11 25 29 10  8 11 10 11  8 10 10 11  8 10  8 10  8 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  6.  3.] 
adversary cards in discard: [23.  6.  0.  3.  6. 15.  0.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0] -> size -> 23 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 102.83815002441406



action possibilites: [-1] 
expected returns: [[98.07713]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.  8.  3. 10. 10. 29. 11. 11. 11. 11.  8.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  6.  3.] 
adversary cards in discard: [23.  6.  0.  3.  6. 15.  0.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0] -> size -> 23 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: trash_cards_n_from_hand - action 8
Learning step: 0
desired expected reward: 114.89646911621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[96.89545]
 [94.26844]
 [99.51441]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  8.  3. 10. 10. 29. 11. 11. 11. 11.  8.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  6.  3.] 
adversary cards in discard: [23.  6.  0.  3.  6. 15.  0.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0] -> size -> 23 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 98.07713317871094






Player: 1 
cards in hand: [ 0.  0. 15.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  6.  3.] 
cards in discard: [23.  6.  0.  3.  6. 15.  0.  0.  3.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [10. 25.  8. 10.  0.] 
adversary cards in discard: [29.  8.  3. 10. 10. 29. 11. 11. 11. 11.  8.  8.  0.  8.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10] -> size -> 19 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [23.  6.  0.  3.  6. 15.  0.  0.  3.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [10. 25.  8. 10.  0.] 
adversary cards in discard: [29.  8.  3. 10. 10. 29. 11. 11. 11. 11.  8.  8.  0.  8.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10] -> size -> 19 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [23.  6.  0.  3.  6. 15.  0.  0.  3.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [10. 25.  8. 10.  0.] 
adversary cards in discard: [29.  8.  3. 10. 10. 29. 11. 11. 11. 11.  8.  8.  0.  8.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10] -> size -> 19 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [23.  6.  0.  3.  6. 15.  0.  0.  3.  0.  3.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [10. 25.  8. 10.  0.] 
adversary cards in discard: [29.  8.  3. 10. 10. 29. 11. 11. 11. 11.  8.  8.  0.  8.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10] -> size -> 19 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [10. 25.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.  8. 10.] 
expected returns: [[109.802376]
 [109.087715]
 [115.44585 ]
 [110.20038 ]
 [109.087715]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  8. 10.  0.] 
cards in discard: [29.  8.  3. 10. 10. 29. 11. 11. 11. 11.  8.  8.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  7. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 8.  0.  3.  0. 10.] 
adversary cards in discard: [23.  6.  0.  3.  6. 15.  0.  0.  3.  0.  3.  0.  1. 15.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1] -> size -> 23 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 99.514404296875



action possibilites: [-1] 
expected returns: [[103.708305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 8.  0.  3.  0. 10.] 
adversary cards in discard: [23.  6.  0.  3.  6. 15.  0.  0.  3.  0.  3.  0.  1. 15.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1  6] -> size -> 24 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 115.2048110961914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[101.06161]
 [ 97.82491]
 [104.23924]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 8.  0.  3.  0. 10.] 
adversary cards in discard: [23.  6.  0.  3.  6. 15.  0.  0.  3.  0.  3.  0.  1. 15.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1  6] -> size -> 24 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 103.70830535888672






Player: 1 
cards in hand: [ 8.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  0. 10.] 
cards in discard: [23.  6.  0.  3.  6. 15.  0.  0.  3.  0.  3.  0.  1. 15.  0.  6.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 0. 11. 29. 11.  3.] 
adversary cards in discard: [25. 10.  8. 10.  0.  8. 11.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10] -> size -> 19 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  0. 10.] 
cards in discard: [23.  6.  0.  3.  6. 15.  0.  0.  3.  0.  3.  0.  1. 15.  0.  6.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  1.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 0. 11. 29. 11.  3.] 
adversary cards in discard: [25. 10.  8. 10.  0.  8. 11.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10] -> size -> 19 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  0. 10.] 
cards in discard: [23.  6.  0.  3.  6. 15.  0.  0.  3.  0.  3.  0.  1. 15.  0.  6.  3.  6.
  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1  6
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 0. 11. 29. 11.  3.] 
adversary cards in discard: [25. 10.  8. 10.  0.  8. 11.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10] -> size -> 19 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 29. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[135.48814]
 [138.23407]
 [140.50308]
 [138.23407]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 11.  3.] 
cards in discard: [25. 10.  8. 10.  0.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 0.  6. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1  6
  8] -> size -> 25 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 104.23924255371094



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[115.29213]
 [117.71366]
 [117.71366]
 [114.40391]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 10.] 
cards in discard: [25. 10.  8. 10.  0.  8. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  8.] 
adversary cards in hand: [ 0.  6. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1  6
  8] -> size -> 25 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 133.59616088867188



action possibilites: [-1] 
expected returns: [[115.55056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.] 
cards in discard: [25. 10.  8. 10.  0.  8. 11.  3. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  7.] 
adversary cards in hand: [ 0.  6. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1  6
  8] -> size -> 25 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 69 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 119.16859436035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[113.25883 ]
 [114.93669 ]
 [110.082214]
 [116.38606 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.] 
cards in discard: [25. 10.  8. 10.  0.  8. 11.  3. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  7.] 
adversary cards in hand: [ 0.  6. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1  6
  8] -> size -> 25 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 115.5505599975586






Player: 1 
cards in hand: [ 0.  6. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1  6
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  7.] 
adversary cards in hand: [ 8. 29.  8. 11. 10.] 
adversary cards in discard: [25. 10.  8. 10.  0.  8. 11.  3. 15. 29. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10 15] -> size -> 20 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1  6
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  7.] 
adversary cards in hand: [ 8. 29.  8. 11. 10.] 
adversary cards in discard: [25. 10.  8. 10.  0.  8. 11.  3. 15. 29. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10 15] -> size -> 20 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 8. 29.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8. 11. 10.] 
expected returns: [[128.85077]
 [129.3508 ]
 [133.73773]
 [129.3508 ]
 [131.51762]
 [127.81082]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  8. 11. 10.] 
cards in discard: [25. 10.  8. 10.  0.  8. 11.  3. 15. 29. 11.  0. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  7.] 
adversary cards in hand: [ 3.  0.  8.  1. 10.] 
adversary cards in discard: [ 0.  6. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1  6
  8] -> size -> 25 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 116.38606262207031



action possibilites: [-1.  8. 11. 10.  8.] 
expected returns: [[152.85939]
 [153.37447]
 [155.44217]
 [151.96037]
 [153.37447]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.  8.] 
cards in discard: [25. 10.  8. 10.  0.  8. 11.  3. 15. 29. 11.  0. 11. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  7.] 
adversary cards in hand: [ 3.  0.  8.  1. 10.] 
adversary cards in discard: [ 0.  6. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1  6
  8] -> size -> 25 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 128.53713989257812



action possibilites: [-1] 
expected returns: [[112.91539]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.] 
cards in discard: [25. 10.  8. 10.  0.  8. 11.  3. 15. 29. 11.  0. 11. 10.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10 15 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  6.] 
adversary cards in hand: [ 3.  0.  8.  1. 10.] 
adversary cards in discard: [ 0.  6. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1  6
  8] -> size -> 25 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 69 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 156.93544006347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[109.96338]
 [106.66716]
 [113.16895]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.] 
cards in discard: [25. 10.  8. 10.  0.  8. 11.  3. 15. 29. 11.  0. 11. 10.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10 15 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  6.] 
adversary cards in hand: [ 3.  0.  8.  1. 10.] 
adversary cards in discard: [ 0.  6. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1  6
  8] -> size -> 25 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.91539001464844






Player: 1 
cards in hand: [ 3.  0.  8.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  1. 10.] 
cards in discard: [ 0.  6. 15.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1  6
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  6.] 
adversary cards in hand: [ 3. 10. 10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10 15 15] -> size -> 21 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 1. 3.] 
cards in discard: [ 0.  6. 15.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  1  6
  8] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  6.] 
adversary cards in hand: [ 3. 10. 10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10 15 15] -> size -> 21 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  6. 15.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  6.] 
adversary cards in hand: [ 3. 10. 10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10 15 15] -> size -> 21 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  6. 15.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  6.] 
adversary cards in hand: [ 3. 10. 10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10 15 15] -> size -> 21 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 10.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8. 15.] 
expected returns: [[113.59891 ]
 [112.711174]
 [112.711174]
 [114.11435 ]
 [113.7353  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  8. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 10 11  8 10  8 10  8 10 15 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  6.] 
adversary cards in hand: [ 8.  6.  0.  0. 23.] 
adversary cards in discard: [ 0.  6. 15.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 21 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 113.16896057128906



action possibilites: [-1] 
expected returns: [[116.716896]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  6.] 
adversary cards in hand: [ 8.  6.  0.  0. 23.] 
adversary cards in discard: [ 0.  6. 15.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 21 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 114.94450378417969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[113.82117]
 [110.33416]
 [117.11918]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  6.] 
adversary cards in hand: [ 8.  6.  0.  0. 23.] 
adversary cards in discard: [ 0.  6. 15.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 21 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 116.7168960571289






Player: 1 
cards in hand: [ 8.  6.  0.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0.  0. 23.] 
cards in discard: [ 0.  6. 15.  0.  3. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  6.] 
adversary cards in hand: [11.  8. 10.  8. 29.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15] -> size -> 18 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 0. 6.] 
cards in discard: [ 0.  6. 15.  0.  3. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 21 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  6.] 
adversary cards in hand: [11.  8. 10.  8. 29.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15] -> size -> 18 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [ 0.  6. 15.  0.  3. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  6.] 
adversary cards in hand: [11.  8. 10.  8. 29.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15] -> size -> 18 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 0.  6. 15.  0.  3. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 20 
action values: 0 
buys: 2 
player value: 2 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  6.] 
adversary cards in hand: [11.  8. 10.  8. 29.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15] -> size -> 18 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [11.  8. 10.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10.  8. 29.] 
expected returns: [[112.4502 ]
 [114.79067]
 [112.94919]
 [111.63708]
 [112.94919]
 [116.66928]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 10.  8. 29.] 
cards in discard: [8. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  6.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [ 0.  6. 15.  0.  3. 10.  8. 23.  8.  6.  0.  6.] 
adversary owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 117.11917114257812



action possibilites: [-1. 11. 10.  8. 11.] 
expected returns: [[131.52179]
 [133.78288]
 [130.69579]
 [131.9801 ]
 [133.78288]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8. 11.] 
cards in discard: [8. 3. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  6.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [ 0.  6. 15.  0.  3. 10.  8. 23.  8.  6.  0.  6.] 
adversary owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 111.5037841796875



action possibilites: [-1] 
expected returns: [[148.49353]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.] 
cards in discard: [ 8.  3.  8. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  5.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [ 0.  6. 15.  0.  3. 10.  8. 23.  8.  6.  0.  6.] 
adversary owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 129 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 135.08099365234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[145.91138]
 [142.25897]
 [149.43088]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 11.] 
cards in discard: [ 8.  3.  8. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  5.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [ 0.  6. 15.  0.  3. 10.  8. 23.  8.  6.  0.  6.] 
adversary owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 148.4935302734375






Player: 1 
cards in hand: [3. 6. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 0. 3.] 
cards in discard: [ 0.  6. 15.  0.  3. 10.  8. 23.  8.  6.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  5.] 
adversary cards in hand: [ 8. 11.  8.  0. 29.] 
adversary cards in discard: [ 8.  3.  8. 15. 29. 11. 10.  8. 11.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15] -> size -> 19 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 3.] 
cards in discard: [ 0.  6. 15.  0.  3. 10.  8. 23.  8.  6.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  5.] 
adversary cards in hand: [ 8. 11.  8.  0. 29.] 
adversary cards in discard: [ 8.  3.  8. 15. 29. 11. 10.  8. 11.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15] -> size -> 19 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8. 29.] 
expected returns: [[115.597786]
 [116.10493 ]
 [117.90028 ]
 [116.10493 ]
 [119.73    ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  8.  0. 29.] 
cards in discard: [ 8.  3.  8. 15. 29. 11. 10.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  5.] 
adversary cards in hand: [ 0. 23.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 149.43087768554688



action possibilites: [-1. 11.  8. 11.] 
expected returns: [[108.391525]
 [111.02914 ]
 [108.97631 ]
 [111.02914 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 11.] 
cards in discard: [ 8.  3.  8. 15. 29. 11. 10.  8. 11.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  5.] 
adversary cards in hand: [ 0. 23.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 115.20455932617188



action possibilites: [-1] 
expected returns: [[107.15625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.] 
cards in discard: [ 8.  3.  8. 15. 29. 11. 10.  8. 11.  8. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  4.] 
adversary cards in hand: [ 0. 23.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 129 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 112.55267333984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[104.69819]
 [106.62632]
 [101.00387]
 [108.17587]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.] 
cards in discard: [ 8.  3.  8. 15. 29. 11. 10.  8. 11.  8. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  4.] 
adversary cards in hand: [ 0. 23.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 107.15625






Player: 1 
cards in hand: [ 0. 23.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  4.] 
adversary cards in hand: [29. 15. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15] -> size -> 20 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  6.  0.  9.  8. 10.  9.  1. 10.  4.] 
adversary cards in hand: [29. 15. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15] -> size -> 20 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  0.  0. 15.] 
cards in discard: [11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  5.  0.  9.  8. 10.  9.  1. 10.  4.] 
adversary cards in hand: [29. 15. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15] -> size -> 20 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [29. 15. 10. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 10. 25.] 
expected returns: [[134.33655]
 [138.40314]
 [134.4977 ]
 [133.59265]
 [140.51492]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 10. 25.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6. 10.  5.  0.  9.  8. 10.  9.  1. 10.  4.] 
adversary cards in hand: [ 8. 15.  3.  0. 10.] 
adversary cards in discard: [11.  0. 23.  0.  0. 15.] 
adversary owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8 11] -> size -> 21 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 108.17587280273438



action possibilites: [-1] 
expected returns: [[130.17609]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 10.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  4.] 
adversary cards in hand: [ 8. 15.  3.  0. 10.] 
adversary cards in discard: [11.  0. 23.  0.  0. 15.  6.] 
adversary owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8 11  6] -> size -> 22 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 140.01046752929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[126.9495  ]
 [123.750206]
 [130.05136 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15. 10.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  4.] 
adversary cards in hand: [ 8. 15.  3.  0. 10.] 
adversary cards in discard: [11.  0. 23.  0.  0. 15.  6.] 
adversary owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8 11  6] -> size -> 22 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 130.17608642578125






Player: 1 
cards in hand: [ 8. 15.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  3.  0. 10.] 
cards in discard: [11.  0. 23.  0.  0. 15.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8 11  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  4.] 
adversary cards in hand: [10.  8.  3.  8. 11.] 
adversary cards in discard: [25. 29. 15. 10.  0. 11.  8.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15] -> size -> 20 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  3.  0.  3.] 
cards in discard: [11.  0. 23.  0.  0. 15.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8 11  6] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  4.] 
adversary cards in hand: [10.  8.  3.  8. 11.] 
adversary cards in discard: [25. 29. 15. 10.  0. 11.  8.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15] -> size -> 20 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  3.  0.  3.] 
cards in discard: [11.  0. 23.  0.  0. 15.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8 11  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  4.] 
adversary cards in hand: [10.  8.  3.  8. 11.] 
adversary cards in discard: [25. 29. 15. 10.  0. 11.  8.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15] -> size -> 20 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [10.  8.  3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8. 11.] 
expected returns: [[159.64519]
 [158.7954 ]
 [160.12585]
 [160.12585]
 [161.9883 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  8. 11.] 
cards in discard: [25. 29. 15. 10.  0. 11.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  4.] 
adversary cards in hand: [0. 6. 6. 8. 6.] 
adversary cards in discard: [11.  0. 23.  0.  0. 15.  6. 10.  8. 15.  3.  0.  3.] 
adversary owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8 11  6] -> size -> 22 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 130.05136108398438



action possibilites: [-1] 
expected returns: [[147.63261]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  8.] 
cards in discard: [25. 29. 15. 10.  0. 11.  8. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  3.] 
adversary cards in hand: [0. 6. 6. 8. 6.] 
adversary cards in discard: [11.  0. 23.  0.  0. 15.  6. 10.  8. 15.  3.  0.  3.] 
adversary owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8 11  6] -> size -> 22 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 162.7412109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[144.02916]
 [140.41765]
 [147.67424]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  8.] 
cards in discard: [25. 29. 15. 10.  0. 11.  8. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  3.] 
adversary cards in hand: [0. 6. 6. 8. 6.] 
adversary cards in discard: [11.  0. 23.  0.  0. 15.  6. 10.  8. 15.  3.  0.  3.] 
adversary owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8 11  6] -> size -> 22 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 147.6326141357422






Player: 1 
cards in hand: [0. 6. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 8. 6.] 
cards in discard: [11.  0. 23.  0.  0. 15.  6. 10.  8. 15.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  6  3  8 15  6  3  0  6 10  0  0  6  8 11  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  3.] 
adversary cards in hand: [ 8.  0. 11. 15.  8.] 
adversary cards in discard: [25. 29. 15. 10.  0. 11.  8. 15. 11. 10.  8.  3.  8.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15] -> size -> 21 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [11.  0. 23.  0.  0. 15.  6. 10.  8. 15.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  3.] 
adversary cards in hand: [ 8.  0. 11. 15.  8.] 
adversary cards in discard: [25. 29. 15. 10.  0. 11.  8. 15. 11. 10.  8.  3.  8.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15] -> size -> 21 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [11.  0. 23.  0.  0. 15.  6. 10.  8. 15.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  3.] 
adversary cards in hand: [ 8.  0. 11. 15.  8.] 
adversary cards in discard: [25. 29. 15. 10.  0. 11.  8. 15. 11. 10.  8.  3.  8.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15] -> size -> 21 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [11.  0. 23.  0.  0. 15.  6. 10.  8. 15.  3.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  3.] 
adversary cards in hand: [ 8.  0. 11. 15.  8.] 
adversary cards in discard: [25. 29. 15. 10.  0. 11.  8. 15. 11. 10.  8.  3.  8.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15] -> size -> 21 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 11. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 15.  8.] 
expected returns: [[110.50641 ]
 [110.96301 ]
 [112.672905]
 [110.63142 ]
 [110.96301 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 15.  8.] 
cards in discard: [25. 29. 15. 10.  0. 11.  8. 15. 11. 10.  8.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  3.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 147.6742401123047



action possibilites: [-1] 
expected returns: [[132.70174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  8.] 
cards in discard: [25. 29. 15. 10.  0. 11.  8. 15. 11. 10.  8.  3.  8. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  2.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 113.36095428466797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[129.2149 ]
 [125.76399]
 [132.5192 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15.  8.] 
cards in discard: [25. 29. 15. 10.  0. 11.  8. 15. 11. 10.  8.  3.  8. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  2.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 132.7017364501953






Player: 1 
cards in hand: [0. 0. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  2.] 
adversary cards in hand: [15. 15. 15. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15] -> size -> 22 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  2.] 
adversary cards in hand: [15. 15. 15. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15] -> size -> 22 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 3.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  2.] 
adversary cards in hand: [15. 15. 15. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15] -> size -> 22 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [15. 15. 15. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15. 11. 29.] 
expected returns: [[122.45508 ]
 [122.676994]
 [122.676994]
 [122.676994]
 [125.4953  ]
 [127.88272 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 11. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  2.] 
adversary cards in hand: [ 6. 11. 15.  3.  8.] 
adversary cards in discard: [0. 0. 0. 6. 3. 3.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 132.51919555664062



action possibilites: [-1. 15. 15. 11. 10.] 
expected returns: [[120.234   ]
 [120.377426]
 [120.377426]
 [122.65888 ]
 [119.38782 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 11. 10.] 
cards in discard: [15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  2.] 
adversary cards in hand: [ 6. 11. 15.  3.  8.] 
adversary cards in discard: [0. 0. 0. 6. 3. 3.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 121.94944763183594



action possibilites: [-1] 
expected returns: [[115.787285]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10.] 
cards in discard: [15. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  1.] 
adversary cards in hand: [ 6. 11. 15.  3.  8.] 
adversary cards in discard: [0. 0. 0. 6. 3. 3.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 99 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 124.10492706298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[114.18013 ]
 [110.372696]
 [117.86076 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 10.] 
cards in discard: [15. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  1.] 
adversary cards in hand: [ 6. 11. 15.  3.  8.] 
adversary cards in discard: [0. 0. 0. 6. 3. 3.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 115.78728485107422






Player: 1 
cards in hand: [ 6. 11. 15.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 15.  3.  8.] 
cards in discard: [0. 0. 0. 6. 3. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  1.] 
adversary cards in hand: [15.  8.  8.  8. 25.] 
adversary cards in discard: [15. 15. 29. 11. 15. 15. 10.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15] -> size -> 23 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.  8.] 
cards in discard: [0. 0. 0. 6. 3. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  1.] 
adversary cards in hand: [15.  8.  8.  8. 25.] 
adversary cards in discard: [15. 15. 29. 11. 15. 15. 10.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15] -> size -> 23 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  3.  8.] 
cards in discard: [0. 0. 0. 6. 3. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  1.] 
adversary cards in hand: [15.  8.  8.  8. 25.] 
adversary cards in discard: [15. 15. 29. 11. 15. 15. 10.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15] -> size -> 23 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [15.  8.  8.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.  8. 25.] 
expected returns: [[111.67123]
 [111.81565]
 [112.2258 ]
 [112.2258 ]
 [112.2258 ]
 [119.05171]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  8.  8. 25.] 
cards in discard: [15. 15. 29. 11. 15. 15. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  5. 10.  5.  0.  9.  8. 10.  9.  1. 10.  1.] 
adversary cards in hand: [ 0.  3. 23.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  3.  3. 15.  6. 11.  3.  8.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 117.86076354980469



action possibilites: [-1] 
expected returns: [[122.29822]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  8.  8. 10. 15.] 
cards in discard: [15. 15. 29. 11. 15. 15. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  4. 10.  5.  0.  9.  8. 10.  9.  1. 10.  1.] 
adversary cards in hand: [ 0.  3. 23.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  3.  3. 15.  6. 11.  3.  8.  6.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 117.73611450195312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[121.10356 ]
 [117.93231 ]
 [124.057816]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  8.  8. 10. 15.] 
cards in discard: [15. 15. 29. 11. 15. 15. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  4. 10.  5.  0.  9.  8. 10.  9.  1. 10.  1.] 
adversary cards in hand: [ 0.  3. 23.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  3.  3. 15.  6. 11.  3.  8.  6.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.2982177734375






Player: 1 
cards in hand: [ 0.  3. 23.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 23.  0.  0.] 
cards in discard: [ 0.  0.  0.  6.  3.  3. 15.  6. 11.  3.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  4. 10.  5.  0.  9.  8. 10.  9.  1. 10.  1.] 
adversary cards in hand: [ 3. 11. 11.  8. 11.] 
adversary cards in discard: [15. 15. 29. 11. 15. 15. 10. 25. 15.  8.  8.  8. 10. 15.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15] -> size -> 23 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 23.  0.  0.] 
cards in discard: [ 0.  0.  0.  6.  3.  3. 15.  6. 11.  3.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 27. 30.  8.  4. 10.  5.  0.  9.  8. 10.  9.  1. 10.  1.] 
adversary cards in hand: [ 3. 11. 11.  8. 11.] 
adversary cards in discard: [15. 15. 29. 11. 15. 15. 10. 25. 15.  8.  8.  8. 10. 15.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15] -> size -> 23 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 11.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8. 11.] 
expected returns: [[112.090836]
 [114.9123  ]
 [114.9123  ]
 [112.68243 ]
 [114.9123  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  8. 11.] 
cards in discard: [15. 15. 29. 11. 15. 15. 10. 25. 15.  8.  8.  8. 10. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  4. 10.  5.  0.  9.  8. 10.  9.  1. 10.  1.] 
adversary cards in hand: [15.  0. 10.  8.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  3.  3. 15.  6. 11.  3.  8.  6.  0.  3. 23.  0.  0.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 124.05781555175781



action possibilites: [-1] 
expected returns: [[155.19894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8. 11.] 
cards in discard: [15. 15. 29. 11. 15. 15. 10. 25. 15.  8.  8.  8. 10. 15. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  4. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [15.  0. 10.  8.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  3.  3. 15.  6. 11.  3.  8.  6.  0.  3. 23.  0.  0.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 116.50120544433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[151.20822]
 [147.50262]
 [154.65793]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  8. 11.] 
cards in discard: [15. 15. 29. 11. 15. 15. 10. 25. 15.  8.  8.  8. 10. 15. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  4. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [15.  0. 10.  8.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  3.  3. 15.  6. 11.  3.  8.  6.  0.  3. 23.  0.  0.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 155.19894409179688






Player: 1 
cards in hand: [15.  0. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10.  8.  0.] 
cards in discard: [ 0.  0.  0.  6.  3.  3. 15.  6. 11.  3.  8.  6.  0.  3. 23.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  4. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [25.  8. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8.  0.  6.] 
cards in discard: [ 0.  0.  0.  6.  3.  3. 15.  6. 11.  3.  8.  6.  0.  3. 23.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  4. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [25.  8. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  8.  0.  6.] 
cards in discard: [ 0.  0.  0.  6.  3.  3. 15.  6. 11.  3.  8.  6.  0.  3. 23.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 27. 30.  8.  4. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [25.  8. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [25.  8. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 29.] 
expected returns: [[119.981094]
 [126.08362 ]
 [120.39309 ]
 [123.98364 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  4. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [15.  8. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 154.65794372558594



action possibilites: [-1] 
expected returns: [[105.09012]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  0.  8. 15.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  3. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [15.  8. 15.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6  6] -> size -> 24 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 124.44650268554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 99.9514 ]
 [101.6782 ]
 [ 96.70462]
 [103.18892]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.  0.  8. 15.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 27. 30.  8.  3. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [15.  8. 15.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6  6] -> size -> 24 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.09011840820312






Player: 1 
cards in hand: [15.  8. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 15.  0.  0.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  3. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [15.  3. 15. 11. 29.] 
adversary cards in discard: [25.  8. 29.  0.  0.  8. 15.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8. 15.  0.  0.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 27. 30.  8.  3. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [15.  3. 15. 11. 29.] 
adversary cards in discard: [25.  8. 29.  0.  0.  8. 15.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
adversary victory points: 1
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [15.  3. 15. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 11. 29.] 
expected returns: [[107.074196]
 [107.23805 ]
 [107.23805 ]
 [109.196976]
 [110.856415]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15. 11. 29.] 
cards in discard: [25.  8. 29.  0.  0.  8. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  3. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [ 6. 15.  8. 15.  0.  0.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6  6] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 103.18891143798828



action possibilites: [-1. 15. 15.] 
expected returns: [[133.49606]
 [133.64636]
 [133.64636]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15.] 
cards in discard: [25.  8. 29.  0.  0.  8. 15. 11. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8.  3. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [ 6. 15.  8. 15.  0.  0.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6  6] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 106.55615234375



action possibilites: [-1] 
expected returns: [[106.29405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.] 
cards in discard: [25.  8. 29.  0.  0.  8. 15. 11. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8.  3. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [ 6. 15.  8. 15.  0.  0.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6  6] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 133.6463623046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[102.21094 ]
 [ 98.38452 ]
 [105.849014]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [25.  8. 29.  0.  0.  8. 15. 11. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8.  3. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [ 6. 15.  8. 15.  0.  0.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6  6] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 106.29405212402344






Player: 1 
cards in hand: [3. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [ 6. 15.  8. 15.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  3. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [ 8. 15. 10. 11. 15.] 
adversary cards in discard: [25.  8. 29.  0.  0.  8. 15. 11. 15. 29. 15.  3. 15.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [ 6. 15.  8. 15.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 27. 30.  8.  3. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [ 8. 15. 10. 11. 15.] 
adversary cards in discard: [25.  8. 29.  0.  0.  8. 15. 11. 15. 29. 15.  3. 15.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [ 6. 15.  8. 15.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6  6
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  3. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [ 8. 15. 10. 11. 15.] 
adversary cards in discard: [25.  8. 29.  0.  0.  8. 15. 11. 15. 29. 15.  3. 15.] 
adversary owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 8. 15. 10. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10. 11. 15.] 
expected returns: [[108.15335 ]
 [108.751015]
 [108.3288  ]
 [107.224144]
 [110.90902 ]
 [108.3288  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 10. 11. 15.] 
cards in discard: [25.  8. 29.  0.  0.  8. 15. 11. 15. 29. 15.  3. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  3. 10.  5.  0.  9.  8. 10.  9.  1. 10.  0.] 
adversary cards in hand: [ 3.  6.  0.  0. 11.] 
adversary cards in discard: [ 6. 15.  8. 15.  0.  0.  3.  3.  3.  0.  0.  8.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6  6
  3] -> size -> 25 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 105.84898376464844



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 4 
Chapel: 6 
Witch: 1 
Poacher: 2 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 8. 15. 10. 15.] 
cards in discard: [25.  8. 29.  0.  0.  8. 15. 11. 15. 29. 15.  3. 15. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 29 11 25 29  8 11 11  8 11  8  8 10  8 10 15 15 15 15 15 15 15
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  3. 10.  5.  0.  9.  8. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 3.  6.  0.  0. 11.] 
adversary cards in discard: [ 6. 15.  8. 15.  0.  0.  3.  3.  3.  0.  0.  8.] 
adversary owned cards: [ 0  3  3 23 15  0  0  3  8 15  3  0  6 10  0  0  6  8 11  6  0  0  6  6
  3] -> size -> 25 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[     -5 3000000       0      30       0       0      20       0       0
       0       0       0       0       0      27       0] 
sum of rewards: 3000072 

action type: gain_card_n - action 8
Learning step: 119998.5234375
desired expected reward: 120107.2734375



