 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.626444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -60        0        0       20        0
        0        0        0     -100        0        0        8        0] 
sum of rewards: -3000137 

action type: buy - action 8.0
Learning step: -120005.3359375
desired expected reward: -120008.9609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.933039]
 [23.365978]
 [22.080696]
 [16.566004]
 [21.317413]
 [25.168884]
 [21.579416]
 [27.27088 ]
 [18.798435]
 [20.380917]
 [23.166346]
 [21.875   ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 22.318918228149414



buy possibilites: [-1] 
expected returns: [[29.935408]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 27.270883560180664






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.604546]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.935407638549805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.103697]
 [28.47495 ]
 [27.350002]
 [21.23718 ]
 [30.100082]
 [26.853777]
 [25.728836]
 [27.633211]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.15983009338379



buy possibilites: [-1] 
expected returns: [[23.946363]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 30.10008430480957






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  0.  3.  3.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[32.08827 ]
 [36.467358]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.94636344909668



action possibilites: [-1.] 
expected returns: [[28.25355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 36.36080551147461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[24.161825]
 [28.361269]
 [27.275587]
 [21.393423]
 [26.662436]
 [29.909702]
 [26.795946]
 [31.996634]
 [24.017754]
 [25.710266]
 [28.217196]
 [28.421385]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 28.253549575805664



buy possibilites: [-1] 
expected returns: [[52.119404]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 31.99663734436035






Player: 1 
cards in hand: [ 3.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0.  0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[73.42517]
 [73.99527]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [29. 29.  0.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 8.  3.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 52.11940383911133



action possibilites: [-1] 
expected returns: [[45.018906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 29.  0.  3.  0.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 8.  3.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 77.21917724609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[40.095886]
 [44.7469  ]
 [43.539814]
 [37.017754]
 [46.467102]
 [43.02318 ]
 [41.816097]
 [43.610485]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 29.  0.  3.  0.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 8.  3.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.01890563964844



buy possibilites: [-1] 
expected returns: [[40.11463]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 29.  0.  3.  0.  0.  3. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 8.  3.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 46.467105865478516






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 8.  3.  3. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 8.  3.  3. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 8.  3.  3. 10.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[32.519863]
 [30.80572 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.11463165283203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[29.66885 ]
 [33.868294]
 [32.782608]
 [26.900444]
 [32.16946 ]
 [35.41673 ]
 [32.302967]
 [37.310505]
 [29.524773]
 [31.217283]
 [33.72422 ]
 [32.93142 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.61624526977539



buy possibilites: [-1] 
expected returns: [[34.750275]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 37.310508728027344






Player: 1 
cards in hand: [0. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0. 29.] 
adversary cards in discard: [29.  0.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0. 29.] 
adversary cards in discard: [29.  0.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [23.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8  0 23] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0. 29.] 
adversary cards in discard: [29.  0.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[61.565464]
 [70.90477 ]
 [70.90477 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0. 29.] 
cards in discard: [29.  0.  0. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [23.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8  0 23] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.750274658203125



action possibilites: [-1. 29. 11.] 
expected returns: [[46.47955 ]
 [53.50236 ]
 [50.737476]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 29. 11.] 
cards in discard: [29.  0.  0. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [23.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8  0 23] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 71.25270080566406



action possibilites: [-1. 11. 11.] 
expected returns: [[74.31027 ]
 [79.005806]
 [79.005806]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11. 11.] 
cards in discard: [29.  0.  0. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [23.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8  0 23] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 53.502376556396484



action possibilites: [-1] 
expected returns: [[38.15826]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.] 
cards in discard: [29.  0.  0. 10.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10.  9.  7. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [23.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8  0 23] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 80.44325256347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[35.397182]
 [39.256317]
 [38.170635]
 [33.032883]
 [41.202023]
 [37.69099 ]
 [36.711376]
 [38.319447]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 11.] 
cards in discard: [29.  0.  0. 10.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10.  9.  7. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [23.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8  0 23] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.158260345458984



buy possibilites: [-1] 
expected returns: [[63.399616]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 11.] 
cards in discard: [29.  0.  0. 10.  0.  0. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10.  9.  7. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [23.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8  0 23] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 109 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 41.202030181884766






Player: 1 
cards in hand: [ 8. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0.  0.] 
cards in discard: [23.  0.  3.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  8  0 23] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [23.  0.  3.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1  8  0 23] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [23.  0.  3.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1  8  0 23] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [23.  0.  3.  0.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1  8  0 23  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.314058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10.  9.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8  0 23  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 63.39961624145508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.868446]
 [27.067886]
 [25.982204]
 [20.100042]
 [25.369053]
 [28.616322]
 [25.502563]
 [30.510103]
 [22.72437 ]
 [24.416882]
 [26.923813]
 [26.131018]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  7. 10.  9.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8  0 23  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 26.37220573425293



buy possibilites: [-1] 
expected returns: [[62.826702]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  6. 10.  9.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8  0 23  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 30.510107040405273






Player: 1 
cards in hand: [8. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8  0 23  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  6. 10.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 11. 29. 10.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  1  8  0 23  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  6. 10.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 11. 29. 10.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  1  8  0 23  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  6. 10.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 11. 29. 10.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  1  8  0 23  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  6. 10.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 11. 29. 10.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[47.714073]
 [49.51279 ]
 [51.201557]
 [45.926838]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29. 10.  0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  6. 10.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [0. 8. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  8  0 23  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 62.82670211791992



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[34.501476]
 [38.758034]
 [32.545307]
 [38.758034]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  0. 11.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  6. 10.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [0. 8. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  8  0 23  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 51.65189743041992



action possibilites: [-1] 
expected returns: [[52.37354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 11.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [0. 8. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  8  0 23  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 40.78055953979492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[48.184307]
 [52.298473]
 [44.615673]
 [51.7815  ]
 [51.02834 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 11.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [0. 8. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  8  0 23  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 52.373538970947266



buy possibilites: [-1] 
expected returns: [[73.60857]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 11.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [0. 8. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  8  0 23  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 81 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 52.29848861694336






Player: 1 
cards in hand: [3. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [0. 8. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  8  0 23  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [10. 29.  3.  0. 11.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0. 10.  3. 29. 11.  3. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [0. 8. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  8  0 23  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [10. 29.  3.  0. 11.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0. 10.  3. 29. 11.  3. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 0.  8.  0.  3.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  8  0 23  0  0 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10.  6. 10.  9.  6. 10.  9.] 
adversary cards in hand: [10. 29.  3.  0. 11.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0. 10.  3. 29. 11.  3. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [10. 29.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[33.63969 ]
 [32.32297 ]
 [41.37604 ]
 [38.585636]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  3.  0. 11.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10.  3. 29. 11.  3. 10.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10.  6. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  8  0 23  0  0 15] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 73.60856628417969



action possibilites: [-1. 10. 11.] 
expected returns: [[58.022778]
 [57.010788]
 [62.89825 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 11.  0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10.  3. 29. 11.  3. 10.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10.  6. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  8  0 23  0  0 15] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 41.93629837036133



action possibilites: [-1] 
expected returns: [[12.139663]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10.  3. 29. 11.  3. 10.  0. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10.  6. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  8  0 23  0  0 15] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 64.64369201660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[10.331443]
 [13.953638]
 [12.957962]
 [ 8.568352]
 [15.238966]
 [12.612447]
 [11.616767]
 [11.753349]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10.  3. 29. 11.  3. 10.  0. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10.  6. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  8  0 23  0  0 15] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.139662742614746



buy possibilites: [-1] 
expected returns: [[22.925926]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10.  3. 29. 11.  3. 10.  0. 11. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  6.  9. 10.  6. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  8  0 23  0  0 15] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 15.238964080810547






Player: 1 
cards in hand: [ 8.  0.  0.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 23.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  8  0 23  0  0 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  6.  9. 10.  6. 10.  9.  5. 10.  9.] 
adversary cards in hand: [10. 10.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11] -> size -> 23 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  1  8  0  0  0 15] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  6.  9. 10.  6. 10.  9.  5. 10.  9.] 
adversary cards in hand: [10. 10.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11] -> size -> 23 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  1  8  0  0  0 15] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  6.  9. 10.  6. 10.  9.  5. 10.  9.] 
adversary cards in hand: [10. 10.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11] -> size -> 23 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [10. 10.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
expected returns: [[43.660027]
 [40.128628]
 [40.128628]
 [48.891376]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  6.  9. 10.  6. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 3  3  3  1  8  0  0  0 15] -> size -> 9 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.925926208496094



action possibilites: [-1. 10. 10.] 
expected returns: [[36.25944 ]
 [33.719097]
 [33.719097]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  6.  9. 10.  6. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 3  3  3  1  8  0  0  0 15] -> size -> 9 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 48.88911819458008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[30.879755]
 [35.997063]
 [34.68107 ]
 [28.111345]
 [33.904274]
 [37.96263 ]
 [34.115997]
 [40.316784]
 [30.768312]
 [32.800003]
 [35.930943]
 [35.340343]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  6.  9. 10.  6. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 3  3  3  1  8  0  0  0 15] -> size -> 9 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 36.25944137573242



buy possibilites: [-1] 
expected returns: [[80.38769]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.  0.] 
cards in discard: [29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  6.  9. 10.  5. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 3  3  3  1  8  0  0  0 15] -> size -> 9 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 40.3167839050293






Player: 1 
cards in hand: [ 0.  3. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  3.  0.] 
cards in discard: [8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0  0  0 15] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  6.  9. 10.  5. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 3. 29. 11.  0. 11.] 
adversary cards in discard: [29. 29. 10. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29] -> size -> 24 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  3.  0.] 
cards in discard: [8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0  0  0 15] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  6.  9. 10.  5. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 3. 29. 11.  0. 11.] 
adversary cards in discard: [29. 29. 10. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29] -> size -> 24 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  3.  0.] 
cards in discard: [8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0  0  0 15  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  6.  9. 10.  5. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 3. 29. 11.  0. 11.] 
adversary cards in discard: [29. 29. 10. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29] -> size -> 24 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[ 96.57596]
 [107.94916]
 [104.34016]
 [104.34016]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11.  0. 11.] 
cards in discard: [29. 29. 10. 10.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  6.  9. 10.  5. 10.  9.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0  0  0 15  0] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 80.38768768310547



action possibilites: [-1. 11. 11.] 
expected returns: [[38.544323]
 [41.737953]
 [41.737953]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 11.  3.] 
cards in discard: [29. 29. 10. 10.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  6.  9. 10.  5. 10.  9.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0  0  0 15  0] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 108.40670776367188



action possibilites: [-1] 
expected returns: [[28.063303]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3.] 
cards in discard: [29. 29. 10. 10.  0.  0.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  6.  9. 10.  5. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0  0  0 15  0] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 43.27949142456055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.18892 ]
 [29.314095]
 [23.21952 ]
 [28.885128]
 [28.33294 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  3.] 
cards in discard: [29. 29. 10. 10.  0.  0.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  6.  9. 10.  5. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0  0  0 15  0] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.063302993774414



buy possibilites: [-1] 
expected returns: [[19.43881]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  3.] 
cards in discard: [29. 29. 10. 10.  0.  0.  0. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10. 10.  6.  9. 10.  5. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0  0  0 15  0] -> size -> 10 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 111 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 29.314096450805664






Player: 1 
cards in hand: [0. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0  0  0 15  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10. 10.  6.  9. 10.  5. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 10. 11.] 
adversary cards in discard: [29. 29. 10. 10.  0.  0.  0. 10.  3. 29. 11.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3] -> size -> 26 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0  0  0 15  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 28. 30.  8. 10. 10.  6.  9. 10.  5. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 10. 11.] 
adversary cards in discard: [29. 29. 10. 10.  0.  0.  0. 10.  3. 29. 11.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3] -> size -> 26 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [4.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0  0  0 15  0  4] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8. 10. 10.  6.  9. 10.  5. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 10. 11.] 
adversary cards in discard: [29. 29. 10. 10.  0.  0.  0. 10.  3. 29. 11.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3] -> size -> 26 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 11.] 
expected returns: [[34.624096]
 [43.45906 ]
 [40.55699 ]
 [33.018578]
 [40.55699 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 10. 11.] 
cards in discard: [29. 29. 10. 10.  0.  0.  0. 10.  3. 29. 11.  3.  0. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8. 10. 10.  6.  9. 10.  5. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  3.  0. 15.  3.] 
adversary cards in discard: [4. 0. 0. 0. 1. 3.] 
adversary owned cards: [ 3  3  3  1  8  0  0  0 15  0  4] -> size -> 11 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.438810348510742



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[87.43658 ]
 [94.70375 ]
 [86.210434]
 [94.70375 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 11.  3.] 
cards in discard: [29. 29. 10. 10.  0.  0.  0. 10.  3. 29. 11.  3.  0. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 29.  8. 10. 10.  6.  9. 10.  5. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 8.  3.  0. 15.  3.] 
adversary cards in discard: [4. 0. 0. 0. 1. 3.] 
adversary owned cards: [ 3  3  3  1  8  0  0  0 15  0  4] -> size -> 11 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.41767120361328



action possibilites: [-1] 
expected returns: [[4.6771126]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  3.] 
cards in discard: [29. 29. 10. 10.  0.  0.  0. 10.  3. 29. 11.  3.  0. 11.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 29.  8. 10. 10.  6.  9. 10.  5. 10.  9.  3. 10.  9.] 
adversary cards in hand: [ 8.  3.  0. 15.  3.] 
adversary cards in discard: [4. 0. 0. 0. 1. 3.] 
adversary owned cards: [ 3  3  3  1  8  0  0  0 15  0  4] -> size -> 11 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 97.006103515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[3.2047393]
 [4.5231   ]
 [2.3154438]
 [4.2036448]
 [4.834112 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  3.] 
cards in discard: [29. 29. 10. 10.  0.  0.  0. 10.  3. 29. 11.  3.  0. 11.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 29.  8. 10. 10.  6.  9. 10.  5. 10.  9.  3. 10.  9.] 
adversary cards in hand: [ 8.  3.  0. 15.  3.] 
adversary cards in discard: [4. 0. 0. 0. 1. 3.] 
adversary owned cards: [ 3  3  3  1  8  0  0  0 15  0  4] -> size -> 11 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.677112579345703






Player: 1 
cards in hand: [ 8.  3.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 15.  3.] 
cards in discard: [4. 0. 0. 0. 1. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0  0  0 15  0  4] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8. 10. 10.  6.  9. 10.  5. 10.  9.  3. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0. 10.] 
adversary cards in discard: [29. 29. 10. 10.  0.  0.  0. 10.  3. 29. 11.  3.  0. 11.  3. 10. 29. 11.
  0. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10] -> size -> 27 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3.] 
cards in discard: [4. 0. 0. 0. 1. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  8  0  0 15  0  4] -> size -> 10 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 28. 29.  8. 10. 10.  6.  9. 10.  5. 10.  9.  3. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0. 10.] 
adversary cards in discard: [29. 29. 10. 10.  0.  0.  0. 10.  3. 29. 11.  3.  0. 11.  3. 10. 29. 11.
  0. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10] -> size -> 27 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [4. 0. 0. 0. 1. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  8  0  0 15  0  4] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 29.  8. 10. 10.  6.  9. 10.  5. 10.  9.  3. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0. 10.] 
adversary cards in discard: [29. 29. 10. 10.  0.  0.  0. 10.  3. 29. 11.  3.  0. 11.  3. 10. 29. 11.
  0. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10] -> size -> 27 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [4. 0. 0. 0. 1. 3. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  8  0  0 15  0  4  1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8. 10. 10.  6.  9. 10.  5. 10.  9.  3. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0. 10.] 
adversary cards in discard: [29. 29. 10. 10.  0.  0.  0. 10.  3. 29. 11.  3.  0. 11.  3. 10. 29. 11.
  0. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10] -> size -> 27 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[25.326973]
 [28.388178]
 [22.606604]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0. 10.] 
cards in discard: [29. 29. 10. 10.  0.  0.  0. 10.  3. 29. 11.  3.  0. 11.  3. 10. 29. 11.
  0. 10. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8. 10. 10.  6.  9. 10.  5. 10.  9.  3. 10.  9.] 
adversary cards in hand: [ 1.  1.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0  0 15  0  4  1] -> size -> 11 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 4.834117889404297



action possibilites: [-1. 10. 10.] 
expected returns: [[36.991276]
 [35.277134]
 [35.277134]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 29.  8. 10. 10.  6.  9. 10.  5. 10.  9.  3. 10.  9.] 
adversary cards in hand: [ 1.  1.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0  0 15  0  4  1] -> size -> 11 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 28.388181686401367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[33.562134]
 [37.761574]
 [36.675888]
 [30.793726]
 [39.31001 ]
 [36.19625 ]
 [35.110565]
 [36.824703]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 28. 29.  8. 10. 10.  6.  9. 10.  5. 10.  9.  3. 10.  9.] 
adversary cards in hand: [ 1.  1.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0  0 15  0  4  1] -> size -> 11 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 36.991275787353516



buy possibilites: [-1] 
expected returns: [[76.77005]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10. 10.] 
cards in discard: [11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8. 10. 10.  5.  9. 10.  5. 10.  9.  3. 10.  9.] 
adversary cards in hand: [ 1.  1.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0  0 15  0  4  1] -> size -> 11 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 39.31000900268555






Player: 1 
cards in hand: [ 1.  1.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0  0 15  0  4  1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8. 10. 10.  5.  9. 10.  5. 10.  9.  3. 10.  9.] 
adversary cards in hand: [10.  3.  0.  3. 29.] 
adversary cards in discard: [11. 29.  3.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11] -> size -> 28 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  8  0 15  0  4  1] -> size -> 10 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 28. 29.  8. 10. 10.  5.  9. 10.  5. 10.  9.  3. 10.  9.] 
adversary cards in hand: [10.  3.  0.  3. 29.] 
adversary cards in discard: [11. 29.  3.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11] -> size -> 28 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  8  0 15  0  4  1] -> size -> 10 
action values: 0 
buys: 1 
player value: 7 
card supply: [26. 28. 30. 28. 29.  8. 10. 10.  5.  9. 10.  5. 10.  9.  3. 10.  9.] 
adversary cards in hand: [10.  3.  0.  3. 29.] 
adversary cards in discard: [11. 29.  3.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11] -> size -> 28 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  8  0 15  0  4  1 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 28. 30. 28. 29.  8. 10. 10.  5.  9. 10.  5. 10.  9.  2. 10.  9.] 
adversary cards in hand: [10.  3.  0.  3. 29.] 
adversary cards in discard: [11. 29.  3.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11] -> size -> 28 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[44.95683 ]
 [44.27885 ]
 [51.913406]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3. 29.] 
cards in discard: [11. 29.  3.  0.  0. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8. 10. 10.  5.  9. 10.  5. 10.  9.  2. 10.  9.] 
adversary cards in hand: [0. 4. 3. 3. 0.] 
adversary cards in discard: [10. 15.  1.  1.  3.] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10] -> size -> 11 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 76.77005004882812



action possibilites: [-1. 10. 11.] 
expected returns: [[49.38183 ]
 [47.198948]
 [53.721096]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3. 11.] 
cards in discard: [11. 29.  3.  0.  0. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 29.  8. 10. 10.  5.  9. 10.  5. 10.  9.  2. 10.  9.] 
adversary cards in hand: [0. 4. 3. 3. 0.] 
adversary cards in discard: [10. 15.  1.  1.  3.] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10] -> size -> 11 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 51.6371955871582



action possibilites: [-1] 
expected returns: [[24.110086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.] 
cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 29.  8. 10. 10.  5.  9. 10.  5. 10.  9.  1. 10.  9.] 
adversary cards in hand: [0. 4. 3. 3. 0.] 
adversary cards in discard: [10. 15.  1.  1.  3.] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10] -> size -> 11 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 55.42856979370117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[22.501923]
 [25.239561]
 [19.869873]
 [24.884119]
 [24.336426]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.] 
cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 29.  8. 10. 10.  5.  9. 10.  5. 10.  9.  1. 10.  9.] 
adversary cards in hand: [0. 4. 3. 3. 0.] 
adversary cards in discard: [10. 15.  1.  1.  3.] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10] -> size -> 11 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.11008644104004



buy possibilites: [-1] 
expected returns: [[17.596502]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.] 
cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8. 10. 10.  5.  9. 10.  5. 10.  9.  1. 10.  9.] 
adversary cards in hand: [0. 4. 3. 3. 0.] 
adversary cards in discard: [10. 15.  1.  1.  3.] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10] -> size -> 11 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 25.239561080932617






Player: 1 
cards in hand: [0. 4. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 3. 3. 0.] 
cards in discard: [10. 15.  1.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0 15  0  4  1 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8. 10. 10.  5.  9. 10.  5. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 11.  0.] 
adversary cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.  3. 29. 11. 10.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3] -> size -> 30 
adversary victory points: 6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 3. 3. 0.] 
cards in discard: [10. 15.  1.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0 15  0  4  1 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 27. 29.  8. 10. 10.  5.  9. 10.  5. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 11.  0.] 
adversary cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.  3. 29. 11. 10.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3] -> size -> 30 
adversary victory points: 6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 3. 3. 0.] 
cards in discard: [10. 15.  1.  1.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8. 10. 10.  5.  8. 10.  5. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 11.  0.] 
adversary cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.  3. 29. 11. 10.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3] -> size -> 30 
adversary victory points: 6
player victory points: 6 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[18.360495]
 [25.564745]
 [23.149405]
 [23.149405]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 11.  0.] 
cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.  3. 29. 11. 10.  3.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8. 10. 10.  5.  8. 10.  5. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8] -> size -> 12 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.59650230407715



action possibilites: [-1. 11. 11. 29.] 
expected returns: [[37.873257]
 [43.054455]
 [43.054455]
 [45.537354]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0. 29.] 
cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.  3. 29. 11. 10.  3.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 27. 29.  8. 10. 10.  5.  8. 10.  5. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8] -> size -> 12 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 25.15647315979004



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[51.197067]
 [57.749416]
 [57.749416]
 [50.414703]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0. 10.] 
cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.  3. 29. 11. 10.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 27. 29.  8. 10. 10.  5.  8. 10.  5. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8] -> size -> 12 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 45.537353515625



action possibilites: [-1] 
expected returns: [[30.19158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.] 
cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.  3. 29. 11. 10.  3.  0.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 27. 29.  8. 10. 10.  5.  8. 10.  5. 10.  9.  0. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8] -> size -> 12 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 59.752628326416016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[28.535355]
 [34.719685]
 [33.102524]
 [24.444195]
 [32.052227]
 [37.12792 ]
 [32.56074 ]
 [39.77384 ]
 [28.455473]
 [34.639805]
 [33.182198]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 10.] 
cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.  3. 29. 11. 10.  3.  0.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 27. 29.  8. 10. 10.  5.  8. 10.  5. 10.  9.  0. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8] -> size -> 12 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.191579818725586



buy possibilites: [-1] 
expected returns: [[50.01663]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 10.] 
cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.  3. 29. 11. 10.  3.  0.  3. 10. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8. 10. 10.  5.  8. 10.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8] -> size -> 12 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 183 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 39.773834228515625






Player: 1 
cards in hand: [ 3. 15.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  1.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8. 10. 10.  5.  8. 10.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [10.  0.  3. 29.  3.] 
adversary cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.  3. 29. 11. 10.  3.  0.  3. 10. 29. 29.
 29. 11.  0. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29] -> size -> 32 
adversary victory points: 6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  1.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 27. 29.  8. 10. 10.  5.  8. 10.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [10.  0.  3. 29.  3.] 
adversary cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.  3. 29. 11. 10.  3.  0.  3. 10. 29. 29.
 29. 11.  0. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29] -> size -> 32 
adversary victory points: 6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  1.  8.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8. 10. 10.  5.  8. 10.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [10.  0.  3. 29.  3.] 
adversary cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.  3. 29. 11. 10.  3.  0.  3. 10. 29. 29.
 29. 11.  0. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29] -> size -> 32 
adversary victory points: 6
player victory points: 6 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10.  0.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[44.60956 ]
 [41.725025]
 [47.99143 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 29.  3.] 
cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.  3. 29. 11. 10.  3.  0.  3. 10. 29. 29.
 29. 11.  0. 11.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8. 10. 10.  5.  8. 10.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [3. 4. 0. 1. 3.] 
adversary cards in discard: [ 1.  3. 15.  0.  1.  8.] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1] -> size -> 13 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.01662826538086



action possibilites: [-1. 10.] 
expected returns: [[25.336859]
 [22.350407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.  3. 29. 11. 10.  3.  0.  3. 10. 29. 29.
 29. 11.  0. 11.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 29.  8. 10. 10.  5.  8. 10.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [3. 4. 0. 1. 3.] 
adversary cards in discard: [ 1.  3. 15.  0.  1.  8.] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1] -> size -> 13 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 44.216434478759766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[20.257591]
 [24.387682]
 [23.236853]
 [17.902473]
 [26.180094]
 [22.685654]
 [24.739351]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.  3. 29. 11. 10.  3.  0.  3. 10. 29. 29.
 29. 11.  0. 11.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 27. 29.  8. 10. 10.  5.  8. 10.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [3. 4. 0. 1. 3.] 
adversary cards in discard: [ 1.  3. 15.  0.  1.  8.] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1] -> size -> 13 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 25.33685874938965



buy possibilites: [-1] 
expected returns: [[35.731205]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [11. 29.  3.  0.  0. 10. 10. 10.  3. 29. 11. 10.  3.  0.  3. 10. 29. 29.
 29. 11.  0. 11.  0. 10.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8. 10. 10.  4.  8. 10.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [3. 4. 0. 1. 3.] 
adversary cards in discard: [ 1.  3. 15.  0.  1.  8.] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1] -> size -> 13 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 26.180091857910156






Player: 1 
cards in hand: [3. 4. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 4. 0. 1. 3.] 
cards in discard: [ 1.  3. 15.  0.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8. 10. 10.  4.  8. 10.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [11. 11. 29. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11] -> size -> 33 
adversary victory points: 6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 4. 0. 1. 3.] 
cards in discard: [ 1.  3. 15.  0.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 27. 29.  8. 10. 10.  4.  8. 10.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [11. 11. 29. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11] -> size -> 33 
adversary victory points: 6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 4. 0. 1. 3.] 
cards in discard: [ 1.  3. 15.  0.  1.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  4.  8. 10.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [11. 11. 29. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11] -> size -> 33 
adversary victory points: 6
player victory points: 7 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11. 11. 29. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29. 11. 10.] 
expected returns: [[51.570686]
 [53.685913]
 [53.685913]
 [56.40461 ]
 [53.685913]
 [48.08986 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 29. 11. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  4.  8. 10.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [ 4. 15.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.731204986572266



action possibilites: [-1. 11. 11. 11. 10.] 
expected returns: [[38.306736]
 [40.159653]
 [40.159653]
 [40.159653]
 [35.838734]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 10.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  4.  8. 10.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [ 4. 15.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 50.424678802490234



action possibilites: [-1] 
expected returns: [[17.762758]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.] 
cards in discard: [ 0. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  4.  8. 10.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 4. 15.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 69 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 41.27571105957031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.424767]
 [13.800123]
 [18.691074]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 10.] 
cards in discard: [ 0. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  4.  8. 10.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 4. 15.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.762758255004883






Player: 1 
cards in hand: [ 4. 15.  3.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 15.  3.  8. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  4.  8. 10.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [10. 10.  3. 29.  0.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15] -> size -> 34 
adversary victory points: 6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 15.  3.  8. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  4.  8. 10.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [10. 10.  3. 29.  0.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15] -> size -> 34 
adversary victory points: 6
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [10. 10.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
expected returns: [[32.496166]
 [29.859661]
 [29.859661]
 [37.289303]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 29.  0.] 
cards in discard: [ 0. 15. 29. 11. 11. 11. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  4.  8. 10.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [1. 0. 1. 0. 1.] 
adversary cards in discard: [ 4. 15.  3.  8. 10.] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 18.691076278686523



action possibilites: [-1. 10. 10.] 
expected returns: [[43.01838 ]
 [41.119892]
 [41.119892]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  4.  8. 10.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [1. 0. 1. 0. 1.] 
adversary cards in discard: [ 4. 15.  3.  8. 10.] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 32.43830490112305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[37.621918]
 [42.26247 ]
 [41.061607]
 [34.57234 ]
 [44.017082]
 [40.57739 ]
 [41.27501 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  4.  8. 10.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [1. 0. 1. 0. 1.] 
adversary cards in discard: [ 4. 15.  3.  8. 10.] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 43.018375396728516



buy possibilites: [-1] 
expected returns: [[18.340654]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  3.  8. 10.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [1. 0. 1. 0. 1.] 
adversary cards in discard: [ 4. 15.  3.  8. 10.] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 44.0170783996582






Player: 1 
cards in hand: [1. 0. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 0. 1.] 
cards in discard: [ 4. 15.  3.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  3.  8. 10.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [29. 10.  0. 11.  3.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11] -> size -> 35 
adversary victory points: 6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0. 1.] 
cards in discard: [ 4. 15.  3.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 8 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  3.  8. 10.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [29. 10.  0. 11.  3.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11] -> size -> 35 
adversary victory points: 6
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [29. 10.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[5.5985785]
 [9.477713 ]
 [5.398526 ]
 [7.7696047]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0. 11.  3.] 
cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  3.  8. 10.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [10.  3.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.340654373168945



action possibilites: [-1. 11. 29.] 
expected returns: [[62.33021]
 [72.35289]
 [76.48993]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 29.] 
cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  3.  8. 10.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [10.  3.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 6.951546669006348



action possibilites: [-1. 11.] 
expected returns: [[80.883255]
 [89.033966]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.] 
cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0. 10. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  3.  8. 10.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [10.  3.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 68.18846130371094



action possibilites: [-1] 
expected returns: [[74.557556]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0. 10. 29. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  3.  8. 10.  4. 10.  9.  0. 10.  7.] 
adversary cards in hand: [10.  3.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 79 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 91.9344253540039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[69.915665]
 [78.28163 ]
 [76.04478 ]
 [64.386116]
 [81.495735]
 [75.36661 ]
 [75.048676]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0. 10. 29. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  3.  8. 10.  4. 10.  9.  0. 10.  7.] 
adversary cards in hand: [10.  3.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.55755615234375



buy possibilites: [-1] 
expected returns: [[74.2983]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0. 10. 29. 15. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0. 10.  7.] 
adversary cards in hand: [10.  3.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 81.49574279785156






Player: 1 
cards in hand: [10.  3.  8.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  3.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  8  0 15  0  4  1 10  8  1  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 10.  0. 10. 10.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0. 10. 29. 15. 11.
 29. 29. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11] -> size -> 37 
adversary victory points: 6
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  0 15  0  4  1  8  1  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 10.  0. 10. 10.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0. 10. 29. 15. 11.
 29. 29. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11] -> size -> 37 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  0 15  0  4  1  8  1  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 10.  0. 10. 10.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0. 10. 29. 15. 11.
 29. 29. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11] -> size -> 37 
adversary victory points: 6
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[73.59442]
 [71.30385]
 [71.30385]
 [71.30385]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10. 10.] 
cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0. 10. 29. 15. 11.
 29. 29. 11.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0. 10.  7.] 
adversary cards in hand: [15.  1.  0.  3.  8.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 1  8  0 15  0  4  1  8  1  3] -> size -> 10 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.29830169677734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[68.025665]
 [74.41094 ]
 [62.175903]
 [73.6969  ]
 [73.67421 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10. 10.] 
cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0. 10. 29. 15. 11.
 29. 29. 11.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 26. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0. 10.  7.] 
adversary cards in hand: [15.  1.  0.  3.  8.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 1  8  0 15  0  4  1  8  1  3] -> size -> 10 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 73.59440612792969



buy possibilites: [-1] 
expected returns: [[20.789122]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10. 10.] 
cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0. 10. 29. 15. 11.
 29. 29. 11.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0. 10.  7.] 
adversary cards in hand: [15.  1.  0.  3.  8.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 1  8  0 15  0  4  1  8  1  3] -> size -> 10 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0  90   0   0   0   0   0   0   0 -30   0   0  16   0] 
sum of rewards: 71 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 74.41094207763672






Player: 1 
cards in hand: [15.  1.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  0.  3.  8.] 
cards in discard: [8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  0 15  0  4  1  8  1  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0. 10.  7.] 
adversary cards in hand: [11.  3.  0.  3. 11.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0. 10. 29. 15. 11.
 29. 29. 11.  0.  3.  3.  0. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3] -> size -> 38 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0.  3.  8.] 
cards in discard: [8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  0 15  0  4  1  8  1  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0. 10.  7.] 
adversary cards in hand: [11.  3.  0.  3. 11.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0. 10. 29. 15. 11.
 29. 29. 11.  0.  3.  3.  0. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3] -> size -> 38 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0.  3.  8.] 
cards in discard: [8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  0 15  0  4  1  8  1  3  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0. 10.  7.] 
adversary cards in hand: [11.  3.  0.  3. 11.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0. 10. 29. 15. 11.
 29. 29. 11.  0.  3.  3.  0. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3] -> size -> 38 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[57.213505]
 [58.810024]
 [58.810024]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3. 11.] 
cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0. 10. 29. 15. 11.
 29. 29. 11.  0.  3.  3.  0. 10.  0. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0. 10.  7.] 
adversary cards in hand: [8. 0. 1. 1. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  0 15  0  4  1  8  1  3  0] -> size -> 11 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.789121627807617



action possibilites: [-1] 
expected returns: [[57.68001]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.] 
cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0. 10. 29. 15. 11.
 29. 29. 11.  0.  3.  3.  0. 10.  0. 10. 10. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0. 10.  6.] 
adversary cards in hand: [8. 0. 1. 1. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  0 15  0  4  1  8  1  3  0] -> size -> 11 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 129 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 59.96604537963867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[52.02243 ]
 [48.725063]
 [57.68002 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.] 
cards in discard: [ 0. 15. 29. 11. 11. 11. 10.  3. 11. 29. 10. 10.  0.  0. 10. 29. 15. 11.
 29. 29. 11.  0.  3.  3.  0. 10.  0. 10. 10. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0. 10.  6.] 
adversary cards in hand: [8. 0. 1. 1. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  0 15  0  4  1  8  1  3  0] -> size -> 11 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.68001174926758






Player: 1 
cards in hand: [8. 0. 1. 1. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 1. 4.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  0 15  0  4  1  8  1  3  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0. 10.  6.] 
adversary cards in hand: [11.  3. 29. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15] -> size -> 39 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 1. 4.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  0 15  0  4  1  8  1  3  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0. 10.  6.] 
adversary cards in hand: [11.  3. 29. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15] -> size -> 39 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 1. 4.] 
cards in discard: [22.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  0 15  0  4  1  8  1  3  0 22] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  6.] 
adversary cards in hand: [11.  3. 29. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15] -> size -> 39 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11.  3. 29. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[32.289593]
 [34.142513]
 [36.1716  ]
 [29.821592]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29. 10.  3.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  6.] 
adversary cards in hand: [15.  0.  8.  3.  0.] 
adversary cards in discard: [22.  8.  0.  1.  1.  4.] 
adversary owned cards: [ 1  8  0 15  0  4  1  8  1  3  0 22] -> size -> 12 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 57.68001174926758



action possibilites: [-1. 11. 10.] 
expected returns: [[33.390263]
 [35.243183]
 [30.922262]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  3.] 
cards in discard: [3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  6.] 
adversary cards in hand: [15.  0.  8.  3.  0.] 
adversary cards in discard: [22.  8.  0.  1.  1.  4.] 
adversary owned cards: [ 1  8  0 15  0  4  1  8  1  3  0 22] -> size -> 12 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 31.19223976135254



action possibilites: [-1] 
expected returns: [[38.600037]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.] 
cards in discard: [ 3. 15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  5.] 
adversary cards in hand: [15.  0.  8.  3.  0.] 
adversary cards in discard: [22.  8.  0.  1.  1.  4.] 
adversary owned cards: [ 1  8  0 15  0  4  1  8  1  3  0 22] -> size -> 12 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -50   0   0  64   0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 36.32640838623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.254063]
 [30.450235]
 [38.403996]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.] 
cards in discard: [ 3. 15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  5.] 
adversary cards in hand: [15.  0.  8.  3.  0.] 
adversary cards in discard: [22.  8.  0.  1.  1.  4.] 
adversary owned cards: [ 1  8  0 15  0  4  1  8  1  3  0 22] -> size -> 12 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.60003662109375






Player: 1 
cards in hand: [15.  0.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8.  3.  0.] 
cards in discard: [22.  8.  0.  1.  1.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  0 15  0  4  1  8  1  3  0 22] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  5.] 
adversary cards in hand: [ 3. 10.  0. 15. 11.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15] -> size -> 40 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0.] 
cards in discard: [22.  8.  0.  1.  1.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  5.] 
adversary cards in hand: [ 3. 10.  0. 15. 11.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15] -> size -> 40 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0.] 
cards in discard: [22.  8.  0.  1.  1.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  5.] 
adversary cards in hand: [ 3. 10.  0. 15. 11.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15] -> size -> 40 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0.] 
cards in discard: [22.  8.  0.  1.  1.  4.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  5.] 
adversary cards in hand: [ 3. 10.  0. 15. 11.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15] -> size -> 40 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11.] 
expected returns: [[42.149017]
 [40.098858]
 [43.08751 ]
 [45.275036]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 15. 11.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  5.] 
adversary cards in hand: [ 8.  4. 22.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0] -> size -> 12 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 38.403995513916016



action possibilites: [-1] 
expected returns: [[41.826878]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 15.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  4.] 
adversary cards in hand: [ 8.  4. 22.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0] -> size -> 12 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -60   0   0  64   0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 46.688289642333984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[39.372303]
 [35.205265]
 [42.073826]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 15.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  4.] 
adversary cards in hand: [ 8.  4. 22.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0] -> size -> 12 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.82687759399414






Player: 1 
cards in hand: [ 8.  4. 22.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  4. 22.  8.  1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  4.] 
adversary cards in hand: [11. 11. 10.  0. 11.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15] -> size -> 41 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 4. 8. 1. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  4.] 
adversary cards in hand: [11. 11. 10.  0. 11.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15] -> size -> 41 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 4. 8. 1. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 27. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  4.] 
adversary cards in hand: [11. 11. 10.  0. 11.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15] -> size -> 41 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 4. 8. 1. 0. 1. 3.] 
cards in discard: [1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  4.] 
adversary cards in hand: [11. 11. 10.  0. 11.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15] -> size -> 41 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [11. 11. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10. 11.] 
expected returns: [[19.838451]
 [23.4625  ]
 [23.4625  ]
 [18.485596]
 [23.4625  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.  0. 11.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  4.] 
adversary cards in hand: [ 8.  1.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 42.07381820678711



action possibilites: [-1] 
expected returns: [[57.98856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 11.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  3.] 
adversary cards in hand: [ 8.  1.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -70   0   0  64   0] 
sum of rewards: 99 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 25.054723739624023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[55.694744]
 [50.674988]
 [59.278805]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0. 11.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  3.] 
adversary cards in hand: [ 8.  1.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.98855972290039






Player: 1 
cards in hand: [ 8.  1.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  3.] 
adversary cards in hand: [29. 10. 11.  0. 10.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15] -> size -> 42 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  3.] 
adversary cards in hand: [29. 10. 11.  0. 10.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15] -> size -> 42 
adversary victory points: 7
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [29. 10. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 10.] 
expected returns: [[14.283885]
 [18.898695]
 [13.589329]
 [17.336716]
 [13.589329]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11.  0. 10.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  3.] 
adversary cards in hand: [ 1. 22.  0.  4.  8.] 
adversary cards in discard: [ 8.  1.  0.  0. 15.] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 59.278812408447266



action possibilites: [-1. 10. 11. 10.] 
expected returns: [[72.94737 ]
 [73.61046 ]
 [82.529465]
 [73.61046 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  0.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  3.] 
adversary cards in hand: [ 1. 22.  0.  4.  8.] 
adversary cards in discard: [ 8.  1.  0.  0. 15.] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 15.976297378540039



action possibilites: [-1] 
expected returns: [[26.541185]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  2.] 
adversary cards in hand: [ 1. 22.  0.  4.  8.] 
adversary cards in discard: [ 8.  1.  0.  0. 15.] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -80   0   0  64   0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 85.03788757324219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[22.67603 ]
 [28.078993]
 [17.37897 ]
 [27.555822]
 [25.77138 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 25. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  2.] 
adversary cards in hand: [ 1. 22.  0.  4.  8.] 
adversary cards in discard: [ 8.  1.  0.  0. 15.] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.54118537902832



buy possibilites: [-1] 
expected returns: [[16.570961]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  2.] 
adversary cards in hand: [ 1. 22.  0.  4.  8.] 
adversary cards in discard: [ 8.  1.  0.  0. 15.] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -90   0   0  16   0] 
sum of rewards: 81 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 28.0789794921875






Player: 1 
cards in hand: [ 1. 22.  0.  4.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 22.  0.  4.  8.] 
cards in discard: [ 8.  1.  0.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  2.] 
adversary cards in hand: [ 0. 15.  3.  0.  0.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3] -> size -> 44 
adversary victory points: 8
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 22.  0.  4.  8.] 
cards in discard: [ 8.  1.  0.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 24. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  2.] 
adversary cards in hand: [ 0. 15.  3.  0.  0.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3] -> size -> 44 
adversary victory points: 8
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[86.18154]
 [88.82704]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0.  0.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29
 10  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  2.] 
adversary cards in hand: [0. 8. 1. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.570960998535156



action possibilites: [-1] 
expected returns: [[13.305054]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 24. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  2.] 
adversary cards in hand: [0. 8. 1. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 88.82705688476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ 9.71064  ]
 [12.895218 ]
 [12.100909 ]
 [ 8.619159 ]
 [ 7.9236746]
 [11.705743 ]
 [14.1285925]
 [11.648566 ]
 [17.007767 ]
 [15.774654 ]
 [ 9.697335 ]
 [12.9526615]
 [ 9.769445 ]
 [12.895483 ]
 [13.305047 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 24. 29.  8. 10. 10.  2.  8. 10.  4. 10.  9.  0.  9.  2.] 
adversary cards in hand: [0. 8. 1. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.3050537109375



buy possibilites: [-1] 
expected returns: [[21.664679]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 29.  8. 10. 10.  2.  8.  9.  4. 10.  9.  0.  9.  2.] 
adversary cards in hand: [0. 8. 1. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -90   0   0 250   0] 
sum of rewards: 295 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 17.007766723632812






Player: 1 
cards in hand: [0. 8. 1. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 3. 1.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 29.  8. 10. 10.  2.  8.  9.  4. 10.  9.  0.  9.  2.] 
adversary cards in hand: [29.  3. 29. 29. 10.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0. 25. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25] -> size -> 44 
adversary victory points: 8
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 3. 1.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 24. 29.  8. 10. 10.  2.  8.  9.  4. 10.  9.  0.  9.  2.] 
adversary cards in hand: [29.  3. 29. 29. 10.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0. 25. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25] -> size -> 44 
adversary victory points: 8
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 3. 1.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 24. 29.  8. 10. 10.  1.  8.  9.  4. 10.  9.  0.  9.  2.] 
adversary cards in hand: [29.  3. 29. 29. 10.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0. 25. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25] -> size -> 44 
adversary victory points: 8
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [29.  3. 29. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 10.] 
expected returns: [[34.331234]
 [45.298565]
 [45.298565]
 [45.298565]
 [34.55019 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29. 29. 10.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0. 25. 15.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 29.  8. 10. 10.  1.  8.  9.  4. 10.  9.  0.  9.  2.] 
adversary cards in hand: [ 8. 22.  4.  1.  0.] 
adversary cards in discard: [11.  0.  8.  1.  3.  1.] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11] -> size -> 14 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.6646785736084



action possibilites: [-1. 29. 10. 11.] 
expected returns: [[59.592106]
 [68.472275]
 [58.63222 ]
 [65.55304 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10. 11.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0. 25. 15.  3.  0.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 24. 29.  8. 10. 10.  1.  8.  9.  4. 10.  9.  0.  9.  2.] 
adversary cards in hand: [ 8. 22.  4.  1.  0.] 
adversary cards in discard: [11.  0.  8.  1.  3.  1.] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11] -> size -> 14 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 39.159610748291016



action possibilites: [-1. 10. 11. 10.] 
expected returns: [[52.747715]
 [53.03101 ]
 [60.3414  ]
 [53.03101 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0. 25. 15.  3.  0.  0. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25] -> size -> 44 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 24. 29.  8. 10. 10.  1.  8.  9.  4. 10.  9.  0.  9.  2.] 
adversary cards in hand: [ 8. 22.  4.  1.  0.] 
adversary cards in discard: [11.  0.  8.  1.  3.  1.] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11] -> size -> 14 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 62.76430130004883



action possibilites: [-1] 
expected returns: [[56.008244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0. 25. 15.  3.  0.  0. 29.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 24. 29.  8. 10. 10.  1.  8.  9.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 8. 22.  4.  1.  0.] 
adversary cards in discard: [11.  0.  8.  1.  3.  1.] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11] -> size -> 14 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  120    0    0   60    0    0    0    0 -100    0    0
   64    0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 62.38349533081055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[53.34996 ]
 [58.300148]
 [48.838856]
 [57.766037]
 [56.00824 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0. 25. 15.  3.  0.  0. 29.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 24. 29.  8. 10. 10.  1.  8.  9.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 8. 22.  4.  1.  0.] 
adversary cards in discard: [11.  0.  8.  1.  3.  1.] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11] -> size -> 14 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.008243560791016



buy possibilites: [-1] 
expected returns: [[40.493366]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0. 25. 15.  3.  0.  0. 29.  3. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 29.  8. 10. 10.  1.  8.  9.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 8. 22.  4.  1.  0.] 
adversary cards in discard: [11.  0.  8.  1.  3.  1.] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11] -> size -> 14 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  150    0    0   60    0    0    0    0 -110    0    0
   16    0] 
sum of rewards: 111 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 58.30015182495117






Player: 1 
cards in hand: [ 8. 22.  4.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22.  4.  1.  0.] 
cards in discard: [11.  0.  8.  1.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 29.  8. 10. 10.  1.  8.  9.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [29. 15. 11.  3. 10.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0. 25. 15.  3.  0.  0. 29.  3. 15.  3.
 29. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3] -> size -> 46 
adversary victory points: 9
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  4.  1.  0. 15.  0.  1.] 
cards in discard: [11.  0.  8.  1.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 29.  8. 10. 10.  1.  8.  9.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [29. 15. 11.  3. 10.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0. 25. 15.  3.  0.  0. 29.  3. 15.  3.
 29. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3] -> size -> 46 
adversary victory points: 9
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  4.  1.  0. 15.  0.  1.] 
cards in discard: [11.  0.  8.  1.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 26. 30. 23. 29.  8. 10. 10.  1.  8.  9.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [29. 15. 11.  3. 10.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0. 25. 15.  3.  0.  0. 29.  3. 15.  3.
 29. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3] -> size -> 46 
adversary victory points: 9
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  4.  1.  0. 15.  0.  1.] 
cards in discard: [11.  0.  8.  1.  3.  1. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 23. 29.  8. 10. 10.  0.  8.  9.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [29. 15. 11.  3. 10.] 
adversary cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0. 25. 15.  3.  0.  0. 29.  3. 15.  3.
 29. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3] -> size -> 46 
adversary victory points: 9
player victory points: 4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [29. 15. 11.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 11. 10.] 
expected returns: [[38.123486]
 [45.72805 ]
 [40.482994]
 [43.118958]
 [36.75329 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 11.  3. 10.] 
cards in discard: [ 3. 15. 29. 11. 10.  3.  3. 15. 11.  3. 10.  0. 15. 15. 11. 11. 10.  0.
 11.  0. 15.  3. 29. 11. 10. 10.  0. 25. 15.  3.  0.  0. 29.  3. 15.  3.
 29. 29. 11. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 29.  8. 10. 10.  0.  8.  9.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 0.  3. 11.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11 11] -> size -> 15 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.49336624145508



action possibilites: [-1. 15. 11.] 
expected returns: [[46.72508 ]
 [46.226025]
 [48.141888]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 11.] 
cards in discard: [10. 11.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 23. 29.  8. 10. 10.  0.  8.  9.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 0.  3. 11.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11 11] -> size -> 15 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 40.70597457885742



action possibilites: [-1] 
expected returns: [[27.81429]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.] 
cards in discard: [10. 11.  1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 23. 29.  8. 10. 10.  0.  8.  9.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 0.  3. 11.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11 11] -> size -> 15 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  150    0    0   40    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: 92 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 46.14064407348633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.065538]
 [21.15563 ]
 [27.208273]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.] 
cards in discard: [10. 11.  1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 23. 29.  8. 10. 10.  0.  8.  9.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 0.  3. 11.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11 11] -> size -> 15 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.814289093017578






Player: 1 
cards in hand: [ 0.  3. 11.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  1.  1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 29.  8. 10. 10.  0.  8.  9.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [11. 15. 29. 15.  0.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1] -> size -> 47 
adversary victory points: 9
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  1.  1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 25. 30. 23. 29.  8. 10. 10.  0.  8.  9.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [11. 15. 29. 15.  0.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1] -> size -> 47 
adversary victory points: 9
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  1.  1.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11 11 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 29.  8. 10. 10.  0.  8.  8.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [11. 15. 29. 15.  0.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1] -> size -> 47 
adversary victory points: 9
player victory points: 4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11. 15. 29. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 29. 15.] 
expected returns: [[51.777554]
 [57.013767]
 [54.885887]
 [58.828114]
 [54.885887]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 29. 15.  0.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 29.  8. 10. 10.  0.  8.  8.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 8.  1. 11.  0.  4.] 
adversary cards in discard: [25.  0.  3. 11.  1.  1.] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11 11 25] -> size -> 16 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 27.20827293395996



action possibilites: [-1. 15. 15.] 
expected returns: [[42.327038]
 [45.49905 ]
 [45.49905 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  0.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10
  3 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 23. 29.  8. 10. 10.  0.  8.  8.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 8.  1. 11.  0.  4.] 
adversary cards in discard: [25.  0.  3. 11.  1.  1.] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11 11 25] -> size -> 16 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 55.28950119018555



action possibilites: [-1] 
expected returns: [[29.37736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 25. 30. 23. 29.  8. 10. 10.  0.  8.  8.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 8.  1. 11.  0.  4.] 
adversary cards in discard: [25.  0.  3. 11.  1.  1.] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11 11 25] -> size -> 16 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 45.49905014038086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[25.473309]
 [29.107847]
 [28.197983]
 [23.162922]
 [27.705198]
 [27.74617 ]
 [32.54919 ]
 [25.428194]
 [29.062733]
 [28.966822]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 25. 30. 23. 29.  8. 10. 10.  0.  8.  8.  4. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 8.  1. 11.  0.  4.] 
adversary cards in discard: [25.  0.  3. 11.  1.  1.] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11 11 25] -> size -> 16 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.37735939025879



buy possibilites: [-1] 
expected returns: [[53.523643]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 8.  1. 11.  0.  4.] 
adversary cards in discard: [25.  0.  3. 11.  1.  1.] 
adversary owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11 11 25] -> size -> 16 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  150    0    0   40    0    0    0    0 -120    0    0
  128    0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 32.54918670654297






Player: 1 
cards in hand: [ 8.  1. 11.  0.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 11.  0.  4.] 
cards in discard: [25.  0.  3. 11.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 15  0  4  1  8  1  3  0 22  0  1 11 11 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  9.  0.  9.  1.] 
adversary cards in hand: [10.  3. 10. 11.  3.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29] -> size -> 47 
adversary victory points: 9
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [25.  0.  3. 11.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 15  0  1  8  1  3  0 22  0  1 11 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  9.  0.  9.  1.] 
adversary cards in hand: [10.  3. 10. 11.  3.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29] -> size -> 47 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [25.  0.  3. 11.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 15  0  1  8  1  3  0 22  0  1 11 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  9.  0.  9.  1.] 
adversary cards in hand: [10.  3. 10. 11.  3.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29] -> size -> 47 
adversary victory points: 9
player victory points: 1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [10.  3. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[10.557148]
 [10.255037]
 [10.255037]
 [13.307392]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 11.  3.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 0.  1.  8. 22. 15.] 
adversary cards in discard: [25.  0.  3. 11.  1.  1.  8.  1.  0.] 
adversary owned cards: [ 1  8 15  0  1  8  1  3  0 22  0  1 11 25] -> size -> 14 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.523643493652344



action possibilites: [-1] 
expected returns: [[19.389967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  3.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 0.  1.  8. 22. 15.] 
adversary cards in discard: [25.  0.  3. 11.  1.  1.  8.  1.  0.] 
adversary owned cards: [ 1  8 15  0  1  8  1  3  0 22  0  1 11 25] -> size -> 14 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -130    0    0
   27    0] 
sum of rewards: 152 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 12.237800598144531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.766256]
 [14.299204]
 [19.174377]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  3.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 24. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 0.  1.  8. 22. 15.] 
adversary cards in discard: [25.  0.  3. 11.  1.  1.  8.  1.  0.] 
adversary owned cards: [ 1  8 15  0  1  8  1  3  0 22  0  1 11 25] -> size -> 14 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.38996696472168






Player: 1 
cards in hand: [ 0.  1.  8. 22. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8. 22. 15.] 
cards in discard: [25.  0.  3. 11.  1.  1.  8.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 15  0  1  8  1  3  0 22  0  1 11 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 0. 11. 15. 29. 11.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1] -> size -> 48 
adversary victory points: 9
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.] 
cards in discard: [25.  0.  3. 11.  1.  1.  8.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  8  1  3  0 22  0  1 11 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 0. 11. 15. 29. 11.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1] -> size -> 48 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.] 
cards in discard: [25.  0.  3. 11.  1.  1.  8.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  8  1  3  0 22  0  1 11 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 24. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 0. 11. 15. 29. 11.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1] -> size -> 48 
adversary victory points: 9
player victory points: 1 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 15. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 29. 11.] 
expected returns: [[80.49231]
 [89.05919]
 [85.70075]
 [91.75766]
 [89.05919]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15. 29. 11.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  9.  0.  9.  1.] 
adversary cards in hand: [22.  3.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  1  3  0 22  0  1 11 25] -> size -> 11 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 19.174379348754883



action possibilites: [-1. 11. 15. 11.] 
expected returns: [[ 94.69983 ]
 [102.632095]
 [ 98.79732 ]
 [102.632095]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 11.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 24. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  9.  0.  9.  1.] 
adversary cards in hand: [22.  3.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  1  3  0 22  0  1 11 25] -> size -> 11 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 86.20294952392578



action possibilites: [-1] 
expected returns: [[166.12474]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 23. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  9.  0.  9.  1.] 
adversary cards in hand: [22.  3.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  1  3  0 22  0  1 11 25] -> size -> 11 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  240    0    0   40    0    0    0    0 -140    0    0
   27    0] 
sum of rewards: 162 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 99.11611938476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[162.4081 ]
 [157.26787]
 [166.12471]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 23. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  9.  0.  9.  1.] 
adversary cards in hand: [22.  3.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  1  3  0 22  0  1 11 25] -> size -> 11 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 166.12474060058594






Player: 1 
cards in hand: [22.  3.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  1  3  0 22  0  1 11 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 3. 15.  0. 10. 15.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1
  1] -> size -> 49 
adversary victory points: 9
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  1.  1.  8.  1.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [22. 25.  8.] 
owned cards: [ 8  1  8  1  3  0 22  0  1 11 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 3. 15.  0. 10. 15.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1
  1] -> size -> 49 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  1.  1.  8.  1.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [22. 25.  8.] 
owned cards: [ 8  1  8  1  3  0 22  0  1 11 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 7 
card supply: [24. 23. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  9.  0.  9.  1.] 
adversary cards in hand: [ 3. 15.  0. 10. 15.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1
  1] -> size -> 49 
adversary victory points: 9
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  1.  1.  8.  1.] 
cards in discard: [23.] 
cards in deck: 1 
card top of deck: [] 
played cards: [22. 25.  8.] 
owned cards: [ 8  1  8  1  3  0 22  0  1 11 25 23] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 23. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [ 3. 15.  0. 10. 15.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1
  1] -> size -> 49 
adversary victory points: 9
player victory points: 1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 15.] 
expected returns: [[-0.5919978 ]
 [ 1.8522866 ]
 [-0.09170389]
 [ 1.8522866 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0. 10. 15.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3
 10 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [ 8. 23. 22.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  1  3  0 22  0  1 11 25 23] -> size -> 12 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 166.12474060058594



action possibilites: [-1] 
expected returns: [[16.44006]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 23. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [ 8. 23. 22.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  1  3  0 22  0  1 11 25 23] -> size -> 12 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 1.8522894382476807





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[13.328012]
 [15.876617]
 [15.268917]
 [11.781403]
 [14.891094]
 [16.440063]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 15.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 23. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [ 8. 23. 22.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  1  3  0 22  0  1 11 25 23] -> size -> 12 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.440059661865234






Player: 1 
cards in hand: [ 8. 23. 22.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23. 22.  1.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  1  3  0 22  0  1 11 25 23] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [ 3. 29.  0. 10. 15.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11. 15.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1] -> size -> 48 
adversary victory points: 9
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  3  0  0  1 11 25] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [ 3. 29.  0. 10. 15.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11. 15.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1] -> size -> 48 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  3  0  0  1 11 25] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 23. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [ 3. 29.  0. 10. 15.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11. 15.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1] -> size -> 48 
adversary victory points: 9
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  3  0  0  1 11 25  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [ 3. 29.  0. 10. 15.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11. 15.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1] -> size -> 48 
adversary victory points: 9
player victory points: 1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 15.] 
expected returns: [[39.687946]
 [45.492702]
 [38.76354 ]
 [41.53989 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 10. 15.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11. 15.  3. 10. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [ 1.  8.  3. 25. 11.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 8  8  1  3  0  0  1 11 25  0] -> size -> 10 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 16.440059661865234



action possibilites: [-1. 10. 25.] 
expected returns: [[ 89.614075]
 [ 89.185844]
 [101.069016]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 25.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11. 15.  3. 10. 15.  3. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 23. 29.  8. 10. 10.  0.  8.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [ 1.  8.  3. 25. 11.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 8  8  1  3  0  0  1 11 25  0] -> size -> 10 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 44.81150436401367



action possibilites: [-1] 
expected returns: [[30.867579]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  3.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11. 15.  3. 10. 15.  3. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 23. 29.  8.  9. 10.  0.  8.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [ 1.  8.  3. 25. 11.] 
adversary cards in discard: [0. 8. 0. 6.] 
adversary owned cards: [ 8  8  1  3  0  0  1 11 25  0  6] -> size -> 11 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 101.06900024414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.759914]
 [31.315077]
 [24.770306]
 [30.840014]
 [30.867579]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 29.  3.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11. 15.  3. 10. 15.  3. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 23. 30. 23. 29.  8.  9. 10.  0.  8.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [ 1.  8.  3. 25. 11.] 
adversary cards in discard: [0. 8. 0. 6.] 
adversary owned cards: [ 8  8  1  3  0  0  1 11 25  0  6] -> size -> 11 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.867578506469727



buy possibilites: [-1] 
expected returns: [[32.60849]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 29.  3.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11. 15.  3. 10. 15.  3. 15.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 29.  8.  9. 10.  0.  8.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [ 1.  8.  3. 25. 11.] 
adversary cards in discard: [0. 8. 0. 6.] 
adversary owned cards: [ 8  8  1  3  0  0  1 11 25  0  6] -> size -> 11 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -140    0    0
   16    0] 
sum of rewards: 181 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 31.3150691986084






Player: 1 
cards in hand: [ 1.  8.  3. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  3. 25. 11.] 
cards in discard: [0. 8. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  3  0  0  1 11 25  0  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 29.  8.  9. 10.  0.  8.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [10. 10.  0.  3. 29.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11. 15.  3. 10. 15.  3. 15.  3. 29. 25.  0.
 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1
  3] -> size -> 49 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.] 
cards in discard: [0. 8. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  0  0  1 25  0  6] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 29.  8.  9. 10.  0.  8.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [10. 10.  0.  3. 29.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11. 15.  3. 10. 15.  3. 15.  3. 29. 25.  0.
 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1
  3] -> size -> 49 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.] 
cards in discard: [0. 8. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  0  0  1 25  0  6] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 23. 30. 22. 29.  8.  9. 10.  0.  8.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [10. 10.  0.  3. 29.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11. 15.  3. 10. 15.  3. 15.  3. 29. 25.  0.
 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1
  3] -> size -> 49 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.] 
cards in discard: [0. 8. 0. 6. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  0  0  1 25  0  6  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 29.  8.  9. 10.  0.  7.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [10. 10.  0.  3. 29.] 
adversary cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11. 15.  3. 10. 15.  3. 15.  3. 29. 25.  0.
 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1
  3] -> size -> 49 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [10. 10.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
expected returns: [[101.26721 ]
 [101.564415]
 [101.564415]
 [114.27911 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  3. 29.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11. 15.  3. 10. 15.  3. 15.  3. 29. 25.  0.
 10. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 29.  8.  9. 10.  0.  7.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [8. 1. 8. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8] -> size -> 10 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.608489990234375



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[115.011314]
 [114.84068 ]
 [114.84068 ]
 [122.94997 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11. 15.  3. 10. 15.  3. 15.  3. 29. 25.  0.
 10. 29.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 22. 29.  8.  9. 10.  0.  7.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [8. 1. 8. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8] -> size -> 10 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 106.20541381835938



action possibilites: [-1] 
expected returns: [[190.19637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11. 15.  3. 10. 15.  3. 15.  3. 29. 25.  0.
 10. 29.  3.  0.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1
  3  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 22. 30. 22. 29.  8.  9. 10.  0.  7.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [8. 1. 8. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8] -> size -> 10 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0   40    0    0    0    0 -150    0    0
   27    0] 
sum of rewards: 242 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 119.81632995605469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[185.80196]
 [178.0504 ]
 [190.19638]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [10. 11.  1. 29. 11. 15.  3. 11.  0. 29. 29. 15. 15.  1. 11. 10.  3. 10.
  3.  0.  3.  1. 29. 11. 15. 11. 15.  3. 10. 15.  3. 15.  3. 29. 25.  0.
 10. 29.  3.  0.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1
  3  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 22. 30. 22. 29.  8.  9. 10.  0.  7.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [8. 1. 8. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8] -> size -> 10 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: 190.1963653564453






Player: 1 
cards in hand: [8. 1. 8. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 8. 0. 1.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  0  0  1 25  0  6  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 22. 29.  8.  9. 10.  0.  7.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [29.  3. 15. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1
  3  1] -> size -> 50 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 8. 0. 1.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  0  0  1 25  0  6  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 22. 30. 22. 29.  8.  9. 10.  0.  7.  8.  3. 10.  8.  0.  9.  1.] 
adversary cards in hand: [29.  3. 15. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1
  3  1] -> size -> 50 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 8. 0. 1.] 
cards in discard: [22.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  0  0  1 25  0  6  8 22] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 22. 29.  8.  9. 10.  0.  7.  8.  3. 10.  8.  0.  8.  1.] 
adversary cards in hand: [29.  3. 15. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1
  3  1] -> size -> 50 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [29.  3. 15. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 11. 10.] 
expected returns: [[21.94674 ]
 [26.829659]
 [22.726158]
 [24.654041]
 [19.779121]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 15. 11. 10.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1
  3  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 22. 29.  8.  9. 10.  0.  7.  8.  3. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 6.  0. 25.  8.  0.] 
adversary cards in discard: [22.  8.  1.  8.  0.  1.] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8 22] -> size -> 11 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 190.1963653564453



action possibilites: [-1. 15. 10.] 
expected returns: [[19.53765]
 [19.68813]
 [17.32918]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.] 
cards in discard: [ 3. 11.] 
cards in deck: 44 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10
 11 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1
  3  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 22. 30. 22. 29.  8.  9. 10.  0.  7.  8.  3. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 6.  0. 25.  8.  0.] 
adversary cards in discard: [22.  8.  1.  8.  0.  1.] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8 22] -> size -> 11 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 25.90610694885254



action possibilites: [-1] 
expected returns: [[-4.3012667]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 3. 11.] 
cards in deck: 44 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11
 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 22. 30. 22. 29.  8.  9. 10.  0.  7.  8.  3. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 6.  0. 25.  8.  0.] 
adversary cards in discard: [22.  8.  1.  8.  0.  1.] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8 22] -> size -> 11 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 19.68812370300293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[-4.3012667]
 [-4.3012667]
 [-4.3012667]
 [-4.3012667]
 [-4.3012667]
 [-4.3012667]
 [-4.3012667]
 [-4.3012667]
 [-4.3012667]
 [-4.3012667]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 3. 11.] 
cards in deck: 44 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11
 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 22. 30. 22. 29.  8.  9. 10.  0.  7.  8.  3. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 6.  0. 25.  8.  0.] 
adversary cards in discard: [22.  8.  1.  8.  0.  1.] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8 22] -> size -> 11 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: -4.301266670227051



buy possibilites: [-1] 
expected returns: [[23.201172]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 3. 11.  0.] 
cards in deck: 44 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11
 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3
  1  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 4 
card supply: [22. 22. 30. 22. 29.  8.  9. 10.  0.  7.  8.  3. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 6.  0. 25.  8.  0.] 
adversary cards in discard: [22.  8.  1.  8.  0.  1.] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8 22] -> size -> 11 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5.    0.    0.  330.    0.    0.   40.    0.    0.    0.    0. -150.
    0.    0.    0.    0.] 
sum of rewards: 215.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -4.301266670227051






Player: 1 
cards in hand: [ 6.  0. 25.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 25.  8.  0.] 
cards in discard: [22.  8.  1.  8.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  0  0  1 25  0  6  8 22] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 29.  8.  9. 10.  0.  7.  8.  3. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0. 10.  1.  0. 10.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11
 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3
  1  0] -> size -> 50 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 25.  8.  0.] 
cards in discard: [22.  8.  1.  8.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  0  0  1 25  0  6  8 22] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 22. 30. 22. 29.  8.  9. 10.  0.  7.  8.  3. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0. 10.  1.  0. 10.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11
 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3
  1  0] -> size -> 50 
adversary victory points: 10
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[38.37792]
 [37.0086 ]
 [37.0086 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  0. 10.] 
cards in discard: [ 3. 11.  0. 29. 15. 10.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11
 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3
  1  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 29.  8.  9. 10.  0.  7.  8.  3. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 6.  0.  0.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8 22] -> size -> 11 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.201171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[35.774837]
 [39.328907]
 [38.381886]
 [33.973755]
 [37.841156]
 [37.964684]
 [42.29162 ]
 [35.684418]
 [39.188328]
 [38.386986]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  0. 10.] 
cards in discard: [ 3. 11.  0. 29. 15. 10.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11
 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3
  1  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 22. 30. 22. 29.  8.  9. 10.  0.  7.  8.  3. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 6.  0.  0.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8 22] -> size -> 11 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 38.3779296875



buy possibilites: [-1] 
expected returns: [[21.361668]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  0. 10.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11
 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3
  1  0 29] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 29.  8.  9. 10.  0.  7.  8.  2. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 6.  0.  0.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8 22] -> size -> 11 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0    0    0    0    0    0 -160    0    0
  128    0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 42.291622161865234






Player: 1 
cards in hand: [ 6.  0.  0.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  1. 25.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  0  0  1 25  0  6  8 22] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 29.  8.  9. 10.  0.  7.  8.  2. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 29. 11. 15.  0.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11
 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3
  1  0 29] -> size -> 51 
adversary victory points: 10
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 1. 8. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  8  1  0  0  1 25  0  6  8 22] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 29.  8.  8. 10.  0.  7.  8.  2. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 29. 11. 15.  0.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11
 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3
  1  0 29  6] -> size -> 52 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 8. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  8  1  0  0  1 25  0  6  8 22] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 22. 30. 22. 29.  8.  8. 10.  0.  7.  8.  2. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 29. 11. 15.  0.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11
 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3
  1  0 29  6] -> size -> 52 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 8. 0.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  8  1  0  0  1 25  0  6  8 22  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 5 
card supply: [21. 22. 30. 22. 29.  8.  8. 10.  0.  7.  8.  2. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 29. 11. 15.  0.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11
 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3
  1  0 29  6] -> size -> 52 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 11. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 15.] 
expected returns: [[84.53235]
 [95.82733]
 [92.4738 ]
 [88.7997 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11. 15.  0.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11
 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3
  1  0 29  6] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 22. 29.  8.  8. 10.  0.  7.  8.  2. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0. 22.  8.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8 22  0] -> size -> 12 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  300    0    0    0    0    0    0    0 -170    0 -300
    0    0] 
sum of rewards: -175 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.36166763305664



action possibilites: [-1. 15.] 
expected returns: [[77.698784]
 [80.38469 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11
 10  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3
  1  0 29  6] -> size -> 52 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 22. 29.  8.  8. 10.  0.  7.  8.  2. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0. 22.  8.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8 22  0] -> size -> 12 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 94.84967041015625



action possibilites: [-1] 
expected returns: [[7.3815365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6] -> size -> 51 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 22. 30. 22. 29.  8.  8. 10.  0.  7.  8.  2. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0. 22.  8.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8 22  0] -> size -> 12 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 80.38468933105469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[ 5.7184267]
 [10.343381 ]
 [ 9.056274 ]
 [ 2.6818898]
 [ 8.242427 ]
 [ 8.655614 ]
 [13.788087 ]
 [ 5.352029 ]
 [ 9.976981 ]
 [ 7.2988834]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6] -> size -> 51 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 22. 30. 22. 29.  8.  8. 10.  0.  7.  8.  2. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0. 22.  8.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8 22  0] -> size -> 12 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.381536483764648



buy possibilites: [-1] 
expected returns: [[42.985928]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 22. 29.  8.  8. 10.  0.  7.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0. 22.  8.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8 22  0] -> size -> 12 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  300    0    0   40    0    0    0    0 -170    0    0
  128    0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 13.788093566894531






Player: 1 
cards in hand: [ 0. 22.  8.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  8.  1.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  0  0  1 25  0  6  8 22  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 22. 29.  8.  8. 10.  0.  7.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 15. 15.  3.  3.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29] -> size -> 52 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  8.  1.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  0  0  1 25  0  6  8 22  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 22. 30. 22. 29.  8.  8. 10.  0.  7.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 15. 15.  3.  3.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29] -> size -> 52 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  8.  1.  8.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  0  0  1 25  0  6  8 22  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 21. 29.  8.  8. 10.  0.  7.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 15. 15.  3.  3.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29] -> size -> 52 
adversary victory points: 9
player victory points: 0 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 3. 15. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[82.9612 ]
 [84.66309]
 [84.66309]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15.  3.  3.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 21. 29.  8.  8. 10.  0.  7.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 8. 0. 1. 0.] 
adversary cards in discard: [ 3.  0. 22.  8.  1.  8.] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8 22  0  3] -> size -> 13 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.98592758178711



action possibilites: [-1] 
expected returns: [[28.542517]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  3.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 21. 29.  8.  8. 10.  0.  7.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 8. 0. 1. 0.] 
adversary cards in discard: [ 3.  0. 22.  8.  1.  8.] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8 22  0  3] -> size -> 13 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 84.6630859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.83946 ]
 [24.673267]
 [28.542517]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  3.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29] -> size -> 52 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 22. 30. 21. 29.  8.  8. 10.  0.  7.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 8. 0. 1. 0.] 
adversary cards in discard: [ 3.  0. 22.  8.  1.  8.] 
adversary owned cards: [ 8  8  1  0  0  1 25  0  6  8 22  0  3] -> size -> 13 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.542516708374023






Player: 1 
cards in hand: [6. 8. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 1. 0.] 
cards in discard: [ 3.  0. 22.  8.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  0  0  1 25  0  6  8 22  0  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 21. 29.  8.  8. 10.  0.  7.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1.  3.  3. 15. 29.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29] -> size -> 52 
adversary victory points: 9
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0.] 
cards in discard: [ 3.  0. 22.  8.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  0  1 25  0  6  8 22  0  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 21. 29.  8.  8. 10.  0.  7.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1.  3.  3. 15. 29.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29] -> size -> 52 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0.] 
cards in discard: [ 3.  0. 22.  8.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  0  1 25  0  6  8 22  0  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 22. 30. 21. 29.  8.  8. 10.  0.  7.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1.  3.  3. 15. 29.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29] -> size -> 52 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0.] 
cards in discard: [ 3.  0. 22.  8.  1.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  0  1 25  0  6  8 22  0  3  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 21. 29.  8.  8. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1.  3.  3. 15. 29.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29] -> size -> 52 
adversary victory points: 9
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  3. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[41.42098 ]
 [44.03077 ]
 [48.476765]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3. 15. 29.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 21. 29.  8.  8. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 8.  8.  1.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  0  1 25  0  6  8 22  0  3  8] -> size -> 13 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 28.542516708374023



action possibilites: [-1. 11.] 
expected returns: [[45.766712]
 [50.801624]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29] -> size -> 52 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 21. 29.  8.  8. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 8.  8.  1.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  0  1 25  0  6  8 22  0  3  8] -> size -> 13 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 44.35219192504883



action possibilites: [-1] 
expected returns: [[20.182875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 21. 29.  8.  8. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 8.  8.  1.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  0  1 25  0  6  8 22  0  3  8] -> size -> 13 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -180    0    0
   27    0] 
sum of rewards: 152 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 48.73869705200195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.826933]
 [13.61047 ]
 [20.182856]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 21. 30. 21. 29.  8.  8. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 8.  8.  1.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  0  1 25  0  6  8 22  0  3  8] -> size -> 13 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.18287467956543






Player: 1 
cards in hand: [ 8.  8.  1.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  1.  0. 25.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  0  1 25  0  6  8 22  0  3  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 21. 29.  8.  8. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1. 11. 10. 10. 11.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1] -> size -> 53 
adversary victory points: 9
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  1.  0.  1. 22.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  8  1  0  1 25  0  6  8 22  0  3  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 21. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1. 11. 10. 10. 11.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6] -> size -> 54 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  1.  0.  1. 22.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  8  1  0  1 25  0  6  8 22  0  3  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 21. 30. 21. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1. 11. 10. 10. 11.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6] -> size -> 54 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  1.  0.  1. 22.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  8  1  0  1 25  0  6  8 22  0  3  8  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 21. 30. 20. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1. 11. 10. 10. 11.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6] -> size -> 54 
adversary victory points: 9
player victory points: 1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 1. 11. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 11.] 
expected returns: [[92.766426]
 [98.63391 ]
 [91.102005]
 [91.102005]
 [98.63391 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 10. 10. 11.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 20. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [ 3. 25.  8.  8.  1.  0.  1. 22.] 
adversary owned cards: [ 8  8  1  0  1 25  0  6  8 22  0  3  8  3] -> size -> 14 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  210    0    0    0    0    0    0    0 -190    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.18287467956543



action possibilites: [-1] 
expected returns: [[86.757324]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10. 11.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 20. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [ 3. 25.  8.  8.  1.  0.  1. 22.] 
adversary owned cards: [ 8  8  1  0  1 25  0  6  8 22  0  3  8  3] -> size -> 14 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -200    0    0
   27    0] 
sum of rewards: 52 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 95.7598648071289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[83.70482 ]
 [88.406136]
 [79.93243 ]
 [87.88841 ]
 [86.757324]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10. 11.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1] -> size -> 55 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 20. 30. 20. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [ 3. 25.  8.  8.  1.  0.  1. 22.] 
adversary owned cards: [ 8  8  1  0  1 25  0  6  8 22  0  3  8  3] -> size -> 14 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.75732421875



buy possibilites: [-1] 
expected returns: [[42.483227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10. 11.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 19. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [ 3. 25.  8.  8.  1.  0.  1. 22.] 
adversary owned cards: [ 8  8  1  0  1 25  0  6  8 22  0  3  8  3] -> size -> 14 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -210    0    0
   16    0] 
sum of rewards: 61 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 88.40614318847656






Player: 1 
cards in hand: [8. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 0. 0.] 
cards in discard: [ 3. 25.  8.  8.  1.  0.  1. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  0  1 25  0  6  8 22  0  3  8  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 19. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [29. 10. 29. 29.  3.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3] -> size -> 56 
adversary victory points: 9
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [ 3. 25.  8.  8.  1.  0.  1. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  1 25  6  8 22  0  3  8  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 19. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [29. 10. 29. 29.  3.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3] -> size -> 56 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [ 3. 25.  8.  8.  1.  0.  1. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  1 25  6  8 22  0  3  8  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 20. 30. 19. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [29. 10. 29. 29.  3.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3] -> size -> 56 
adversary victory points: 9
player victory points: 1 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [29. 10. 29. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29. 29.] 
expected returns: [[45.542133]
 [53.924015]
 [44.54025 ]
 [53.924015]
 [53.924015]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 29. 29.  3.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 19. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [25.  0.  1.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  1 25  6  8 22  0  3  8  3] -> size -> 12 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.48322677612305



action possibilites: [-1. 10. 15.] 
expected returns: [[69.58141 ]
 [68.325745]
 [73.946655]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 15.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3] -> size -> 56 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 20. 30. 19. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [25.  0.  1.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  1 25  6  8 22  0  3  8  3] -> size -> 12 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 48.44144058227539



action possibilites: [-1] 
expected returns: [[22.510468]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3] -> size -> 56 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 20. 30. 19. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [25.  0.  1.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  1 25  6  8 22  0  3  8  3] -> size -> 12 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 73.94661712646484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.627274]
 [17.911171]
 [22.510464]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3] -> size -> 56 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 20. 30. 19. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [25.  0.  1.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  1 25  6  8 22  0  3  8  3] -> size -> 12 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.510467529296875






Player: 1 
cards in hand: [25.  0.  1.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  1.  8.  6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  1 25  6  8 22  0  3  8  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 19. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 11. 11.  1. 15.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11. 29. 29. 29. 15. 10.  3.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3] -> size -> 56 
adversary victory points: 9
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  6  8 22  0  3  8  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 19. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 11. 11.  1. 15.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11. 29. 29. 29. 15. 10.  3.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3] -> size -> 56 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  6  8 22  0  3  8  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 20. 30. 19. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 11. 11.  1. 15.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11. 29. 29. 29. 15. 10.  3.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3] -> size -> 56 
adversary victory points: 9
player victory points: 1 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 11.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.] 
expected returns: [[72.49579]
 [77.86198]
 [77.86198]
 [74.99928]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  1. 15.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11. 29. 29. 29. 15. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 19. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1.  8.  3.  3. 22.] 
adversary cards in discard: [8. 0. 6.] 
adversary owned cards: [ 8  8  1  6  8 22  0  3  8  3] -> size -> 10 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 22.510467529296875



action possibilites: [-1] 
expected returns: [[85.89887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1. 15.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11. 29. 29. 29. 15. 10.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 19. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1.  8.  3.  3. 22.] 
adversary cards in discard: [8. 0. 6.] 
adversary owned cards: [ 8  8  1  6  8 22  0  3  8  3] -> size -> 10 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -220    0    0
   27    0] 
sum of rewards: 62 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 75.24229431152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[82.61457]
 [86.75919]
 [79.20804]
 [86.23924]
 [85.8989 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1. 15.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11. 29. 29. 29. 15. 10.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1] -> size -> 57 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 19. 30. 19. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1.  8.  3.  3. 22.] 
adversary cards in discard: [8. 0. 6.] 
adversary owned cards: [ 8  8  1  6  8 22  0  3  8  3] -> size -> 10 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 85.89887237548828



buy possibilites: [-1] 
expected returns: [[75.58751]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1. 15.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11. 29. 29. 29. 15. 10.  3.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 18. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1.  8.  3.  3. 22.] 
adversary cards in discard: [8. 0. 6.] 
adversary owned cards: [ 8  8  1  6  8 22  0  3  8  3] -> size -> 10 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -230    0    0
   16    0] 
sum of rewards: 71 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 86.75917053222656






Player: 1 
cards in hand: [ 1.  8.  3.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  3.  3. 22.] 
cards in discard: [8. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  6  8 22  0  3  8  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 18. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [29. 10. 15. 25. 11.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11. 29. 29. 29. 15. 10.  3.  1.  3. 11.  3. 11.  1. 15.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3] -> size -> 58 
adversary victory points: 10
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 8. 8.] 
cards in discard: [8. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.  8.] 
owned cards: [ 8  8  1  6  8 22  0  3  8  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 18. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [29. 10. 15. 25. 11.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11. 29. 29. 29. 15. 10.  3.  1.  3. 11.  3. 11.  1. 15.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3] -> size -> 58 
adversary victory points: 10
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 8. 8.] 
cards in discard: [8. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.  8.] 
owned cards: [ 8  8  1  6  8 22  0  3  8  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 19. 30. 18. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [29. 10. 15. 25. 11.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11. 29. 29. 29. 15. 10.  3.  1.  3. 11.  3. 11.  1. 15.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3] -> size -> 58 
adversary victory points: 10
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 8. 8.] 
cards in discard: [8. 0. 6. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.  8.] 
owned cards: [ 8  8  1  6  8 22  0  3  8  3  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 17. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [29. 10. 15. 25. 11.] 
adversary cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11. 29. 29. 29. 15. 10.  3.  1.  3. 11.  3. 11.  1. 15.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3] -> size -> 58 
adversary victory points: 10
player victory points: 2 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [29. 10. 15. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 15. 25. 11.] 
expected returns: [[36.4471  ]
 [43.93611 ]
 [34.29043 ]
 [38.250824]
 [46.796875]
 [41.111584]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 15. 25. 11.] 
cards in discard: [ 3. 11.  0. 29. 15. 10. 29.  0. 10.  1.  0. 10.  6.  3. 11. 29. 29. 15.
  3. 15.  3. 15.  3.  3.  1. 15.  1. 29. 11.  3.  3.  6.  1.  3. 11.  1.
 10. 10. 11. 29. 29. 29. 15. 10.  3.  1.  3. 11.  3. 11.  1. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 17. 29.  8.  7. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 8.  8. 22.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  6  8 22  0  3  8  3  3] -> size -> 11 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.58750915527344



action possibilites: [-1] 
expected returns: [[47.538418]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 15. 11. 29. 10.] 
cards in discard: [] 
cards in deck: 51 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 8.  8. 22.  6.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  8  1  6  8 22  0  3  8  3  3  6] -> size -> 12 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 46.7968635559082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[42.51874 ]
 [40.85989 ]
 [45.435837]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 15. 11. 29. 10.] 
cards in discard: [] 
cards in deck: 51 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3] -> size -> 58 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 19. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 8.  8. 22.  6.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  8  1  6  8 22  0  3  8  3  3  6] -> size -> 12 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.53841781616211






Player: 1 
cards in hand: [ 8.  8. 22.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 22.  6.  3.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  6  8 22  0  3  8  3  3  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 15. 11. 29. 11.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3] -> size -> 58 
adversary victory points: 10
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22.  3.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  8 22  0  3  8  3  3  6] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 15. 11. 29. 11.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3] -> size -> 58 
adversary victory points: 10
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 22.  3.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  8 22  0  3  8  3  3  6] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 19. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 15. 11. 29. 11.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3] -> size -> 58 
adversary victory points: 10
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 22.  3.] 
cards in discard: [6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  8 22  0  3  8  3  3  6  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 15. 11. 29. 11.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3] -> size -> 58 
adversary victory points: 10
player victory points: 2 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 3. 15. 11. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 29. 11.] 
expected returns: [[38.781506]
 [39.084522]
 [40.752583]
 [42.991352]
 [40.752583]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 11. 29. 11.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 0. 3. 1.] 
adversary cards in discard: [ 6.  0.  8.  8. 22.  3.] 
adversary owned cards: [ 8  8  1  8 22  0  3  8  3  3  6  0] -> size -> 12 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 45.43584060668945



action possibilites: [-1. 11.] 
expected returns: [[45.231213]
 [47.2008  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.] 
cards in deck: 45 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3] -> size -> 58 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 19. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 0. 3. 1.] 
adversary cards in discard: [ 6.  0.  8.  8. 22.  3.] 
adversary owned cards: [ 8  8  1  8 22  0  3  8  3  3  6  0] -> size -> 12 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 39.110382080078125



action possibilites: [-1] 
expected returns: [[21.589018]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3  1] -> size -> 59 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 18. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 0. 3. 1.] 
adversary cards in discard: [ 6.  0.  8.  8. 22.  3.] 
adversary owned cards: [ 8  8  1  8 22  0  3  8  3  3  6  0] -> size -> 12 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  240    0    0   40    0    0    0    0 -240    0    0
   27    0] 
sum of rewards: 62 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 46.01554489135742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[20.064272]
 [21.257746]
 [20.981768]
 [19.346138]
 [20.72651 ]
 [21.589016]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3  1] -> size -> 59 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 18. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 0. 3. 1.] 
adversary cards in discard: [ 6.  0.  8.  8. 22.  3.] 
adversary owned cards: [ 8  8  1  8 22  0  3  8  3  3  6  0] -> size -> 12 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.589017868041992






Player: 1 
cards in hand: [8. 8. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 3. 1.] 
cards in discard: [ 6.  0.  8.  8. 22.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  8 22  0  3  8  3  3  6  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 18. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [11.  0.  3.  3.  1.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3  1] -> size -> 59 
adversary victory points: 10
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 3. 1.] 
cards in discard: [ 6.  0.  8.  8. 22.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  8 22  0  3  8  3  3  6  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 18. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [11.  0.  3.  3.  1.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3  1] -> size -> 59 
adversary victory points: 10
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 3. 1.] 
cards in discard: [ 6.  0.  8.  8. 22.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  8 22  0  3  8  3  3  6  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 18. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [11.  0.  3.  3.  1.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3  1] -> size -> 59 
adversary victory points: 10
player victory points: 2 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[48.59657]
 [53.83936]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  3.  1.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3  1] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 18. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  8 22  0  3  8  3  3  6  0  0] -> size -> 13 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 21.589017868041992



action possibilites: [-1] 
expected returns: [[75.03569]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3  1  1] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 17. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  8 22  0  3  8  3  3  6  0  0] -> size -> 13 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -250    0    0
   27    0] 
sum of rewards: 32 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 51.140071868896484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[72.85979 ]
 [78.68743 ]
 [76.97104 ]
 [69.36429 ]
 [76.50179 ]
 [75.035706]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3  1  1] -> size -> 60 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 17. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  8 22  0  3  8  3  3  6  0  0] -> size -> 13 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 75.03569030761719



buy possibilites: [-1] 
expected returns: [[87.924576]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3  1  1  1] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 16. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  8 22  0  3  8  3  3  6  0  0] -> size -> 13 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -260    0    0
   54    0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 78.68742370605469






Player: 1 
cards in hand: [8. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  8 22  0  3  8  3  3  6  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 16. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3.  6.  3.  0. 15.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3  1  1  1] -> size -> 61 
adversary victory points: 10
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  8 22  3  8  3  3  6  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 16. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3.  6.  3.  0. 15.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3  1  1  1] -> size -> 61 
adversary victory points: 10
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  8 22  3  8  3  3  6  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 16. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3.  6.  3.  0. 15.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3  1  1  1] -> size -> 61 
adversary victory points: 10
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 16. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3.  6.  3.  0. 15.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.] 
adversary owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3  1  1  1] -> size -> 61 
adversary victory points: 10
player victory points: 2 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[36.477665]
 [38.61521 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  3.  0. 15.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10
  3 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1
  0 29  6 29  1  6  1  3  1  3  1  1  1] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 16. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 8. 0. 1. 8.] 
adversary cards in discard: [0. 8. 3. 3.] 
adversary owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 87.92457580566406



action possibilites: [-1] 
expected returns: [[63.10082]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1] -> size -> 60 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 16. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 8. 0. 1. 8.] 
adversary cards in discard: [0. 8. 3. 3.] 
adversary owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 38.615211486816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[60.32552 ]
 [69.83726 ]
 [67.11715 ]
 [53.926105]
 [66.54582 ]
 [63.10081 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1] -> size -> 60 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 16. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 8. 0. 1. 8.] 
adversary cards in discard: [0. 8. 3. 3.] 
adversary owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.1008186340332



buy possibilites: [-1] 
expected returns: [[100.70647]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 15. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 8. 0. 1. 8.] 
adversary cards in discard: [0. 8. 3. 3.] 
adversary owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -260    0    0
   54    0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 69.8372573852539






Player: 1 
cards in hand: [6. 8. 0. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 1. 8.] 
cards in discard: [0. 8. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 15. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [15. 11. 29. 10. 29.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1] -> size -> 61 
adversary victory points: 10
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 1. 8.] 
cards in discard: [0. 8. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 15. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [15. 11. 29. 10. 29.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1] -> size -> 61 
adversary victory points: 10
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 1. 8.] 
cards in discard: [0. 8. 3. 3. 1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [15. 11. 29. 10. 29.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1] -> size -> 61 
adversary victory points: 10
player victory points: 2 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [15. 11. 29. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 29. 10. 29.] 
expected returns: [[11.066218]
 [11.858875]
 [13.240824]
 [14.746416]
 [ 9.813236]
 [14.746416]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 29. 10. 29.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  3.  3.  8. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0  1] -> size -> 13 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 100.70646667480469



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[35.204975]
 [39.25099 ]
 [34.46773 ]
 [41.489933]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1] -> size -> 61 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 14. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  3.  3.  8. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0  1] -> size -> 13 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 14.134035110473633



action possibilites: [-1.] 
expected returns: [[40.96043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1] -> size -> 61 
action values: 1 
buys: 0 
player value: 2 
card supply: [18. 14. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  3.  3.  8. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0  1] -> size -> 13 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 37.10939407348633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[39.04123 ]
 [42.233677]
 [35.97141 ]
 [41.848763]
 [40.960415]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1] -> size -> 61 
action values: 1 
buys: 1 
player value: 2 
card supply: [18. 14. 30. 17. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  3.  3.  8. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0  1] -> size -> 13 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 40.96043014526367



buy possibilites: [-1] 
expected returns: [[12.888075]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  3.  3.  8. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0  1] -> size -> 13 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -270    0    0
   16    0] 
sum of rewards: 51 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 42.23369216918945






Player: 1 
cards in hand: [ 0.  3.  3.  8. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  8. 22.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1. 29.  3.  6. 15.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3] -> size -> 62 
adversary victory points: 11
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  8. 22.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 14. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1. 29.  3.  6. 15.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3] -> size -> 62 
adversary victory points: 11
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 1. 29.  3.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[14.355289]
 [20.081945]
 [15.993719]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3.  6. 15.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 3. 8. 8. 0.] 
adversary cards in discard: [ 0.  3.  3.  8. 22.] 
adversary owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0  1] -> size -> 13 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.88807487487793



action possibilites: [-1. 15.] 
expected returns: [[45.167896]
 [50.00777 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  1.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3] -> size -> 62 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 14. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 3. 8. 8. 0.] 
adversary cards in discard: [ 0.  3.  3.  8. 22.] 
adversary owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0  1] -> size -> 13 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 19.376327514648438



action possibilites: [-1] 
expected returns: [[84.40732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3] -> size -> 62 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 14. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 3. 8. 8. 0.] 
adversary cards in discard: [ 0.  3.  3.  8. 22.] 
adversary owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0  1] -> size -> 13 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 50.00777816772461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[80.83912 ]
 [88.127594]
 [86.139595]
 [76.06459 ]
 [85.58101 ]
 [84.407295]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3] -> size -> 62 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 14. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 3. 8. 8. 0.] 
adversary cards in discard: [ 0.  3.  3.  8. 22.] 
adversary owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0  1] -> size -> 13 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.40731811523438



buy possibilites: [-1] 
expected returns: [[40.562344]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1] -> size -> 63 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 13. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 3. 8. 8. 0.] 
adversary cards in discard: [ 0.  3.  3.  8. 22.] 
adversary owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0  1] -> size -> 13 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -280    0    0
   54    0] 
sum of rewards: 79 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 88.12759399414062






Player: 1 
cards in hand: [6. 3. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 8. 0.] 
cards in discard: [ 0.  3.  3.  8. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  8 22  3  8  3  3  6  0  0  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 13. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1.  3. 29.  3. 15.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1] -> size -> 63 
adversary victory points: 11
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0.  3.  3.  8. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  8 22  3  8  3  3  0  1] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 13. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1.  3. 29.  3. 15.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1] -> size -> 63 
adversary victory points: 11
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  3.  3.  8. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  8 22  3  8  3  3  0  1] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 13. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1.  3. 29.  3. 15.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1] -> size -> 63 
adversary victory points: 11
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  3.  3.  8. 22.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  8 22  3  8  3  3  0  1  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 13. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1.  3. 29.  3. 15.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1] -> size -> 63 
adversary victory points: 11
player victory points: 3 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 29.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[84.319336]
 [93.57094 ]
 [87.46411 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29.  3. 15.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 13. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 22.  1.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8 22  3  8  3  3  0  1  0] -> size -> 11 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.56234359741211



action possibilites: [-1. 15.] 
expected returns: [[151.76   ]
 [157.16438]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 15.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1] -> size -> 63 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 13. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 22.  1.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8 22  3  8  3  3  0  1  0] -> size -> 11 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 87.7198715209961



action possibilites: [-1] 
expected returns: [[67.97276]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1] -> size -> 63 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 13. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 22.  1.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8 22  3  8  3  3  0  1  0] -> size -> 11 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 157.1643829345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[63.927616]
 [71.61116 ]
 [69.5287  ]
 [58.64436 ]
 [68.918655]
 [67.972786]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1] -> size -> 63 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 13. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 22.  1.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8 22  3  8  3  3  0  1  0] -> size -> 11 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 67.97276306152344



buy possibilites: [-1] 
expected returns: [[143.37584]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1] -> size -> 64 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 12. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3. 22.  1.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8 22  3  8  3  3  0  1  0] -> size -> 11 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  240    0    0   40    0    0    0    0 -290    0    0
   54    0] 
sum of rewards: 39 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 71.61114501953125






Player: 1 
cards in hand: [ 3. 22.  1.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 22.  1.  8.  1.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8 22  3  8  3  3  0  1  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 12. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0. 11. 10.  3.  3.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1. 29. 15.  1.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1] -> size -> 64 
adversary victory points: 11
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  1.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 22  8  3  3  0  1  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 12. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0. 11. 10.  3.  3.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1. 29. 15.  1.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1] -> size -> 64 
adversary victory points: 11
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  1.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 22  8  3  3  0  1  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 12. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0. 11. 10.  3.  3.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1. 29. 15.  1.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1] -> size -> 64 
adversary victory points: 11
player victory points: 2 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[20.96926 ]
 [27.241796]
 [21.07348 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3.  3.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1. 29. 15.  1.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 12. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [3. 8. 0. 0. 8.] 
adversary cards in discard: [ 8. 22.  1.] 
adversary owned cards: [ 8  8 22  8  3  3  0  1  0] -> size -> 9 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 143.37583923339844



action possibilites: [-1] 
expected returns: [[36.712692]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1. 29. 15.  1.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1] -> size -> 65 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 11. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [3. 8. 0. 0. 8.] 
adversary cards in discard: [ 8. 22.  1.] 
adversary owned cards: [ 8  8 22  8  3  3  0  1  0] -> size -> 9 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -300    0    0
   27    0] 
sum of rewards: 12 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 24.71559715270996





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.952873]
 [31.883966]
 [36.71268 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1. 29. 15.  1.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1] -> size -> 65 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 11. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [3. 8. 0. 0. 8.] 
adversary cards in discard: [ 8. 22.  1.] 
adversary owned cards: [ 8  8 22  8  3  3  0  1  0] -> size -> 9 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.71269226074219






Player: 1 
cards in hand: [3. 8. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 8.] 
cards in discard: [ 8. 22.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 22  8  3  3  0  1  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 11. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [15. 10. 10. 29.  1.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1. 29. 15.  1.  3.  1. 11.  0. 10.  3.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1] -> size -> 65 
adversary victory points: 11
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 8.] 
cards in discard: [ 8. 22.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 22  8  3  3  0  1  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 11. 30. 16. 29.  8.  6. 10.  0.  6.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [15. 10. 10. 29.  1.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1. 29. 15.  1.  3.  1. 11.  0. 10.  3.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1] -> size -> 65 
adversary victory points: 11
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 8.] 
cards in discard: [ 8. 22.  1.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 22  8  3  3  0  1  0  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 11. 30. 16. 29.  8.  6. 10.  0.  5.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [15. 10. 10. 29.  1.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1. 29. 15.  1.  3.  1. 11.  0. 10.  3.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1] -> size -> 65 
adversary victory points: 11
player victory points: 2 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [15. 10. 10. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10. 29.] 
expected returns: [[32.524696]
 [35.89539 ]
 [33.01412 ]
 [33.01412 ]
 [40.04017 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10. 29.  1.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1. 29. 15.  1.  3.  1. 11.  0. 10.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1] -> size -> 65 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 11. 30. 16. 29.  8.  6. 10.  0.  5.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  8. 22.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 22  8  3  3  0  1  0  8] -> size -> 10 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 36.71269226074219



action possibilites: [-1. 15. 10.] 
expected returns: [[52.137566]
 [56.333004]
 [52.812885]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  3.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1. 29. 15.  1.  3.  1. 11.  0. 10.  3.  3.
 10.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1] -> size -> 65 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 11. 30. 16. 29.  8.  6. 10.  0.  5.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  8. 22.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 22  8  3  3  0  1  0  8] -> size -> 10 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 36.29048538208008



action possibilites: [-1] 
expected returns: [[110.755875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1. 29. 15.  1.  3.  1. 11.  0. 10.  3.  3.
 10.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1] -> size -> 65 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 11. 30. 16. 29.  8.  6. 10.  0.  5.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  8. 22.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 22  8  3  3  0  1  0  8] -> size -> 10 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 56.333003997802734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[107.05104 ]
 [ 99.66136 ]
 [110.755875]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1. 29. 15.  1.  3.  1. 11.  0. 10.  3.  3.
 10.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1] -> size -> 65 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 11. 30. 16. 29.  8.  6. 10.  0.  5.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  8. 22.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 22  8  3  3  0  1  0  8] -> size -> 10 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 110.75587463378906






Player: 1 
cards in hand: [ 0.  8. 22.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 22.  0.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 22  8  3  3  0  1  0  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 11. 30. 16. 29.  8.  6. 10.  0.  5.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [10. 11. 11. 29.  1.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1. 29. 15.  1.  3.  1. 11.  0. 10.  3.  3.
 10.  1. 29. 15. 10.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1] -> size -> 65 
adversary victory points: 11
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 22.  0.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 22  8  3  3  0  1  0  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 11. 30. 16. 29.  8.  6. 10.  0.  5.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [10. 11. 11. 29.  1.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1. 29. 15.  1.  3.  1. 11.  0. 10.  3.  3.
 10.  1. 29. 15. 10.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1] -> size -> 65 
adversary victory points: 11
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 22.  0.  3.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 22  8  3  3  0  1  0  8  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 11. 30. 15. 29.  8.  6. 10.  0.  5.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [10. 11. 11. 29.  1.] 
adversary cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1. 29. 15.  1.  3.  1. 11.  0. 10.  3.  3.
 10.  1. 29. 15. 10.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1] -> size -> 65 
adversary victory points: 11
player victory points: 3 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [10. 11. 11. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 29.] 
expected returns: [[1.5709522]
 [1.7571185]
 [3.939706 ]
 [3.939706 ]
 [5.0265293]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 29.  1.] 
cards in discard: [25. 29. 10. 15. 11. 29. 10. 15. 11.  1. 29. 11.  3.  1.  1.  1. 11.  0.
  3.  3.  1.  1. 15.  3.  6.  3. 15. 15. 11. 10.  3. 29. 29.  3.  1.  3.
  1. 29. 15.  6.  1.  3. 10.  1. 29. 15.  1.  3.  1. 11.  0. 10.  3.  3.
 10.  1. 29. 15. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1] -> size -> 65 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 11. 30. 15. 29.  8.  6. 10.  0.  5.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [3. 8. 8. 8. 1.] 
adversary cards in discard: [ 3.  0.  8. 22.  0.  3.] 
adversary owned cards: [ 8  8 22  8  3  3  0  1  0  8  3] -> size -> 11 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 110.75587463378906



action possibilites: [-1. 11.] 
expected returns: [[-1.4080645]
 [-1.9601784]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  1.] 
cards in discard: [10. 11.] 
cards in deck: 59 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1] -> size -> 65 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 11. 30. 15. 29.  8.  6. 10.  0.  5.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [3. 8. 8. 8. 1.] 
adversary cards in discard: [ 3.  0.  8. 22.  0.  3.] 
adversary owned cards: [ 8  8 22  8  3  3  0  1  0  8  3] -> size -> 11 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 3.2163445949554443





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[-2.7762675]
 [-2.087794 ]
 [-2.2181253]
 [-2.9966016]
 [-3.1239562]
 [-2.169991 ]
 [-2.4486883]
 [-1.1539385]
 [-1.3742716]
 [-2.7993546]
 [-1.8321825]
 [-2.520657 ]
 [-2.1108806]
 [-1.3384336]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  1.] 
cards in discard: [10. 11.] 
cards in deck: 59 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1] -> size -> 65 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 11. 30. 15. 29.  8.  6. 10.  0.  5.  8.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [3. 8. 8. 8. 1.] 
adversary cards in discard: [ 3.  0.  8. 22.  0.  3.] 
adversary owned cards: [ 8  8 22  8  3  3  0  1  0  8  3] -> size -> 11 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -1.4080634117126465



buy possibilites: [-1] 
expected returns: [[28.569254]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  1.] 
cards in discard: [10. 11. 25.] 
cards in deck: 59 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25] -> size -> 66 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 11. 30. 15. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [3. 8. 8. 8. 1.] 
adversary cards in discard: [ 3.  0.  8. 22.  0.  3.] 
adversary owned cards: [ 8  8 22  8  3  3  0  1  0  8  3] -> size -> 11 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -310    0    0
  250    0] 
sum of rewards: 195 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -1.1539356708526611






Player: 1 
cards in hand: [3. 8. 8. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 8. 1.] 
cards in discard: [ 3.  0.  8. 22.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 22  8  3  3  0  1  0  8  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 11. 30. 15. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [10.  1.  3. 29. 11.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25] -> size -> 66 
adversary victory points: 11
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 8. 8. 1.] 
cards in discard: [ 3.  0.  8. 22.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 22  8  3  3  0  1  0  8  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 11. 30. 15. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [10.  1.  3. 29. 11.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25] -> size -> 66 
adversary victory points: 11
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 8. 8. 1.] 
cards in discard: [ 3.  0.  8. 22.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 22  8  3  3  0  1  0  8  3  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 11. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [10.  1.  3. 29. 11.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25] -> size -> 66 
adversary victory points: 11
player victory points: 4 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [10.  1.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[144.21419]
 [140.63971]
 [153.91786]
 [149.98335]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3. 29. 11.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.] 
cards in deck: 54 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25] -> size -> 66 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 11. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  3.  3. 22.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 22  8  3  3  0  1  0  8  3  3] -> size -> 12 
adversary victory points: 4
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.56925392150879



action possibilites: [-1. 10. 11.] 
expected returns: [[174.49702]
 [171.17091]
 [178.18584]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.] 
cards in deck: 53 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25] -> size -> 66 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 11. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  3.  3. 22.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 22  8  3  3  0  1  0  8  3  3] -> size -> 12 
adversary victory points: 4
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 146.36514282226562



action possibilites: [-1] 
expected returns: [[183.63374]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1.] 
cards in deck: 53 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1] -> size -> 67 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 10. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  3.  3. 22.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 22  8  3  3  0  1  0  8  3  3] -> size -> 12 
adversary victory points: 4
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  210    0    0   40    0    0    0    0 -320    0    0
   27    0] 
sum of rewards: -48 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 175.46652221679688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[177.82182]
 [174.09857]
 [183.63374]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1.] 
cards in deck: 53 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1] -> size -> 67 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 10. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  3.  3. 22.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 22  8  3  3  0  1  0  8  3  3] -> size -> 12 
adversary victory points: 4
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 183.6337432861328






Player: 1 
cards in hand: [ 0.  3.  3. 22.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 22.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 22  8  3  3  0  1  0  8  3  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 10. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [15. 29.  3. 10.  1.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1] -> size -> 67 
adversary victory points: 11
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 3 1 0 8 3 3] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 10. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [15. 29.  3. 10.  1.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1] -> size -> 67 
adversary victory points: 11
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 3 1 0 8 3 3] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 10. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [15. 29.  3. 10.  1.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1] -> size -> 67 
adversary victory points: 11
player victory points: 3 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [15. 29.  3. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 10.] 
expected returns: [[37.200703]
 [39.730167]
 [43.037533]
 [37.471462]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  3. 10.  1.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1] -> size -> 67 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 10. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [0. 8. 8. 8. 3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [8 8 8 3 1 0 8 3 3] -> size -> 9 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 183.6337432861328



action possibilites: [-1. 15. 10.] 
expected returns: [[57.37584]
 [59.02554]
 [56.74793]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  1.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11.] 
cards in deck: 47 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1] -> size -> 67 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 10. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [0. 8. 8. 8. 3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [8 8 8 3 1 0 8 3 3] -> size -> 9 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 42.63693618774414



action possibilites: [-1] 
expected returns: [[43.867317]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11.] 
cards in deck: 47 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1] -> size -> 67 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 10. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [0. 8. 8. 8. 3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [8 8 8 3 1 0 8 3 3] -> size -> 9 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 59.02553939819336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[37.790516]
 [43.208374]
 [41.867584]
 [35.161457]
 [41.24218 ]
 [43.867325]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11.] 
cards in deck: 47 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1] -> size -> 67 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 10. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [0. 8. 8. 8. 3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [8 8 8 3 1 0 8 3 3] -> size -> 9 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.86731719970703






Player: 1 
cards in hand: [0. 8. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 8. 3.] 
cards in discard: [8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 3 1 0 8 3 3] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 10. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3.  3.  3. 10. 11.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1] -> size -> 67 
adversary victory points: 11
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8.] 
cards in discard: [8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 1 0 8 3 3] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 10. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3.  3.  3. 10. 11.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1] -> size -> 67 
adversary victory points: 11
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8.] 
cards in discard: [8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 1 0 8 3 3] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 10. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3.  3.  3. 10. 11.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1] -> size -> 67 
adversary victory points: 11
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8.] 
cards in discard: [8. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 1 0 8 3 3 0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 10. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3.  3.  3. 10. 11.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1] -> size -> 67 
adversary victory points: 11
player victory points: 2 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[34.91134 ]
 [34.831226]
 [39.45723 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10. 11.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1] -> size -> 67 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 10. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 1 0 8 3 3 0] -> size -> 9 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 43.86731719970703



action possibilites: [-1] 
expected returns: [[70.541794]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1.] 
cards in deck: 42 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1] -> size -> 68 
action values: 0 
buys: 0 
player value: 0 
card supply: [16.  9. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 1 0 8 3 3 0] -> size -> 9 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -330    0    0
   27    0] 
sum of rewards: -18 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 37.66001510620117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[67.93326]
 [65.10729]
 [70.5418 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 10.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1.] 
cards in deck: 42 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1] -> size -> 68 
action values: 0 
buys: 1 
player value: 0 
card supply: [16.  9. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 1 0 8 3 3 0] -> size -> 9 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.54179382324219






Player: 1 
cards in hand: [8. 8. 8. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8. 3. 1.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 1 0 8 3 3 0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [16.  9. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3.  3. 15.  1. 25.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1] -> size -> 68 
adversary victory points: 11
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 8. 3. 1.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 1 0 8 3 3 0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [16.  9. 30. 14. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3.  3. 15.  1. 25.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1] -> size -> 68 
adversary victory points: 11
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 8. 3. 1.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 1 0 8 3 3 0 3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [16.  9. 30. 13. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 3.  3. 15.  1. 25.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1] -> size -> 68 
adversary victory points: 11
player victory points: 3 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 15.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[10.084055]
 [11.078903]
 [14.423445]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.  1. 25.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1] -> size -> 68 
action values: 1 
buys: 0 
player value: 0 
card supply: [16.  9. 30. 13. 29.  8.  6. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 1 0 8 3 3 0 3] -> size -> 10 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 70.54179382324219



action possibilites: [-1] 
expected returns: [[-2.1971827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.  1.  0.  1.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1] -> size -> 68 
action values: 0 
buys: 0 
player value: 0 
card supply: [16.  9. 30. 13. 29.  8.  5. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 8 1 0 8 3 3 0 3 6] -> size -> 11 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 14.423452377319336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[-3.7916095 ]
 [ 0.01065886]
 [-1.0340488 ]
 [-4.3012667 ]
 [-4.3012667 ]
 [-1.6675935 ]
 [-1.3903928 ]
 [ 4.536504  ]
 [ 2.8953369 ]
 [-4.06697   ]
 [-0.5508884 ]
 [-4.263871  ]
 [-0.27368438]
 [-2.1971898 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15.  1.  0.  1.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1] -> size -> 68 
action values: 0 
buys: 1 
player value: 5 
card supply: [16.  9. 30. 13. 29.  8.  5. 10.  0.  5.  7.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 8 1 0 8 3 3 0 3 6] -> size -> 11 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.1971826553344727



buy possibilites: [-1] 
expected returns: [[44.625504]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15.  1.  0.  1.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25] -> size -> 69 
action values: 0 
buys: 0 
player value: 0 
card supply: [16.  9. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 8 1 0 8 3 3 0 3 6] -> size -> 11 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -340    0    0
  250    0] 
sum of rewards: 165 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 4.536506652832031






Player: 1 
cards in hand: [8. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 8. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 1 0 8 3 3 0 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [16.  9. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1. 29. 10.  3. 10.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25] -> size -> 69 
adversary victory points: 11
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 1 0 8 3 0 3 6] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [16.  9. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1. 29. 10.  3. 10.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25] -> size -> 69 
adversary victory points: 11
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 1 0 8 3 0 3 6] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [16.  9. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1. 29. 10.  3. 10.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25] -> size -> 69 
adversary victory points: 11
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 1 0 8 3 0 3 6 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [15.  9. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1. 29. 10.  3. 10.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25] -> size -> 69 
adversary victory points: 11
player victory points: 1 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 1. 29. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[ 9.880074]
 [17.801893]
 [ 9.816262]
 [ 9.816262]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 10.  3. 10.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25] -> size -> 69 
action values: 1 
buys: 0 
player value: 0 
card supply: [15.  9. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [3. 1. 8. 8. 3.] 
adversary cards in discard: [6. 0. 8. 0. 8. 0.] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0] -> size -> 11 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.62550354003906



action possibilites: [-1.] 
expected returns: [[95.743576]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25] -> size -> 69 
action values: 1 
buys: 0 
player value: 1 
card supply: [15.  9. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [3. 1. 8. 8. 3.] 
adversary cards in discard: [6. 0. 8. 0. 8. 0.] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0] -> size -> 11 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 13.359319686889648





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[90.02451 ]
 [97.92609 ]
 [95.76063 ]
 [85.16798 ]
 [95.04005 ]
 [95.743576]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25] -> size -> 69 
action values: 0 
buys: 1 
player value: 3 
card supply: [15.  9. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [3. 1. 8. 8. 3.] 
adversary cards in discard: [6. 0. 8. 0. 8. 0.] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0] -> size -> 11 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 95.74357604980469



buy possibilites: [-1] 
expected returns: [[79.253044]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1] -> size -> 70 
action values: 0 
buys: 0 
player value: 0 
card supply: [15.  8. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [3. 1. 8. 8. 3.] 
adversary cards in discard: [6. 0. 8. 0. 8. 0.] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0] -> size -> 11 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -350    0    0
   54    0] 
sum of rewards: 19 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 97.92607879638672






Player: 1 
cards in hand: [3. 1. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 8. 8. 3.] 
cards in discard: [6. 0. 8. 0. 8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 1 0 8 3 0 3 6 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [15.  8. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1. 15. 10. 15. 29.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1] -> size -> 70 
adversary victory points: 11
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 8. 8. 3.] 
cards in discard: [6. 0. 8. 0. 8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 1 0 8 3 0 3 6 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [15.  8. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1. 15. 10. 15. 29.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1] -> size -> 70 
adversary victory points: 11
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 1. 15. 10. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 15. 29.] 
expected returns: [[105.62115 ]
 [109.156715]
 [105.50132 ]
 [109.156715]
 [114.375305]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 10. 15. 29.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1] -> size -> 70 
action values: 1 
buys: 0 
player value: 0 
card supply: [15.  8. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [3. 1. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0] -> size -> 11 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.25304412841797



action possibilites: [-1. 10. 15. 10.] 
expected returns: [[143.83528]
 [141.92912]
 [148.20363]
 [141.92912]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1] -> size -> 70 
action values: 1 
buys: 0 
player value: 1 
card supply: [15.  8. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [3. 1. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0] -> size -> 11 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 109.52911376953125



action possibilites: [-1] 
expected returns: [[28.959703]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1] -> size -> 70 
action values: 0 
buys: 0 
player value: 1 
card supply: [15.  8. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [3. 1. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0] -> size -> 11 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 148.20362854003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.44562 ]
 [23.266756]
 [28.959702]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1] -> size -> 70 
action values: 0 
buys: 1 
player value: 1 
card supply: [15.  8. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [3. 1. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0] -> size -> 11 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.95970344543457






Player: 1 
cards in hand: [3. 1. 6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 6. 8. 8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 1 0 8 3 0 3 6 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [15.  8. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [15. 29.  1.  1.  1.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1] -> size -> 70 
adversary victory points: 11
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6. 8. 8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 1 0 8 3 0 3 6 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [15.  8. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [15. 29.  1.  1.  1.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1] -> size -> 70 
adversary victory points: 11
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6. 8. 8.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 1 0 8 3 0 3 6 0 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [14.  8. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [15. 29.  1.  1.  1.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1] -> size -> 70 
adversary victory points: 11
player victory points: 1 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [15. 29.  1.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[10.588215]
 [12.929307]
 [16.535044]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  1.  1.  1.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1] -> size -> 70 
action values: 1 
buys: 0 
player value: 0 
card supply: [14.  8. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [0. 3. 1. 6. 8. 8.] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0 0] -> size -> 12 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 28.95970344543457



action possibilites: [-1. 15.] 
expected returns: [[61.08088]
 [63.6346 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  1.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1] -> size -> 70 
action values: 1 
buys: 0 
player value: 1 
card supply: [14.  8. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [0. 3. 1. 6. 8. 8.] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0 0] -> size -> 12 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 13.248329162597656



action possibilites: [-1] 
expected returns: [[54.726414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1] -> size -> 70 
action values: 0 
buys: 0 
player value: 1 
card supply: [14.  8. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [0. 3. 1. 6. 8. 8.] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0 0] -> size -> 12 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 63.63460159301758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[52.92313 ]
 [59.36438 ]
 [57.545364]
 [50.45806 ]
 [49.082237]
 [56.27825 ]
 [57.09278 ]
 [67.06836 ]
 [64.04436 ]
 [52.473763]
 [58.055687]
 [51.819344]
 [58.87024 ]
 [54.726418]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1] -> size -> 70 
action values: 0 
buys: 1 
player value: 5 
card supply: [14.  8. 30. 13. 29.  8.  5. 10.  0.  5.  6.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [0. 3. 1. 6. 8. 8.] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0 0] -> size -> 12 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: 54.72641372680664



buy possibilites: [-1] 
expected returns: [[70.943115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25] -> size -> 71 
action values: 0 
buys: 0 
player value: 0 
card supply: [14.  8. 30. 13. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [0. 3. 1. 6. 8. 8.] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0 0] -> size -> 12 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  300    0    0   40    0    0    0    0 -360    0    0
  250    0] 
sum of rewards: 225 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 67.06837463378906






Player: 1 
cards in hand: [0. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [0. 3. 1. 6. 8. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 1 0 8 3 0 3 6 0 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [14.  8. 30. 13. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1.  3. 29. 11.  6.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25] -> size -> 71 
adversary victory points: 11
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [0. 3. 1. 6. 8. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 1 0 8 3 0 3 6 0 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [14.  8. 30. 13. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1.  3. 29. 11.  6.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25] -> size -> 71 
adversary victory points: 11
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [0. 3. 1. 6. 8. 8. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 1 0 8 3 0 3 6 0 0 3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [14.  8. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1.  3. 29. 11.  6.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25] -> size -> 71 
adversary victory points: 11
player victory points: 2 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 29. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[44.77193 ]
 [51.281895]
 [49.07461 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29. 11.  6.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25] -> size -> 71 
action values: 1 
buys: 0 
player value: 0 
card supply: [14.  8. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0 0 3] -> size -> 13 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.943115234375



action possibilites: [-1. 15.] 
expected returns: [[79.60936]
 [82.53949]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 15.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.
  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25] -> size -> 71 
action values: 1 
buys: 0 
player value: 1 
card supply: [14.  8. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0 0 3] -> size -> 13 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 50.51839065551758



action possibilites: [-1] 
expected returns: [[65.4496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.
  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25] -> size -> 71 
action values: 0 
buys: 0 
player value: 1 
card supply: [14.  8. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0 0 3] -> size -> 13 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 82.53949737548828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[61.058167]
 [70.371864]
 [67.82266 ]
 [54.592995]
 [67.17064 ]
 [65.4496  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.
  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25] -> size -> 71 
action values: 0 
buys: 1 
player value: 3 
card supply: [14.  8. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0 0 3] -> size -> 13 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.44960021972656



buy possibilites: [-1] 
expected returns: [[81.8332]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.
  3. 11.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1] -> size -> 72 
action values: 0 
buys: 0 
player value: 0 
card supply: [14.  7. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 1 0 8 3 0 3 6 0 0 3] -> size -> 13 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -370    0    0
   54    0] 
sum of rewards: -11 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 70.37187957763672






Player: 1 
cards in hand: [8. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 1 0 8 3 0 3 6 0 0 3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [14.  7. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1. 29. 15.  1.  3.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.
  3. 11.  1. 29. 15.  1.  6.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1] -> size -> 72 
adversary victory points: 11
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 1 8 0 3 6 0 0 3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [14.  7. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1. 29. 15.  1.  3.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.
  3. 11.  1. 29. 15.  1.  6.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1] -> size -> 72 
adversary victory points: 11
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 1 8 0 3 6 0 0 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [14.  7. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1. 29. 15.  1.  3.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.
  3. 11.  1. 29. 15.  1.  6.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1] -> size -> 72 
adversary victory points: 11
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 1 8 0 3 6 0 0 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [13.  7. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 1. 29. 15.  1.  3.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.
  3. 11.  1. 29. 15.  1.  6.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1] -> size -> 72 
adversary victory points: 11
player victory points: 1 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 1. 29. 15.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[36.33993 ]
 [43.207912]
 [38.746994]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 15.  1.  3.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.
  3. 11.  1. 29. 15.  1.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1] -> size -> 72 
action values: 1 
buys: 0 
player value: 0 
card supply: [13.  7. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [8 8 1 8 0 3 6 0 0 3 0] -> size -> 11 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 81.83319854736328



action possibilites: [-1. 15.] 
expected returns: [[66.93022]
 [68.23816]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.
  3. 11.  1. 29. 15.  1.  6.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1] -> size -> 72 
action values: 1 
buys: 0 
player value: 1 
card supply: [13.  7. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [8 8 1 8 0 3 6 0 0 3 0] -> size -> 11 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 39.0626335144043



action possibilites: [-1] 
expected returns: [[27.27854]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.
  3. 11.  1. 29. 15.  1.  6.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1] -> size -> 72 
action values: 0 
buys: 0 
player value: 1 
card supply: [13.  7. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [8 8 1 8 0 3 6 0 0 3 0] -> size -> 11 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 68.2381591796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.767338]
 [19.995745]
 [27.278536]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.
  3. 11.  1. 29. 15.  1.  6.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1] -> size -> 72 
action values: 0 
buys: 1 
player value: 1 
card supply: [13.  7. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [8 8 1 8 0 3 6 0 0 3 0] -> size -> 11 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.278539657592773






Player: 1 
cards in hand: [8. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 1 8 0 3 6 0 0 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [13.  7. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 6. 11.  3. 29. 15.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.
  3. 11.  1. 29. 15.  1.  6.  1.  1. 29. 15.  3.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1] -> size -> 72 
adversary victory points: 11
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 1 8 3 6 0 3 0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [13.  7. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 6. 11.  3. 29. 15.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.
  3. 11.  1. 29. 15.  1.  6.  1.  1. 29. 15.  3.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1] -> size -> 72 
adversary victory points: 11
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 1 8 3 6 0 3 0] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [13.  7. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 6. 11.  3. 29. 15.] 
adversary cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.
  3. 11.  1. 29. 15.  1.  6.  1.  1. 29. 15.  3.  3.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1] -> size -> 72 
adversary victory points: 11
player victory points: 1 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  3. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 15.] 
expected returns: [[18.780903]
 [22.23093 ]
 [24.138922]
 [20.270369]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3. 29. 15.] 
cards in discard: [10. 11. 25. 29. 11.  1.  1.  1. 11.  1. 29. 11. 10.  3.  3. 11. 29. 15.
 10.  1.  1. 11.  3.  3.  3. 10. 25. 25.  3.  3. 15.  1.  0.  1. 10. 10.
  1. 29.  1.  3.  3.  1. 15. 29. 15. 10. 10.  1.  0. 25. 29. 15.  1.  1.
  3. 11.  1. 29. 15.  1.  6.  1.  1. 29. 15.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1] -> size -> 72 
action values: 1 
buys: 0 
player value: 0 
card supply: [13.  7. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [0. 8. 3. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 1 8 3 6 0 3 0] -> size -> 9 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 27.278539657592773



action possibilites: [-1. 11. 29.] 
expected returns: [[7.6104317]
 [7.669734 ]
 [8.355642 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 29.] 
cards in discard: [ 3. 15.] 
cards in deck: 66 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1] -> size -> 72 
action values: 1 
buys: 0 
player value: 1 
card supply: [13.  7. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [0. 8. 3. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 1 8 3 6 0 3 0] -> size -> 9 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 23.54136085510254



action possibilites: [-1. 11.] 
expected returns: [[17.494404]
 [17.59812 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 3. 15.  6. 15.] 
cards in deck: 65 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1] -> size -> 72 
action values: 1 
buys: 0 
player value: 2 
card supply: [13.  7. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [0. 8. 3. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 1 8 3 6 0 3 0] -> size -> 9 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 7.28388786315918



action possibilites: [-1] 
expected returns: [[9.290186]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 15.  6. 15.  1.] 
cards in deck: 65 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1] -> size -> 73 
action values: 0 
buys: 0 
player value: 2 
card supply: [13.  6. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [0. 8. 3. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 1 8 3 6 0 3 0] -> size -> 9 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  300    0    0   60    0    0    0    0 -380    0    0
   27    0] 
sum of rewards: 2 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 16.787092208862305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[6.6090107]
 [8.061154 ]
 [5.691332 ]
 [7.720913 ]
 [9.290182 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 15.  6. 15.  1.] 
cards in deck: 65 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1] -> size -> 73 
action values: 0 
buys: 1 
player value: 2 
card supply: [13.  6. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [0. 8. 3. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 1 8 3 6 0 3 0] -> size -> 9 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.290185928344727






Player: 1 
cards in hand: [0. 8. 3. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 6. 1.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 1 8 3 6 0 3 0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [13.  6. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [10. 15. 25. 10.  3.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1] -> size -> 73 
adversary victory points: 11
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 1 8 3 3 0] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [13.  6. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [10. 15. 25. 10.  3.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1] -> size -> 73 
adversary victory points: 11
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 1 8 3 3 0] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [13.  6. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [10. 15. 25. 10.  3.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1] -> size -> 73 
adversary victory points: 11
player victory points: 2 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [10. 15. 25. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 25. 10.] 
expected returns: [[64.4245  ]
 [62.386005]
 [64.77685 ]
 [71.16497 ]
 [62.386005]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 25. 10.  3.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11.] 
cards in deck: 60 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1] -> size -> 73 
action values: 1 
buys: 0 
player value: 0 
card supply: [13.  6. 30. 12. 29.  8.  5. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 0. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 1 8 3 3 0] -> size -> 7 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 9.290185928344727



action possibilites: [-1] 
expected returns: [[6.531844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10.  3. 11. 29.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11.] 
cards in deck: 58 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1] -> size -> 73 
action values: 0 
buys: 0 
player value: 0 
card supply: [13.  6. 30. 12. 29.  8.  4. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 0. 3. 8. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 1 8 3 3 0 6] -> size -> 8 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 71.16497802734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[3.8506682]
 [2.9329913]
 [6.5318394]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 10.  3. 11. 29.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11.] 
cards in deck: 58 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1] -> size -> 73 
action values: 0 
buys: 1 
player value: 0 
card supply: [13.  6. 30. 12. 29.  8.  4. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 0. 3. 8. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 1 8 3 3 0 6] -> size -> 8 
adversary victory points: 2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.531844139099121






Player: 1 
cards in hand: [8. 0. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 8. 8.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 1 8 3 3 0 6] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [13.  6. 30. 12. 29.  8.  4. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [29.  1.  3. 11.  1.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1] -> size -> 73 
adversary victory points: 11
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 8. 8.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 1 8 3 3 0 6] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [13.  6. 30. 12. 29.  8.  4. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [29.  1.  3. 11.  1.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1] -> size -> 73 
adversary victory points: 11
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [29.  1.  3. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[45.793613]
 [50.862354]
 [48.312107]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3. 11.  1.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1] -> size -> 73 
action values: 1 
buys: 0 
player value: 0 
card supply: [13.  6. 30. 12. 29.  8.  4. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 8. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 1 8 3 3 0 6] -> size -> 8 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 6.531844139099121



action possibilites: [-1. 11.] 
expected returns: [[58.37223 ]
 [63.414494]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.] 
cards in deck: 52 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1] -> size -> 73 
action values: 1 
buys: 0 
player value: 1 
card supply: [13.  6. 30. 12. 29.  8.  4. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 8. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 1 8 3 3 0 6] -> size -> 8 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 46.14957046508789



action possibilites: [-1] 
expected returns: [[86.64607]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.] 
cards in deck: 52 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1] -> size -> 74 
action values: 0 
buys: 0 
player value: 1 
card supply: [13.  5. 30. 12. 29.  8.  4. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 8. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 1 8 3 3 0 6] -> size -> 8 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  300    0    0   40    0    0    0    0 -390    0    0
   27    0] 
sum of rewards: -28 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 61.349735260009766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[84.195366]
 [88.92985 ]
 [87.64636 ]
 [80.930565]
 [87.247314]
 [86.646065]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.] 
cards in deck: 52 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1] -> size -> 74 
action values: 0 
buys: 1 
player value: 3 
card supply: [13.  5. 30. 12. 29.  8.  4. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 8. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 1 8 3 3 0 6] -> size -> 8 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.64607238769531



buy possibilites: [-1] 
expected returns: [[99.51137]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1.] 
cards in deck: 52 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1] -> size -> 75 
action values: 0 
buys: 0 
player value: 0 
card supply: [13.  4. 30. 12. 29.  8.  4. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 8. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 1 8 3 3 0 6] -> size -> 8 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  300    0    0   40    0    0    0    0 -400    0    0
   54    0] 
sum of rewards: -11 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 88.92986297607422






Player: 1 
cards in hand: [6. 8. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 1 8 3 3 0 6] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [13.  4. 30. 12. 29.  8.  4. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  1. 15.  3. 25.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1] -> size -> 75 
adversary victory points: 11
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 1 8 3 0 6] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [13.  4. 30. 12. 29.  8.  4. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  1. 15.  3. 25.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1] -> size -> 75 
adversary victory points: 11
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 1 8 3 0 6] -> size -> 7 
action values: 0 
buys: 1 
player value: 3 
card supply: [13.  4. 30. 12. 29.  8.  4. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  1. 15.  3. 25.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1] -> size -> 75 
adversary victory points: 11
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1.] 
cards in discard: [1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 1 8 3 0 6 1] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [13.  3. 30. 12. 29.  8.  4. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  1. 15.  3. 25.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1] -> size -> 75 
adversary victory points: 11
player victory points: 0 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 15.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[33.819946]
 [35.53372 ]
 [41.110737]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 15.  3. 25.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1] -> size -> 75 
action values: 1 
buys: 0 
player value: 0 
card supply: [13.  3. 30. 12. 29.  8.  4. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [1. 0. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 1 8 3 0 6 1] -> size -> 8 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 99.51136779785156



action possibilites: [-1] 
expected returns: [[61.470325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 15.  3. 29. 29.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1] -> size -> 75 
action values: 0 
buys: 0 
player value: 0 
card supply: [13.  3. 30. 12. 29.  8.  3. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [1. 0. 3. 8. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 1 8 3 0 6 1 6] -> size -> 9 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.11074447631836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[57.59246 ]
 [65.32474 ]
 [62.81    ]
 [53.113472]
 [62.191383]
 [61.470325]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 15.  3. 29. 29.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1] -> size -> 75 
action values: 0 
buys: 1 
player value: 3 
card supply: [13.  3. 30. 12. 29.  8.  3. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [1. 0. 3. 8. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 1 8 3 0 6 1 6] -> size -> 9 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.4703254699707



buy possibilites: [-1] 
expected returns: [[39.269516]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 15.  3. 29. 29.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1  1] -> size -> 76 
action values: 0 
buys: 0 
player value: 0 
card supply: [13.  2. 30. 12. 29.  8.  3. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [1. 0. 3. 8. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 1 8 3 0 6 1 6] -> size -> 9 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -410    0    0
   54    0] 
sum of rewards: -11 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 65.32473754882812






Player: 1 
cards in hand: [1. 0. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 8. 8.] 
cards in discard: [6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 1 8 3 0 6 1 6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [13.  2. 30. 12. 29.  8.  3. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [29.  1.  3.  3. 25.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1  1] -> size -> 76 
adversary victory points: 11
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 1 8 6 1 6] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [13.  2. 30. 12. 29.  8.  3. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [29.  1.  3.  3. 25.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1  1] -> size -> 76 
adversary victory points: 11
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 1 8 6 1 6] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [13.  2. 30. 12. 29.  8.  3. 10.  0.  5.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [29.  1.  3.  3. 25.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1  1] -> size -> 76 
adversary victory points: 11
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [6. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 1 8 6 1 6 8] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [13.  2. 30. 12. 29.  8.  3. 10.  0.  4.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [29.  1.  3.  3. 25.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1  1] -> size -> 76 
adversary victory points: 11
player victory points: -2 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [29.  1.  3.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[23.26755 ]
 [25.119167]
 [25.968922]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3.  3. 25.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1  1] -> size -> 76 
action values: 1 
buys: 0 
player value: 0 
card supply: [13.  2. 30. 12. 29.  8.  3. 10.  0.  4.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 8. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [8 1 8 6 1 6 8] -> size -> 7 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.26951599121094



action possibilites: [-1] 
expected returns: [[22.310385]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3.  3. 15. 10.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29.] 
cards in deck: 38 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1  1] -> size -> 76 
action values: 0 
buys: 0 
player value: 0 
card supply: [13.  2. 30. 12. 29.  8.  2. 10.  0.  4.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 8. 6. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 1 8 6 1 6 8 6] -> size -> 8 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 25.968923568725586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.580618]
 [20.886375]
 [18.646591]
 [20.57829 ]
 [22.31038 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  3.  3. 15. 10.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29.] 
cards in deck: 38 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1  1] -> size -> 76 
action values: 0 
buys: 1 
player value: 2 
card supply: [13.  2. 30. 12. 29.  8.  2. 10.  0.  4.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [8. 8. 8. 6. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 1 8 6 1 6 8 6] -> size -> 8 
adversary victory points: -2
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.31038475036621






Player: 1 
cards in hand: [8. 8. 8. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8. 6. 1.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 1 8 6 1 6 8 6] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [13.  2. 30. 12. 29.  8.  2. 10.  0.  4.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  1.  3.  1. 15.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29. 25. 29.  1.  3.  3.
 15. 10.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1  1] -> size -> 76 
adversary victory points: 11
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [1 6 1 6 8 6] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [13.  2. 30. 12. 29.  8.  2. 10.  0.  4.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  1.  3.  1. 15.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29. 25. 29.  1.  3.  3.
 15. 10.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1  1] -> size -> 76 
adversary victory points: 11
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [1 6 1 6 8 6] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [13.  2. 30. 12. 29.  8.  2. 10.  0.  4.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  1.  3.  1. 15.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29. 25. 29.  1.  3.  3.
 15. 10.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1  1] -> size -> 76 
adversary victory points: 11
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1.] 
cards in discard: [6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [1 6 1 6 8 6 0] -> size -> 7 
action values: 0 
buys: 0 
player value: 2 
card supply: [12.  2. 30. 12. 29.  8.  2. 10.  0.  4.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [ 0.  1.  3.  1. 15.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29. 25. 29.  1.  3.  3.
 15. 10.] 
adversary owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1  1] -> size -> 76 
adversary victory points: 11
player victory points: -3 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  3.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[20.627823]
 [22.340792]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  1. 15.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29. 25. 29.  1.  3.  3.
 15. 10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3
 10 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0
 29  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1
  1  1  1  1] -> size -> 76 
action values: 1 
buys: 0 
player value: 0 
card supply: [12.  2. 30. 12. 29.  8.  2. 10.  0.  4.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 1. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [1 6 1 6 8 6 0] -> size -> 7 
adversary victory points: -3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 22.31038475036621



action possibilites: [-1] 
expected returns: [[25.772825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29. 25. 29.  1.  3.  3.
 15. 10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3 10
 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0 29
  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1  1
  1  1  1] -> size -> 75 
action values: 0 
buys: 0 
player value: 3 
card supply: [12.  2. 30. 12. 29.  8.  2. 10.  0.  4.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 1. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [1 6 1 6 8 6 0] -> size -> 7 
adversary victory points: -3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 22.340822219848633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[23.968184]
 [29.287487]
 [22.484808]
 [27.8041  ]
 [21.657612]
 [20.18849 ]
 [26.776838]
 [27.416965]
 [35.544907]
 [33.23433 ]
 [23.622992]
 [28.30217 ]
 [22.982876]
 [28.942293]
 [25.772825]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29. 25. 29.  1.  3.  3.
 15. 10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3 10
 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0 29
  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1  1
  1  1  1] -> size -> 75 
action values: 0 
buys: 1 
player value: 7 
card supply: [12.  2. 30. 12. 29.  8.  2. 10.  0.  4.  5.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 1. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [1 6 1 6 8 6 0] -> size -> 7 
adversary victory points: -3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.772825241088867



buy possibilites: [-1] 
expected returns: [[130.49428]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29. 25. 29.  1.  3.  3.
 15. 10. 25.] 
cards in deck: 33 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3 10
 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0 29
  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1  1
  1  1  1 25] -> size -> 76 
action values: 0 
buys: 0 
player value: 2 
card supply: [12.  2. 30. 12. 29.  8.  2. 10.  0.  4.  4.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [6. 1. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [1 6 1 6 8 6 0] -> size -> 7 
adversary victory points: -3
player victory points: 11 

Reward from previous game state: 
[  -5.     0.     0.   420.     0.     0.    20.     0.     0.     0.
    0.  -410.     0.     0.    62.5    0. ] 
sum of rewards: 87.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 35.544918060302734






Player: 1 
cards in hand: [6. 1. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 6. 1.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [1 6 1 6 8 6 0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [12.  2. 30. 12. 29.  8.  2. 10.  0.  4.  4.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [10.  1.  6.  1.  3.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29. 25. 29.  1.  3.  3.
 15. 10. 25. 15.  1.  3.  1.] 
adversary owned cards: [ 3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3 10
 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0 29
  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1  1
  1  1  1 25] -> size -> 76 
adversary victory points: 11
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 6. 1.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [1 6 1 6 8 6 0] -> size -> 7 
action values: 0 
buys: 1 
player value: 5 
card supply: [12.  2. 30. 12. 29.  8.  2. 10.  0.  4.  4.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [10.  1.  6.  1.  3.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29. 25. 29.  1.  3.  3.
 15. 10. 25. 15.  1.  3.  1.] 
adversary owned cards: [ 3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3 10
 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0 29
  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1  1
  1  1  1 25] -> size -> 76 
adversary victory points: 11
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 6. 1.] 
cards in discard: [1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [1 6 1 6 8 6 0 1] -> size -> 8 
action values: 0 
buys: 0 
player value: 2 
card supply: [12.  1. 30. 12. 29.  8.  2. 10.  0.  4.  4.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [10.  1.  6.  1.  3.] 
adversary cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29. 25. 29.  1.  3.  3.
 15. 10. 25. 15.  1.  3.  1.] 
adversary owned cards: [ 3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3 10
 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0 29
  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1  1
  1  1  1 25] -> size -> 76 
adversary victory points: 11
player victory points: -3 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [10.  1.  6.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[84.33921]
 [82.90201]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  6.  1.  3.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29. 25. 29.  1.  3.  3.
 15. 10. 25. 15.  1.  3.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3 10
 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0 29
  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1  1
  1  1  1 25] -> size -> 76 
action values: 1 
buys: 0 
player value: 0 
card supply: [12.  1. 30. 12. 29.  8.  2. 10.  0.  4.  4.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [1. 6. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [1 6 1 6 8 6 0 1] -> size -> 8 
adversary victory points: -3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 130.49427795410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[80.469025]
 [86.819534]
 [85.12023 ]
 [76.16239 ]
 [83.98714 ]
 [84.60128 ]
 [92.039795]
 [80.27941 ]
 [86.62993 ]
 [84.33922 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  6.  1.  3.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29. 25. 29.  1.  3.  3.
 15. 10. 25. 15.  1.  3.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3 10
 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0 29
  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1  1
  1  1  1 25] -> size -> 76 
action values: 0 
buys: 1 
player value: 4 
card supply: [12.  1. 30. 12. 29.  8.  2. 10.  0.  4.  4.  1. 10.  8.  0.  8.  1.] 
adversary cards in hand: [1. 6. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [1 6 1 6 8 6 0 1] -> size -> 8 
adversary victory points: -3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 84.3392333984375



Player 0 won the game! 



Player 0 bought cards:
Copper: 1 
Silver: 8 
Gold: 0 
Estate: 10 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 0 
Witch: 5 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10.  1.  6.  1.  3.] 
cards in discard: [ 3. 15.  6. 15.  1. 29. 29. 11. 25. 10. 15. 10.  3. 11. 29.  1. 11.  1.
  1. 29. 11.  3.  1.  1. 25.  0.  1. 15.  3. 29. 29. 25. 29.  1.  3.  3.
 15. 10. 25. 15.  1.  3.  1. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29 11 29 10 11 29 10 11 29 10  3 10 11 29 10  3 10 11 10  3 10
 29 11 15 11 15 11  3 15 15 15 15 15  3 25 15  3  1 29  1  1  3  1  0 29
  6 29  1  6  1  3  1  3  1  1  1  1  3  1  1  1 25  1  1 25  1 25  1  1
  1  1  1 25 29] -> size -> 77 
action values: 0 
buys: 0 
player value: 0 
card supply: [12.  1. 30. 12. 29.  8.  2. 10.  0.  4.  4.  0. 10.  8.  0.  8.  1.] 
adversary cards in hand: [1. 6. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [1 6 1 6 8 6 0 1] -> size -> 8 
adversary victory points: -3
player victory points: 11 

Reward from previous game state: 
[     -5 3000000       0     420       0       0       0       0       0
       0       0    -420       0       0      64       0] 
sum of rewards: 3000059 

action type: buy - action 29.0
Learning step: 119998.6796875
desired expected reward: 120090.71875



