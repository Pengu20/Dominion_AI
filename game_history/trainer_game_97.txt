 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[278.8229]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    3  -70    0    0   20    0    0    0    0  -20    0    0
    4    0] 
sum of rewards: -568 

action type: buy - action 8.0
Learning step: -28.297128677368164
desired expected reward: -30.35457992553711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[246.21028]
 [258.04507]
 [207.26675]
 [260.70987]
 [279.37057]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.237191200256348
desired expected reward: 272.96185302734375



buy possibilites: [-1] 
expected returns: [[253.31882]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 6 

action type: buy - action 8.0
Learning step: -7.035821437835693
desired expected reward: 253.674072265625






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[280.2405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 3. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.4792938232421875
desired expected reward: 246.8395233154297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[260.80475]
 [277.74243]
 [268.74756]
 [238.58817]
 [226.78125]
 [268.33948]
 [284.51886]
 [273.3001 ]
 [298.94772]
 [271.5793 ]
 [243.26958]
 [251.3047 ]
 [266.89355]
 [234.5888 ]
 [257.95035]
 [284.2276 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 3. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.793613433837891
desired expected reward: 271.6129150390625



buy possibilites: [-1] 
expected returns: [[259.86203]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 48 

action type: buy - action 25.0
Learning step: -6.700490474700928
desired expected reward: 292.2472229003906






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[269.37872]
 [279.6829 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.8841166496276855
desired expected reward: 252.97792053222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[248.89096]
 [256.08737]
 [216.30835]
 [259.65482]
 [270.93042]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.685971260070801
desired expected reward: 260.8138122558594



buy possibilites: [-1] 
expected returns: [[247.90451]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 25.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -20.887563705444336
desired expected reward: 195.4207763671875






Player: 1 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  3.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  3.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  3.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[220.917  ]
 [210.29597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 6.  3.  3.  0.  0. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.174445152282715
desired expected reward: 239.73007202148438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[196.04199]
 [212.29207]
 [205.0475 ]
 [167.40749]
 [218.0577 ]
 [206.59142]
 [201.56758]
 [217.35487]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 6.  3.  3.  0.  0. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -6.905371189117432
desired expected reward: 212.5753631591797



buy possibilites: [-1] 
expected returns: [[222.64508]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 6.  3.  3.  0.  0. 25.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -11.0 

action type: buy - action 8.0
Learning step: -5.870054244995117
desired expected reward: 200.7213134765625






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 3. 0. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  7.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[251.22464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  7.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -6.138976573944092
desired expected reward: 216.506103515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[216.07399]
 [236.7721 ]
 [226.49976]
 [188.66753]
 [174.07158]
 [225.28683]
 [243.94308]
 [230.06908]
 [261.6144 ]
 [228.15701]
 [193.91301]
 [204.97998]
 [222.94604]
 [183.96059]
 [212.12006]
 [243.67004]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  7.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.845694065093994
desired expected reward: 242.9666748046875



buy possibilites: [-1] 
expected returns: [[198.63786]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6  8 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 37 

action type: buy - action 25.0
Learning step: -6.7613701820373535
desired expected reward: 254.8530731201172






Player: 1 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 3. 3. 8.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6  8 25] -> size -> 15 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 3. 3. 8.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6  8 25] -> size -> 15 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 6. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[239.34392]
 [226.06705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3. 8.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6  8 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -5.320247650146484
desired expected reward: 193.31761169433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[207.5838 ]
 [161.44429]
 [236.43855]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 8.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6  8 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.642047882080078
desired expected reward: 229.94334411621094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [ 0.  0.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6  8 25] -> size -> 15 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  0.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6  8 25] -> size -> 15 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  0.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6  8 25] -> size -> 15 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[246.8678 ]
 [258.88425]
 [234.60114]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25  6  8 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0  8] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -5.571023464202881
desired expected reward: 216.36135864257812



action possibilites: [-1] 
expected returns: [[133.95813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0  8] -> size -> 11 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: trash_cards_n_from_hand - action 11
Learning step: -9.056490898132324
desired expected reward: 238.3544921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[108.278564]
 [ 81.124695]
 [123.40626 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0  8] -> size -> 11 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -3.860438585281372
desired expected reward: 130.09768676757812






Player: 1 
cards in hand: [8. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [ 8. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25] -> size -> 12 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 11  0  8] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [ 8. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25] -> size -> 12 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 11  0  8] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [ 8. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25] -> size -> 12 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 11  0  8  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [ 8. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25] -> size -> 12 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[160.8374]
 [173.0454]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  0.  0.] 
cards in discard: [ 8. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3  0 11  0  8  0] -> size -> 10 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -2.5363659858703613
desired expected reward: 120.86990356445312



action possibilites: [-1] 
expected returns: [[151.07033]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8. 6.] 
cards in discard: [ 8. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  8. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [0. 8. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  0 11  0  8  0  6] -> size -> 11 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action 25.0
Learning step: -4.496170997619629
desired expected reward: 169.4088897705078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[134.91594 ]
 [148.3053  ]
 [141.81229 ]
 [ 94.154755]
 [141.09477 ]
 [151.93282 ]
 [143.88295 ]
 [142.49683 ]
 [112.07306 ]
 [139.38281 ]
 [130.2414  ]
 [151.60236 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8. 6.] 
cards in discard: [ 8. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 30. 30.  8.  8. 10.  9.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [0. 8. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  0 11  0  8  0  6] -> size -> 11 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -3.5342705249786377
desired expected reward: 147.5360565185547



buy possibilites: [-1] 
expected returns: [[134.03687]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8. 6.] 
cards in discard: [ 8. 25. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8.  8. 10.  8.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [0. 8. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  0 11  0  8  0  6] -> size -> 11 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5.   0.   1.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 20.5 

action type: buy - action 11.0
Learning step: -3.5558106899261475
desired expected reward: 148.37698364257812






Player: 1 
cards in hand: [ 0.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [0. 8. 0. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  0  8  0  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  8. 10.  8.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11] -> size -> 13 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [0. 8. 0. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  0  8  0  6] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 30. 30.  8.  8. 10.  8.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11] -> size -> 13 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [ 0.  8.  0.  3.  6. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  0  8  0  6 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8.  8. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11] -> size -> 13 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[190.42891]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  8. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 11  0  8  0  6 11] -> size -> 12 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -2.1116855144500732
desired expected reward: 131.92518615722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[167.28726]
 [175.03862]
 [137.02065]
 [178.26581]
 [187.022  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8.  8. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 11  0  8  0  6 11] -> size -> 12 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -5.251847743988037
desired expected reward: 185.4218292236328



buy possibilites: [-1] 
expected returns: [[211.72292]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 30. 30.  8.  8. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 11  0  8  0  6 11] -> size -> 12 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.  10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -24.0 

action type: buy - action 0.0
Learning step: -4.800597190856934
desired expected reward: 162.4866485595703






Player: 1 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  0  8  0  6 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  8. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  8.  0.  0. 25.] 
adversary cards in discard: [0. 6. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  0  8  0  6 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 30. 30.  8.  8. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  8.  0.  0. 25.] 
adversary cards in discard: [0. 6. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [11.  8.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 25.] 
expected returns: [[303.79837]
 [302.44077]
 [290.99536]
 [312.85223]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  0. 25.] 
cards in discard: [0. 6. 0. 3. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  8. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  0 11  0  8  0  6 11] -> size -> 12 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -3.316209554672241
desired expected reward: 208.40670776367188



action possibilites: [-1] 
expected returns: [[221.1433]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  0. 25.  0.] 
cards in discard: [0. 6. 0. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  7. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  0 11  0  8  0  6 11  6] -> size -> 13 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 27 

action type: take_action - action 25.0
Learning step: -9.449912071228027
desired expected reward: 306.06280517578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[187.84373]
 [205.27747]
 [198.27701]
 [156.65524]
 [213.77887]
 [199.16277]
 [195.67537]
 [215.09502]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0.  0. 25.  0.] 
cards in discard: [0. 6. 0. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 30. 30.  8.  7. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  0 11  0  8  0  6 11  6] -> size -> 13 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1
Learning step: -5.150300025939941
desired expected reward: 215.9929962158203






Player: 1 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  0  8  0  6 11  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  7. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 11.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [11.  0.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 11  0  8  0  6 11  6] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  7. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 11.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [11.  0.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 11  0  8  0  6 11  6] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 30. 30.  8.  7. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 11.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [11.  0.  0.  0.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 11  0  8  0  6 11  6  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 30. 30.  8.  7. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 11.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [25. 11.  0.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.  8.] 
expected returns: [[159.35005]
 [173.33743]
 [161.49843]
 [155.70842]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0.  6.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  7. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 11  0  8  0  6 11  6  0] -> size -> 12 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: buy - action -1.0
Learning step: -6.186891078948975
desired expected reward: 208.90814208984375



action possibilites: [-1] 
expected returns: [[142.41312]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  8.  8. 25.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  6. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  6. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  0 11  0  8  0  6 11  6  0  6] -> size -> 13 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: take_action - action 25.0
Learning step: -3.606422185897827
desired expected reward: 170.17462158203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[126.64097]
 [106.004  ]
 [142.58566]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  8.  8. 25.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 30. 30.  8.  6. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  6. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  0 11  0  8  0  6 11  6  0  6] -> size -> 13 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: take_action - action -1
Learning step: -2.3313088417053223
desired expected reward: 140.08180236816406






Player: 1 
cards in hand: [ 8.  0. 11.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  6. 11.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11  0  8  0  6 11  6  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  6. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [25. 11.  0.  6.  8.  8. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
adversary victory points: 1
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 0 0 8 0 6 6 0 6] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  6. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [25. 11.  0.  6.  8.  8. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 0 0 8 0 6 6 0 6] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  6. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [25. 11.  0.  6.  8.  8. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[136.74615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [25. 11.  0.  6.  8.  8. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  6. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [0 3 0 0 8 0 6 6 0 6] -> size -> 10 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: buy - action -1.0
Learning step: -2.7641122341156006
desired expected reward: 139.82154846191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[113.83547 ]
 [125.12063 ]
 [118.98912 ]
 [ 91.5913  ]
 [118.91302 ]
 [128.29378 ]
 [121.788506]
 [120.501274]
 [101.52335 ]
 [117.04805 ]
 [110.98769 ]
 [127.128075]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [25. 11.  0.  6.  8.  8. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 30. 30.  8.  6. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [0 3 0 0 8 0 6 6 0 6] -> size -> 10 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1.0
Learning step: -2.774658203125
desired expected reward: 133.45516967773438



buy possibilites: [-1] 
expected returns: [[131.63873]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [25. 11.  0.  6.  8.  8. 25.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 30. 30. 30. 30.  8.  6. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [0 3 0 0 8 0 6 6 0 6] -> size -> 10 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.  30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -4.0 

action type: buy - action 0.0
Learning step: -2.929901599884033
desired expected reward: 110.90555572509766






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [6. 8. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 0 0 8 0 6 6 0 6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  6. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 25.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0] -> size -> 15 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [6. 8. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 0 0 8 0 6 6 0 6] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 30. 30. 30. 30.  8.  6. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 25.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0] -> size -> 15 
adversary victory points: 1
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [11. 25.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[142.08038]
 [144.2798 ]
 [158.42082]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  6. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 0 0 8 0 6 6 0 6] -> size -> 10 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: buy - action -1
Learning step: -1.8457252979278564
desired expected reward: 129.7930145263672



action possibilites: [-1] 
expected returns: [[86.92597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  5. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 3 0 0 8 0 6 6 0 6 6] -> size -> 11 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 48 

action type: take_action - action 25.0
Learning step: -3.5657432079315186
desired expected reward: 154.8657989501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 91.45241 ]
 [104.83479 ]
 [ 97.272354]
 [ 61.792046]
 [ 97.51758 ]
 [108.21285 ]
 [100.93886 ]
 [ 99.373215]
 [ 74.77902 ]
 [ 94.65525 ]
 [ 87.35454 ]
 [106.364685]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 30. 30. 30. 30.  8.  5. 10.  7.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 3 0 0 8 0 6 6 0 6 6] -> size -> 11 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: take_action - action -1
Learning step: 0.2072582244873047
desired expected reward: 87.13323211669922



buy possibilites: [-1] 
expected returns: [[136.65051]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.  0.  0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 30. 30.  8.  5. 10.  6.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 3 0 0 8 0 6 6 0 6 6] -> size -> 11 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5.   0.   1.  30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 50.5 

action type: buy - action 11.0
Learning step: 0.1889934539794922
desired expected reward: 108.40185546875






Player: 1 
cards in hand: [3. 8. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 6. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 0 0 8 0 6 6 0 6 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  5. 10.  6.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  6.  0.  0.  0.] 
adversary cards in discard: [11. 25. 11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11] -> size -> 16 
adversary victory points: 1
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 8 0 6 6 0 6 6] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  5. 10.  6.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  6.  0.  0.  0.] 
adversary cards in discard: [11. 25. 11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11] -> size -> 16 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 8 0 6 6 0 6 6] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 30. 30.  8.  5. 10.  6.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  6.  0.  0.  0.] 
adversary cards in discard: [11. 25. 11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11] -> size -> 16 
adversary victory points: 1
player victory points: -4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [25.  6.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[133.08551]
 [143.40564]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.  0.  0.  0.] 
cards in discard: [11. 25. 11.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  5. 10.  6.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [6. 8. 6. 0.] 
adversary owned cards: [0 0 8 0 6 6 0 6 6] -> size -> 9 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: buy - action -1
Learning step: -1.3859962224960327
desired expected reward: 135.26451110839844



action possibilites: [-1] 
expected returns: [[146.60309]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 8. 8.] 
cards in discard: [11. 25. 11.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  4. 10.  6.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [6. 8. 6. 0. 6.] 
adversary owned cards: [0 0 8 0 6 6 0 6 6 6] -> size -> 10 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 66 

action type: take_action - action 25.0
Learning step: -0.5305511355400085
desired expected reward: 142.05186462402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[107.05294 ]
 [126.396095]
 [118.68279 ]
 [ 71.08257 ]
 [135.56699 ]
 [119.92255 ]
 [115.810646]
 [136.92976 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 8. 8.] 
cards in discard: [11. 25. 11.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 30. 30.  8.  4. 10.  6.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [6. 8. 6. 0. 6.] 
adversary owned cards: [0 0 8 0 6 6 0 6 6 6] -> size -> 10 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 66 

action type: take_action - action -1
Learning step: -1.2054405212402344
desired expected reward: 145.39764404296875






Player: 1 
cards in hand: [0. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 0.] 
cards in discard: [6. 8. 6. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 0 6 6 0 6 6 6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  4. 10.  6.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11] -> size -> 16 
adversary victory points: 1
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 0.] 
cards in discard: [6. 8. 6. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 0 6 6 0 6 6 6] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 30. 30.  8.  4. 10.  6.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11] -> size -> 16 
adversary victory points: 1
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[140.36119]
 [138.02943]
 [138.02943]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  4. 10.  6.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 0 6 6 0 6 6 6] -> size -> 10 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[-5  0  1 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 56 

action type: buy - action -1.0
Learning step: -0.9504364132881165
desired expected reward: 135.9792938232422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[130.11624]
 [135.13094]
 [102.60967]
 [139.72064]
 [142.68501]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 30. 30.  8.  4. 10.  6.  7.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 0 6 6 0 6 6 6] -> size -> 10 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[-5  0  1 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 56 

action type: take_action - action -1.0
Learning step: -1.059320092201233
desired expected reward: 137.17762756347656



buy possibilites: [-1] 
expected returns: [[104.76688]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8. 3.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  4. 10.  6.  6.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 0 6 6 0 6 6 6] -> size -> 10 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[-5  0  1 60  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 64 

action type: buy - action 8.0
Learning step: -1.4287766218185425
desired expected reward: 138.29185485839844






Player: 1 
cards in hand: [0. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 0 6 6 0 6 6 6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  4. 10.  6.  6.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 11.  0.  3.  0.] 
adversary cards in discard: [8. 0. 0. 8. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11  8] -> size -> 17 
adversary victory points: 1
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 0 6 6 0 6 6 6] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 30. 30.  8.  4. 10.  6.  6.  8. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 11.  0.  3.  0.] 
adversary cards in discard: [8. 0. 0. 8. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11  8] -> size -> 17 
adversary victory points: 1
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  4. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25. 11.  0.  3.  0.] 
adversary cards in discard: [8. 0. 0. 8. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11  8] -> size -> 17 
adversary victory points: 1
player victory points: -5 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [25. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[186.2829 ]
 [194.30716]
 [184.86281]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0.  3.  0.] 
cards in discard: [8. 0. 0. 8. 8. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  4. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 6. 8. 6.] 
adversary cards in discard: [10.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10] -> size -> 11 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[-5  0  1 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 56 

action type: buy - action -1
Learning step: 1.8650985956192017
desired expected reward: 106.63197326660156



action possibilites: [-1] 
expected returns: [[84.573296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  0. 25.] 
cards in discard: [8. 0. 0. 8. 8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  3. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 6. 8. 6.] 
adversary cards in discard: [10.  0.  0.  0.  6.  6.  6.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6] -> size -> 12 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[-5  0  1 60  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 77 

action type: take_action - action 25.0
Learning step: -3.9380390644073486
desired expected reward: 190.44622802734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[76.55564 ]
 [87.50027 ]
 [81.48452 ]
 [54.238087]
 [90.83843 ]
 [84.28592 ]
 [79.46377 ]
 [89.59393 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  0. 25.] 
cards in discard: [8. 0. 0. 8. 8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 30. 30.  8.  3. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 6. 8. 6.] 
adversary cards in discard: [10.  0.  0.  0.  6.  6.  6.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6] -> size -> 12 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[-5  0  1 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 76 

action type: take_action - action -1
Learning step: 1.4859256744384766
desired expected reward: 86.05921936035156






Player: 1 
cards in hand: [6. 0. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 8. 6.] 
cards in discard: [10.  0.  0.  0.  6.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  3. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11  8] -> size -> 17 
adversary victory points: 1
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 8. 6.] 
cards in discard: [10.  0.  0.  0.  6.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 30. 30.  8.  3. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11  8] -> size -> 17 
adversary victory points: 1
player victory points: -6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[96.765236]
 [84.45949 ]
 [98.53041 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25  6  8 25 11  0  0 11  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  3. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6] -> size -> 12 
adversary victory points: -6
player victory points: 1 

Reward from previous game state: 
[-5  0  1 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 66 

action type: buy - action -1.0
Learning step: 0.9564823508262634
desired expected reward: 90.5504379272461



action possibilites: [-1] 
expected returns: [[78.023865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8 25  8 25 11  0  0 11  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  3. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6] -> size -> 12 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[-5  0  2 80  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 97 

action type: trash_cards_n_from_hand - action 9
Learning step: 1.120703101158142
desired expected reward: 110.81737518310547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[66.11422 ]
 [48.739674]
 [74.84015 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8 25  8 25 11  0  0 11  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  3. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6] -> size -> 12 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[-5  0  2 80  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 97 

action type: take_action - action -1
Learning step: 2.4876198768615723
desired expected reward: 80.51148223876953



buy possibilites: [-1] 
expected returns: [[17.64476]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8 25  8 25 11  0  0 11  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 30. 30.  8.  3. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6] -> size -> 12 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2  80   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 67 

action type: buy - action 0.0
Learning step: 0.44129523634910583
desired expected reward: 66.55552673339844






Player: 1 
cards in hand: [ 0.  6. 10.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  6.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 30. 30.  8.  3. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 25.  8.] 
adversary cards in discard: [ 0.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3  8 25  8 25 11  0  0 11  8  0] -> size -> 15 
adversary victory points: 2
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  6.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 30. 30.  8.  3. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 25.  8.] 
adversary cards in discard: [ 0.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3  8 25  8 25 11  0  0 11  8  0] -> size -> 15 
adversary victory points: 2
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  6.  8.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 30. 30.  8.  3. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 25.  8.] 
adversary cards in discard: [ 0.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3  8 25  8 25 11  0  0 11  8  0] -> size -> 15 
adversary victory points: 2
player victory points: -6 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8.] 
expected returns: [[42.643024]
 [44.70797 ]
 [56.03    ]
 [37.55669 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 25.  8.] 
cards in discard: [ 0.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 25  8 25 11  0  0 11  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 30. 30.  8.  3. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 6.] 
adversary cards in discard: [ 0.  0.  6. 10.  6.  8.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0] -> size -> 13 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[-5  0  2 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 77 

action type: buy - action -1
Learning step: 4.09280252456665
desired expected reward: 21.73756217956543



action possibilites: [-1] 
expected returns: [[137.5655]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.] 
cards in discard: [ 0.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 30. 30.  8.  3. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 6.] 
adversary cards in discard: [ 0.  0.  6. 10.  6.  8.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0] -> size -> 13 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[-5  0  2 80  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 97 

action type: trash_cards_n_from_hand - action 9
Learning step: 5.550692081451416
desired expected reward: 53.44132995605469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[124.367226]
 [ 92.27777 ]
 [140.7425  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.] 
cards in discard: [ 0.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 30. 30. 30. 30.  8.  3. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 6.] 
adversary cards in discard: [ 0.  0.  6. 10.  6.  8.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0] -> size -> 13 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[-5  0  2 80  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 97 

action type: take_action - action -1
Learning step: 0.8683006167411804
desired expected reward: 138.43380737304688



buy possibilites: [-1] 
expected returns: [[68.719284]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.] 
cards in discard: [ 0.  8. 11.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 30. 30.  8.  2. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 6.] 
adversary cards in discard: [ 0.  0.  6. 10.  6.  8.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0] -> size -> 13 
adversary victory points: -6
player victory points: 1 

Reward from previous game state: 
[  -5    0    1   70    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -214 

action type: buy - action 6.0
Learning step: -13.767704963684082
desired expected reward: 78.51006317138672






Player: 1 
cards in hand: [0. 6. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 6.] 
cards in discard: [ 0.  0.  6. 10.  6.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 30. 30.  8.  2. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 25.  3.] 
adversary cards in discard: [ 0.  8. 11.  6.  8.  3. 25.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6] -> size -> 14 
adversary victory points: 1
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 6.] 
cards in discard: [ 0.  0.  6. 10.  6.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 30. 30.  8.  2. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 25.  3.] 
adversary cards in discard: [ 0.  8. 11.  6.  8.  3. 25.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6] -> size -> 14 
adversary victory points: 1
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 6.] 
cards in discard: [ 0.  0.  6. 10.  6.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 30. 30. 30. 30.  8.  2. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 25.  3.] 
adversary cards in discard: [ 0.  8. 11.  6.  8.  3. 25.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6] -> size -> 14 
adversary victory points: 1
player victory points: -6 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[23.761293]
 [19.208143]
 [27.115294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 25.  3.] 
cards in discard: [ 0.  8. 11.  6.  8.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 30. 30.  8.  2. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 6. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0] -> size -> 14 
adversary victory points: -6
player victory points: 1 

Reward from previous game state: 
[-5  0  1 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 66 

action type: buy - action -1
Learning step: 0.40186309814453125
desired expected reward: 69.12114715576172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[16.640596 ]
 [19.761698 ]
 [ 7.3906965]
 [19.630322 ]
 [24.072912 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 25.  3.] 
cards in discard: [ 0.  8. 11.  6.  8.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 30. 30.  8.  2. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 6. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0] -> size -> 14 
adversary victory points: -6
player victory points: 1 

Reward from previous game state: 
[-5  0  1 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 66 

action type: take_action - action -1.0
Learning step: 2.6113171577453613
desired expected reward: 25.574586868286133



buy possibilites: [-1] 
expected returns: [[65.54713]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 25.  3.] 
cards in discard: [ 0.  8. 11.  6.  8.  3. 25.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 30. 30. 30. 30.  8.  1. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 6. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0] -> size -> 14 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.   60.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -245.0 

action type: buy - action 6.0
Learning step: -11.14472484588623
desired expected reward: -3.7540283203125






Player: 1 
cards in hand: [8. 6. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 30. 30.  8.  1. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
adversary victory points: 0
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 30. 30. 30. 30.  8.  1. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
adversary victory points: 0
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6. 0. 6.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 30. 30.  8.  1. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
adversary victory points: 0
player victory points: -6 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [8. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[83.78841]
 [74.91285]
 [74.91285]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 30. 30.  8.  1. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [0. 8. 6. 6. 0. 6.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0] -> size -> 15 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 1.2163437604904175
desired expected reward: 66.76347351074219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[61.694237]
 [68.50152 ]
 [32.50527 ]
 [69.93641 ]
 [78.67088 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 30. 30.  8.  1. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [0. 8. 6. 6. 0. 6.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0] -> size -> 15 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0.27670517563819885
desired expected reward: 81.04273986816406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [0. 8. 6. 6. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 30. 30.  8.  1. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  6. 25.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
adversary victory points: 0
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [0. 8. 6. 6. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 30. 30.  8.  1. 10.  6.  6.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  6. 25.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
adversary victory points: 0
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [0. 8. 6. 6. 0. 6. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 30. 30.  8.  1. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  6. 25.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
adversary victory points: 0
player victory points: -6 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[111.017456]
 [124.33632 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  6. 25.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 30. 30.  8.  1. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8] -> size -> 16 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 1.4610382318496704
desired expected reward: 80.7165298461914



action possibilites: [-1] 
expected returns: [[69.33183]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  6. 11. 25.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 30. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6] -> size -> 17 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: -0.8196040987968445
desired expected reward: 121.77180480957031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[56.361805]
 [60.891052]
 [61.82293 ]
 [69.872185]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  6. 11. 25.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 30. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6] -> size -> 17 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 1.7601054906845093
desired expected reward: 71.0919418334961






Player: 1 
cards in hand: [ 0.  0.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  6. 10.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 30. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
adversary victory points: 0
player victory points: -7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 30. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
adversary victory points: 0
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 30. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
adversary victory points: 0
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [6. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
adversary victory points: 0
player victory points: -6 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [25.  0.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[60.8892 ]
 [71.2378 ]
 [52.46183]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  6.  0.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 6. 8. 6.] 
adversary cards in discard: [ 6.  3. 10.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3] -> size -> 18 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0.7122028470039368
desired expected reward: 70.58439636230469



action possibilites: [-1] 
expected returns: [[38.945465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 6. 8. 6.] 
adversary cards in discard: [ 6.  3. 10.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3] -> size -> 18 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 76 

action type: take_action - action 25.0
Learning step: 1.1713497638702393
desired expected reward: 71.26981353759766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[31.227312]
 [42.137978]
 [36.027245]
 [43.871277]
 [39.016186]
 [33.695065]
 [41.251286]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 6. 8. 6.] 
adversary cards in discard: [ 6.  3. 10.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3] -> size -> 18 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 2.7186391353607178
desired expected reward: 41.66410446166992






Player: 1 
cards in hand: [0. 8. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 8. 6.] 
cards in discard: [ 6.  3. 10.  0.  0.  0.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 25.  6.  0.  8.] 
adversary cards in discard: [25.  0.  6.  0.  8.  0.  8.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
adversary victory points: 0
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 8. 6.] 
cards in discard: [ 6.  3. 10.  0.  0.  0.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 30. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 25.  6.  0.  8.] 
adversary cards in discard: [25.  0.  6.  0.  8.  0.  8.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
adversary victory points: 0
player victory points: -6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11. 25.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8.] 
expected returns: [[51.232628]
 [51.178104]
 [61.167618]
 [41.87772 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  6.  0.  8.] 
cards in discard: [25.  0.  6.  0.  8.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [ 6.  3. 10.  0.  0.  0.  6.  6.  0.  8.  6.  8.  6.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3] -> size -> 18 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 1.946089744567871
desired expected reward: 43.197391510009766



action possibilites: [-1] 
expected returns: [[40.564564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  8.  3.  0.] 
cards in discard: [25.  0.  6.  0.  8.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [ 6.  3. 10.  0.  0.  0.  6.  6.  0.  8.  6.  8.  6.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3] -> size -> 18 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 76 

action type: take_action - action 25.0
Learning step: 1.671091914176941
desired expected reward: 62.5033073425293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[30.651155]
 [34.25522 ]
 [35.887486]
 [40.320164]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  8.  3.  0.] 
cards in discard: [25.  0.  6.  0.  8.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [ 6.  3. 10.  0.  0.  0.  6.  6.  0.  8.  6.  8.  6.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3] -> size -> 18 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 2.5659632682800293
desired expected reward: 43.13052749633789






Player: 1 
cards in hand: [6. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [ 6.  3. 10.  0.  0.  0.  6.  6.  0.  8.  6.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
adversary victory points: 0
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [ 6.  3. 10.  0.  0.  0.  6.  6.  0.  8.  6.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
adversary victory points: 0
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [ 6.  3. 10.  0.  0.  0.  6.  6.  0.  8.  6.  8.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
adversary victory points: 0
player victory points: -6 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[88.91529]
 [80.85243]
 [89.28116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3  1] -> size -> 19 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 2.656583070755005
desired expected reward: 42.976749420166016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[68.292244]
 [73.769714]
 [74.80849 ]
 [83.06836 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3  1] -> size -> 19 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0.1914089173078537
desired expected reward: 86.72335052490234



buy possibilites: [-1] 
expected returns: [[40.12355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.  3.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 29. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3  1] -> size -> 19 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.  60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 25.0 

action type: buy - action 0.0
Learning step: -1.2618324756622314
desired expected reward: 67.03041076660156






Player: 1 
cards in hand: [6. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 25.  6.  0.  0.] 
adversary cards in discard: [ 0.  8. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0] -> size -> 16 
adversary victory points: 0
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 29. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 25.  6.  0.  0.] 
adversary cards in discard: [ 0.  8. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0] -> size -> 16 
adversary victory points: 0
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3  1  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 29. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 25.  6.  0.  0.] 
adversary cards in discard: [ 0.  8. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0] -> size -> 16 
adversary victory points: 0
player victory points: -6 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[67.11115]
 [77.57298]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  6.  0.  0.] 
cards in discard: [ 0.  8. 11.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 8. 6. 8. 6.] 
adversary cards in discard: [0. 6. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3  1  0] -> size -> 20 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 2.4116172790527344
desired expected reward: 42.5351676940918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[49.37862 ]
 [56.980625]
 [58.124832]
 [64.43557 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  6.  0.  0.] 
cards in discard: [ 0.  8. 11.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 8. 6. 8. 6.] 
adversary cards in discard: [0. 6. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3  1  0] -> size -> 20 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0.782550036907196
desired expected reward: 67.32638549804688



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [1. 8. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 6. 8. 6.] 
cards in discard: [0. 6. 6. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  6  6  0  6  6  6 10  6  0  0  0  8  6  3  1  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  8.  6.  0.  8.] 
adversary cards in discard: [ 0.  8. 11.  0.  0.  3.  3. 25.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0] -> size -> 16 
adversary victory points: 0
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [0. 6. 6. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  8.  6.  0.  8.] 
adversary cards in discard: [ 0.  8. 11.  0.  0.  3.  3. 25.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0] -> size -> 16 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0. 6. 6. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 29. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  8.  6.  0.  8.] 
adversary cards in discard: [ 0.  8. 11.  0.  0.  3.  3. 25.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0] -> size -> 16 
adversary victory points: 0
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0. 6. 6. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  8.  6.  0.  8.] 
adversary cards in discard: [ 0.  8. 11.  0.  0.  3.  3. 25.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0] -> size -> 16 
adversary victory points: 0
player victory points: -4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [25.  8.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.  8.] 
expected returns: [[52.443573]
 [56.777008]
 [43.8803  ]
 [43.8803  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  6.  0.  8.] 
cards in discard: [ 0.  8. 11.  0.  0.  3.  3. 25.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 6. 6. 0. 0. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0] -> size -> 17 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[-5  0  0 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: buy - action -1.0
Learning step: -0.3361968994140625
desired expected reward: 64.09938049316406



action possibilites: [-1] 
expected returns: [[63.558964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 6. 6. 0. 0. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0] -> size -> 17 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[-5  0  0 40  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 57 

action type: take_action - action 25.0
Learning step: 1.5575107336044312
desired expected reward: 55.860206604003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[57.96507 ]
 [63.697346]
 [59.751045]
 [64.536766]
 [62.47488 ]
 [58.955566]
 [63.022655]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 29. 30. 29. 30.  8.  0. 10.  6.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 6. 6. 0. 0. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0] -> size -> 17 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[-5  0  0 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0.9860017895698547
desired expected reward: 64.54496765136719



buy possibilites: [-1] 
expected returns: [[85.70193]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 8. 0. 0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 6. 6. 0. 0. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0] -> size -> 17 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[-5  0  0 40  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 73 

action type: buy - action 11.0
Learning step: 2.351454496383667
desired expected reward: 66.88822937011719






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 6. 6. 0. 0. 0. 0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  6.  3. 11.] 
adversary cards in discard: [11. 25.  8.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11] -> size -> 17 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 6. 6. 0. 0. 0. 0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  6.  3. 11.] 
adversary cards in discard: [11. 25.  8.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11] -> size -> 17 
adversary victory points: 0
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  6.  6.  0.  0.  0.  0.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  6.  3. 11.] 
adversary cards in discard: [11. 25.  8.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11] -> size -> 17 
adversary victory points: 0
player victory points: -4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[44.34371 ]
 [35.966885]
 [44.177982]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6.  3. 11.] 
cards in discard: [11. 25.  8.  6.  0.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  6. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14] -> size -> 18 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[-5  0  0 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: buy - action -1
Learning step: -1.6248667240142822
desired expected reward: 84.07705688476562



action possibilites: [-1] 
expected returns: [[56.726295]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 3.] 
cards in discard: [11. 25.  8.  6.  0.  8.  0.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14] -> size -> 18 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[-5  0  0 40  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 71 

action type: gain_card_n - action 9
Learning step: 2.5397942066192627
desired expected reward: 48.27074432373047





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[47.611176]
 [62.29581 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 3.] 
cards in discard: [11. 25.  8.  6.  0.  8.  0.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14] -> size -> 18 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[-5  0  0 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 1.2235745191574097
desired expected reward: 57.94987106323242



buy possibilites: [-1] 
expected returns: [[48.60415]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 3.] 
cards in discard: [11. 25.  8.  6.  0.  8.  0.  0. 15.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11 15  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14] -> size -> 18 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.  40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 25.0 

action type: buy - action 0.0
Learning step: -0.03696403652429581
desired expected reward: 47.574180603027344






Player: 1 
cards in hand: [ 0.  6.  6. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 10.  6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11 15  0] -> size -> 19 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 10.  6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11 15  0] -> size -> 19 
adversary victory points: 0
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 10.  6.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11 15  0] -> size -> 19 
adversary victory points: 0
player victory points: -4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[50.567608]
 [58.566956]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11 15  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 0.  0.  6.  6. 10.  6.] 
adversary owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0] -> size -> 19 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[-5  0  0 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: buy - action -1
Learning step: 0.5473846793174744
desired expected reward: 49.15153503417969



action possibilites: [-1] 
expected returns: [[49.352997]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11 15  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 0.  0.  6.  6. 10.  6.] 
adversary owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0] -> size -> 19 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[-5  0  0 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 25.0
Learning step: 1.0227625370025635
desired expected reward: 57.77635955810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[43.279064]
 [46.68856 ]
 [45.925045]
 [48.57067 ]
 [45.296474]
 [45.049496]
 [48.55868 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 11.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11 15  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 0.  0.  6.  6. 10.  6.] 
adversary owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0] -> size -> 19 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[-5  0  0 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 1.3455036878585815
desired expected reward: 50.69850158691406



buy possibilites: [-1] 
expected returns: [[33.492165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 11.  3.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11 15  0 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 0.  0.  6.  6. 10.  6.] 
adversary owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0] -> size -> 19 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[-5  0  0 40  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 73 

action type: buy - action 10.0
Learning step: 2.151099443435669
desired expected reward: 47.200584411621094






Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 0.  0.  6.  6. 10.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 8. 6. 8.] 
adversary cards in discard: [10. 25.  0.  0.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11 15  0 10] -> size -> 20 
adversary victory points: 0
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0.  0.  6.  6. 10.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 8. 6. 8.] 
adversary cards in discard: [10. 25.  0.  0.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11 15  0 10] -> size -> 20 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  0.  6.  6. 10.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 29. 30. 29. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 8. 6. 8.] 
adversary cards in discard: [10. 25.  0.  0.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11 15  0 10] -> size -> 20 
adversary victory points: 0
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  0.  6.  6. 10.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 8. 6. 8.] 
adversary cards in discard: [10. 25.  0.  0.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11 15  0 10] -> size -> 20 
adversary victory points: 0
player victory points: -3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [0. 8. 8. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
expected returns: [[71.99468]
 [62.75877]
 [62.75877]
 [62.75877]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 6. 8.] 
cards in discard: [10. 25.  0.  0.  0.  3. 11.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8 25  8 25  0  0 11  8  0  6  6  0 11 15  0 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [ 0.  0.  6.  6. 10.  6.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3] -> size -> 18 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 1.050183892250061
desired expected reward: 34.5423469543457



action possibilites: [-1] 
expected returns: [[-11.385075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [10. 25.  0.  0.  0.  3. 11.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [ 0.  0.  6.  6. 10.  6.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3] -> size -> 18 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: trash_cards_n_from_hand - action 3
Learning step: -0.8188617825508118
desired expected reward: 55.435089111328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ -9.5949745]
 [-11.51855  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [10. 25.  0.  0.  0.  3. 11.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 29. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [ 0.  0.  6.  6. 10.  6.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3] -> size -> 18 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 2.591346263885498
desired expected reward: -8.79372787475586



buy possibilites: [-1] 
expected returns: [[51.48116]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [10. 25.  0.  0.  0.  3. 11.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 29. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [ 0.  0.  6.  6. 10.  6.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3] -> size -> 18 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.  30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 2.358818769454956
desired expected reward: -7.236156463623047






Player: 1 
cards in hand: [0. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [ 0.  0.  6.  6. 10.  6.  3.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15. 11.  0.  6.] 
adversary cards in discard: [10. 25.  0.  0.  0.  3. 11.  3.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0] -> size -> 19 
adversary victory points: 0
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [ 0.  0.  6.  6. 10.  6.  3.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 29. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15. 11.  0.  6.] 
adversary cards in discard: [10. 25.  0.  0.  0.  3. 11.  3.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0] -> size -> 19 
adversary victory points: 0
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [ 0.  0.  6.  6. 10.  6.  3.  8.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15. 11.  0.  6.] 
adversary cards in discard: [10. 25.  0.  0.  0.  3. 11.  3.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0] -> size -> 19 
adversary victory points: 0
player victory points: -3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 15. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[30.385296]
 [21.416502]
 [30.304222]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11.  0.  6.] 
cards in discard: [10. 25.  0.  0.  0.  3. 11.  3.  0.  8.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1] -> size -> 19 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: -0.7366388440132141
desired expected reward: 50.74452209472656



action possibilites: [-1] 
expected returns: [[21.904182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  6.] 
cards in discard: [10. 25.  0.  0.  0.  3. 11.  3.  0.  8.  0.  6. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1] -> size -> 19 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: gain_card_n - action 9
Learning step: 2.079559326171875
desired expected reward: 31.345252990722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 5.422742 ]
 [14.2364435]
 [16.00362  ]
 [21.69615  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  6.] 
cards in discard: [10. 25.  0.  0.  0.  3. 11.  3.  0.  8.  0.  6. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1] -> size -> 19 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 1.5510114431381226
desired expected reward: 23.4551944732666



buy possibilites: [-1] 
expected returns: [[43.893738]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  6.] 
cards in discard: [10. 25.  0.  0.  0.  3. 11.  3.  0.  8.  0.  6. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1] -> size -> 19 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.  30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 1.4664725065231323
desired expected reward: 6.889204025268555






Player: 1 
cards in hand: [ 8.  0.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  0. 14.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6. 11.  8.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0] -> size -> 21 
adversary victory points: 0
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [11. 25.] 
adversary owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0] -> size -> 21 
adversary victory points: 0
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  8.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [11. 25.] 
adversary owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0] -> size -> 21 
adversary victory points: 0
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0.] 
cards in discard: [15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  7.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [11. 25.] 
adversary owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0] -> size -> 21 
adversary victory points: 0
player victory points: -3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[15.010932]
 [ 9.984145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0.] 
cards in discard: [11. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  7.] 
adversary cards in hand: [10.  1.  0.  0.  0.] 
adversary cards in discard: [15. 14.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15] -> size -> 20 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0  30   0   0   0 -30   0   0   0   0   0   0 100   0] 
sum of rewards: 95 

action type: discard_down_to_3_cards - action 4
Learning step: 4.682593822479248
desired expected reward: 10.695186614990234





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 1.3121984]
 [11.698709 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0.] 
cards in discard: [11. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  7.] 
adversary cards in hand: [10.  1.  0.  0.  0.] 
adversary cards in discard: [15. 14.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15] -> size -> 20 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0.855061948299408
desired expected reward: 12.720102310180664



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  1.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  0.  0.] 
cards in discard: [15. 14.  8.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  7.] 
adversary cards in hand: [15. 25.  3.  0.  3.] 
adversary cards in discard: [11. 25.  6.  8.  0.] 
adversary owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0] -> size -> 21 
adversary victory points: 0
player victory points: -3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 6.] 
cards in discard: [15. 14.  8.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  7.] 
adversary cards in hand: [15. 25.  3.  0.  3.] 
adversary cards in discard: [11. 25.  6.  8.  0.] 
adversary owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0] -> size -> 21 
adversary victory points: 0
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 6.] 
cards in discard: [15. 14.  8.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  8. 10.  7.] 
adversary cards in hand: [15. 25.  3.  0.  3.] 
adversary cards in discard: [11. 25.  6.  8.  0.] 
adversary owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0] -> size -> 21 
adversary victory points: 0
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 6.] 
cards in discard: [15. 14.  8.  0.  3.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [15. 25.  3.  0.  3.] 
adversary cards in discard: [11. 25.  6.  8.  0.] 
adversary owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0] -> size -> 21 
adversary victory points: 0
player victory points: -3 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [15. 25.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[7.6402597]
 [5.6852436]
 [7.4460955]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25.  3.  0.  3.] 
cards in discard: [11. 25.  6.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 6. 6. 6.] 
adversary cards in discard: [15. 14.  8.  0.  3.  0. 10. 10.  1.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10] -> size -> 21 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0.792730450630188
desired expected reward: 12.491426467895508



action possibilites: [-1] 
expected returns: [[-37.860382]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  3.  0.  6.] 
cards in discard: [11. 25.  6.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 6. 6. 6.] 
adversary cards in discard: [15. 14.  8.  0.  3.  0. 10. 10.  1.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10] -> size -> 21 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 46 

action type: take_action - action 25.0
Learning step: 1.1612870693206787
desired expected reward: 6.898374557495117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-38.9439  ]
 [-35.772114]
 [-37.62629 ]
 [-34.73503 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  3.  0.  6.] 
cards in discard: [11. 25.  6.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 28. 30. 28. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 6. 6. 6.] 
adversary cards in discard: [15. 14.  8.  0.  3.  0. 10. 10.  1.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10] -> size -> 21 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 3.3360557556152344
desired expected reward: -34.52432632446289



buy possibilites: [-1] 
expected returns: [[14.708749]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  3.  0.  6.] 
cards in discard: [11. 25.  6.  8.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 27. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 6. 6. 6.] 
adversary cards in discard: [15. 14.  8.  0.  3.  0. 10. 10.  1.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10] -> size -> 21 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 64 

action type: buy - action 3.0
Learning step: 5.319551944732666
desired expected reward: -30.452550888061523






Player: 1 
cards in hand: [0. 0. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 6.] 
cards in discard: [15. 14.  8.  0.  3.  0. 10. 10.  1.  0.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 27. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [15. 10. 11.  0.  0.] 
adversary cards in discard: [11. 25.  6.  8.  0.  3. 25. 15.  3.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3] -> size -> 22 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 6.] 
cards in discard: [15. 14.  8.  0.  3.  0. 10. 10.  1.  0.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 28. 30. 27. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [15. 10. 11.  0.  0.] 
adversary cards in discard: [11. 25.  6.  8.  0.  3. 25. 15.  3.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3] -> size -> 22 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 6.] 
cards in discard: [15. 14.  8.  0.  3.  0. 10. 10.  1.  0.  0.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 28. 30. 27. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [15. 10. 11.  0.  0.] 
adversary cards in discard: [11. 25.  6.  8.  0.  3. 25. 15.  3.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3] -> size -> 22 
adversary victory points: 1
player victory points: -3 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [15. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11.] 
expected returns: [[ 1.8597982]
 [-3.661448 ]
 [-2.231712 ]
 [ 2.3893034]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11.  0.  0.] 
cards in discard: [11. 25.  6.  8.  0.  3. 25. 15.  3.  0.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 27. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0] -> size -> 22 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: buy - action -1
Learning step: 1.0675678253173828
desired expected reward: 15.77631664276123



action possibilites: [-1] 
expected returns: [[-2.9614568]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  0.] 
cards in discard: [11. 25.  6.  8.  0.  3. 25. 15.  3.  0.  3.  0.  6. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 27. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 10.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0] -> size -> 22 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 3.3964297771453857
desired expected reward: 6.135176658630371





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-12.894072  ]
 [ -6.366295  ]
 [ -9.109938  ]
 [ -0.16973162]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.  0.] 
cards in discard: [11. 25.  6.  8.  0.  3. 25. 15.  3.  0.  3.  0.  6. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 28. 30. 27. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 10.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0] -> size -> 22 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 56 

action type: take_action - action -1
Learning step: 2.8571996688842773
desired expected reward: -0.10425710678100586



buy possibilites: [-1] 
expected returns: [[30.629969]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.  0.] 
cards in discard: [11. 25.  6.  8.  0.  3. 25. 15.  3.  0.  3.  0.  6. 15.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 26. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 10.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0] -> size -> 22 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 75 

action type: buy - action 3.0
Learning step: 4.578435897827148
desired expected reward: 1.7932069301605225






Player: 1 
cards in hand: [ 0. 10.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 26. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [15.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3] -> size -> 24 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 28. 30. 26. 30.  8.  0. 10.  5.  5.  8. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [15.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3] -> size -> 24 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  6.] 
cards in discard: [8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 26. 30.  8.  0. 10.  5.  4.  8. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [15.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3] -> size -> 24 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [15.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[-1.8052294]
 [-4.478655 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 26. 30.  8.  0. 10.  5.  4.  8. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [6. 6. 0. 8. 0.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8] -> size -> 23 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: buy - action -1
Learning step: 0.7590228319168091
desired expected reward: 31.388992309570312



action possibilites: [-1] 
expected returns: [[31.228708]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 28. 30. 26. 30.  8.  0. 10.  5.  4.  8. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [6. 6. 0. 8. 0.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8] -> size -> 23 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 67 

action type: take_action - action 15.0
Learning step: 4.284696578979492
desired expected reward: -0.35631895065307617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[22.671535]
 [29.500162]
 [19.150702]
 [26.171806]
 [15.090655]
 [25.789394]
 [31.464575]
 [26.830578]
 [38.80544 ]
 [26.269922]
 [16.079962]
 [19.418655]
 [24.17126 ]
 [14.259513]
 [20.80805 ]
 [31.632303]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [12. 28. 30. 26. 30.  8.  0. 10.  5.  4.  8. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [6. 6. 0. 8. 0.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8] -> size -> 23 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 67 

action type: take_action - action -1
Learning step: 2.479858160018921
desired expected reward: 33.70856475830078



buy possibilites: [-1] 
expected returns: [[-6.0764046]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [6. 6. 0. 8. 0.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8] -> size -> 23 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5.   0.   2.  50.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 79.5 

action type: buy - action 25.0
Learning step: 1.8980093002319336
desired expected reward: 40.70344161987305






Player: 1 
cards in hand: [6. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 8. 0.] 
cards in discard: [ 8.  0. 10.  0.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [25.  0. 15.  0.  0.] 
adversary cards in discard: [25. 15.  0.  0.  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25] -> size -> 24 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 8. 0.] 
cards in discard: [ 8.  0. 10.  0.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 28. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [25.  0. 15.  0.  0.] 
adversary cards in discard: [25. 15.  0.  0.  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25] -> size -> 24 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 8. 0.] 
cards in discard: [ 8.  0. 10.  0.  3.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 28. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [25.  0. 15.  0.  0.] 
adversary cards in discard: [25. 15.  0.  0.  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25] -> size -> 24 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [25.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
expected returns: [[-21.93737  ]
 [ -3.2850118]
 [-51.60825  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 15.  0.  0.] 
cards in discard: [25. 15.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0. 15.  1.  0.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  6.  0.  6.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0] -> size -> 24 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: buy - action -1
Learning step: 2.3135600090026855
desired expected reward: -3.7628445625305176





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-44.48684 ]
 [-27.575308]
 [-32.6489  ]
 [-21.580687]
 [-36.663017]
 [-39.401966]
 [-19.922892]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 15.  0.  0.] 
cards in discard: [25. 15.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 28. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0. 15.  1.  0.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  6.  0.  6.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0] -> size -> 24 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1.0
Learning step: 2.778437852859497
desired expected reward: -17.713056564331055



buy possibilites: [-1] 
expected returns: [[37.767265]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 15.  0.  0.] 
cards in discard: [25. 15.  0.  0.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0. 15.  1.  0.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  6.  0.  6.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0] -> size -> 24 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 65 

action type: buy - action 1.0
Learning step: 5.478529453277588
desired expected reward: -22.096792221069336






Player: 1 
cards in hand: [ 0.  0. 15.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  1.  0.] 
cards in discard: [ 8.  0. 10.  0.  3.  6.  0.  6.  6.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 3.  6.  3. 10. 11.] 
adversary cards in discard: [25. 15.  0.  0.  0.  1. 25.  0. 15.  0.  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [ 8.  0. 10.  0.  3.  6.  0.  6.  6.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 3.  6.  3. 10. 11.] 
adversary cards in discard: [25. 15.  0.  0.  0.  1. 25.  0. 15.  0.  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 8.  0. 10.  0.  3.  6.  0.  6.  6.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 7 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 3.  6.  3. 10. 11.] 
adversary cards in discard: [25. 15.  0.  0.  0.  1. 25.  0. 15.  0.  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 8.  0. 10.  0.  3.  6.  0.  6.  6.  0.  8.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 3.  6.  3. 10. 11.] 
adversary cards in discard: [25. 15.  0.  0.  0.  1. 25.  0. 15.  0.  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[6.800661 ]
 [2.9881432]
 [6.780347 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  3. 10. 11.] 
cards in discard: [25. 15.  0.  0.  0.  1. 25.  0. 15.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  6.  0.  3. 10.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  6.  0.  6.  6.  0.  8.  0. 14. 15.  0.  1.  0.] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: buy - action -1
Learning step: 0.5986835360527039
desired expected reward: 38.36594772338867





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[1.0662577]
 [6.594058 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  3. 10. 11.] 
cards in discard: [25. 15.  0.  0.  0.  1. 25.  0. 15.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  6.  0.  3. 10.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  6.  0.  6.  6.  0.  8.  0. 14. 15.  0.  1.  0.] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1.0
Learning step: 2.123789072036743
desired expected reward: 8.92445182800293



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  6.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  3. 10.] 
cards in discard: [ 8.  0. 10.  0.  3.  6.  0.  6.  6.  0.  8.  0. 14. 15.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  6. 15.  8. 11.] 
adversary cards in discard: [25. 15.  0.  0.  0.  1. 25.  0. 15.  0.  0.  3.  6.  3. 10. 11.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  3. 10.] 
cards in discard: [ 8.  0. 10.  0.  3.  6.  0.  6.  6.  0.  8.  0. 14. 15.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  6. 15.  8. 11.] 
adversary cards in discard: [25. 15.  0.  0.  0.  1. 25.  0. 15.  0.  0.  3.  6.  3. 10. 11.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
adversary victory points: 2
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 15.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 11.] 
expected returns: [[ 3.881674 ]
 [-4.677607 ]
 [-1.8821416]
 [ 3.4242985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  8. 11.] 
cards in discard: [25. 15.  0.  0.  0.  1. 25.  0. 15.  0.  0.  3.  6.  3. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  8. 15. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: buy - action -1.0
Learning step: 2.0614516735076904
desired expected reward: 8.655513763427734





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-3.2815652]
 [ 4.731207 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  8. 11.] 
cards in discard: [25. 15.  0.  0.  0.  1. 25.  0. 15.  0.  0.  3.  6.  3. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  8. 15. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1.0
Learning step: 2.2122962474823
desired expected reward: 6.093954563140869



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  8. 15. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 15. 14.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [15. 25.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 15.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [15.  3.  0.] 
adversary cards in discard: [25.  3.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 15.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [15.  3.  0.] 
adversary cards in discard: [25.  3.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[ -3.5059829]
 [-17.41621  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.] 
cards in discard: [25.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [1. 6. 0. 3. 0.] 
adversary cards in discard: [14.  6.  8. 15.  0.] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2  50   0   0   0   0   0   0   0   0   0   0 133   0] 
sum of rewards: 180 

action type: discard_down_to_3_cards - action 1
Learning step: 6.940186977386475
desired expected reward: 44.52830505371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-15.308535]
 [ -3.505463]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.] 
cards in discard: [25.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [1. 6. 0. 3. 0.] 
adversary cards in discard: [14.  6.  8. 15.  0.] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1.0
Learning step: 2.4026904106140137
desired expected reward: -1.7037601470947266



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [1. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 3. 0.] 
cards in discard: [14.  6.  8. 15.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0. 11. 15.  0.] 
adversary cards in discard: [25.  3. 15.  3.  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 3. 0.] 
cards in discard: [14.  6.  8. 15.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0. 11. 15.  0.] 
adversary cards in discard: [25.  3. 15.  3.  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
adversary victory points: 2
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[-18.393112]
 [-19.25494 ]
 [-71.945206]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 15.  0.] 
cards in discard: [25.  3. 15.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  5.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [14.  6.  8. 15.  0.  1.  6.  0.  3.  0.] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: buy - action -1.0
Learning step: 1.9941093921661377
desired expected reward: -1.511359453201294



action possibilites: [-1] 
expected returns: [[-0.6270008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0.] 
cards in discard: [25.  3. 15.  3.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  4.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [14.  6.  8. 15.  0.  1.  6.  0.  3.  0.] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 76 

action type: gain_card_n - action 4
Learning step: 8.397420883178711
desired expected reward: -83.83313751220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-7.638492 ]
 [-4.531739 ]
 [-5.4926705]
 [-1.9578811]
 [-6.6101885]
 [-6.5765657]
 [-1.1219707]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.] 
cards in discard: [25.  3. 15.  3.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  4.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [14.  6.  8. 15.  0.  1.  6.  0.  3.  0.] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 67 

action type: take_action - action -1
Learning step: 3.3095481395721436
desired expected reward: 2.6825473308563232






Player: 1 
cards in hand: [0. 0. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [14.  6.  8. 15.  0.  1.  6.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  4.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0.  0. 25.  1.] 
adversary cards in discard: [25.  3. 15.  3.  0. 11. 11.  0.  0. 15.  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11] -> size -> 26 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [14.  6.  8. 15.  0.  1.  6.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  4.  4.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0.  0. 25.  1.] 
adversary cards in discard: [25.  3. 15.  3.  0. 11. 11.  0.  0. 15.  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11] -> size -> 26 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [14.  6.  8. 15.  0.  1.  6.  0.  3.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  4.  3.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0.  0. 25.  1.] 
adversary cards in discard: [25.  3. 15.  3.  0. 11. 11.  0.  0. 15.  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11] -> size -> 26 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[3.6972425]
 [4.1859045]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.  1.] 
cards in discard: [25.  3. 15.  3.  0. 11. 11.  0.  0. 15.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  4.  3.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 8. 0. 0. 6.] 
adversary cards in discard: [14.  6.  8. 15.  0.  1.  6.  0.  3.  0.  8.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8] -> size -> 25 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: buy - action -1.0
Learning step: 2.497227668762207
desired expected reward: 1.375255823135376



action possibilites: [-1] 
expected returns: [[19.86923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  1. 25.  6.] 
cards in discard: [25.  3. 15.  3.  0. 11. 11.  0.  0. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  4.  3.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 8. 0. 0. 6.] 
adversary cards in discard: [14.  6.  8. 15.  0.  1.  6.  0.  3.  0.  8.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8] -> size -> 25 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 67 

action type: take_action - action 25.0
Learning step: 3.5877625942230225
desired expected reward: 7.773672103881836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[14.15006  ]
 [17.022602 ]
 [15.517505 ]
 [10.479003 ]
 [15.484551 ]
 [17.766933 ]
 [16.080477 ]
 [20.38535  ]
 [15.834399 ]
 [11.139753 ]
 [12.546256 ]
 [14.930181 ]
 [10.1566105]
 [13.418937 ]
 [17.80129  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  1. 25.  6.] 
cards in discard: [25.  3. 15.  3.  0. 11. 11.  0.  0. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  4.  3.  7. 10.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 8. 0. 0. 6.] 
adversary cards in discard: [14.  6.  8. 15.  0.  1.  6.  0.  3.  0.  8.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8] -> size -> 25 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 67 

action type: take_action - action -1
Learning step: 2.7459962368011475
desired expected reward: 22.61522674560547



buy possibilites: [-1] 
expected returns: [[10.394826]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  1. 25.  6.] 
cards in discard: [25.  3. 15.  3.  0. 11. 11.  0.  0. 15.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 8. 0. 0. 6.] 
adversary cards in discard: [14.  6.  8. 15.  0.  1.  6.  0.  3.  0.  8.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8] -> size -> 25 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2. 50.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 75.0 

action type: buy - action 29.0
Learning step: 3.1921634674072266
desired expected reward: 19.026569366455078






Player: 1 
cards in hand: [0. 8. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 6.] 
cards in discard: [14.  6.  8. 15.  0.  1.  6.  0.  3.  0.  8.  0.  0.  6.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [15.  8.  0. 11.  3.] 
adversary cards in discard: [25.  3. 15.  3.  0. 11. 11.  0.  0. 15.  0. 29. 25.  0.  0.  0.  1. 25.
  6.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29] -> size -> 27 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 6.] 
cards in discard: [14.  6.  8. 15.  0.  1.  6.  0.  3.  0.  8.  0.  0.  6.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 26. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [15.  8.  0. 11.  3.] 
adversary cards in discard: [25.  3. 15.  3.  0. 11. 11.  0.  0. 15.  0. 29. 25.  0.  0.  0.  1. 25.
  6.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29] -> size -> 27 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 6.] 
cards in discard: [14.  6.  8. 15.  0.  1.  6.  0.  3.  0.  8.  0.  0.  6.  3.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 27. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [15.  8.  0. 11.  3.] 
adversary cards in discard: [25.  3. 15.  3.  0. 11. 11.  0.  0. 15.  0. 29. 25.  0.  0.  0.  1. 25.
  6.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29] -> size -> 27 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [15.  8.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 11.] 
expected returns: [[ 7.3250723]
 [-1.4077306]
 [ 5.485532 ]
 [ 9.336226 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0. 11.  3.] 
cards in discard: [25.  3. 15.  3.  0. 11. 11.  0.  0. 15.  0. 29. 25.  0.  0.  0.  1. 25.
  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 3. 14.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8  3] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: buy - action -1
Learning step: 1.4884376525878906
desired expected reward: 11.88326358795166



action possibilites: [-1] 
expected returns: [[-12.339717]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  3.] 
cards in discard: [25.  3. 15.  3.  0. 11. 11.  0.  0. 15.  0. 29. 25.  0.  0.  0.  1. 25.
  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 3. 14.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8  3] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   2  40   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 27 

action type: gain_card_n - action 0
Learning step: 1.0687942504882812
desired expected reward: 1.1400384902954102





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-14.593968]
 [-12.037192]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.  3.] 
cards in discard: [25.  3. 15.  3.  0. 11. 11.  0.  0. 15.  0. 29. 25.  0.  0.  0.  1. 25.
  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 27. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 3. 14.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8  3] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 57 

action type: take_action - action -1
Learning step: 3.180171489715576
desired expected reward: -9.1595458984375






Player: 1 
cards in hand: [ 3. 14.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [15. 15.  3. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0] -> size -> 28 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 27. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [15. 15.  3. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0] -> size -> 28 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0. 10. 10.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 27. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [15. 15.  3. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0] -> size -> 28 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [15. 15.  3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 10.] 
expected returns: [[ 0.29435015]
 [-3.5856736 ]
 [-3.5856736 ]
 [-1.2906549 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  3. 10.  6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 1. 0. 0. 8.] 
adversary cards in discard: [ 0.  3. 14.  0. 10. 10.] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8  3  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: buy - action -1.0
Learning step: 2.411628484725952
desired expected reward: -9.62556266784668





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-4.4462996]
 [ 0.0156095]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  3. 10.  6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 27. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 1. 0. 0. 8.] 
adversary cards in discard: [ 0.  3. 14.  0. 10. 10.] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8  3  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1.0
Learning step: 1.8344448804855347
desired expected reward: 1.5949074029922485



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 1. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 8.] 
cards in discard: [ 0.  3. 14.  0. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 11.  3. 25. 25.] 
adversary cards in discard: [15. 15.  3. 10.  6.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0] -> size -> 28 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 8.] 
cards in discard: [ 0.  3. 14.  0. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 27. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 11.  3. 25. 25.] 
adversary cards in discard: [15. 15.  3. 10.  6.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0] -> size -> 28 
adversary victory points: 2
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 25.] 
expected returns: [[-9.066091]
 [-8.91522 ]
 [-9.710688]
 [-9.710688]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 25. 25.] 
cards in discard: [15. 15.  3. 10.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8  3  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: buy - action -1.0
Learning step: 1.6431849002838135
desired expected reward: 1.6587910652160645



action possibilites: [-1] 
expected returns: [[3.0235264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 25. 15.  1.] 
cards in discard: [15. 15.  3. 10.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8  3  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 59 

action type: take_action - action 25.0
Learning step: 3.5035641193389893
desired expected reward: -6.207130432128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-4.698186 ]
 [ 0.8513825]
 [-0.5034101]
 [ 2.551039 ]
 [-1.7807385]
 [-2.6692035]
 [ 2.2344105]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3. 25. 15.  1.] 
cards in discard: [15. 15.  3. 10.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 27. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8  3  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 57 

action type: take_action - action -1
Learning step: 2.717170476913452
desired expected reward: 5.740696907043457



buy possibilites: [-1] 
expected returns: [[9.027031]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3. 25. 15.  1.] 
cards in discard: [15. 15.  3. 10.  6.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.] 
adversary owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8  3  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 75 

action type: buy - action 1.0
Learning step: 3.7377307415008545
desired expected reward: 8.045276641845703






Player: 1 
cards in hand: [8. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 3. 0.] 
cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6  6  6 10  6  0  0  0  8  6  3  0  0 14  0  3  1 15 10  0  8  0 14
  8  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [11.  0.  3.  6.  0.] 
adversary cards in discard: [15. 15.  3. 10.  6.  1. 25.  0. 11.  3. 25. 15.  1.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1] -> size -> 29 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6  6  6 10  6  0  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [11.  0.  3.  6.  0.] 
adversary cards in discard: [15. 15.  3. 10.  6.  1. 25.  0. 11.  3. 25. 15.  1.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1] -> size -> 29 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6  6  6 10  6  0  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 26. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [11.  0.  3.  6.  0.] 
adversary cards in discard: [15. 15.  3. 10.  6.  1. 25.  0. 11.  3. 25. 15.  1.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1] -> size -> 29 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-12.269817]
 [-15.636613]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  6.  0.] 
cards in discard: [15. 15.  3. 10.  6.  1. 25.  0. 11.  3. 25. 15.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  0. 15.  0.] 
adversary cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.  8.  6.  0.] 
adversary owned cards: [ 6  6  6 10  6  0  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3
  0] -> size -> 25 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: buy - action -1
Learning step: 1.6015379428863525
desired expected reward: 10.628568649291992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-19.692757]
 [-17.861717]
 [-21.784374]
 [-12.681422]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  6.  0.] 
cards in discard: [15. 15.  3. 10.  6.  1. 25.  0. 11.  3. 25. 15.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 25. 30.  8.  0. 10.  4.  3.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  0. 15.  0.] 
adversary cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.  8.  6.  0.] 
adversary owned cards: [ 6  6  6 10  6  0  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3
  0] -> size -> 25 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1.0
Learning step: 2.611623525619507
desired expected reward: -9.658218383789062



buy possibilites: [-1] 
expected returns: [[-5.7768493]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  6.  0.] 
cards in discard: [15. 15.  3. 10.  6.  1. 25.  0. 11.  3. 25. 15.  1.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 25. 30.  8.  0. 10.  4.  2.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  0. 15.  0.] 
adversary cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.  8.  6.  0.] 
adversary owned cards: [ 6  6  6 10  6  0  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3
  0] -> size -> 25 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 55 

action type: buy - action 8.0
Learning step: 3.709239959716797
desired expected reward: -18.07514190673828






Player: 1 
cards in hand: [ 0.  3.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 15.  0.] 
cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.  8.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  6  6 10  6  0  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 25. 30.  8.  0. 10.  4.  2.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [25.  0.  0.  0. 29.] 
adversary cards in discard: [15. 15.  3. 10.  6.  1. 25.  0. 11.  3. 25. 15.  1.  8. 11.  0.  3.  6.
  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8] -> size -> 30 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.  8.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 26. 30. 25. 30.  8.  0. 10.  4.  2.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [25.  0.  0.  0. 29.] 
adversary cards in discard: [15. 15.  3. 10.  6.  1. 25.  0. 11.  3. 25. 15.  1.  8. 11.  0.  3.  6.
  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8] -> size -> 30 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.  8.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 26. 30. 25. 30.  8.  0. 10.  4.  2.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [25.  0.  0.  0. 29.] 
adversary cards in discard: [15. 15.  3. 10.  6.  1. 25.  0. 11.  3. 25. 15.  1.  8. 11.  0.  3.  6.
  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8] -> size -> 30 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.  8.  6.  0. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 26. 30. 25. 30.  8.  0.  9.  4.  2.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [25.  0.  0.  0. 29.] 
adversary cards in discard: [15. 15.  3. 10.  6.  1. 25.  0. 11.  3. 25. 15.  1.  8. 11.  0.  3.  6.
  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8] -> size -> 30 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [25.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-11.368935]
 [ -8.355951]
 [-13.883989]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0. 29.] 
cards in discard: [15. 15.  3. 10.  6.  1. 25.  0. 11.  3. 25. 15.  1.  8. 11.  0.  3.  6.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 25. 30.  8.  0.  9.  4.  2.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  8.  6.  6. 14.] 
adversary cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.  8.  6.  0. 16. 15.  3.  0.
  0.] 
adversary owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16] -> size -> 25 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: buy - action -1
Learning step: 2.415250778198242
desired expected reward: -3.361598491668701



action possibilites: [-1] 
expected returns: [[14.008216]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  8.  3.] 
cards in discard: [15. 15.  3. 10.  6.  1. 25.  0. 11.  3. 25. 15.  1.  8. 11.  0.  3.  6.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 25. 30.  8.  0.  9.  4.  2.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  8.  6.  6. 14.] 
adversary cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.  8.  6.  0. 16. 15.  3.  0.
  0.] 
adversary owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16] -> size -> 25 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 67 

action type: take_action - action 25.0
Learning step: 4.082981109619141
desired expected reward: -4.272941589355469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 7.360465]
 [14.075141]
 [11.913935]
 [16.252987]
 [11.66989 ]
 [ 9.940803]
 [15.785087]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  8.  3.] 
cards in discard: [15. 15.  3. 10.  6.  1. 25.  0. 11.  3. 25. 15.  1.  8. 11.  0.  3.  6.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 26. 30. 25. 30.  8.  0.  9.  4.  2.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  8.  6.  6. 14.] 
adversary cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.  8.  6.  0. 16. 15.  3.  0.
  0.] 
adversary owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16] -> size -> 25 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 67 

action type: take_action - action -1
Learning step: 2.967479705810547
desired expected reward: 16.975696563720703



buy possibilites: [-1] 
expected returns: [[-11.296572]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  8.  3.] 
cards in discard: [15. 15.  3. 10.  6.  1. 25.  0. 11.  3. 25. 15.  1.  8. 11.  0.  3.  6.
  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 25. 30.  8.  0.  9.  3.  2.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  8.  6.  6. 14.] 
adversary cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.  8.  6.  0. 16. 15.  3.  0.
  0.] 
adversary owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16] -> size -> 25 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 85 

action type: buy - action 11.0
Learning step: 3.1831777095794678
desired expected reward: 19.43616485595703






Player: 1 
cards in hand: [ 6.  8.  6.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  6.  6. 14.] 
cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.  8.  6.  0. 16. 15.  3.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 25. 30.  8.  0.  9.  3.  2.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11] -> size -> 31 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 6.] 
cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.  8.  6.  0. 16. 15.  3.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 26. 30. 25. 30.  8.  0.  9.  3.  2.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11] -> size -> 31 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 6.] 
cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.  8.  6.  0. 16. 15.  3.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 25. 30.  8.  0.  9.  3.  2.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11] -> size -> 31 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 6.] 
cards in discard: [ 0.  3. 14.  0. 10. 10.  0.  1.  0.  0.  8.  8.  6.  0. 16. 15.  3.  0.
  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 25. 30.  8.  0.  9.  3.  1.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11] -> size -> 31 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-13.109719]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 25. 30.  8.  0.  9.  3.  1.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [14.  8.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8] -> size -> 26 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2  50   0   0   0 -30   0   0   0   0   0   0 176   0] 
sum of rewards: 193 

action type: discard_down_to_3_cards - action 1
Learning step: 8.737364768981934
desired expected reward: 22.09139060974121





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ -5.449216 ]
 [ -7.7402306]
 [-10.130205 ]
 [ -7.56628  ]
 [ -6.9828243]
 [ -9.2253475]
 [-11.203248 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 26. 30. 25. 30.  8.  0.  9.  3.  1.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [14.  8.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8] -> size -> 26 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1.0
Learning step: 2.7357094287872314
desired expected reward: -8.150275230407715



buy possibilites: [-1] 
expected returns: [[12.768399]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 11.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 26. 30. 24. 30.  8.  0.  9.  3.  1.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [14.  8.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8] -> size -> 26 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 60.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 60.0 

action type: buy - action 3.0
Learning step: 3.7938008308410645
desired expected reward: -6.33643102645874






Player: 1 
cards in hand: [14.  8.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  6.  3.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 24. 30.  8.  0.  9.  3.  1.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3] -> size -> 32 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 26. 30. 24. 30.  8.  0.  9.  3.  1.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3] -> size -> 32 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 24. 30.  8.  0.  9.  3.  1.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3] -> size -> 32 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[54.415043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 24. 30.  8.  0.  9.  3.  1.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [6. 0. 0. 8. 1.] 
adversary cards in discard: [14.  8.  6.  3.  6.] 
adversary owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8] -> size -> 26 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   3  60   0   0   0 -30   0   0   0   0   0   0 180   0] 
sum of rewards: 208 

action type: discard_down_to_3_cards - action 0
Learning step: 10.552631378173828
desired expected reward: 31.986770629882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[40.490295]
 [55.877666]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 26. 30. 24. 30.  8.  0.  9.  3.  1.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [6. 0. 0. 8. 1.] 
adversary cards in discard: [14.  8.  6.  3.  6.] 
adversary owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8] -> size -> 26 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[-5  0  3 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: take_action - action -1.0
Learning step: 1.3403371572494507
desired expected reward: 55.75537872314453



buy possibilites: [-1] 
expected returns: [[38.729393]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  3.  1.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [6. 0. 0. 8. 1.] 
adversary cards in discard: [14.  8.  6.  3.  6.] 
adversary owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8] -> size -> 26 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.  60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 28.0 

action type: buy - action 0.0
Learning step: 0.2375146895647049
desired expected reward: 40.727806091308594






Player: 1 
cards in hand: [6. 0. 0. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 8. 1.] 
cards in discard: [14.  8.  6.  3.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  3.  1.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [29.  3.  1. 15. 25.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0] -> size -> 33 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 8. 1.] 
cards in discard: [14.  8.  6.  3.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  3.  1.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [29.  3.  1. 15. 25.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0] -> size -> 33 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 8. 1.] 
cards in discard: [14.  8.  6.  3.  6.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  3.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [29.  3.  1. 15. 25.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0] -> size -> 33 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [29.  3.  1. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 25.] 
expected returns: [[26.03244 ]
 [12.532177]
 [ 8.602461]
 [33.01858 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1. 15. 25.] 
cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  3.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [10.  0.  0.  6.  6.] 
adversary cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1.] 
adversary owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8  8] -> size -> 27 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[-5  0  3 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: buy - action -1
Learning step: 1.544318437576294
desired expected reward: 40.273712158203125



action possibilites: [-1] 
expected returns: [[85.62743]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1. 15.  3.  0.] 
cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  3.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [10.  0.  0.  6.  6.] 
adversary cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1.] 
adversary owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8  8] -> size -> 27 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[-5  0  3 60  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 79 

action type: take_action - action 25.0
Learning step: 4.2256879806518555
desired expected reward: 37.24428176879883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[74.157776]
 [83.94969 ]
 [80.93146 ]
 [88.99644 ]
 [78.878235]
 [90.22558 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1. 15.  3.  0.] 
cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  3.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [10.  0.  0.  6.  6.] 
adversary cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1.] 
adversary owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8  8] -> size -> 27 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[-5  0  3 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 78 

action type: take_action - action -1
Learning step: 1.5566033124923706
desired expected reward: 87.18403625488281



buy possibilites: [-1] 
expected returns: [[80.10807]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1. 15.  3.  0.] 
cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  2.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [10.  0.  0.  6.  6.] 
adversary cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1.] 
adversary owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8  8] -> size -> 27 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[-5  0  3 60  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 96 

action type: buy - action 11.0
Learning step: 2.152608871459961
desired expected reward: 91.14906311035156






Player: 1 
cards in hand: [10.  0.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  6.  6.] 
cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  2.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 8.  0. 10. 11.  8.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3. 11. 25. 29.  3.  1. 15.
  3.  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0 11] -> size -> 34 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  6. 16.] 
cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8  8] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  2.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 8.  0. 10. 11.  8.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3. 11. 25. 29.  3.  1. 15.
  3.  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0 11] -> size -> 34 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  6. 16.] 
cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  2.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 8.  0. 10. 11.  8.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3. 11. 25. 29.  3.  1. 15.
  3.  0.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0 11] -> size -> 34 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 10. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.  8.] 
expected returns: [[86.283585]
 [76.36055 ]
 [77.60452 ]
 [83.45263 ]
 [76.36055 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 11.  8.] 
cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3. 11. 25. 29.  3.  1. 15.
  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  2.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 8.  0.  0. 10.  8.] 
adversary cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1. 10.  0.  0.  6.  6. 16.] 
adversary owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8  8] -> size -> 27 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[-5  0  3 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: buy - action -1
Learning step: 0.7575977444648743
desired expected reward: 80.86566925048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[72.7655 ]
 [86.34663]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10. 11.  8.] 
cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3. 11. 25. 29.  3.  1. 15.
  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  2.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 8.  0.  0. 10.  8.] 
adversary cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1. 10.  0.  0.  6.  6. 16.] 
adversary owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8  8] -> size -> 27 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[-5  0  3 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: take_action - action -1.0
Learning step: 0.44374847412109375
desired expected reward: 86.72734832763672



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10.  8.] 
cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1. 10.  0.  0.  6.  6. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  6  6 10  6  0  0  8  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0
 16  8  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  2.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [25.  6. 25. 11.  0.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3. 11. 25. 29.  3.  1. 15.
  3.  0.  8.  0. 10. 11.  8.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0 11] -> size -> 34 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1. 10.  0.  0.  6.  6. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6  6  6 10  6  0  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16
  8  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  2.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [25.  6. 25. 11.  0.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3. 11. 25. 29.  3.  1. 15.
  3.  0.  8.  0. 10. 11.  8.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0 11] -> size -> 34 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1. 10.  0.  0.  6.  6. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6  6  6 10  6  0  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16
  8  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  2.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [25.  6. 25. 11.  0.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3. 11. 25. 29.  3.  1. 15.
  3.  0.  8.  0. 10. 11.  8.] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0 11] -> size -> 34 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [25.  6. 25. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 11.] 
expected returns: [[85.091385]
 [92.24372 ]
 [92.24372 ]
 [81.32841 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6. 25. 11.  0.] 
cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3. 11. 25. 29.  3.  1. 15.
  3.  0.  8.  0. 10. 11.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  2.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 14. 15.  0.  3.] 
adversary cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1. 10.  0.  0.  6.  6. 16.  8.
  0.  0. 10.] 
adversary owned cards: [ 6  6  6 10  6  0  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16
  8  8] -> size -> 26 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[-5  0  3 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: buy - action -1.0
Learning step: 0.6016986966133118
desired expected reward: 86.94832611083984



action possibilites: [-1] 
expected returns: [[28.480984]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25. 11.  0. 15.  6.] 
cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3. 11. 25. 29.  3.  1. 15.
  3.  0.  8.  0. 10. 11.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  2.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 14. 15.  0.  3.] 
adversary cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1. 10.  0.  0.  6.  6. 16.  8.
  0.  0. 10.] 
adversary owned cards: [ 6  6  6 10  6  0  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16
  8  8] -> size -> 26 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[-5  0  3 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 78 

action type: take_action - action 25.0
Learning step: -0.07136421650648117
desired expected reward: 92.17236328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[24.959955]
 [29.849888]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25. 11.  0. 15.  6.] 
cards in discard: [ 0. 11.  3.  0.  0.  0.  0.  1.  0.  0.  3.  3. 11. 25. 29.  3.  1. 15.
  3.  0.  8.  0. 10. 11.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  2.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 14. 15.  0.  3.] 
adversary cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1. 10.  0.  0.  6.  6. 16.  8.
  0.  0. 10.] 
adversary owned cards: [ 6  6  6 10  6  0  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16
  8  8] -> size -> 26 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[-5  0  3 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 78 

action type: take_action - action -1
Learning step: 3.1170153617858887
desired expected reward: 31.597999572753906






Player: 1 
cards in hand: [ 0. 14. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 15.  0.  3.] 
cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1. 10.  0.  0.  6.  6. 16.  8.
  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  6  6 10  6  0  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16
  8  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  2.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 15.  6. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0 11] -> size -> 34 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.] 
cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1. 10.  0.  0.  6.  6. 16.  8.
  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 6  6  6 10  6  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16  8
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  2.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 15.  6. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0 11] -> size -> 34 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.] 
cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1. 10.  0.  0.  6.  6. 16.  8.
  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 6  6  6 10  6  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16  8
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  2.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 15.  6. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0 11] -> size -> 34 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.] 
cards in discard: [14.  8.  6.  3.  6.  8.  6.  0.  0.  8.  1. 10.  0.  0.  6.  6. 16.  8.
  0.  0. 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 6  6  6 10  6  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16  8
  8 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  1.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 15.  6. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0 11] -> size -> 34 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  6. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 15.] 
expected returns: [[-9.023643]
 [-7.84063 ]
 [-9.104952]
 [-7.84063 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6. 11. 15.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25
  1 11 29  0  1  8 11  3  0 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  1.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  6  6 10  6  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16  8
  8 11] -> size -> 26 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[-5  0  3 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: buy - action -1.0
Learning step: 1.2234448194503784
desired expected reward: 31.073328018188477



action possibilites: [-1] 
expected returns: [[3.9085174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 15.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25  1
 11 29  0  1  8 11  3  0 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  1.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  6  6 10  6  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16  8
  8 11] -> size -> 26 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[-5  0  3 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 78 

action type: take_action - action 15.0
Learning step: 4.379973411560059
desired expected reward: -3.4606566429138184





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[1.8800159]
 [3.2759027]
 [2.9146304]
 [3.7227955]
 [2.3687844]
 [3.8438172]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 15.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25  1
 11 29  0  1  8 11  3  0 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 26. 30. 24. 30.  8.  0.  9.  1.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  6  6 10  6  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16  8
  8 11] -> size -> 26 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[-5  0  3 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 78 

action type: take_action - action -1
Learning step: 3.7805263996124268
desired expected reward: 7.689043998718262



buy possibilites: [-1] 
expected returns: [[21.889935]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 15.] 
cards in discard: [3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25  1
 11 29  0  1  8 11  3  0 11  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 26. 30. 23. 30.  8.  0.  9.  1.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 6  6  6 10  6  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16  8
  8 11] -> size -> 26 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 70.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 91.0 

action type: buy - action 3.0
Learning step: 4.896792411804199
desired expected reward: 7.811421871185303






Player: 1 
cards in hand: [6. 0. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 6  6  6 10  6  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16  8
  8 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 23. 30.  8.  0.  9.  1.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [25.  0.  6. 29.  1.] 
adversary cards in discard: [ 3. 15.  6. 11. 15.] 
adversary owned cards: [ 3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25  1
 11 29  0  1  8 11  3  0 11  3] -> size -> 34 
adversary victory points: 4
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6  6 10  6  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16  8  8
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 23. 30.  8.  0.  9.  1.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [25.  0.  6. 29.  1.] 
adversary cards in discard: [ 3. 15.  6. 11. 15.] 
adversary owned cards: [ 3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25  1
 11 29  0  1  8 11  3  0 11  3] -> size -> 34 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6  6 10  6  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16  8  8
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 30. 23. 30.  8.  0.  9.  1.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [25.  0.  6. 29.  1.] 
adversary cards in discard: [ 3. 15.  6. 11. 15.] 
adversary owned cards: [ 3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25  1
 11 29  0  1  8 11  3  0 11  3] -> size -> 34 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [25.  0.  6. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-13.64572 ]
 [-14.976664]
 [-12.23509 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  6. 29.  1.] 
cards in discard: [ 3. 15.  6. 11. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25  1
 11 29  0  1  8 11  3  0 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 23. 30.  8.  0.  9.  1.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 3.  6. 14.  8.  0.] 
adversary cards in discard: [8. 0. 0. 6.] 
adversary owned cards: [ 6  6 10  6  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16  8  8
 11] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: buy - action -1
Learning step: 1.5629152059555054
desired expected reward: 23.452850341796875



action possibilites: [-1. 25.] 
expected returns: [[-6.653989 ]
 [-6.4186096]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0.] 
cards in discard: [ 3. 15.  6. 11. 15.  6.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25  1
 11 29  0  1  8 11  3  0 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 26. 30. 23. 30.  8.  0.  9.  1.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 3.  6. 14.  8.  0.] 
adversary cards in discard: [8. 0. 0. 6.] 
adversary owned cards: [ 6  6 10  6  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16  8  8
 11] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 79 

action type: discard_n_cards - action 6
Learning step: 4.463846206665039
desired expected reward: -9.963781356811523



action possibilites: [-1] 
expected returns: [[-1.8468668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 8.] 
cards in discard: [ 3. 15.  6. 11. 15.  6.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25  1
 11 29  0  1  8 11  3  0 11  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 26. 30. 23. 30.  8.  0.  9.  1.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 3.  6. 14.  8.  0.] 
adversary cards in discard: [8. 0. 0. 6.] 
adversary owned cards: [ 6  6 10  6  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16  8  8
 11] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 99 

action type: take_action - action 25.0
Learning step: 5.229375839233398
desired expected reward: -1.1892337799072266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-0.10559058]
 [ 2.456717  ]
 [ 2.0795417 ]
 [ 1.6221461 ]
 [ 3.074666  ]
 [ 1.6512518 ]
 [-3.3818567 ]
 [ 1.7491355 ]
 [ 1.058919  ]
 [ 2.134511  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 8.] 
cards in discard: [ 3. 15.  6. 11. 15.  6.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25  1
 11 29  0  1  8 11  3  0 11  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 26. 30. 23. 30.  8.  0.  9.  1.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 3.  6. 14.  8.  0.] 
adversary cards in discard: [8. 0. 0. 6.] 
adversary owned cards: [ 6  6 10  6  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16  8  8
 11] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 99 

action type: take_action - action -1
Learning step: 5.088517665863037
desired expected reward: 3.2416508197784424



Player 0 won the game! 



Player 0 bought cards:
Copper: 8 
Silver: 2 
Gold: 0 
Estate: 4 
Duchy: 0 
Province: 0 
Curse: 3 

Remodel: 0 
Workshop: 6 
Chapel: 4 
Witch: 3 
Poacher: 1 
Militia: 0 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [1. 0. 3. 8.] 
cards in discard: [ 3. 15.  6. 11. 15.  6.  0. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 3  3 25 25  0  0 11  8  0  6  6  0 11 15  0 10  0 15  0  3 15  3 25  1
 11 29  0  1  8 11  3  0 11  3 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 26. 30. 23. 30.  8.  0.  9.  0.  0.  7.  9.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 3.  6. 14.  8.  0.] 
adversary cards in discard: [8. 0. 0. 6.] 
adversary owned cards: [ 6  6 10  6  0  6  0  0 14  0  3  1 15 10  0  8  0 14  8  3  0 16  8  8
 11] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5 500   4  60   0   0  40   0   0   0   0   0   0   0   9   0] 
sum of rewards: 608 

action type: buy - action 11.0
Learning step: 30.246267318725586
desired expected reward: 33.3209342956543



