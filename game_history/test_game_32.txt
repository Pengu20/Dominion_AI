 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[10.809043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      30       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000025 

action type: buy - action -1
Learning step: 120002.0703125
desired expected reward: 119975.4375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  7.5296335]
 [ 16.796846 ]
 [ 10.193359 ]
 [-18.125446 ]
 [ 12.0892515]
 [ 16.011166 ]
 [ 11.498221 ]
 [ 23.39846  ]
 [ 10.842453 ]
 [ 11.301852 ]
 [ 18.769302 ]
 [  9.19482  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 11.195842742919922



buy possibilites: [-1] 
expected returns: [[8.7996025]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 23.39846420288086






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[13.456243]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.799602508544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 12.421217]
 [ 22.139524]
 [ 15.35118 ]
 [-12.758254]
 [ 21.315413]
 [ 16.457214]
 [ 16.268862]
 [ 14.047208]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 11.796463966369629



buy possibilites: [-1] 
expected returns: [[2.9581726]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 22.1395263671875






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.120138]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.958172559738159





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[16.008152]
 [25.45646 ]
 [18.847006]
 [-9.269594]
 [24.682747]
 [19.972557]
 [19.77963 ]
 [17.604057]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 17.30474090576172



buy possibilites: [-1] 
expected returns: [[20.338432]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 25.456464767456055






Player: 1 
cards in hand: [14. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  1.  3.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-4.3022356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [ 1.  3.  0.  0.  0.  3. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 4. 14. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0 118   0] 
sum of rewards: 23 

action type: discard_down_to_3_cards - action 5
Learning step: 0
desired expected reward: 14.290310859680176





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -6.3749447]
 [  3.0735896]
 [ -3.4645119]
 [-30.912518 ]
 [ -1.6909273]
 [  2.3418248]
 [ -2.5572405]
 [  9.784589 ]
 [ -2.914285 ]
 [ -2.653489 ]
 [  5.118107 ]
 [ -4.7113347]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 1.  3.  0.  0.  0.  3. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 4. 14. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -6.614073753356934



buy possibilites: [-1] 
expected returns: [[-14.770675]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 1.  3.  0.  0.  0.  3. 29.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 4. 14. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 33 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 9.784586906433105






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 4. 14. 11.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29] -> size -> 14 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 4. 14. 11.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29] -> size -> 14 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 4. 14. 11.  0.  0.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29] -> size -> 14 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [1. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[10.035076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 4. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4 15] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.770674705505371





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 11.245127 ]
 [ 20.526075 ]
 [ 13.932853 ]
 [  1.8840215]
 [-15.175438 ]
 [ 15.928435 ]
 [ 19.861805 ]
 [ 15.235637 ]
 [ 24.655062 ]
 [ 27.019323 ]
 [ 14.639146 ]
 [ 20.52389  ]
 [ 15.079549 ]
 [  1.0612128]
 [ 22.50146  ]
 [ 13.02502  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 4. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4 15] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 8.172436714172363



buy possibilites: [-1] 
expected returns: [[19.483889]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10.  7.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 4. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4 15] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: -63.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 27.019319534301758






Player: 1 
cards in hand: [0. 4. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10.  7.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  0.  3.  1.] 
adversary cards in discard: [29.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10.  7.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  0.  3.  1.] 
adversary cards in discard: [29.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4 15  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 29.  8. 10. 10.  9. 10. 10.  7.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  0.  3.  1.] 
adversary cards in discard: [29.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 6.5001802]
 [19.57683  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.  1.] 
cards in discard: [29.  1.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 29.  8. 10. 10.  9. 10. 10.  7.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [3. 0. 4. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4 15  3] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.483888626098633



action possibilites: [-1.] 
expected returns: [[23.074669]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [29.  1.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 29.  8. 10. 10.  9. 10. 10.  7.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [3. 0. 4. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4 15  3] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 20.32124900817871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[23.005491 ]
 [32.179535 ]
 [ 9.19118  ]
 [25.771559 ]
 [14.402072 ]
 [-1.9171919]
 [27.594501 ]
 [31.373701 ]
 [26.583612 ]
 [36.23074  ]
 [38.63507  ]
 [26.380842 ]
 [32.227013 ]
 [26.574697 ]
 [13.505916 ]
 [34.12167  ]
 [24.730068 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [29.  1.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 28. 30. 29. 29.  8. 10. 10.  9. 10. 10.  7.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [3. 0. 4. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4 15  3] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 23.074668884277344



buy possibilites: [-1] 
expected returns: [[9.023343]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [29.  1.  0.  3.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 29.  8. 10. 10.  9. 10. 10.  6.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [3. 0. 4. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4 15  3] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   20.    0.    0.    0.    0.    0.
    0.    0.   32.    0.] 
sum of rewards: -73.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 38.635066986083984






Player: 1 
cards in hand: [ 3.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [3. 0. 4. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11  4 15  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 29.  8. 10. 10.  9. 10. 10.  6.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [3. 0. 4. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 29. 29.  8. 10. 10.  9. 10. 10.  6.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [3. 0. 4. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 29.  8. 10. 10.  9. 10. 10.  6.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 3.  0.  4.  0.  3.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  6.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [29.  3. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[22.48144]
 [35.3216 ]
 [35.3216 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  6.  9. 10. 10. 10.  9.] 
adversary cards in hand: [11. 11. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.023343086242676



action possibilites: [-1. 29.] 
expected returns: [[19.938559]
 [33.23057 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  6.  9. 10. 10. 10.  9.] 
adversary cards in hand: [11. 11. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.07382583618164



action possibilites: [-1.] 
expected returns: [[22.61186]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  6.  9. 10. 10. 10.  9.] 
adversary cards in hand: [11. 11. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.23057174682617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[22.29822  ]
 [31.282862 ]
 [24.804403 ]
 [12.56604  ]
 [-4.5580688]
 [27.046743 ]
 [30.544695 ]
 [25.851425 ]
 [35.087463 ]
 [37.256233 ]
 [25.704426 ]
 [31.156294 ]
 [25.948942 ]
 [11.848869 ]
 [33.102848 ]
 [24.34857  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  6.  9. 10. 10. 10.  9.] 
adversary cards in hand: [11. 11. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 22.611860275268555



buy possibilites: [-1] 
expected returns: [[27.673067]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  5.  9. 10. 10. 10.  9.] 
adversary cards in hand: [11. 11. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.   32.    0.] 
sum of rewards: -53.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 37.25623321533203






Player: 1 
cards in hand: [11. 11. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  5.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 29.  0.  0. 29.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  5.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 29.  0.  0. 29.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 14.  0.  0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  5.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 29.  0.  0. 29.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 1. 29.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[31.67169 ]
 [43.891132]
 [43.891132]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  0. 29.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  5.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 3. 4. 0.] 
adversary cards in discard: [ 0. 11. 11. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11  0] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.673067092895508



action possibilites: [-1. 29.] 
expected returns: [[27.31243 ]
 [39.503582]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 29.  1.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  5.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 3. 4. 0.] 
adversary cards in discard: [ 0. 11. 11. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11  0] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.17758560180664



action possibilites: [-1.] 
expected returns: [[50.01652]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 1. 0.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  5.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 3. 4. 0.] 
adversary cards in discard: [ 0. 11. 11. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11  0] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 39.50358200073242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[51.264164]
 [60.403774]
 [36.20369 ]
 [53.80405 ]
 [41.465607]
 [61.071964]
 [24.070148]
 [56.00128 ]
 [59.722725]
 [55.139565]
 [64.35403 ]
 [66.6122  ]
 [54.657757]
 [60.313007]
 [55.076153]
 [40.70512 ]
 [62.293736]
 [53.282833]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 0.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 9 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  5.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 3. 4. 0.] 
adversary cards in discard: [ 0. 11. 11. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11  0] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 50.01652145385742



buy possibilites: [-1] 
expected returns: [[28.719301]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 0.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  4.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 3. 4. 0.] 
adversary cards in discard: [ 0. 11. 11. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11  0] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.   32.    0.] 
sum of rewards: -53.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 66.61222076416016






Player: 1 
cards in hand: [3. 3. 3. 4. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 4. 0.] 
cards in discard: [ 0. 11. 11. 14.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  4.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 4. 0.] 
cards in discard: [ 0. 11. 11. 14.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  4.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 4. 0.] 
cards in discard: [ 0. 11. 11. 14.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  4.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 9.615358]
 [22.134424]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  4.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  0.] 
adversary cards in discard: [ 0. 11. 11. 14.  0.  0.  0.  3.  3.  3.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0] -> size -> 17 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.719301223754883



action possibilites: [-1. 29.] 
expected returns: [[39.194477]
 [53.621666]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  4.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  0.] 
adversary cards in discard: [ 0. 11. 11. 14.  0.  0.  0.  3.  3.  3.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0] -> size -> 17 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 20.415142059326172



action possibilites: [-1.] 
expected returns: [[41.07052]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  4.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  0.] 
adversary cards in discard: [ 0. 11. 11. 14.  0.  0.  0.  3.  3.  3.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0] -> size -> 17 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 53.62166976928711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[42.812523]
 [51.818584]
 [27.950233]
 [45.332134]
 [33.09672 ]
 [15.889655]
 [47.56315 ]
 [51.083614]
 [46.378963]
 [55.64006 ]
 [57.81668 ]
 [46.22272 ]
 [51.697895]
 [46.46961 ]
 [32.377007]
 [53.646465]
 [44.85262 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  4.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  0.] 
adversary cards in discard: [ 0. 11. 11. 14.  0.  0.  0.  3.  3.  3.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0] -> size -> 17 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 41.070518493652344



buy possibilites: [-1] 
expected returns: [[33.644863]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  3.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  0.] 
adversary cards in discard: [ 0. 11. 11. 14.  0.  0.  0.  3.  3.  3.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0] -> size -> 17 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.   32.    0.] 
sum of rewards: -53.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 57.81667709350586






Player: 1 
cards in hand: [ 0.  0.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 15.  0.] 
cards in discard: [ 0. 11. 11. 14.  0.  0.  0.  3.  3.  3.  4.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  3.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [29. 29. 29.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0. 11. 11. 14.  0.  0.  0.  3.  3.  3.  4.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  3.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [29. 29. 29.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0. 11. 11. 14.  0.  0.  0.  3.  3.  3.  4.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  8. 10. 10.  3.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [29. 29. 29.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0. 11. 11. 14.  0.  0.  0.  3.  3.  3.  4.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  3.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [29. 29. 29.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [29. 29. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[32.39306]
 [45.18545]
 [45.18545]
 [45.18545]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  3.  0.] 
cards in discard: [29. 29. 29.  0.  1.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  3.  9. 10. 10. 10.  9.] 
adversary cards in hand: [11.  3. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.64486312866211



action possibilites: [-1. 29. 29.] 
expected returns: [[29.625906]
 [42.03296 ]
 [42.03296 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  0.  3.] 
cards in discard: [29. 29. 29.  0.  1.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  3.  9. 10. 10. 10.  9.] 
adversary cards in hand: [11.  3. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.62881088256836



action possibilites: [-1. 29.] 
expected returns: [[35.25204]
 [48.27712]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  3.  1.] 
cards in discard: [29. 29. 29.  0.  1.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  3.  9. 10. 10. 10.  9.] 
adversary cards in hand: [11.  3. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 42.03296661376953



action possibilites: [-1.] 
expected returns: [[54.300194]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [29. 29. 29.  0.  1.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  3.  9. 10. 10. 10.  9.] 
adversary cards in hand: [11.  3. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 48.277122497558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[56.22001 ]
 [65.29621 ]
 [40.25911 ]
 [58.583492]
 [45.530743]
 [27.384588]
 [61.05717 ]
 [64.72604 ]
 [60.310932]
 [69.16222 ]
 [71.29049 ]
 [59.61919 ]
 [65.099976]
 [60.206448]
 [44.889534]
 [67.14074 ]
 [58.3165  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [29. 29. 29.  0.  1.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  3.  9. 10. 10. 10.  9.] 
adversary cards in hand: [11.  3. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 54.300193786621094



buy possibilites: [-1] 
expected returns: [[97.7778]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [29. 29. 29.  0.  1.  3.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  2.  9. 10. 10. 10.  9.] 
adversary cards in hand: [11.  3. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -150.    0.    0.   60.    0.    0.    0.    0.    0.
    0.    0.   32.    0.] 
sum of rewards: -63.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 71.29048919677734






Player: 1 
cards in hand: [11.  3. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 15.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  2.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 15.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  2.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[45.75845 ]
 [59.651516]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  2.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [11.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 97.77780151367188



action possibilites: [-1. 29.] 
expected returns: [[46.422955]
 [58.965267]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  2.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [11.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 56.99761199951172



action possibilites: [-1. 29.] 
expected returns: [[51.29682 ]
 [63.977665]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  2.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [11.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 58.96525955200195



action possibilites: [-1. 29.] 
expected returns: [[54.765812]
 [66.983986]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  2.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [11.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 63.977664947509766



action possibilites: [-1. 29.] 
expected returns: [[61.990017]
 [74.47268 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 4 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  2.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [11.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   80    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 66.98397827148438



action possibilites: [-1. 29.] 
expected returns: [[55.29304]
 [66.67071]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 5 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  2.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [11.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0  100    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 74.47268676757812



action possibilites: [-1.] 
expected returns: [[74.32873]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 6 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  2.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [11.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0  120    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 66.67070007324219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[73.63252 ]
 [82.64796 ]
 [58.94635 ]
 [76.2514  ]
 [64.03238 ]
 [83.214424]
 [47.063675]
 [78.375854]
 [82.01364 ]
 [77.245674]
 [86.573395]
 [88.707985]
 [77.06249 ]
 [82.56539 ]
 [77.30161 ]
 [63.381824]
 [84.51847 ]
 [75.59191 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 10 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  2.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [11.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0  120    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 74.32872772216797



buy possibilites: [-1] 
expected returns: [[55.932438]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 6 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  1.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [11.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -150.    0.    0.  120.    0.    0.    0.    0.    0.
    0.    0.   32.    0.] 
sum of rewards: -3.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 88.70800018310547






Player: 1 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [11.  3. 15.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  1.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 29.  3.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11.  3. 15.  3.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  1.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  1. 29.  3.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11.  3. 15.  3.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  1.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  1. 29.  3.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11.  3. 15.  3.  0. 15. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  1. 29.  3.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  1. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 98.91291]
 [110.77965]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 29.  3.] 
cards in discard: [29. 29. 29. 29. 29. 29. 29.  0.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [4. 0. 3. 3. 3.] 
adversary cards in discard: [11.  3. 15.  3.  0. 15. 10. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10] -> size -> 19 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.932437896728516



action possibilites: [-1.] 
expected returns: [[100.026085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [29. 29. 29. 29. 29. 29. 29.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [4. 0. 3. 3. 3.] 
adversary cards in discard: [11.  3. 15.  3.  0. 15. 10. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10] -> size -> 19 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 107.90171813964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 98.371956]
 [106.747856]
 [ 83.80624 ]
 [100.56982 ]
 [ 88.65515 ]
 [ 71.99833 ]
 [102.8577  ]
 [106.12668 ]
 [101.9244  ]
 [110.25754 ]
 [112.23399 ]
 [101.53631 ]
 [106.56102 ]
 [101.94074 ]
 [ 88.03481 ]
 [108.426094]
 [100.36994 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [29. 29. 29. 29. 29. 29. 29.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [4. 0. 3. 3. 3.] 
adversary cards in discard: [11.  3. 15.  3.  0. 15. 10. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10] -> size -> 19 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 100.02608489990234



buy possibilites: [-1] 
expected returns: [[162.57315]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [29. 29. 29. 29. 29. 29. 29.  0.  0.  0.  0.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [4. 0. 3. 3. 3.] 
adversary cards in discard: [11.  3. 15.  3.  0. 15. 10. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10] -> size -> 19 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -150.    0.    0.   20.    0.    0.    0.    0.    0.
    0.    0.   32.    0.] 
sum of rewards: -103.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 112.23399353027344






Player: 1 
cards in hand: [4. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 3. 3. 3.] 
cards in discard: [11.  3. 15.  3.  0. 15. 10. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [29.  3. 29.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 3. 3. 3.] 
cards in discard: [11.  3. 15.  3.  0. 15. 10. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [29.  3. 29.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 3
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [29.  3. 29.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[28.403894]
 [41.15512 ]
 [41.15512 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  1.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 11.  4.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10] -> size -> 19 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 162.57315063476562



action possibilites: [-1.] 
expected returns: [[46.375813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 11.  4.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10] -> size -> 19 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 32.59318923950195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[47.72169 ]
 [56.8595  ]
 [50.31248 ]
 [20.026058]
 [52.605885]
 [56.249825]
 [51.434696]
 [51.226097]
 [51.506138]
 [58.73402 ]
 [49.808025]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 11.  4.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10] -> size -> 19 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 46.37581253051758



buy possibilites: [-1] 
expected returns: [[31.921583]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0.] 
cards in discard: [29. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 3. 11.  4.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10] -> size -> 19 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
  128    0] 
sum of rewards: -7 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 58.734012603759766






Player: 1 
cards in hand: [ 3. 11.  4.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  4.  0. 14.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  7.] 
adversary cards in hand: [29.  0.  0. 29.  0.] 
adversary cards in discard: [29. 15. 29.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15] -> size -> 23 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  4.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 29.  0.] 
adversary cards in discard: [29. 15. 29.  3.  1.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15] -> size -> 23 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  4.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 29.  0.] 
adversary cards in discard: [29. 15. 29.  3.  1.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15] -> size -> 23 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  4.  0.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 29.  0.] 
adversary cards in discard: [29. 15. 29.  3.  1.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15] -> size -> 23 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[26.920855]
 [40.33193 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [29. 15. 29.  3.  1.  3.  0. 29.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 3. 15. 10.  0.  3.] 
adversary cards in discard: [ 0. 14.  3. 11.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
  694    0] 
sum of rewards: 539 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 39.76259994506836



action possibilites: [-1.] 
expected returns: [[53.245182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [29. 15. 29.  3.  1.  3.  0. 29.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 3. 15. 10.  0.  3.] 
adversary cards in discard: [ 0. 14.  3. 11.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 32.6662483215332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[53.05981 ]
 [61.451733]
 [55.32499 ]
 [27.422583]
 [60.572525]
 [55.91623 ]
 [56.28599 ]
 [55.253536]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 15. 29.  3.  1.  3.  0. 29.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 3. 15. 10.  0.  3.] 
adversary cards in discard: [ 0. 14.  3. 11.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 53.245182037353516



buy possibilites: [-1] 
expected returns: [[66.191055]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 15. 29.  3.  1.  3.  0. 29.  0. 29.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 3. 15. 10.  0.  3.] 
adversary cards in discard: [ 0. 14.  3. 11.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -81 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 61.45175552368164






Player: 1 
cards in hand: [ 3. 15. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10.  0.  3.] 
cards in discard: [ 0. 14.  3. 11.  4.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 1. 29.  0. 29.  3.] 
adversary cards in discard: [29. 15. 29.  3.  1.  3.  0. 29.  0. 29.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1] -> size -> 24 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.] 
cards in discard: [ 0. 14.  3. 11.  4.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 27. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 1. 29.  0. 29.  3.] 
adversary cards in discard: [29. 15. 29.  3.  1.  3.  0. 29.  0. 29.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1] -> size -> 24 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.] 
cards in discard: [ 0. 14.  3. 11.  4.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 1. 29.  0. 29.  3.] 
adversary cards in discard: [29. 15. 29.  3.  1.  3.  0. 29.  0. 29.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1] -> size -> 24 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.] 
cards in discard: [ 0. 14.  3. 11.  4.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 1. 29.  0. 29.  3.] 
adversary cards in discard: [29. 15. 29.  3.  1.  3.  0. 29.  0. 29.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1] -> size -> 24 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 1. 29.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[187.14659]
 [197.7068 ]
 [197.7068 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0. 29.  3.] 
cards in discard: [29. 15. 29.  3.  1.  3.  0. 29.  0. 29.  1. 29.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [ 0. 14.  3. 11.  4.  0.  1. 15.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.19105529785156



action possibilites: [-1. 29. 29.] 
expected returns: [[142.04652]
 [151.96123]
 [151.96123]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 29.] 
cards in discard: [29. 15. 29.  3.  1.  3.  0. 29.  0. 29.  1. 29.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [ 0. 14.  3. 11.  4.  0.  1. 15.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 192.23341369628906



action possibilites: [-1.] 
expected returns: [[68.90885]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [29. 15. 29.  3.  1.  3.  0. 29.  0. 29.  1. 29.  0.  0.  1. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [ 0. 14.  3. 11.  4.  0.  1. 15.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 147.36122131347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[66.85697]
 [75.41261]
 [69.09494]
 [40.17243]
 [71.44624]
 [74.63602]
 [70.2434 ]
 [70.10269]
 [70.37872]
 [77.09181]
 [68.96898]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [29. 15. 29.  3.  1.  3.  0. 29.  0. 29.  1. 29.  0.  0.  1. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [ 0. 14.  3. 11.  4.  0.  1. 15.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 68.90885162353516



buy possibilites: [-1] 
expected returns: [[46.520363]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [29. 15. 29.  3.  1.  3.  0. 29.  0. 29.  1. 29.  0.  0.  1. 29. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  6.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [ 0. 14.  3. 11.  4.  0.  1. 15.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
  128    0] 
sum of rewards: 13 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 77.09183502197266






Player: 1 
cards in hand: [ 0.  0.  3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 15.  3.] 
cards in discard: [ 0. 14.  3. 11.  4.  0.  1. 15.  3. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  6.] 
adversary cards in hand: [29. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1
 15] -> size -> 25 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [ 0. 14.  3. 11.  4.  0.  1. 15.  3. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  6.] 
adversary cards in hand: [29. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1
 15] -> size -> 25 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 0. 14.  3. 11.  4.  0.  1. 15.  3. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8. 10. 10.  0.  9. 10.  9. 10.  6.] 
adversary cards in hand: [29. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1
 15] -> size -> 25 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 0. 14.  3. 11.  4.  0.  1. 15.  3. 10.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8.  9. 10.  0.  9. 10.  9. 10.  6.] 
adversary cards in hand: [29. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1
 15] -> size -> 25 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[13.33237 ]
 [22.946527]
 [22.946527]
 [22.946527]
 [22.946527]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8.  9. 10.  0.  9. 10.  9. 10.  6.] 
adversary cards in hand: [ 1.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.520362854003906



action possibilites: [-1. 29. 29.] 
expected returns: [[28.977549]
 [40.316074]
 [40.316074]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  1.] 
cards in discard: [29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8.  9. 10.  0.  9. 10.  9. 10.  6.] 
adversary cards in hand: [ 1.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 16.334707260131836



action possibilites: [-1.] 
expected returns: [[56.667812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [29. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8.  9. 10.  0.  9. 10.  9. 10.  6.] 
adversary cards in hand: [ 1.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 34.49180603027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[56.763836]
 [66.16911 ]
 [40.37837 ]
 [59.25788 ]
 [45.81014 ]
 [27.14556 ]
 [61.782078]
 [65.56888 ]
 [60.90977 ]
 [70.183136]
 [60.305714]
 [65.977554]
 [60.843815]
 [45.156048]
 [68.083206]
 [58.935936]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [29. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8.  9. 10.  0.  9. 10.  9. 10.  6.] 
adversary cards in hand: [ 1.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 56.66781234741211



buy possibilites: [-1] 
expected returns: [[47.080166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [29. 29. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1
 15 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8.  9.  9.  0.  9. 10.  9. 10.  6.] 
adversary cards in hand: [ 1.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.  -150.     0.     0.    40.     0.     0.     0.
    0.     0.     0.     0.    62.5    0. ] 
sum of rewards: -52.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 70.18313598632812






Player: 1 
cards in hand: [ 1.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8.  9.  9.  0.  9. 10.  9. 10.  6.] 
adversary cards in hand: [29.  0.  1.  0. 29.] 
adversary cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1
 15 25] -> size -> 26 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8.  9.  9.  0.  9. 10.  8. 10.  6.] 
adversary cards in hand: [29.  0.  1.  0. 29.] 
adversary cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1
 15 25] -> size -> 26 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 26. 30. 28. 29.  8. 10. 10.  8.  9.  9.  0.  9. 10.  8. 10.  6.] 
adversary cards in hand: [29.  0.  1.  0. 29.] 
adversary cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1
 15 25] -> size -> 26 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [10.  4.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 28.  8. 10. 10.  8.  9.  9.  0.  9. 10.  8. 10.  6.] 
adversary cards in hand: [29.  0.  1.  0. 29.] 
adversary cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1
 15 25] -> size -> 26 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [29.  0.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[38.676456]
 [50.02052 ]
 [50.02052 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  0. 29.] 
cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1
 15 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 28.  8. 10. 10.  8.  9.  9.  0.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 0.  3.  3. 15.  0.] 
adversary cards in discard: [10.  4. 11.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4] -> size -> 22 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1
Learning step: 0
desired expected reward: 47.08016586303711



action possibilites: [-1. 29. 15.] 
expected returns: [[ 99.11859]
 [112.29744]
 [108.06454]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 15.] 
cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1
 15 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 28.  8. 10. 10.  8.  9.  9.  0.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 0.  3.  3. 15.  0.] 
adversary cards in discard: [10.  4. 11.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4] -> size -> 22 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 43.724945068359375



action possibilites: [-1. 15.] 
expected returns: [[128.43895]
 [136.59587]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.] 
cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1
 15 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 28. 28.  8. 10. 10.  8.  9.  9.  0.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 0.  3.  3. 15.  0.] 
adversary cards in discard: [10.  4. 11.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4] -> size -> 22 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -205 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 106.26856994628906



action possibilites: [-1] 
expected returns: [[82.17882]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 5 
card supply: [27. 26. 30. 28. 28.  8. 10. 10.  8.  9.  9.  0.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 0.  3.  3. 15.  0.] 
adversary cards in discard: [10.  4. 11.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4] -> size -> 22 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 136.59588623046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[80.54506 ]
 [88.7166  ]
 [65.97031 ]
 [82.54968 ]
 [70.779434]
 [54.0142  ]
 [85.02544 ]
 [87.88254 ]
 [83.692085]
 [91.91258 ]
 [83.67375 ]
 [88.44025 ]
 [83.91783 ]
 [70.09028 ]
 [90.25497 ]
 [82.76259 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 26. 30. 28. 28.  8. 10. 10.  8.  9.  9.  0.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 0.  3.  3. 15.  0.] 
adversary cards in discard: [10.  4. 11.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4] -> size -> 22 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.17881774902344



buy possibilites: [-1] 
expected returns: [[114.67049]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.  1.  1. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15
 25 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 28.  8. 10. 10.  8.  9.  8.  0.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 0.  3.  3. 15.  0.] 
adversary cards in discard: [10.  4. 11.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4] -> size -> 22 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.  -240.     0.     0.    60.     0.     0.     0.
    0.     0.     0.     0.    62.5    0. ] 
sum of rewards: -122.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 91.91258239746094






Player: 1 
cards in hand: [ 0.  3.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 15.  0.] 
cards in discard: [10.  4. 11.  1.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 28.  8. 10. 10.  8.  9.  8.  0.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.  1.  1. 25. 29. 29. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15
 25 25] -> size -> 26 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [10.  4. 11.  1.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 26. 30. 28. 28.  8. 10. 10.  8.  9.  8.  0.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.  1.  1. 25. 29. 29. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15
 25 25] -> size -> 26 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [10.  4. 11.  1.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 28. 28.  8. 10. 10.  8.  9.  8.  0.  9. 10.  8. 10.  6.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.  1.  1. 25. 29. 29. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15
 25 25] -> size -> 26 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [10.  4. 11.  1.  0.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 28.  8. 10. 10.  8.  9.  8.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.  1.  1. 25. 29. 29. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15
 25 25] -> size -> 26 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[65.582214]
 [75.83482 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 29.] 
cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.  1.  1. 25. 29. 29. 15.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15
 25 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 28.  8. 10. 10.  8.  9.  8.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 4. 10.  3.  3.  0.] 
adversary cards in discard: [10.  4. 11.  1.  0.  0.  0. 10. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10] -> size -> 22 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1
Learning step: 0
desired expected reward: 114.67048645019531



action possibilites: [-1.] 
expected returns: [[47.689236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.  1.  1. 25. 29. 29. 15.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15
 25 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 28.  8. 10. 10.  8.  9.  8.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 4. 10.  3.  3.  0.] 
adversary cards in discard: [10.  4. 11.  1.  0.  0.  0. 10. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10] -> size -> 22 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 71.08523559570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[43.50209 ]
 [51.558823]
 [45.57989 ]
 [18.405262]
 [50.76385 ]
 [46.646553]
 [46.792595]
 [45.50883 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.  1.  1. 25. 29. 29. 15.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15
 25 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 28. 28.  8. 10. 10.  8.  9.  8.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 4. 10.  3.  3.  0.] 
adversary cards in discard: [10.  4. 11.  1.  0.  0.  0. 10. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10] -> size -> 22 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 47.68923568725586



buy possibilites: [-1] 
expected returns: [[71.271255]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.  1.  1. 25. 29. 29. 15.  0.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15
 25 25  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 28.  8. 10. 10.  8.  9.  8.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 4. 10.  3.  3.  0.] 
adversary cards in discard: [10.  4. 11.  1.  0.  0.  0. 10. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10] -> size -> 22 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -171 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 51.558807373046875






Player: 1 
cards in hand: [ 4. 10.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 10.  3.  3.  0.] 
cards in discard: [10.  4. 11.  1.  0.  0.  0. 10. 15.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 28.  8. 10. 10.  8.  9.  8.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [29. 29. 29. 15.  0.] 
adversary cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.  1.  1. 25. 29. 29. 15.  0.  3.  1. 29.
  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15
 25 25  1] -> size -> 27 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 10.  3.  3.  0.] 
cards in discard: [10.  4. 11.  1.  0.  0.  0. 10. 15.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 25. 30. 28. 28.  8. 10. 10.  8.  9.  8.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [29. 29. 29. 15.  0.] 
adversary cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.  1.  1. 25. 29. 29. 15.  0.  3.  1. 29.
  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15
 25 25  1] -> size -> 27 
adversary victory points: 3
player victory points: 11 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [29. 29. 29. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 15.] 
expected returns: [[-9.8245945 ]
 [-0.15520883]
 [-0.15520883]
 [-0.15520883]
 [-3.346016  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 15.  0.] 
cards in discard: [29. 29. 25. 29. 29.  0.  1.  0.  1.  1. 25. 29. 29. 15.  0.  3.  1. 29.
  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15
 25 25  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 28.  8. 10. 10.  8.  9.  8.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [14. 11. 15.  8.  3.] 
adversary cards in discard: [10.  4. 11.  1.  0.  0.  0. 10. 15.  3.  3.  0.  4. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10] -> size -> 22 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1
Learning step: 0
desired expected reward: 71.27125549316406



action possibilites: [-1. 29. 15.] 
expected returns: [[12.575506]
 [22.859907]
 [19.483488]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  0.  1.] 
cards in discard: [29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15
 25 25  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 28. 28.  8. 10. 10.  8.  9.  8.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [14. 11. 15.  8.  3.] 
adversary cards in discard: [10.  4. 11.  1.  0.  0.  0. 10. 15.  3.  3.  0.  4. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10] -> size -> 22 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -4.664514541625977



action possibilites: [-1. 15. 15.] 
expected returns: [[-7.6684294 ]
 [-0.94605184]
 [-0.94605184]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15.] 
cards in discard: [29.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15
 25 25  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 28. 28.  8. 10. 10.  8.  9.  8.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [14. 11. 15.  8.  3.] 
adversary cards in discard: [10.  4. 11.  1.  0.  0.  0. 10. 15.  3.  3.  0.  4. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10] -> size -> 22 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -205 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 18.08458709716797



action possibilites: [-1] 
expected returns: [[-3.6193826]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [29.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 5 
card supply: [27. 25. 30. 28. 28.  8. 10. 10.  8.  9.  8.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [14. 11. 15.  8.  3.] 
adversary cards in discard: [10.  4. 11.  1.  0.  0.  0. 10. 15.  3.  3.  0.  4. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10] -> size -> 22 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -0.9460582733154297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -5.5248246 ]
 [  1.91832   ]
 [ -3.6469204 ]
 [-13.422985  ]
 [-27.607153  ]
 [ -1.5245647 ]
 [  0.93296313]
 [ -3.334579  ]
 [  4.8367815 ]
 [ -2.6669874 ]
 [  1.7123134 ]
 [ -2.872338  ]
 [-14.098887  ]
 [  3.3288805 ]
 [ -3.3748622 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [29.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 25. 30. 28. 28.  8. 10. 10.  8.  9.  8.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [14. 11. 15.  8.  3.] 
adversary cards in discard: [10.  4. 11.  1.  0.  0.  0. 10. 15.  3.  3.  0.  4. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10] -> size -> 22 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.619382619857788



buy possibilites: [-1] 
expected returns: [[11.837399]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [29.  1. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 28.  8. 10. 10.  8.  9.  7.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [14. 11. 15.  8.  3.] 
adversary cards in discard: [10.  4. 11.  1.  0.  0.  0. 10. 15.  3.  3.  0.  4. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10] -> size -> 22 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   60    0    0    0    0    0    0    0
  250    0] 
sum of rewards: 65 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 4.836785316467285






Player: 1 
cards in hand: [14. 11. 15.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11. 15.  8.  3.] 
cards in discard: [10.  4. 11.  1.  0.  0.  0. 10. 15.  3.  3.  0.  4. 10.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 28.  8. 10. 10.  8.  9.  7.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [29. 25.  3.  0.  3.] 
adversary cards in discard: [29.  1. 25. 29. 29. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25] -> size -> 27 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11. 15.] 
cards in discard: [10.  4. 11.  1.  0.  0.  0. 10. 15.  3.  3.  0.  4. 10.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 28.  8. 10. 10.  8.  9.  7.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [29. 25.  3.  0.  3.] 
adversary cards in discard: [29.  1. 25. 29. 29. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25] -> size -> 27 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11. 15.] 
cards in discard: [10.  4. 11.  1.  0.  0.  0. 10. 15.  3.  3.  0.  4. 10.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 25. 30. 28. 28.  8. 10. 10.  8.  9.  7.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [29. 25.  3.  0.  3.] 
adversary cards in discard: [29.  1. 25. 29. 29. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25] -> size -> 27 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11. 15.] 
cards in discard: [10.  4. 11.  1.  0.  0.  0. 10. 15.  3.  3.  0.  4. 10.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 28.  8. 10. 10.  8.  9.  7.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [29. 25.  3.  0.  3.] 
adversary cards in discard: [29.  1. 25. 29. 29. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25] -> size -> 27 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [29. 25.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[24.997095]
 [36.84653 ]
 [34.73652 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  3.  0.  3.] 
cards in discard: [29.  1. 25. 29. 29. 15. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 28.  8. 10. 10.  8.  9.  7.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [11. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0] -> size -> 22 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.837398529052734



action possibilites: [-1. 25.] 
expected returns: [[65.49502]
 [74.93236]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  3.] 
cards in discard: [29.  1. 25. 29. 29. 15. 15. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 28. 28.  8. 10. 10.  8.  9.  7.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [11. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0] -> size -> 22 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 30.481489181518555



action possibilites: [-1] 
expected returns: [[56.04025]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [29.  1. 25. 29. 29. 15. 15. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 28. 28.  8.  9. 10.  8.  9.  7.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [11. 11. 10.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6] -> size -> 23 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -175 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 74.9323501586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[53.210533]
 [60.926243]
 [55.223198]
 [44.874527]
 [30.268274]
 [57.409344]
 [59.958866]
 [55.73223 ]
 [63.901447]
 [56.19685 ]
 [60.714176]
 [56.132812]
 [44.17523 ]
 [62.365543]
 [55.30734 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [29.  1. 25. 29. 29. 15. 15. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 25. 30. 28. 28.  8.  9. 10.  8.  9.  7.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [11. 11. 10.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6] -> size -> 23 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.04024887084961



buy possibilites: [-1] 
expected returns: [[-5.7715178]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [29.  1. 25. 29. 29. 15. 15. 29. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 28.  8.  9. 10.  8.  9.  6.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [11. 11. 10.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6] -> size -> 23 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   40    0    0    0    0    0    0    0
  250    0] 
sum of rewards: 75 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 63.90146255493164






Player: 1 
cards in hand: [11. 11. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.  0.  0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 28.  8.  9. 10.  8.  9.  6.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [25.  1.  1. 29.  0.] 
adversary cards in discard: [29.  1. 25. 29. 29. 15. 15. 29. 25. 29. 25.  3.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25] -> size -> 28 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 10.  0.  0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 28. 28.  8.  9. 10.  8.  9.  6.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [25.  1.  1. 29.  0.] 
adversary cards in discard: [29.  1. 25. 29. 29. 15. 15. 29. 25. 29. 25.  3.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25] -> size -> 28 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 10.  0.  0.] 
cards in discard: [6. 8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 28.  8.  9. 10.  8.  8.  6.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [25.  1.  1. 29.  0.] 
adversary cards in discard: [29.  1. 25. 29. 29. 15. 15. 29. 25. 29. 25.  3.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25] -> size -> 28 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [25.  1.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[29.483229]
 [36.22643 ]
 [37.73651 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  1. 29.  0.] 
cards in discard: [29.  1. 25. 29. 29. 15. 15. 29. 25. 29. 25.  3.  0.  3.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 28.  8.  9. 10.  8.  8.  6.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [3. 0. 8. 4. 3.] 
adversary cards in discard: [ 6.  8. 11. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8] -> size -> 24 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.771517753601074



action possibilites: [-1. 25. 29.] 
expected returns: [[58.16655]
 [65.04375]
 [66.58757]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0. 29.] 
cards in discard: [29.  1. 25. 29. 29. 15. 15. 29. 25. 29. 25.  3.  0.  3.  0.  1.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 28. 28.  8.  9. 10.  8.  8.  6.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [3. 0. 8. 4. 3.] 
adversary cards in discard: [ 6.  8. 11. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8] -> size -> 24 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 33.8890495300293



action possibilites: [-1. 25. 29.] 
expected returns: [[40.391197]
 [47.33298 ]
 [48.895718]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29.] 
cards in discard: [29.  1. 25. 29. 29. 15. 15. 29. 25. 29. 25.  3.  0.  3.  0.  1.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 28. 28.  8.  9. 10.  8.  8.  6.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [3. 0. 8. 4. 3.] 
adversary cards in discard: [ 6.  8. 11. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8] -> size -> 24 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -145 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 62.66054916381836



action possibilites: [-1. 25.] 
expected returns: [[43.195393]
 [50.806053]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.] 
cards in discard: [29.  1. 25. 29. 29. 15. 15. 29. 25. 29. 25.  3.  0.  3.  0.  1.  1.  1.
 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 25. 30. 28. 28.  8.  9. 10.  8.  8.  6.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [3. 0. 8. 4. 3.] 
adversary cards in discard: [ 6.  8. 11. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8] -> size -> 24 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 44.93102264404297



action possibilites: [-1] 
expected returns: [[1.7916081]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [29.  1. 25. 29. 29. 15. 15. 29. 25. 29. 25.  3.  0.  3.  0.  1.  1.  1.
 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 25. 30. 28. 28.  8.  8. 10.  8.  8.  6.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [3. 0. 8. 4. 3.] 
adversary cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8
  6] -> size -> 25 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   80    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 50.80608367919922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -0.85544324]
 [  6.4585733 ]
 [  1.0507061 ]
 [ -9.077929  ]
 [-22.985472  ]
 [  3.2629173 ]
 [  5.526498  ]
 [  1.3179452 ]
 [  9.204634  ]
 [  2.0693333 ]
 [  6.197257  ]
 [  1.8598883 ]
 [ -9.80698   ]
 [  7.7820835 ]
 [  1.3189471 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [29.  1. 25. 29. 29. 15. 15. 29. 25. 29. 25.  3.  0.  3.  0.  1.  1.  1.
 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 25. 30. 28. 28.  8.  8. 10.  8.  8.  6.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [3. 0. 8. 4. 3.] 
adversary cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8
  6] -> size -> 25 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   80    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.7916080951690674



buy possibilites: [-1] 
expected returns: [[7.9829206]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [29.  1. 25. 29. 29. 15. 15. 29. 25. 29. 25.  3.  0.  3.  0.  1.  1.  1.
 29. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 28.  8.  8. 10.  8.  8.  5.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [3. 0. 8. 4. 3.] 
adversary cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8
  6] -> size -> 25 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   80    0    0    0    0    0    0    0
  250    0] 
sum of rewards: 145 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 9.204638481140137






Player: 1 
cards in hand: [3. 0. 8. 4. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 4. 3.] 
cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 28.  8.  8. 10.  8.  8.  5.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [29.  3.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25] -> size -> 29 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 3.] 
cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 28.  8.  8. 10.  8.  8.  5.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [29.  3.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25] -> size -> 29 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3.] 
cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 25. 30. 28. 28.  8.  8. 10.  8.  8.  5.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [29.  3.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25] -> size -> 29 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3.] 
cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 28.  8.  8. 10.  8.  8.  5.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [29.  3.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25] -> size -> 29 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [29.  3.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[14.692126]
 [26.115908]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  3.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 28.  8.  8. 10.  8.  8.  5.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 1.  0.  0.  3. 10.] 
adversary cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.  0.  8.  4.  3.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.9829206466674805



action possibilites: [-1.] 
expected returns: [[22.290396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 28. 28.  8.  8. 10.  8.  8.  5.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 1.  0.  0.  3. 10.] 
adversary cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.  0.  8.  4.  3.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 19.881261825561523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.808548 ]
 [27.861603 ]
 [22.043287 ]
 [-3.9138575]
 [26.966164 ]
 [22.566252 ]
 [22.871803 ]
 [21.79149  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 28. 28.  8.  8. 10.  8.  8.  5.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 1.  0.  0.  3. 10.] 
adversary cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.  0.  8.  4.  3.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 22.290395736694336



buy possibilites: [-1] 
expected returns: [[17.75834]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [1. 1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 28.  8.  8. 10.  8.  8.  5.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 1.  0.  0.  3. 10.] 
adversary cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.  0.  8.  4.  3.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -51 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 27.861604690551758






Player: 1 
cards in hand: [ 1.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  3. 10.] 
cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.  0.  8.  4.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 28.  8.  8. 10.  8.  8.  5.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 29.  0. 29.  1.] 
adversary cards in discard: [ 1.  1. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1] -> size -> 30 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.  0.  8.  4.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 28.  8.  8. 10.  8.  8.  5.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 29.  0. 29.  1.] 
adversary cards in discard: [ 1.  1. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1] -> size -> 30 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.  0.  8.  4.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 24. 30. 28. 28.  8.  8. 10.  8.  8.  5.  0.  9. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 29.  0. 29.  1.] 
adversary cards in discard: [ 1.  1. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1] -> size -> 30 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.  0.  8.  4.  3. 22.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 28.  8.  8. 10.  8.  8.  5.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 0. 29.  0. 29.  1.] 
adversary cards in discard: [ 1.  1. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1] -> size -> 30 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[61.978313]
 [73.101036]
 [73.101036]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29.  1.] 
cards in discard: [ 1.  1. 29.  3.  3.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 28.  8.  8. 10.  8.  8.  5.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 4. 10.  3. 15. 14.] 
adversary cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.  0.  8.  4.  3. 22. 10.  1.  0.  0.  3.
  0.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22] -> size -> 25 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.75834083557129



action possibilites: [-1. 25.] 
expected returns: [[71.45817]
 [80.767  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 25.] 
cards in discard: [ 1.  1. 29.  3.  3.  0.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 28. 28.  8.  8. 10.  8.  8.  5.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 4. 10.  3. 15. 14.] 
adversary cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.  0.  8.  4.  3. 22. 10.  1.  0.  0.  3.
  0.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22] -> size -> 25 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 67.93156433105469



action possibilites: [-1] 
expected returns: [[71.39711]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 25.  1.] 
cards in discard: [ 1.  1. 29.  3.  3.  0.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 28. 28.  8.  7. 10.  8.  8.  5.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 4. 10.  3. 15. 14.] 
adversary cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.  0.  8.  4.  3. 22. 10.  1.  0.  0.  3.
  0.  6.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 80.76701354980469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[69.606636]
 [78.299126]
 [54.656982]
 [71.88737 ]
 [59.36398 ]
 [42.934895]
 [74.37036 ]
 [77.57568 ]
 [73.00664 ]
 [81.844666]
 [72.96984 ]
 [78.05698 ]
 [73.205956]
 [58.75691 ]
 [79.99346 ]
 [71.854614]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 25.  1.] 
cards in discard: [ 1.  1. 29.  3.  3.  0.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 7 
card supply: [25. 24. 30. 28. 28.  8.  7. 10.  8.  8.  5.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 4. 10.  3. 15. 14.] 
adversary cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.  0.  8.  4.  3. 22. 10.  1.  0.  0.  3.
  0.  6.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 71.39710998535156



buy possibilites: [-1] 
expected returns: [[16.450823]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 25.  1.] 
cards in discard: [ 1.  1. 29.  3.  3.  0.  0. 29. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 24. 30. 28. 28.  8.  7. 10.  8.  8.  4.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 4. 10.  3. 15. 14.] 
adversary cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.  0.  8.  4.  3. 22. 10.  1.  0.  0.  3.
  0.  6.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.  -120.     0.     0.    40.     0.     0.     0.
    0.     0.     0.     0.    62.5    0. ] 
sum of rewards: -22.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 81.84467315673828






Player: 1 
cards in hand: [ 4. 10.  3. 15. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 10.  3. 15. 14.] 
cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.  0.  8.  4.  3. 22. 10.  1.  0.  0.  3.
  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 28.  8.  7. 10.  8.  8.  4.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [29. 25. 29.  0. 29.] 
adversary cards in discard: [ 1.  1. 29.  3.  3.  0.  0. 29. 25. 29. 25.  0.  0.  1. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1 25] -> size -> 31 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 10.  3. 15. 14.] 
cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.  0.  8.  4.  3. 22. 10.  1.  0.  0.  3.
  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 24. 30. 28. 28.  8.  7. 10.  8.  8.  4.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [29. 25. 29.  0. 29.] 
adversary cards in discard: [ 1.  1. 29.  3.  3.  0.  0. 29. 25. 29. 25.  0.  0.  1. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1 25] -> size -> 31 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 10.  3. 15. 14.] 
cards in discard: [ 6.  8. 11. 11. 10.  0.  0.  6.  0.  8.  4.  3. 22. 10.  1.  0.  0.  3.
  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 28. 28.  8.  7. 10.  8.  8.  4.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [29. 25. 29.  0. 29.] 
adversary cards in discard: [ 1.  1. 29.  3.  3.  0.  0. 29. 25. 29. 25.  0.  0.  1. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1 25] -> size -> 31 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [29. 25. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 29.] 
expected returns: [[24.303663]
 [32.909657]
 [31.30118 ]
 [32.909657]
 [32.909657]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29.  0. 29.] 
cards in discard: [ 1.  1. 29.  3.  3.  0.  0. 29. 25. 29. 25.  0.  0.  1. 25.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 28. 28.  8.  7. 10.  8.  8.  4.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 8.  0.  4. 14. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.450822830200195



action possibilites: [-1. 25. 29.] 
expected returns: [[13.8716955]
 [21.050081 ]
 [22.689562 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29.  1.] 
cards in discard: [ 1.  1. 29.  3.  3.  0.  0. 29. 25. 29. 25.  0.  0.  1. 25.  1. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 24. 30. 28. 28.  8.  7. 10.  8.  8.  4.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 8.  0.  4. 14. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 28.891416549682617



action possibilites: [-1. 25. 25.] 
expected returns: [[ 9.479259]
 [17.549818]
 [17.549818]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25.] 
cards in discard: [ 1.  1. 29.  3.  3.  0.  0. 29. 25. 29. 25.  0.  0.  1. 25.  1. 29.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 24. 30. 28. 28.  8.  7. 10.  8.  8.  4.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 8.  0.  4. 14. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 18.575151443481445



action possibilites: [-1] 
expected returns: [[1.840399]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25. 29.] 
cards in discard: [ 1.  1. 29.  3.  3.  0.  0. 29. 25. 29. 25.  0.  0.  1. 25.  1. 29.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 24. 30. 28. 28.  8.  6. 10.  8.  8.  4.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 8.  0.  4. 14. 15.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6] -> size -> 28 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 17.549823760986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -0.58539534]
 [  5.863818  ]
 [  1.1586182 ]
 [-20.120642  ]
 [  4.900345  ]
 [  0.7095823 ]
 [  1.4935191 ]
 [  1.4841969 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 25. 29.] 
cards in discard: [ 1.  1. 29.  3.  3.  0.  0. 29. 25. 29. 25.  0.  0.  1. 25.  1. 29.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1 25] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 30. 28. 28.  8.  6. 10.  8.  8.  4.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 8.  0.  4. 14. 15.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6] -> size -> 28 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.8403990268707275



buy possibilites: [-1] 
expected returns: [[-3.1084337]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 25. 29.] 
cards in discard: [ 1.  1. 29.  3.  3.  0.  0. 29. 25. 29. 25.  0.  0.  1. 25.  1. 29.  1.
  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1 25  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 28. 28.  8.  6. 10.  8.  8.  4.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 8.  0.  4. 14. 15.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6] -> size -> 28 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 5.863821983337402






Player: 1 
cards in hand: [ 8.  0.  4. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  4. 14. 15.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 28. 28.  8.  6. 10.  8.  8.  4.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [15.  3. 29. 29. 29.] 
adversary cards in discard: [ 1.  1. 29.  3.  3.  0.  0. 29. 25. 29. 25.  0.  0.  1. 25.  1. 29.  1.
  1. 29. 29. 25.  0. 25. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1 25  1] -> size -> 32 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  4. 14. 15.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 23. 30. 28. 28.  8.  6. 10.  8.  8.  4.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [15.  3. 29. 29. 29.] 
adversary cards in discard: [ 1.  1. 29.  3.  3.  0.  0. 29. 25. 29. 25.  0.  0.  1. 25.  1. 29.  1.
  1. 29. 29. 25.  0. 25. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1 25  1] -> size -> 32 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [15.  3. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 29. 29.] 
expected returns: [[ 5.4386797]
 [11.306633 ]
 [14.322484 ]
 [14.322484 ]
 [14.322484 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 29. 29. 29.] 
cards in discard: [ 1.  1. 29.  3.  3.  0.  0. 29. 25. 29. 25.  0.  0.  1. 25.  1. 29.  1.
  1. 29. 29. 25.  0. 25. 25. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1 25  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 28. 28.  8.  6. 10.  8.  8.  4.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 8. 11.  6.  6.  6.] 
adversary cards in discard: [ 6.  8.  0.  4. 14. 15.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6] -> size -> 28 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -3.108433723449707



action possibilites: [-1. 15. 29. 29. 15.] 
expected returns: [[-1.0182023]
 [ 4.2251797]
 [ 6.9124346]
 [ 6.9124346]
 [ 4.2251797]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 29. 15.] 
cards in discard: [ 1.  1. 29.  3.  3.  0.  0. 29. 25. 29. 25.  0.  0.  1. 25.  1. 29.  1.
  1. 29. 29. 25.  0. 25. 25. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1 25  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 23. 30. 28. 28.  8.  6. 10.  8.  8.  4.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 8. 11.  6.  6.  6.] 
adversary cards in discard: [ 6.  8.  0.  4. 14. 15.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6] -> size -> 28 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 10.095413208007812



action possibilites: [-1. 15. 15.] 
expected returns: [[-2.3891926e-03]
 [ 7.0171518e+00]
 [ 7.0171518e+00]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  0.] 
cards in discard: [29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25
 25  1 25 25 25  1 25  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 23. 30. 28. 28.  8.  6. 10.  8.  8.  4.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 8. 11.  6.  6.  6.] 
adversary cards in discard: [ 6.  8.  0.  4. 14. 15.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6] -> size -> 28 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 3.1827762126922607



action possibilites: [-1] 
expected returns: [[-15.9628]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 5 
card supply: [24. 23. 30. 28. 28.  8.  6. 10.  8.  8.  4.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 8. 11.  6.  6.  6.] 
adversary cards in discard: [ 6.  8.  0.  4. 14. 15.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6] -> size -> 28 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 7.017165184020996





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-18.161875]
 [-11.563327]
 [-16.388155]
 [-25.267183]
 [-38.24834 ]
 [-14.407147]
 [-12.695984]
 [-16.835154]
 [ -9.24584 ]
 [-15.456585]
 [-11.80377 ]
 [-16.034428]
 [-25.930641]
 [-10.436169]
 [-16.041481]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 23. 30. 28. 28.  8.  6. 10.  8.  8.  4.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 8. 11.  6.  6.  6.] 
adversary cards in discard: [ 6.  8.  0.  4. 14. 15.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6] -> size -> 28 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: 0
desired expected reward: -15.962800025939941



buy possibilites: [-1] 
expected returns: [[-4.360211]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [29. 25.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 28. 28.  8.  6. 10.  8.  8.  3.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 8. 11.  6.  6.  6.] 
adversary cards in discard: [ 6.  8.  0.  4. 14. 15.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6] -> size -> 28 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -9.245835304260254






Player: 1 
cards in hand: [ 8. 11.  6.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  6.  6.  6.] 
cards in discard: [ 6.  8.  0.  4. 14. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 28. 28.  8.  6. 10.  8.  8.  3.  0.  9. 10.  7.  9.  6.] 
adversary cards in hand: [ 1.  1.  3. 29.  3.] 
adversary cards in discard: [29. 25. 29. 29. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25] -> size -> 32 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 6.] 
cards in discard: [ 6.  8.  0.  4. 14. 15. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 28. 28.  8.  6. 10.  8.  8.  3.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [ 1.  1.  3. 29.  3.] 
adversary cards in discard: [29. 25. 29. 29. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25] -> size -> 32 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6. 6.] 
cards in discard: [ 6.  8.  0.  4. 14. 15. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 23. 30. 28. 28.  8.  6. 10.  8.  8.  3.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [ 1.  1.  3. 29.  3.] 
adversary cards in discard: [29. 25. 29. 29. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25] -> size -> 32 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6. 6.] 
cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6 14  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 28. 28.  8.  6. 10.  8.  8.  3.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [ 1.  1.  3. 29.  3.] 
adversary cards in discard: [29. 25. 29. 29. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25] -> size -> 32 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 1.  1.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[23.484007]
 [32.080563]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  3. 29.  3.] 
cards in discard: [29. 25. 29. 29. 15. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 28. 28.  8.  6. 10.  8.  8.  3.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [15.  1.  0.  0. 10.] 
adversary cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6 14  0] -> size -> 30 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.36021089553833



action possibilites: [-1. 25.] 
expected returns: [[31.325834]
 [40.168736]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  3. 25.] 
cards in discard: [29. 25. 29. 29. 15. 15.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 28. 28.  8.  6. 10.  8.  8.  3.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [15.  1.  0.  0. 10.] 
adversary cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6 14  0] -> size -> 30 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 28.053852081298828



action possibilites: [-1] 
expected returns: [[17.54864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  3. 29. 29.] 
cards in discard: [29. 25. 29. 29. 15. 15.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 28. 28.  8.  5. 10.  8.  8.  3.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [15.  1.  0.  0. 10.] 
adversary cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6 14  0  6] -> size -> 31 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 40.16875076293945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[16.242582 ]
 [23.95616  ]
 [18.25468  ]
 [ 7.801837 ]
 [-6.7710915]
 [20.441105 ]
 [22.989504 ]
 [18.763166 ]
 [26.92775  ]
 [19.228622 ]
 [23.743477 ]
 [19.16421  ]
 [ 7.102701 ]
 [25.392519 ]
 [18.339748 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  3. 29. 29.] 
cards in discard: [29. 25. 29. 29. 15. 15.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 23. 30. 28. 28.  8.  5. 10.  8.  8.  3.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [15.  1.  0.  0. 10.] 
adversary cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6 14  0  6] -> size -> 31 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.54863929748535



buy possibilites: [-1] 
expected returns: [[53.383488]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  3. 29. 29.] 
cards in discard: [29. 25. 29. 29. 15. 15.  3. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 28. 28.  8.  5. 10.  8.  8.  2.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [15.  1.  0.  0. 10.] 
adversary cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6.] 
adversary owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6 14  0  6] -> size -> 31 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 225 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 26.92774200439453






Player: 1 
cards in hand: [15.  1.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  0.  0. 10.] 
cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0
 22  6  0  6 14  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 28. 28.  8.  5. 10.  8.  8.  2.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [ 1. 25.  1.  1. 29.] 
adversary cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25] -> size -> 33 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.] 
cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 23. 30. 28. 28.  8.  5. 10.  8.  8.  2.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [ 1. 25.  1.  1. 29.] 
adversary cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25] -> size -> 33 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.] 
cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 23. 30. 28. 28.  8.  5. 10.  8.  8.  2.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [ 1. 25.  1.  1. 29.] 
adversary cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25] -> size -> 33 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.] 
cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 28. 28.  8.  5. 10.  8.  8.  1.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [ 1. 25.  1.  1. 29.] 
adversary cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25] -> size -> 33 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 1. 25.  1.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[12.032623]
 [19.645504]
 [21.298948]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  1.  1. 29.] 
cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 28. 28.  8.  5. 10.  8.  8.  1.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [10.  0. 10.  3.  3.] 
adversary cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6. 25. 15.  1.  0.
 10.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25] -> size -> 31 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.383487701416016



action possibilites: [-1. 25.] 
expected returns: [[53.634327]
 [60.632687]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  1. 25.] 
cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 28. 28.  8.  5. 10.  8.  8.  1.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [10.  0. 10.  3.  3.] 
adversary cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6. 25. 15.  1.  0.
 10.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25] -> size -> 31 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 16.99190330505371



action possibilites: [-1] 
expected returns: [[21.819778]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  1. 25.  0.] 
cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 28. 28.  8.  4. 10.  8.  8.  1.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [10.  0. 10.  3.  3.] 
adversary cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6. 25. 15.  1.  0.
 10.  6.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 60.6326789855957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[1.9766087e+01]
 [2.6583488e+01]
 [9.0583916e+00]
 [2.1686085e+01]
 [1.2937446e+01]
 [2.7138041e+01]
 [1.1457205e-02]
 [2.3534727e+01]
 [2.5445702e+01]
 [2.1208063e+01]
 [2.9120367e+01]
 [2.2513008e+01]
 [2.6411001e+01]
 [2.1945320e+01]
 [1.2208894e+01]
 [2.7794813e+01]
 [2.1776897e+01]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  1. 25.  0.] 
cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 8 
card supply: [23. 23. 30. 28. 28.  8.  4. 10.  8.  8.  1.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [10.  0. 10.  3.  3.] 
adversary cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6. 25. 15.  1.  0.
 10.  6.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.819778442382812



buy possibilites: [-1] 
expected returns: [[4.6003733]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  1. 25.  0.] 
cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29. 25. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 23. 30. 28. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [10.  0. 10.  3.  3.] 
adversary cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6. 25. 15.  1.  0.
 10.  6.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 67.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 29.1203670501709






Player: 1 
cards in hand: [10.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3.  3.] 
cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6. 25. 15.  1.  0.
 10.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 28. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [25. 29. 29. 29.  1.] 
adversary cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29. 25. 25. 29.
 25.  1.  1.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25] -> size -> 34 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 10. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3. 22.] 
cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6. 25. 15.  1.  0.
 10.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 28. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [25. 29. 29. 29.  1.] 
adversary cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29. 25. 25. 29.
 25.  1.  1.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25] -> size -> 34 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.  0.  0.  4.] 
cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6. 25. 15.  1.  0.
 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 22.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 28. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [25. 29. 29. 29.  1.] 
adversary cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29. 25. 25. 29.
 25.  1.  1.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25] -> size -> 34 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0. 4. 3.] 
cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6. 25. 15.  1.  0.
 10.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 22. 10.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 28. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [25. 29. 29. 29.  1.] 
adversary cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29. 25. 25. 29.
 25.  1.  1.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25] -> size -> 34 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0. 4. 3.] 
cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6. 25. 15.  1.  0.
 10.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 22. 10.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 23. 30. 28. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [25. 29. 29. 29.  1.] 
adversary cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29. 25. 25. 29.
 25.  1.  1.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25] -> size -> 34 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0. 4. 3.] 
cards in discard: [ 6.  8.  0.  4. 14. 15. 14.  0. 11.  8.  6.  6.  6.  6. 25. 15.  1.  0.
 10.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 22. 10.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 23. 30. 28. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [25. 29. 29. 29.  1.] 
adversary cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29. 25. 25. 29.
 25.  1.  1.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25] -> size -> 34 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [25. 29. 29. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29. 29.] 
expected returns: [[ 8.298097]
 [14.624303]
 [16.22198 ]
 [16.22198 ]
 [16.22198 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29. 29.  1.] 
cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29. 25. 25. 29.
 25.  1.  1.  1. 25.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 28. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [ 0. 10. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.600373268127441



action possibilites: [-1. 25. 29. 29.] 
expected returns: [[ 4.1338882]
 [11.430433 ]
 [13.167354 ]
 [13.167354 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29.] 
cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29. 25. 25. 29.
 25.  1.  1.  1. 25.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 23. 30. 28. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [ 0. 10. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: 12.969449043273926



action possibilites: [-1.] 
expected returns: [[-12.267745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29. 25. 25. 29.
 25.  1.  1.  1. 25.  0.  1.  0. 25. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 23. 30. 28. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [ 0. 10. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 8.940278053283691





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-14.270551]
 [ -7.58529 ]
 [-12.457274]
 [-34.427208]
 [ -8.701836]
 [-12.883419]
 [-12.099119]
 [-12.154406]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29. 25. 25. 29.
 25.  1.  1.  1. 25.  0.  1.  0. 25. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 23. 30. 28. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [ 0. 10. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -12.267745018005371



buy possibilites: [-1] 
expected returns: [[-8.908663]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 25. 29. 29. 15. 15.  3. 25. 29. 25.  1.  1.  3. 29. 29. 25. 25. 29.
 25.  1.  1.  1. 25.  0.  1.  0. 25. 29.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 28. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [ 0. 10. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -7.585287094116211






Player: 1 
cards in hand: [ 0. 10. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 28. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [29.  1. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1] -> size -> 35 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 28. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [29.  1. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1] -> size -> 35 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 22. 30. 28. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [29.  1. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1] -> size -> 35 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 11.  0.] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 22. 30. 27. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [29.  1. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [29.  1. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[19.136223]
 [28.30039 ]
 [26.640682]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 27. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 3. 10.  0. 11.  0. 11.  0.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.908662796020508



action possibilites: [-1. 25.] 
expected returns: [[-2.5941875]
 [ 4.218461 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 25.] 
cards in discard: [ 0. 25.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 22. 30. 27. 28.  8.  4. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 3. 10.  0. 11.  0. 11.  0.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: 24.4117374420166



action possibilites: [-1] 
expected returns: [[3.798549]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29.  1.] 
cards in discard: [ 0. 25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 22. 30. 27. 28.  8.  3. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 4.218467712402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  3.2590353]
 [ 10.923726 ]
 [  5.452853 ]
 [ -4.538677 ]
 [-18.936367 ]
 [  7.419881 ]
 [  9.90088  ]
 [  5.396282 ]
 [  6.2877083]
 [ 10.778948 ]
 [  5.9328823]
 [ -5.267437 ]
 [ 12.367872 ]
 [  5.302472 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 29.  1.] 
cards in discard: [ 0. 25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 22. 30. 27. 28.  8.  3. 10.  8.  8.  0.  0.  8. 10.  7.  9.  6.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.798548936843872



buy possibilites: [-1] 
expected returns: [[8.821764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 29.  1.] 
cards in discard: [ 0. 25. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 22. 30. 27. 28.  8.  3. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  40.   0.   0.   0.   0. -10.   0.   0.
  32.   0.] 
sum of rewards: 27.0 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 12.36788272857666






Player: 1 
cards in hand: [6. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 27. 28.  8.  3. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [29.  3. 25. 29. 25.] 
adversary cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 22. 30. 27. 28.  8.  3. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [29.  3. 25. 29. 25.] 
adversary cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [29.  3. 25. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 25.] 
expected returns: [[61.050938]
 [70.74487 ]
 [68.935394]
 [70.74487 ]
 [68.935394]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 25. 29. 25.] 
cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 27. 28.  8.  3. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [15.  6. 14.  6. 25.] 
adversary cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.82176399230957



action possibilites: [-1. 29. 25. 29.] 
expected returns: [[12.466118]
 [22.974386]
 [21.019566]
 [22.974386]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29.] 
cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 22. 30. 27. 28.  8.  3. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [15.  6. 14.  6. 25.] 
adversary cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: 66.67151641845703



action possibilites: [-1. 25.] 
expected returns: [[13.849919]
 [21.325697]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.] 
cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 22. 30. 27. 28.  8.  3. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [15.  6. 14.  6. 25.] 
adversary cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 18.070880889892578



action possibilites: [-1] 
expected returns: [[-18.224575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.] 
cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 22. 30. 27. 28.  8.  2. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [15.  6. 14.  6. 25.] 
adversary cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 21.325687408447266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-20.357264]
 [-18.69712 ]
 [-38.959938]
 [-19.247084]
 [-18.323633]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 29.] 
cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 22. 30. 27. 28.  8.  2. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [15.  6. 14.  6. 25.] 
adversary cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: -18.22457504272461






Player: 1 
cards in hand: [15.  6. 14.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 25.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6. 14.  6. 25.] 
cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 27. 28.  8.  2. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [25. 29.  0. 25. 25.] 
adversary cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29. 29. 29. 25. 15. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  6. 25.] 
cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 22. 30. 27. 28.  8.  2. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [29. 25. 25.] 
adversary cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29. 29. 29. 25. 15. 29.
  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  6. 25.] 
cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 22. 30. 27. 28.  8.  2. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [29. 25. 25.] 
adversary cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29. 29. 29. 25. 15. 29.
  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  6. 25.] 
cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 22. 30. 27. 28.  8.  2. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [29. 25. 25.] 
adversary cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29. 29. 29. 25. 15. 29.
  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [29. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[19.938904]
 [28.753244]
 [27.171448]
 [27.171448]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 25.] 
cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29. 29. 29. 25. 15. 29.
  0. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 27. 28.  8.  2. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [ 1.  6. 22.  0.  3.] 
adversary cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.  0. 14. 15.  6.
  6. 25.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: discard_down_to_3_cards - action 5
Learning step: 0
desired expected reward: -31.490324020385742



action possibilites: [-1.] 
expected returns: [[4.2795696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29. 29. 29. 25. 15. 29.
  0. 25. 25. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 27. 28.  8.  2. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [ 1.  6. 22.  0.  3.] 
adversary cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.  0. 14. 15.  6.
  6. 25.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 24.653898239135742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[  2.2921202]
 [  3.9522574]
 [-16.372896 ]
 [  3.4022982]
 [  4.3257504]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29. 29. 29. 25. 15. 29.
  0. 25. 25. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 22. 30. 27. 28.  8.  2. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [ 1.  6. 22.  0.  3.] 
adversary cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.  0. 14. 15.  6.
  6. 25.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 4.279569625854492






Player: 1 
cards in hand: [ 1.  6. 22.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 22.  0.  3.] 
cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.  0. 14. 15.  6.
  6. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 27. 28.  8.  2. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [25. 25.  1.  1.  0.] 
adversary cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29. 29. 29. 25. 15. 29.
  0. 25. 25. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 3. 4. 6. 0.] 
cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.  0. 14. 15.  6.
  6. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 27. 28.  8.  2. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [25. 25.  1.  1.  0.] 
adversary cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29. 29. 29. 25. 15. 29.
  0. 25. 25. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 3. 4. 6. 0.] 
cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.  0. 14. 15.  6.
  6. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 22. 30. 27. 28.  8.  2. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [25. 25.  1.  1.  0.] 
adversary cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29. 29. 29. 25. 15. 29.
  0. 25. 25. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [25. 25.  1.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[2.8959124]
 [9.220811 ]
 [9.220811 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  1.  1.  0.] 
cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29. 29. 29. 25. 15. 29.
  0. 25. 25. 25. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 27. 28.  8.  2. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [ 3.  4.  8. 15.  0.] 
adversary cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.  0. 14. 15.  6.
  6. 25. 22.  1.  6.  0.  3.  4.  6.  0.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 4.325752258300781



action possibilites: [-1] 
expected returns: [[9.99358]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  1.  0. 29. 15.] 
cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29. 29. 29. 25. 15. 29.
  0. 25. 25. 25. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 27. 28.  8.  1. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [ 3.  4.  8. 15.  0.] 
adversary cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.  0. 14. 15.  6.
  6. 25. 22.  1.  6.  0.  3.  4.  6.  0.  6.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0  6] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 9.220810890197754





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  5.866639 ]
 [ 12.680859 ]
 [  7.787176 ]
 [ -0.9563637]
 [-13.835232 ]
 [  9.633626 ]
 [ 11.544245 ]
 [  7.307418 ]
 [  8.612736 ]
 [ 12.508941 ]
 [  8.044478 ]
 [ -1.6840781]
 [ 13.892079 ]
 [  7.875808 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  1.  0. 29. 15.] 
cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29. 29. 29. 25. 15. 29.
  0. 25. 25. 25. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 22. 30. 27. 28.  8.  1. 10.  8.  8.  0.  0.  8. 10.  7.  9.  5.] 
adversary cards in hand: [ 3.  4.  8. 15.  0.] 
adversary cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.  0. 14. 15.  6.
  6. 25. 22.  1.  6.  0.  3.  4.  6.  0.  6.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0  6] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.993579864501953



buy possibilites: [-1] 
expected returns: [[21.514532]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  1.  0. 29. 15.] 
cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29. 29. 29. 25. 15. 29.
  0. 25. 25. 25. 29.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 27. 28.  8.  1. 10.  8.  8.  0.  0.  8. 10.  7.  9.  4.] 
adversary cards in hand: [ 3.  4.  8. 15.  0.] 
adversary cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.  0. 14. 15.  6.
  6. 25. 22.  1.  6.  0.  3.  4.  6.  0.  6.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0  6] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.  30.   0.   0.  20.   0.   0.   0.   0. -20.   0.   0.
  32.   0.] 
sum of rewards: 57.0 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 13.89207935333252






Player: 1 
cards in hand: [ 3.  4.  8. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  4.  8. 15.  0.] 
cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.  0. 14. 15.  6.
  6. 25. 22.  1.  6.  0.  3.  4.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 27. 28.  8.  1. 10.  8.  8.  0.  0.  8. 10.  7.  9.  4.] 
adversary cards in hand: [ 1.  1.  1.  3. 29.] 
adversary cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29. 29. 29. 25. 15. 29.
  0. 25. 25. 25. 29.  0. 15. 25. 25.  1.  1.  0. 29. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15 15] -> size -> 37 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  4.  8. 15.  0.] 
cards in discard: [ 3. 10.  0. 11.  0. 11.  0.  6.  6.  0.  0.  3.  6.  6.  0. 14. 15.  6.
  6. 25. 22.  1.  6.  0.  3.  4.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 22. 30. 27. 28.  8.  1. 10.  8.  8.  0.  0.  8. 10.  7.  9.  4.] 
adversary cards in hand: [ 1.  1.  1.  3. 29.] 
adversary cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29. 29. 29. 25. 15. 29.
  0. 25. 25. 25. 29.  0. 15. 25. 25.  1.  1.  0. 29. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15 15] -> size -> 37 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 1.  1.  1.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[25.15528 ]
 [35.439976]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  1.  3. 29.] 
cards in discard: [ 0. 25. 15. 29. 25.  1.  3. 29.  1.  3. 25. 29. 29. 29. 29. 25. 15. 29.
  0. 25. 25. 25. 29.  0. 15. 25. 25.  1.  1.  0. 29. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 27. 28.  8.  1. 10.  8.  8.  0.  0.  8. 10.  7.  9.  4.] 
adversary cards in hand: [ 6. 14.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0  6] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.5145320892334



action possibilites: [-1. 15.] 
expected returns: [[11.312092]
 [17.179798]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 15.] 
cards in discard: [1. 3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 27. 28.  8.  1. 10.  8.  8.  0.  0.  8. 10.  7.  9.  4.] 
adversary cards in hand: [ 6. 14.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0  6] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 30.64400291442871



action possibilites: [-1] 
expected returns: [[-10.389823]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [1. 3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 27. 28.  8.  1. 10.  8.  8.  0.  0.  8. 10.  7.  9.  4.] 
adversary cards in hand: [ 6. 14.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0  6] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 17.179800033569336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.887162 ]
 [ -3.8432207]
 [ -8.998683 ]
 [-18.699507 ]
 [-32.36182  ]
 [ -6.9084334]
 [ -4.815629 ]
 [ -9.016515 ]
 [ -8.038991 ]
 [ -4.084322 ]
 [ -8.389163 ]
 [-19.367304 ]
 [ -2.5802367]
 [ -8.760463 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [1. 3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 22. 30. 27. 28.  8.  1. 10.  8.  8.  0.  0.  8. 10.  7.  9.  4.] 
adversary cards in hand: [ 6. 14.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0  6] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.389822959899902



buy possibilites: [-1] 
expected returns: [[13.073501]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 1.  3. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 27. 28.  8.  1. 10.  8.  8.  0.  0.  8. 10.  7.  9.  3.] 
adversary cards in hand: [ 6. 14.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0  6] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.  60.   0.   0.  40.   0.   0.   0.   0. -30.   0.   0.
  32.   0.] 
sum of rewards: 97.0 

action type: buy - action 15.0
Learning step: 0
desired expected reward: -2.5802347660064697






Player: 1 
cards in hand: [ 6. 14.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  8. 10. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 27. 28.  8.  1. 10.  8.  8.  0.  0.  8. 10.  7.  9.  3.] 
adversary cards in hand: [15. 25.  1. 29. 29.] 
adversary cards in discard: [ 1.  3. 15. 29. 15.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 14.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  8. 10.  4.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15 10  0  1  8 10  4 10  0  6  8  6  0 22
  6  0  6 14  0  6 25  6  0  3  6  6  0  6] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 27. 28.  8.  1. 10.  8.  8.  0.  0.  8. 10.  7.  9.  3.] 
adversary cards in hand: [15. 25.  1. 29. 29.] 
adversary cards in discard: [ 1.  3. 15. 29. 15.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  4.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15  0  1  8 10  4 10  0  6  8  6  0 22  6
  0  6 14  0  6 25  6  0  3  6  6  0  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 27. 28.  8.  1. 10.  8.  8.  0.  0.  8. 10.  7.  9.  3.] 
adversary cards in hand: [15. 25.  1. 29. 29.] 
adversary cards in discard: [ 1.  3. 15. 29. 15.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  4.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 14 11  4 15  3 11  0  0  3 15  0  1  8 10  4 10  0  6  8  6  0 22  6
  0  6 14  0  6 25  6  0  3  6  6  0  6] -> size -> 37 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 22. 30. 27. 28.  8.  1. 10.  8.  8.  0.  0.  8. 10.  7.  9.  3.] 
adversary cards in hand: [15. 25.  1. 29. 29.] 
adversary cards in discard: [ 1.  3. 15. 29. 15.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [15. 25.  1. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 29. 29.] 
expected returns: [[29.628023]
 [35.906235]
 [37.247364]
 [39.037846]
 [39.037846]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25.  1. 29. 29.] 
cards in discard: [ 1.  3. 15. 29. 15.  1.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 27. 28.  8.  1. 10.  8.  8.  0.  0.  8. 10.  7.  9.  3.] 
adversary cards in hand: [ 6.  6. 25. 22. 15.] 
adversary cards in discard: [10.  8.  6. 14.  4.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15  0  1  8 10  4 10  0  6  8  6  0 22  6
  0  6 14  0  6 25  6  0  3  6  6  0  6] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.073500633239746



action possibilites: [-1. 15. 25. 29.] 
expected returns: [[-7.7299337 ]
 [-1.0839396 ]
 [ 0.35558438]
 [ 2.292145  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25. 29.] 
cards in discard: [ 1.  3. 15. 29. 15.  1.  1.  1. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 27. 28.  8.  1. 10.  8.  8.  0.  0.  8. 10.  7.  9.  3.] 
adversary cards in hand: [ 6.  6. 25. 22. 15.] 
adversary cards in discard: [10.  8.  6. 14.  4.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15  0  1  8 10  4 10  0  6  8  6  0 22  6
  0  6 14  0  6 25  6  0  3  6  6  0  6] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: 35.08073043823242



action possibilites: [-1. 25.] 
expected returns: [[ 2.8904908]
 [10.387547 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.] 
cards in discard: [ 1.  3. 15. 29. 15.  1.  1.  1. 29. 15. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 22. 30. 27. 28.  8.  1. 10.  8.  8.  0.  0.  8. 10.  7.  9.  3.] 
adversary cards in hand: [ 6.  6. 25. 22. 15.] 
adversary cards in discard: [10.  8.  6. 14.  4.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15  0  1  8 10  4 10  0  6  8  6  0 22  6
  0  6 14  0  6 25  6  0  3  6  6  0  6] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -2.4436795711517334



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 7 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 9 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 5 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15. 25.] 
cards in discard: [ 1.  3. 15. 29. 15.  1.  1.  1. 29. 15. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  1 29 29 29 29 29 29 29 29 29 15  1 15 25 25
  1 25 25 25  1 25  1 25 25 25  1 15 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 22. 30. 27. 28.  8.  0. 10.  8.  8.  0.  0.  8. 10.  7.  9.  3.] 
adversary cards in hand: [ 6.  6. 25. 22. 15.] 
adversary cards in discard: [10.  8.  6. 14.  4.  6.] 
adversary owned cards: [ 3 14 11  4 15  3 11  0  0  3 15  0  1  8 10  4 10  0  6  8  6  0 22  6
  0  6 14  0  6 25  6  0  3  6  6  0  6  6] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      60       0       0      60       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000115 

action type: take_action - action 25.0
Learning step: 120004.1796875
desired expected reward: 120014.5703125



