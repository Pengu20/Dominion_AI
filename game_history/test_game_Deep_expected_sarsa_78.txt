 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[66.42565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000095 

action type: buy - action -1
Learning step: -119999.3046875
desired expected reward: -120111.515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[45.99649 ]
 [65.92573 ]
 [61.376087]
 [20.552767]
 [87.11503 ]
 [71.32526 ]
 [66.68012 ]
 [65.35646 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 65.3698501586914



buy possibilites: [-1] 
expected returns: [[68.820816]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 87.11504364013672






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[77.65434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 68.82081604003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[57.60365]
 [77.38347]
 [72.87004]
 [32.44234]
 [74.94816]
 [97.98623]
 [82.63338]
 [98.67198]
 [56.95886]
 [78.11997]
 [76.72762]
 [76.77985]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 72.98860931396484



buy possibilites: [-1] 
expected returns: [[85.85849]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 98.67196655273438






Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [10.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [10.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [10.  0.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[70.82568]
 [93.26146]
 [92.49001]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 85.85848999023438



action possibilites: [-1. 11.] 
expected returns: [[80.35051]
 [98.0347 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 89.78713989257812



action possibilites: [-1] 
expected returns: [[84.46622]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 100.60736083984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 73.00162 ]
 [ 91.40416 ]
 [ 87.18996 ]
 [ 53.74996 ]
 [ 49.70881 ]
 [ 89.1602  ]
 [111.027565]
 [ 96.41557 ]
 [133.36926 ]
 [111.80777 ]
 [ 72.447464]
 [ 83.73199 ]
 [ 92.08013 ]
 [ 65.329445]
 [ 90.850006]
 [ 91.28735 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.46621704101562



buy possibilites: [-1] 
expected returns: [[103.484406]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 133.3692626953125






Player: 1 
cards in hand: [ 3.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[126.92911]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 103.48440551757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[108.96252]
 [128.8794 ]
 [124.32941]
 [ 83.39714]
 [149.74545]
 [134.15605]
 [129.60608]
 [128.60086]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 122.09234619140625



buy possibilites: [-1] 
expected returns: [[129.6914]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 149.74542236328125






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25. 29. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25. 29. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25. 29. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [25. 29. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 11.] 
expected returns: [[ 63.154133]
 [103.86325 ]
 [ 83.61345 ]
 [ 82.81596 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 129.69140625



action possibilites: [-1] 
expected returns: [[81.374985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 99.44697570800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[63.80334 ]
 [76.92036 ]
 [42.282875]
 [85.67322 ]
 [80.9131  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.37498474121094



buy possibilites: [-1] 
expected returns: [[91.654724]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0.  3.  3.  0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 85.6732177734375






Player: 1 
cards in hand: [1. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 8. 25. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 8. 25. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 6. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 8. 25. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[108.16925 ]
 [127.157684]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 8. 25. 29. 11.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 6. 15.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 91.65472412109375



action possibilites: [-1] 
expected returns: [[100.8647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 8. 25. 29. 11.  0.  3.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 6. 15.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 127.51025390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 89.96921 ]
 [107.444275]
 [103.43425 ]
 [ 67.47644 ]
 [105.32719 ]
 [125.76199 ]
 [112.081924]
 [126.56798 ]
 [ 89.48611 ]
 [108.07191 ]
 [106.9612  ]
 [107.43119 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 8. 25. 29. 11.  0.  3.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 6. 15.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.86470031738281



buy possibilites: [-1] 
expected returns: [[98.82318]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 8. 25. 29. 11.  0.  3.  3.  0. 10. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 6. 15.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 126.56797790527344






Player: 1 
cards in hand: [10.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [ 6. 15.  1.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [ 6. 15.  1.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[87.188805]
 [87.972206]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 98.82318115234375



action possibilites: [-1. 29.] 
expected returns: [[80.69953]
 [97.69368]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 82.46454620361328



action possibilites: [-1.] 
expected returns: [[85.66816]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29] -> size -> 18 
action values: 2 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 97.69367980957031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 73.90503 ]
 [ 91.259476]
 [ 87.14322 ]
 [ 51.975487]
 [ 89.08594 ]
 [109.88772 ]
 [ 96.00638 ]
 [110.70532 ]
 [ 73.43481 ]
 [ 91.89012 ]
 [ 90.76357 ]
 [ 91.40266 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 85.66815948486328



buy possibilites: [-1] 
expected returns: [[110.68425]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 110.70532989501953






Player: 1 
cards in hand: [1. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 25.  3.] 
adversary cards in discard: [29. 10. 29.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 25.  3.] 
adversary cards in discard: [29. 10. 29.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 25.  3.] 
adversary cards in discard: [29. 10. 29.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[125.669556]
 [144.48611 ]
 [164.71487 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 25.  3.] 
cards in discard: [29. 10. 29.  3.  0.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 1. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.68424987792969



action possibilites: [-1] 
expected returns: [[124.14728]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3. 29. 10.] 
cards in discard: [29. 10. 29.  3.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  9.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 1. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 158.6470489501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[108.16441]
 [120.61577]
 [ 87.44085]
 [128.66153]
 [124.39081]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3. 29. 10.] 
cards in discard: [29. 10. 29.  3.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  9.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 1. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 124.14727783203125



buy possibilites: [-1] 
expected returns: [[112.0901]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3. 29. 10.] 
cards in discard: [29. 10. 29.  3.  0.  3.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  8.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 1. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 128.66156005859375






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 1. 0. 0. 3. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  8.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  8. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29  8] -> size -> 20 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 1. 0. 0. 3. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  8.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  8. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29  8] -> size -> 20 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  1.  0.  0.  3.  3.  6. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  8.  9.  7. 10. 10.  7. 10.  8.] 
adversary cards in hand: [11.  8. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29  8] -> size -> 20 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11.  8. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[73.040245]
 [89.60118 ]
 [77.07785 ]
 [89.60118 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  8.  9.  7. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 6. 10.  0. 15.  0.] 
adversary cards in discard: [ 0.  1.  0.  0.  3.  3.  6. 15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 112.09010314941406



action possibilites: [-1] 
expected returns: [[84.10884]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29  8 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  8.  9.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 10.  0. 15.  0.] 
adversary cards in discard: [ 0.  1.  0.  0.  3.  3.  6. 15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 89.41727447509766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[71.10267 ]
 [83.636894]
 [51.28731 ]
 [91.94475 ]
 [87.67477 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  8.  9.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 10.  0. 15.  0.] 
adversary cards in discard: [ 0.  1.  0.  0.  3.  3.  6. 15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.10884094238281



buy possibilites: [-1] 
expected returns: [[79.87287]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.] 
cards in discard: [10.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29  8 10  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  7.  9.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 10.  0. 15.  0.] 
adversary cards in discard: [ 0.  1.  0.  0.  3.  3.  6. 15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 91.94475555419922






Player: 1 
cards in hand: [ 6. 10.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0. 15.  0.] 
cards in discard: [ 0.  1.  0.  0.  3.  3.  6. 15.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  7.  9.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  0.  3.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29  8 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  7.  9.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  0.  3.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29  8 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15] -> size -> 17 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  7.  9.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  0.  3.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29  8 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  7.  9.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  0.  3.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29  8 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [23.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  7.  9.  7. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  0.  3.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29  8 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 8. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[ 85.99889]
 [ 90.42344]
 [104.35903]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  0.  3.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29  8 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  7.  9.  7. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 15.] 
adversary cards in discard: [23. 10. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.87287139892578



action possibilites: [-1.  8.] 
expected returns: [[101.33842]
 [105.82054]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11  8 10 29 29  8 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  7.  9.  7. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 15.] 
adversary cards in discard: [23. 10. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 98.332275390625



action possibilites: [-1] 
expected returns: [[55.749348]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10.  8. 11.  8. 11.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  7.  9.  7. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 15.] 
adversary cards in discard: [23. 10. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23] -> size -> 18 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: trash_cards_n_from_hand - action 8
Learning step: 0
desired expected reward: 105.91770935058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.499535]
 [27.632326]
 [58.19344 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10.  8. 11.  8. 11.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  7.  9.  7. 10.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 15.] 
adversary cards in discard: [23. 10. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23] -> size -> 18 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.74934768676758






Player: 1 
cards in hand: [ 3.  0.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 15.] 
cards in discard: [23. 10. 15.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  7.  9.  7. 10.  9.  6. 10.  8.] 
adversary cards in hand: [10.  0. 29. 29.  3.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8] -> size -> 18 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 15.] 
cards in discard: [23. 10. 15.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  7.  9.  7. 10.  9.  6. 10.  8.] 
adversary cards in hand: [10.  0. 29. 29.  3.] 
adversary cards in discard: [10.  8. 11.  8. 11.  0.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8] -> size -> 18 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [10.  0. 29. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
expected returns: [[ 87.12907]
 [ 87.73386]
 [106.52727]
 [106.52727]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 29.  3.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0. 29.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  7.  9.  7. 10.  9.  6. 10.  8.] 
adversary cards in hand: [1. 6. 3. 0. 0.] 
adversary cards in discard: [23. 10. 15.  6.  0.  0.  3.  0.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23] -> size -> 18 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 58.19343948364258



action possibilites: [-1. 10. 29.] 
expected returns: [[101.32085]
 [101.98619]
 [121.60681]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  3.  0.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0. 29.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  7.  9.  7. 10.  9.  6. 10.  8.] 
adversary cards in hand: [1. 6. 3. 0. 0.] 
adversary cards in discard: [23. 10. 15.  6.  0.  0.  3.  0.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23] -> size -> 18 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 101.31608581542969



action possibilites: [-1. 10. 25.] 
expected returns: [[ 96.644554]
 [ 97.20575 ]
 [135.5031  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0. 25.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0. 29.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  8.  7.  9.  7. 10.  9.  6. 10.  8.] 
adversary cards in hand: [1. 6. 3. 0. 0.] 
adversary cards in discard: [23. 10. 15.  6.  0.  0.  3.  0.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23] -> size -> 18 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 121.6068115234375



action possibilites: [-1] 
expected returns: [[100.00951]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0. 10.  3.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0. 29.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  7. 10.  8.  7.  9.  7. 10.  9.  6. 10.  8.] 
adversary cards in hand: [1. 6. 3. 0. 0.] 
adversary cards in discard: [23. 10. 15.  6.  0.  0.  3.  0.  0.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 135.50311279296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 82.98742 ]
 [ 99.43066 ]
 [ 95.64153 ]
 [ 62.200443]
 [ 97.4284  ]
 [116.73216 ]
 [103.851074]
 [117.50042 ]
 [ 82.54696 ]
 [100.02838 ]
 [ 98.98351 ]
 [ 99.44395 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0. 10.  3.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0. 29.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  7. 10.  8.  7.  9.  7. 10.  9.  6. 10.  8.] 
adversary cards in hand: [1. 6. 3. 0. 0.] 
adversary cards in discard: [23. 10. 15.  6.  0.  0.  3.  0.  0.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.00950622558594



buy possibilites: [-1] 
expected returns: [[120.7245]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0. 10.  3.] 
cards in discard: [10.  8. 11.  8. 11.  0.  0. 29.  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  7. 10.  8.  7.  9.  6. 10.  9.  6. 10.  8.] 
adversary cards in hand: [1. 6. 3. 0. 0.] 
adversary cards in discard: [23. 10. 15.  6.  0.  0.  3.  0.  0.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 213 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 117.50042724609375






Player: 1 
cards in hand: [1. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 3. 0. 0.] 
cards in discard: [23. 10. 15.  6.  0.  0.  3.  0.  0.  3. 15.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  7. 10.  8.  7.  9.  6. 10.  9.  6. 10.  8.] 
adversary cards in hand: [25. 29.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29] -> size -> 19 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 3. 0. 0.] 
cards in discard: [23. 10. 15.  6.  0.  0.  3.  0.  0.  3. 15.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  7. 10.  8.  7.  9.  6. 10.  9.  6. 10.  8.] 
adversary cards in hand: [25. 29.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29] -> size -> 19 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 3. 0. 0.] 
cards in discard: [23. 10. 15.  6.  0.  0.  3.  0.  0.  3. 15.  6. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  7. 10.  8.  7.  9.  6. 10.  9.  5. 10.  8.] 
adversary cards in hand: [25. 29.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29] -> size -> 19 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [25. 29.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 11.] 
expected returns: [[62.219166]
 [91.7564  ]
 [76.803894]
 [76.102135]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  7. 10.  8.  7.  9.  6. 10.  9.  5. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10] -> size -> 20 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 120.72450256347656



action possibilites: [-1] 
expected returns: [[46.424107]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 11. 29. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  5. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6] -> size -> 21 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 87.63619232177734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[34.48342 ]
 [22.182009]
 [45.961647]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 11. 29. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  5. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6] -> size -> 21 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.42410659790039






Player: 1 
cards in hand: [0. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  5. 10.  8.] 
adversary cards in hand: [ 8.  0. 10. 10. 11.] 
adversary cards in discard: [25. 29.  3.  0. 11. 29. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29] -> size -> 19 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  5. 10.  8.] 
adversary cards in hand: [ 8.  0. 10. 10. 11.] 
adversary cards in discard: [25. 29.  3.  0. 11. 29. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29] -> size -> 19 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [6. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  5. 10.  8.] 
adversary cards in hand: [ 8.  0. 10. 10. 11.] 
adversary cards in discard: [25. 29.  3.  0. 11. 29. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29] -> size -> 19 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 11.] 
expected returns: [[66.224464]
 [69.63718 ]
 [66.38432 ]
 [66.38432 ]
 [80.44434 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 10. 11.] 
cards in discard: [25. 29.  3.  0. 11. 29. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  5. 10.  8.] 
adversary cards in hand: [0. 3. 6. 0. 1.] 
adversary cards in discard: [6. 0. 0. 0. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 45.9616584777832



action possibilites: [-1] 
expected returns: [[40.52871]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 10.] 
cards in discard: [25. 29.  3.  0. 11. 29. 29. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  4. 10.  8.] 
adversary cards in hand: [0. 3. 6. 0. 1.] 
adversary cards in discard: [6. 0. 0. 0. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 78.0797119140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.460989]
 [15.364103]
 [42.61543 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10. 10.] 
cards in discard: [25. 29.  3.  0. 11. 29. 29. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  4. 10.  8.] 
adversary cards in hand: [0. 3. 6. 0. 1.] 
adversary cards in discard: [6. 0. 0. 0. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.528709411621094






Player: 1 
cards in hand: [0. 3. 6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 1.] 
cards in discard: [6. 0. 0. 0. 6. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  4. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  3.  8.] 
adversary cards in discard: [25. 29.  3.  0. 11. 29. 29. 10. 11.  8.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29 10] -> size -> 20 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 1.] 
cards in discard: [6. 0. 0. 0. 6. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  4. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  3.  8.] 
adversary cards in discard: [25. 29.  3.  0. 11. 29. 29. 10. 11.  8.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29 10] -> size -> 20 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 1.] 
cards in discard: [ 6.  0.  0.  0.  6.  0.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [ 0. 29.  0.  3.  8.] 
adversary cards in discard: [25. 29.  3.  0. 11. 29. 29. 10. 11.  8.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29 10] -> size -> 20 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[29.524534]
 [44.08134 ]
 [32.53924 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  8.] 
cards in discard: [25. 29.  3.  0. 11. 29. 29. 10. 11.  8.  0. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [10.  0.  0.  3. 10.] 
adversary cards in discard: [ 6.  0.  0.  0.  6.  0.  0. 15.  0.  3.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 23 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 42.61542892456055



action possibilites: [-1.  8.  8.] 
expected returns: [[29.613222]
 [33.28391 ]
 [33.28391 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [25. 29.  3.  0. 11. 29. 29. 10. 11.  8.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29 10 25 11  8 10 29 29  8 10  8 29 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [10.  0.  0.  3. 10.] 
adversary cards in discard: [ 6.  0.  0.  0.  6.  0.  0. 15.  0.  3.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 23 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 42.32444763183594



action possibilites: [-1] 
expected returns: [[62.0529]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [25. 29.  3.  0. 11. 29. 29. 10. 11.  8.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3 11 29 10 25 11  8 10 29 29  8 10  8 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [10.  0.  0.  3. 10.] 
adversary cards in discard: [ 6.  0.  0.  0.  6.  0.  0. 15.  0.  3.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 23 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 49.6087532043457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[49.578575]
 [31.350534]
 [64.42764 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [25. 29.  3.  0. 11. 29. 29. 10. 11.  8.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3 11 29 10 25 11  8 10 29 29  8 10  8 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [10.  0.  0.  3. 10.] 
adversary cards in discard: [ 6.  0.  0.  0.  6.  0.  0. 15.  0.  3.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 23 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.05289840698242






Player: 1 
cards in hand: [10.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3. 10.] 
cards in discard: [ 6.  0.  0.  0.  6.  0.  0. 15.  0.  3.  6.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [10.  0. 29. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 11 29 10 25 11  8 10 29 29  8 10  8 29 10] -> size -> 17 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10. 15.] 
cards in discard: [ 6.  0.  0.  0.  6.  0.  0. 15.  0.  3.  6.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [10.  0. 29. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 11 29 10 25 11  8 10 29 29  8 10  8 29 10] -> size -> 17 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10. 15.] 
cards in discard: [ 6.  0.  0.  0.  6.  0.  0. 15.  0.  3.  6.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [10.  0. 29. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 11 29 10 25 11  8 10 29 29  8 10  8 29 10] -> size -> 17 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10.  0. 29. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29. 10.] 
expected returns: [[ 6.2539115]
 [ 6.227843 ]
 [18.586025 ]
 [18.586025 ]
 [ 6.227843 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 29. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 29 10 25 11  8 10 29 29  8 10  8 29 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [10. 15.  6. 23.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 23 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 64.42766571044922



action possibilites: [-1. 10. 29. 10.  8.] 
expected returns: [[16.909616]
 [16.826374]
 [28.333963]
 [16.826374]
 [19.362846]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 10.  8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 11 29 10 25 11  8 10 29 29  8 10  8 29 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [10. 15.  6. 23.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 23 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 15.674406051635742



action possibilites: [-1. 10. 10.  8.] 
expected returns: [[58.52823]
 [58.58922]
 [58.58922]
 [61.61318]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  8.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  3 11 29 10 25 11  8 10 29 29  8 10  8 29 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [10. 15.  6. 23.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 23 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 28.333967208862305



action possibilites: [-1] 
expected returns: [[-16.265835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [10. 15.  6. 23.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 23 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 71.77482604980469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-23.243778]
 [-15.682787]
 [-17.50526 ]
 [-32.477074]
 [ -6.920041]
 [-13.558121]
 [-15.445185]
 [-14.997549]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  8.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [10. 15.  6. 23.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 23 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: -16.26583480834961



buy possibilites: [-1] 
expected returns: [[14.162981]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  7.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [10. 15.  6. 23.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 23 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 169 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -6.920044898986816






Player: 1 
cards in hand: [10. 15.  6. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  6. 23.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  7.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [25.  8. 11.  3. 29.] 
adversary cards in discard: [11. 29. 29.  8.  0.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11] -> size -> 15 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1. 10. 15. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  6.  3. 15.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 23 
action values: 1 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  7.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [25.  8. 11.  3. 29.] 
adversary cards in discard: [11. 29. 29.  8.  0.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11] -> size -> 15 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1. 15. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  3. 15.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 23 
action values: 2 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  7.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [25.  8. 11.  3. 29.] 
adversary cards in discard: [11. 29. 29.  8.  0.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11] -> size -> 15 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [23. 10. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 22 
action values: 1 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  7.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [25.  8. 11.  3. 29.] 
adversary cards in discard: [11. 29. 29.  8.  0.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11] -> size -> 15 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [23. 10. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15] -> size -> 22 
action values: 1 
buys: 2 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  7.  7.  9.  6. 10.  9.  4. 10.  7.] 
adversary cards in hand: [25.  8. 11.  3. 29.] 
adversary cards in discard: [11. 29. 29.  8.  0.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11] -> size -> 15 
adversary victory points: 1
player victory points: -1 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 15.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [23. 10. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  7.  7.  9.  5. 10.  9.  4. 10.  7.] 
adversary cards in hand: [25.  8. 11.  3. 29.] 
adversary cards in discard: [11. 29. 29.  8.  0.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11] -> size -> 15 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [25.  8. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 11. 29.] 
expected returns: [[24.548834]
 [50.61342 ]
 [27.3413  ]
 [36.802647]
 [37.445004]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 11.  3. 29.] 
cards in discard: [11. 29. 29.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  7.  7.  9.  5. 10.  9.  4. 10.  7.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [29. 23. 10. 15.  6.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29] -> size -> 23 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.162981033325195



action possibilites: [-1] 
expected returns: [[36.169243]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3. 29.  8. 10.] 
cards in discard: [11. 29. 29.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  7.  9.  5. 10.  9.  4. 10.  7.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [29. 23. 10. 15.  6.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 46.78044509887695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.562761]
 [ 8.733719]
 [33.903324]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3. 29.  8. 10.] 
cards in discard: [11. 29. 29.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  7.  9.  5. 10.  9.  4. 10.  7.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [29. 23. 10. 15.  6.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.16924285888672






Player: 1 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [29. 23. 10. 15.  6.  3. 15.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  7.  9.  5. 10.  9.  4. 10.  7.] 
adversary cards in hand: [29. 11. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11] -> size -> 15 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [29. 23. 10. 15.  6.  3. 15.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  7.  9.  5. 10.  9.  4. 10.  7.] 
adversary cards in hand: [29. 11. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11] -> size -> 15 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [29. 23. 10. 15.  6.  3. 15.  6. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  7.  8.  5. 10.  9.  4. 10.  7.] 
adversary cards in hand: [29. 11. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11] -> size -> 15 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [29. 11. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11. 10. 29.] 
expected returns: [[-18.32811 ]
 [-10.275312]
 [-10.744766]
 [-10.744766]
 [-18.54955 ]
 [-10.275312]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 11. 10. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  7.  8.  5. 10.  9.  4. 10.  7.] 
adversary cards in hand: [0. 6. 6. 0. 6.] 
adversary cards in discard: [29. 23. 10. 15.  6.  3. 15.  6. 25.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6
 25] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.903324127197266



action possibilites: [-1. 11. 11. 10. 29.  8.] 
expected returns: [[-20.545845 ]
 [-12.491355 ]
 [-12.491355 ]
 [-20.749924 ]
 [-12.0023575]
 [-18.86099  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10. 29.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  7.  8.  5. 10.  9.  4. 10.  7.] 
adversary cards in hand: [0. 6. 6. 0. 6.] 
adversary cards in discard: [29. 23. 10. 15.  6.  3. 15.  6. 25.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6
 25] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -10.894207954406738



action possibilites: [-1. 11. 11. 10.  8.] 
expected returns: [[-14.403275 ]
 [ -4.855212 ]
 [ -4.855212 ]
 [-14.474865 ]
 [-12.2590065]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  7.  8.  5. 10.  9.  4. 10.  7.] 
adversary cards in hand: [0. 6. 6. 0. 6.] 
adversary cards in discard: [29. 23. 10. 15.  6.  3. 15.  6. 25.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6
 25] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -12.00235366821289



action possibilites: [-1] 
expected returns: [[-5.094951]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8.  3.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  7.  8.  5. 10.  9.  3. 10.  7.] 
adversary cards in hand: [0. 6. 6. 0. 6.] 
adversary cards in discard: [29. 23. 10. 15.  6.  3. 15.  6. 25.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6
 25] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 172 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -2.538689136505127





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-12.671779]
 [ -6.59671 ]
 [-22.883146]
 [ -2.610597]
 [ -4.175603]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  8.  3.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  7.  8.  5. 10.  9.  3. 10.  7.] 
adversary cards in hand: [0. 6. 6. 0. 6.] 
adversary cards in discard: [29. 23. 10. 15.  6.  3. 15.  6. 25.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6
 25] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.094951152801514



buy possibilites: [-1] 
expected returns: [[2.0453525]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  8.  3.] 
cards in discard: [10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  6.  8.  5. 10.  9.  3. 10.  7.] 
adversary cards in hand: [0. 6. 6. 0. 6.] 
adversary cards in discard: [29. 23. 10. 15.  6.  3. 15.  6. 25.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6
 25] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0 16  0] 
sum of rewards: 161 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -2.6105964183807373






Player: 1 
cards in hand: [0. 6. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 6.] 
cards in discard: [29. 23. 10. 15.  6.  3. 15.  6. 25.  0.  0.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  6.  8.  5. 10.  9.  3. 10.  7.] 
adversary cards in hand: [ 0. 29.  8.  8. 10.] 
adversary cards in discard: [10.  8. 29. 29. 11. 11. 10.  8.  3.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8] -> size -> 17 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 6.] 
cards in discard: [29. 23. 10. 15.  6.  3. 15.  6. 25.  0.  0.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  6.  8.  5. 10.  9.  3. 10.  7.] 
adversary cards in hand: [ 0. 29.  8.  8. 10.] 
adversary cards in discard: [10.  8. 29. 29. 11. 11. 10.  8.  3.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8] -> size -> 17 
adversary victory points: 1
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8. 10.] 
expected returns: [[-12.763868  ]
 [  0.44758558]
 [-10.007166  ]
 [-10.007166  ]
 [-12.741998  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  8. 10.] 
cards in discard: [10.  8. 29. 29. 11. 11. 10.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  6.  8.  5. 10.  9.  3. 10.  7.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [29. 23. 10. 15.  6.  3. 15.  6. 25.  0.  0.  1.  0.  0.  0.  6.  6.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6
 25] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.0453524589538574



action possibilites: [-1.  8.  8. 10. 11.] 
expected returns: [[15.7233925]
 [18.680803 ]
 [18.680803 ]
 [15.662802 ]
 [28.904608 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 10. 11.] 
cards in discard: [10.  8. 29. 29. 11. 11. 10.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  6.  8.  5. 10.  9.  3. 10.  7.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [29. 23. 10. 15.  6.  3. 15.  6. 25.  0.  0.  1.  0.  0.  0.  6.  6.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6
 25] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -2.61238956451416



action possibilites: [-1] 
expected returns: [[-5.740195]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 10.] 
cards in discard: [10.  8. 29. 29. 11. 11. 10.  8.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  6.  8.  5. 10.  9.  2. 10.  7.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [29. 23. 10. 15.  6.  3. 15.  6. 25.  0.  0.  1.  0.  0.  0.  6.  6.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6
 25] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 152 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 32.07160949707031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-15.676765]
 [ -7.708325]
 [-28.697908]
 [ -2.355735]
 [ -4.894732]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8. 10.] 
cards in discard: [10.  8. 29. 29. 11. 11. 10.  8.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  6.  8.  5. 10.  9.  2. 10.  7.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [29. 23. 10. 15.  6.  3. 15.  6. 25.  0.  0.  1.  0.  0.  0.  6.  6.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6
 25] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.740194797515869



buy possibilites: [-1] 
expected returns: [[8.9091625]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8. 10.] 
cards in discard: [10.  8. 29. 29. 11. 11. 10.  8.  3. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  5.  8.  5. 10.  9.  2. 10.  7.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [29. 23. 10. 15.  6.  3. 15.  6. 25.  0.  0.  1.  0.  0.  0.  6.  6.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6
 25] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 141 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -2.35573148727417






Player: 1 
cards in hand: [15.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  3.  0.] 
cards in discard: [29. 23. 10. 15.  6.  3. 15.  6. 25.  0.  0.  1.  0.  0.  0.  6.  6.  0.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  5.  8.  5. 10.  9.  2. 10.  7.] 
adversary cards in hand: [10. 11. 10. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8] -> size -> 19 
adversary victory points: 1
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [29. 23. 10. 15.  6.  3. 15.  6. 25.  0.  0.  1.  0.  0.  0.  6.  6.  0.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  5.  8.  5. 10.  9.  2. 10.  7.] 
adversary cards in hand: [10. 11. 10. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8] -> size -> 19 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [29. 23. 10. 15.  6.  3. 15.  6. 25.  0.  0.  1.  0.  0.  0.  6.  6.  0.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  5.  8.  5. 10.  9.  2. 10.  7.] 
adversary cards in hand: [10. 11. 10. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8] -> size -> 19 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [10. 11. 10. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 29. 25.] 
expected returns: [[-26.029076]
 [-26.283861]
 [-17.881706]
 [-26.283861]
 [-17.380325]
 [ -8.521028]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 29. 25.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  5. 10.  7.  5.  8.  5. 10.  9.  2. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25] -> size -> 24 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.909162521362305



action possibilites: [-1] 
expected returns: [[-19.397451]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 29. 10.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  7.  5.  8.  5. 10.  9.  2. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25
  6] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -9.312800407409668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-30.905684]
 [-41.456074]
 [-22.065031]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10. 29. 10.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  7.  5.  8.  5. 10.  9.  2. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25
  6] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -19.397451400756836






Player: 1 
cards in hand: [ 6.  0.  0. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 15. 10.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  7.  5.  8.  5. 10.  9.  2. 10.  7.] 
adversary cards in hand: [ 8. 11. 29. 10.  8.] 
adversary cards in discard: [25. 10. 11. 10. 29. 10.  8.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8] -> size -> 19 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 15. 10.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  7.  5.  8.  5. 10.  9.  2. 10.  7.] 
adversary cards in hand: [ 8. 11. 29. 10.  8.] 
adversary cards in discard: [25. 10. 11. 10. 29. 10.  8.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8] -> size -> 19 
adversary victory points: 1
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 29. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29. 10.  8.] 
expected returns: [[21.643976]
 [24.060055]
 [32.357914]
 [32.961067]
 [21.586403]
 [24.060055]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 29. 10.  8.] 
cards in discard: [25. 10. 11. 10. 29. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  7.  5.  8.  5. 10.  9.  2. 10.  7.] 
adversary cards in hand: [ 3. 15. 10.  1. 23.] 
adversary cards in discard: [ 6.  6.  0.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25
  6] -> size -> 25 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -22.065032958984375



action possibilites: [-1.  8. 11. 10.  8.  8.] 
expected returns: [[-1.4754858]
 [ 1.2530746]
 [10.236221 ]
 [-1.4486918]
 [ 1.2530746]
 [ 1.2530746]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.  8.  8.] 
cards in discard: [25. 10. 11. 10. 29. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  7.  5.  8.  5. 10.  9.  2. 10.  7.] 
adversary cards in hand: [ 3. 15. 10.  1. 23.] 
adversary cards in discard: [ 6.  6.  0.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25
  6] -> size -> 25 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 30.751733779907227



action possibilites: [-1] 
expected returns: [[-10.141406]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  8.] 
cards in discard: [25. 10. 11. 10. 29. 10.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  7.  5.  8.  5. 10.  9.  1. 10.  7.] 
adversary cards in hand: [ 3. 15. 10.  1. 23.] 
adversary cards in discard: [ 6.  6.  0.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25
  6] -> size -> 25 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 13.005849838256836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-19.465591]
 [-31.115541]
 [ -9.221888]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.  8.] 
cards in discard: [25. 10. 11. 10. 29. 10.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  7.  5.  8.  5. 10.  9.  1. 10.  7.] 
adversary cards in hand: [ 3. 15. 10.  1. 23.] 
adversary cards in discard: [ 6.  6.  0.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25
  6] -> size -> 25 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.141406059265137






Player: 1 
cards in hand: [ 3. 15. 10.  1. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 23.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10.  1. 23.] 
cards in discard: [ 6.  6.  0.  0. 15. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  7.  5.  8.  5. 10.  9.  1. 10.  7.] 
adversary cards in hand: [29. 29. 11.  0.  3.] 
adversary cards in discard: [25. 10. 11. 10. 29. 10.  8. 10. 29. 11.  8. 10.  8.  8.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10] -> size -> 20 
adversary victory points: 1
player victory points: -3 


action possibilites: [-1. 15. 23.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  1. 23.  0.] 
cards in discard: [ 6.  6.  0.  0. 15. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25
  6] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  7.  5.  8.  5. 10.  9.  1. 10.  7.] 
adversary cards in hand: [29. 29. 11.  0.  3.] 
adversary cards in discard: [25. 10. 11. 10. 29. 10.  8. 10. 29. 11.  8. 10.  8.  8.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10] -> size -> 20 
adversary victory points: 1
player victory points: -3 


action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 23.] 
cards in discard: [ 6.  6.  0.  0. 15. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  7.  5.  8.  5. 10.  9.  1. 10.  7.] 
adversary cards in hand: [29. 29. 11.  0.  3.] 
adversary cards in discard: [25. 10. 11. 10. 29. 10.  8. 10. 29. 11.  8. 10.  8.  8.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10] -> size -> 20 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 23.] 
cards in discard: [ 6.  6.  0.  0. 15. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  7.  5.  8.  5. 10.  9.  1. 10.  7.] 
adversary cards in hand: [29. 29. 11.  0.  3.] 
adversary cards in discard: [25. 10. 11. 10. 29. 10.  8. 10. 29. 11.  8. 10.  8.  8.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10] -> size -> 20 
adversary victory points: 1
player victory points: -3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [29. 29. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[20.726927]
 [32.33186 ]
 [32.33186 ]
 [31.712984]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11.  0.  3.] 
cards in discard: [25. 10. 11. 10. 29. 10.  8. 10. 29. 11.  8. 10.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  7.  5.  8.  5. 10.  9.  1. 10.  7.] 
adversary cards in hand: [ 3. 29.  6. 15.  0.] 
adversary cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.] 
adversary owned cards: [ 0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6] -> size -> 24 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -9.221882820129395



action possibilites: [-1. 29. 11.  8.] 
expected returns: [[10.831186]
 [23.712807]
 [23.073164]
 [13.712368]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  3.  8.] 
cards in discard: [25. 10. 11. 10. 29. 10.  8. 10. 29. 11.  8. 10.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  7.  5.  8.  5. 10.  9.  1. 10.  7.] 
adversary cards in hand: [ 3. 29.  6. 15.  0.] 
adversary cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.] 
adversary owned cards: [ 0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6] -> size -> 24 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.930635452270508



action possibilites: [-1. 11.  8. 10.] 
expected returns: [[-13.0707035]
 [ -3.1847522]
 [-10.890271 ]
 [-13.231026 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  8. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  7.  5.  8.  5. 10.  9.  1. 10.  7.] 
adversary cards in hand: [ 3. 29.  6. 15.  0.] 
adversary cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.] 
adversary owned cards: [ 0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6] -> size -> 24 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 23.71281623840332



action possibilites: [-1] 
expected returns: [[11.188496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 10.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  7.  5.  8.  5. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 3. 29.  6. 15.  0.] 
adversary cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.] 
adversary owned cards: [ 0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6] -> size -> 24 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 202 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -0.8298354148864746





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[  2.6916518]
 [ 13.759359 ]
 [ 11.185755 ]
 [-11.465328 ]
 [ 25.197855 ]
 [ 16.706861 ]
 [ 14.193947 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8. 10.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  7.  5.  8.  5. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 3. 29.  6. 15.  0.] 
adversary cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.] 
adversary owned cards: [ 0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6] -> size -> 24 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.188495635986328



buy possibilites: [-1] 
expected returns: [[-15.3605]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8. 10.] 
cards in discard: [10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  6.  5.  8.  5. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 3. 29.  6. 15.  0.] 
adversary cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.] 
adversary owned cards: [ 0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6] -> size -> 24 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 229 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 25.197858810424805






Player: 1 
cards in hand: [ 3. 29.  6. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  6. 15.  0.] 
cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  6.  5.  8.  5. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 8. 10. 11. 29. 10.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3.  8. 10.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11] -> size -> 22 
adversary victory points: 1
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  6.] 
cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  6.  5.  8.  5. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 8. 10. 11. 29. 10.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3.  8. 10.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11] -> size -> 22 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  6.] 
cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  6.  5.  8.  5. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 8. 10. 11. 29. 10.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3.  8. 10.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11] -> size -> 22 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  6.] 
cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  6.  4.  8.  5. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 8. 10. 11. 29. 10.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3.  8. 10.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11] -> size -> 22 
adversary victory points: 1
player victory points: -3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 8. 10. 11. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11. 29. 10.] 
expected returns: [[-2.618524 ]
 [-0.5627675]
 [-2.7435527]
 [ 6.8730254]
 [ 7.435244 ]
 [-2.7435527]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 11. 29. 10.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3.  8. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  6.  4.  8.  5. 10.  9.  0. 10.  7.] 
adversary cards in hand: [25.  0.  0.  3.  0.] 
adversary cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.  8. 15.  3. 29.  6.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8] -> size -> 24 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -15.36050033569336



action possibilites: [-1. 10. 11. 10. 11.] 
expected returns: [[-4.8966227]
 [-4.9769692]
 [ 5.8516145]
 [-4.9769692]
 [ 5.8516145]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 11.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3.  8. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  6.  4.  8.  5. 10.  9.  0. 10.  7.] 
adversary cards in hand: [25.  0.  0.  3.  0.] 
adversary cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.  8. 15.  3. 29.  6.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8] -> size -> 24 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -3.8144474029541016



action possibilites: [-1] 
expected returns: [[11.084784]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3.  8. 10.  8. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  6.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [25.  0.  0.  3.  0.] 
adversary cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.  8. 15.  3. 29.  6.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8] -> size -> 24 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 8.466707229614258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 0.9865279]
 [-9.309382 ]
 [10.953882 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3.  8. 10.  8. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  6.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [25.  0.  0.  3.  0.] 
adversary cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.  8. 15.  3. 29.  6.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8] -> size -> 24 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.084783554077148






Player: 1 
cards in hand: [25.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  3.  0.] 
cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.  8. 15.  3. 29.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  4. 10.  6.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [25. 10. 29.  8. 10.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3.  8. 10.  8. 15. 29. 11. 10. 10. 11.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15] -> size -> 23 
adversary victory points: 1
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 6. 6.] 
cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.  8. 15.  3. 29.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  3. 10.  6.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [25. 10. 29.  8. 10.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3.  8. 10.  8. 15. 29. 11. 10. 10. 11.  6.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6] -> size -> 24 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 6. 6.] 
cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.  8. 15.  3. 29.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  3. 10.  6.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [25. 10. 29.  8. 10.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3.  8. 10.  8. 15. 29. 11. 10. 10. 11.  6.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6] -> size -> 24 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 6. 6.] 
cards in discard: [ 6.  6.  0.  0. 15. 10. 10. 15.  3.  1. 23.  8. 15.  3. 29.  6. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  3. 10.  5.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [25. 10. 29.  8. 10.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3.  8. 10.  8. 15. 29. 11. 10. 10. 11.  6.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6] -> size -> 24 
adversary victory points: 1
player victory points: -3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [25. 10. 29.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29.  8. 10.] 
expected returns: [[12.0566025]
 [35.580532 ]
 [12.133186 ]
 [23.763048 ]
 [14.725142 ]
 [12.133186 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 29.  8. 10.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3.  8. 10.  8. 15. 29. 11. 10. 10. 11.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  3. 10.  5.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [6. 6. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11] -> size -> 25 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[  -5    0    0   90    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 10.953897476196289



action possibilites: [-1] 
expected returns: [[-20.152487]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  8. 10.  8.  8.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3.  8. 10.  8. 15. 29. 11. 10. 10. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  2. 10.  5.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [6. 6. 6. 0. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6] -> size -> 26 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.580535888671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-30.75364 ]
 [-41.543182]
 [-20.74648 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  8. 10.  8.  8.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3.  8. 10.  8. 15. 29. 11. 10. 10. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  2. 10.  5.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [6. 6. 6. 0. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6] -> size -> 26 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -20.15248680114746






Player: 1 
cards in hand: [6. 6. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 0. 6.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  2. 10.  5.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [29.  0. 10. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6] -> size -> 24 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 6.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  2. 10.  5.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [29.  0. 10. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6] -> size -> 24 
adversary victory points: 0
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [29.  0. 10. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 15. 11.] 
expected returns: [[-21.590752]
 [-12.343314]
 [-21.856094]
 [-22.31838 ]
 [-12.897644]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10. 15. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  2. 10.  5.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 3. 15. 11.  1. 29.] 
adversary cards in discard: [6. 6. 6. 6. 0. 6.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6] -> size -> 26 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -20.746488571166992



action possibilites: [-1. 10. 15. 29.] 
expected returns: [[-13.506384 ]
 [-13.68446  ]
 [-14.217167 ]
 [ -2.7061934]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 15. 29.] 
cards in discard: [11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  2. 10.  5.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 3. 15. 11.  1. 29.] 
adversary cards in discard: [6. 6. 6. 6. 0. 6.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6] -> size -> 26 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -23.65838050842285



action possibilites: [-1. 10. 10.] 
expected returns: [[-44.2057  ]
 [-48.230522]
 [-48.230522]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.] 
cards in discard: [11. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  2. 10.  5.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 3. 15. 11.  1. 29.] 
adversary cards in discard: [6. 6. 6. 6. 0. 6.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6] -> size -> 26 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -14.019571304321289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[-56.40496 ]
 [-45.344486]
 [-48.168003]
 [-67.16005 ]
 [-34.316093]
 [-42.318504]
 [-41.12734 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [11. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  2. 10.  5.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 3. 15. 11.  1. 29.] 
adversary cards in discard: [6. 6. 6. 6. 0. 6.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6] -> size -> 26 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -44.2056770324707



buy possibilites: [-1] 
expected returns: [[-22.366531]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [11. 15. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  2. 10.  4.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 3. 15. 11.  1. 29.] 
adversary cards in discard: [6. 6. 6. 6. 0. 6.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6] -> size -> 26 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 209 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -34.316078186035156






Player: 1 
cards in hand: [ 3. 15. 11.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 11.  1. 29.] 
cards in discard: [6. 6. 6. 6. 0. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  2. 10.  4.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 8.  8.  8. 25. 10.] 
adversary cards in discard: [11. 15. 11. 29. 29.  0. 10. 10.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11] -> size -> 25 
adversary victory points: 0
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1. 29.] 
cards in discard: [6. 6. 6. 6. 0. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  2. 10.  4.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 8.  8.  8. 25. 10.] 
adversary cards in discard: [11. 15. 11. 29. 29.  0. 10. 10.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11] -> size -> 25 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1. 29.] 
cards in discard: [6. 6. 6. 6. 0. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  2. 10.  4.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 8.  8.  8. 25. 10.] 
adversary cards in discard: [11. 15. 11. 29. 29.  0. 10. 10.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11] -> size -> 25 
adversary victory points: 0
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1. 29.] 
cards in discard: [6. 6. 6. 6. 0. 6. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  2. 10.  4.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 8.  8.  8. 25. 10.] 
adversary cards in discard: [11. 15. 11. 29. 29.  0. 10. 10.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11] -> size -> 25 
adversary victory points: 0
player victory points: -3 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  8. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 25. 10.] 
expected returns: [[-8.11026  ]
 [-6.4086947]
 [-6.4086947]
 [-6.4086947]
 [ 9.62784  ]
 [-8.374654 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8. 25. 10.] 
cards in discard: [11. 15. 11. 29. 29.  0. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  2. 10.  4.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 0. 15.  3.  0. 25.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3] -> size -> 27 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -22.366531372070312



action possibilites: [-1] 
expected returns: [[-26.738811]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8. 10.  8. 11.] 
cards in discard: [11. 15. 11. 29. 29.  0. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  1. 10.  4.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 0. 15.  3.  0. 25.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6] -> size -> 28 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 9.627847671508789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-34.480934]
 [-43.850155]
 [-26.494253]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  8. 10.  8. 11.] 
cards in discard: [11. 15. 11. 29. 29.  0. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  1. 10.  4.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 0. 15.  3.  0. 25.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6] -> size -> 28 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -26.738811492919922






Player: 1 
cards in hand: [ 0. 15.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0. 25.] 
cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  1. 10.  4.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [29. 10.  6. 29. 11.] 
adversary cards in discard: [11. 15. 11. 29. 29.  0. 10. 10. 25.  8.  8.  8. 10.  8. 11.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11] -> size -> 25 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  0. 25.] 
cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  1. 10.  4.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [29. 10.  6. 29. 11.] 
adversary cards in discard: [11. 15. 11. 29. 29.  0. 10. 10. 25.  8.  8.  8. 10.  8. 11.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11] -> size -> 25 
adversary victory points: 0
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [29. 10.  6. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29. 11.] 
expected returns: [[-16.02803 ]
 [ -8.12703 ]
 [-16.331375]
 [ -8.12703 ]
 [ -8.635471]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  6. 29. 11.] 
cards in discard: [11. 15. 11. 29. 29.  0. 10. 10. 25.  8.  8.  8. 10.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  1. 10.  4.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 3.  0.  8. 10. 23.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.  0. 15.  3.  0. 25.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6] -> size -> 28 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -26.4942569732666



action possibilites: [-1. 10. 29.] 
expected returns: [[ 5.4706683]
 [ 5.536015 ]
 [16.005888 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 29.  3.] 
cards in discard: [11. 15. 11. 29. 29.  0. 10. 10. 25.  8.  8.  8. 10.  8. 11. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8.  1. 10.  4.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 3.  0.  8. 10. 23.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.  0. 15.  3.  0. 25.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6] -> size -> 28 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -16.577566146850586



action possibilites: [-1. 10.] 
expected returns: [[-5.205058]
 [-5.271029]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  3.] 
cards in discard: [11. 15. 11. 29. 29.  0. 10. 10. 25.  8.  8.  8. 10.  8. 11. 11.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  1. 10.  4.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 3.  0.  8. 10. 23.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.  0. 15.  3.  0. 25.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6] -> size -> 28 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 5.200710773468018





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-15.597612 ]
 [ -8.233593 ]
 [-27.204138 ]
 [ -3.369365 ]
 [ -5.6805334]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  3.] 
cards in discard: [11. 15. 11. 29. 29.  0. 10. 10. 25.  8.  8.  8. 10.  8. 11. 11.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11] -> size -> 25 
action values: 1 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  1. 10.  4.  4.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 3.  0.  8. 10. 23.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.  0. 15.  3.  0. 25.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6] -> size -> 28 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.20505428314209



buy possibilites: [-1] 
expected returns: [[-14.987328]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  3.] 
cards in discard: [11. 15. 11. 29. 29.  0. 10. 10. 25.  8.  8.  8. 10.  8. 11. 11.  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  1. 10.  4.  3.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 3.  0.  8. 10. 23.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.  0. 15.  3.  0. 25.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6] -> size -> 28 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 171 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -3.369351625442505






Player: 1 
cards in hand: [ 3.  0.  8. 10. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 10. 23.] 
cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.  0. 15.  3.  0. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  1. 10.  4.  3.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [29. 10. 11. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8] -> size -> 26 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8. 10. 23.] 
cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.  0. 15.  3.  0. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8.  1. 10.  4.  3.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [29. 10. 11. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8] -> size -> 26 
adversary victory points: 0
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8. 10. 23.] 
cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.  0. 15.  3.  0. 25.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8.  1. 10.  4.  3.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [29. 10. 11. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8] -> size -> 26 
adversary victory points: 0
player victory points: -4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [29. 10. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 10. 10.] 
expected returns: [[-42.391155]
 [-38.639194]
 [-46.676834]
 [-39.935944]
 [-46.676834]
 [-46.676834]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11. 10. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  1. 10.  4.  3.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [15.  0.  6. 10.  6.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.  0. 15.  3.  0. 25.
  0.  3.  0.  8. 10. 23.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0] -> size -> 29 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.987327575683594



action possibilites: [-1. 11. 10. 10. 10.] 
expected returns: [[-29.998936]
 [-21.707472]
 [-30.317915]
 [-30.317915]
 [-30.317915]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 10.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8.  1. 10.  4.  3.  8.  5. 10.  9.  0. 10.  6.] 
adversary cards in hand: [15.  0.  6. 10.  6.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.  0. 15.  3.  0. 25.
  0.  3.  0.  8. 10. 23.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0] -> size -> 29 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -47.73055648803711



action possibilites: [-1] 
expected returns: [[-33.841286]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.] 
cards in discard: [10. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8.  1. 10.  4.  3.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [15.  0.  6. 10.  6.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.  0. 15.  3.  0. 25.
  0.  3.  0.  8. 10. 23.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0] -> size -> 29 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -19.626934051513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-41.669697]
 [-51.352165]
 [-33.500103]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.] 
cards in discard: [10. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8.  1. 10.  4.  3.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [15.  0.  6. 10.  6.] 
adversary cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.  0. 15.  3.  0. 25.
  0.  3.  0.  8. 10. 23.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0] -> size -> 29 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: -33.841285705566406






Player: 1 
cards in hand: [15.  0.  6. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  6. 10.  6.] 
cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.  0. 15.  3.  0. 25.
  0.  3.  0.  8. 10. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  1. 10.  4.  3.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [29. 25.  8. 10. 15.] 
adversary cards in discard: [10. 15. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8 15] -> size -> 27 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6. 10.  6.] 
cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.  0. 15.  3.  0. 25.
  0.  3.  0.  8. 10. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8.  1. 10.  4.  3.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [29. 25.  8. 10. 15.] 
adversary cards in discard: [10. 15. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8 15] -> size -> 27 
adversary victory points: 0
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6. 10.  6.] 
cards in discard: [ 6.  6.  6.  6.  0.  6.  3. 15.  3. 11.  1. 29.  6.  0. 15.  3.  0. 25.
  0.  3.  0.  8. 10. 23.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8.  1. 10.  4.  3.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [29. 25.  8. 10. 15.] 
adversary cards in discard: [10. 15. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8 15] -> size -> 27 
adversary victory points: 0
player victory points: -4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [29. 25.  8. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.  8. 10. 15.] 
expected returns: [[-8.347524 ]
 [ 0.0739069]
 [ 8.620022 ]
 [-6.747184 ]
 [-8.677834 ]
 [-9.089972 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  8. 10. 15.] 
cards in discard: [10. 15. 29. 11. 10. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  1. 10.  4.  3.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 6.  6. 15.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -33.50010299682617



action possibilites: [-1] 
expected returns: [[-13.187191]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 10. 15.  8.  8.] 
cards in discard: [10. 15. 29. 11. 10. 10. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  3.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 6.  6. 15.  6.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6] -> size -> 31 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 8.62002182006836





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-23.183947]
 [-14.048899]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8. 10. 15.  8.  8.] 
cards in discard: [10. 15. 29. 11. 10. 10. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  3.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 6.  6. 15.  6.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6] -> size -> 31 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -13.187191009521484






Player: 1 
cards in hand: [ 6.  6. 15.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 15.  6.  3.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  3.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 8.  6. 10.  0.  8.] 
adversary cards in discard: [10. 15. 29. 11. 10. 10. 10. 25. 29.  8. 10. 15.  8.  8.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8 15] -> size -> 27 
adversary victory points: 0
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 3.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  3.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 8.  6. 10.  0.  8.] 
adversary cards in discard: [10. 15. 29. 11. 10. 10. 10. 25. 29.  8. 10. 15.  8.  8.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8 15] -> size -> 27 
adversary victory points: 0
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 3.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  3.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 8.  6. 10.  0.  8.] 
adversary cards in discard: [10. 15. 29. 11. 10. 10. 10. 25. 29.  8. 10. 15.  8.  8.] 
adversary owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8 15] -> size -> 27 
adversary victory points: 0
player victory points: -5 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 8.  6. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
expected returns: [[-6.858556 ]
 [-4.9217224]
 [-6.990062 ]
 [-4.9217224]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 10.  0.  8.] 
cards in discard: [10. 15. 29. 11. 10. 10. 10. 25. 29.  8. 10. 15.  8.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 29 25 11  8 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6
 11  8 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  3.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 6. 15.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6] -> size -> 31 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -14.048894882202148



action possibilites: [-1] 
expected returns: [[-10.2983055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.] 
cards in discard: [10. 15. 29. 11. 10. 10. 10. 25. 29.  8. 10. 15.  8.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  3.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 6. 15.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6] -> size -> 31 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 4.5614914894104





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-18.217863]
 [ -9.977158]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.] 
cards in discard: [10. 15. 29. 11. 10. 10. 10. 25. 29.  8. 10. 15.  8.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  3.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 6. 15.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6] -> size -> 31 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.29830551147461






Player: 1 
cards in hand: [0. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [ 6. 15.  6.  6.  6.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  3.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [11. 29. 29. 11.  3.] 
adversary cards in discard: [10. 15. 29. 11. 10. 10. 10. 25. 29.  8. 10. 15.  8.  8.  8.  6. 10.] 
adversary owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15] -> size -> 25 
adversary victory points: 0
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [ 6. 15.  6.  6.  6.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  3.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [11. 29. 29. 11.  3.] 
adversary cards in discard: [10. 15. 29. 11. 10. 10. 10. 25. 29.  8. 10. 15.  8.  8.  8.  6. 10.] 
adversary owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15] -> size -> 25 
adversary victory points: 0
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [ 6. 15.  6.  6.  6.  3.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  2.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [11. 29. 29. 11.  3.] 
adversary cards in discard: [10. 15. 29. 11. 10. 10. 10. 25. 29.  8. 10. 15.  8.  8.  8.  6. 10.] 
adversary owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15] -> size -> 25 
adversary victory points: 0
player victory points: -5 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [11. 29. 29. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29. 11.] 
expected returns: [[-1.3627336]
 [ 9.53314  ]
 [10.136496 ]
 [10.136496 ]
 [ 9.53314  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 29. 11.  3.] 
cards in discard: [10. 15. 29. 11. 10. 10. 10. 25. 29.  8. 10. 15.  8.  8.  8.  6. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  2.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [11. 15.  8.  0. 29.] 
adversary cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8] -> size -> 32 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -9.977150917053223



action possibilites: [-1. 29. 11. 11.] 
expected returns: [[-9.46682  ]
 [-1.3995123]
 [-1.9213734]
 [-1.9213734]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 11.] 
cards in discard: [10. 15. 29. 11. 10. 10. 10. 25. 29.  8. 10. 15.  8.  8.  8.  6. 10. 11.
  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  2.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [11. 15.  8.  0. 29.] 
adversary cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8] -> size -> 32 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -1.7396869659423828



action possibilites: [-1.  8.] 
expected returns: [[-22.292938]
 [-21.174326]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [10. 15. 29. 11. 10. 10. 10. 25. 29.  8. 10. 15.  8.  8.  8.  6. 10. 11.
  3. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  2.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [11. 15.  8.  0. 29.] 
adversary cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8] -> size -> 32 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -10.050470352172852



action possibilites: [-1] 
expected returns: [[-21.765299]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10. 15. 29. 11. 10. 10. 10. 25. 29.  8. 10. 15.  8.  8.  8.  6. 10. 11.
  3. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  2.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [11. 15.  8.  0. 29.] 
adversary cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8] -> size -> 32 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action 8.0
Learning step: 0
desired expected reward: -21.174325942993164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-31.217379]
 [-24.420877]
 [-19.928988]
 [-21.894035]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 15. 29. 11. 10. 10. 10. 25. 29.  8. 10. 15.  8.  8.  8.  6. 10. 11.
  3. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  2.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [11. 15.  8.  0. 29.] 
adversary cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8] -> size -> 32 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1
Learning step: 0
desired expected reward: -21.76529884338379



buy possibilites: [-1] 
expected returns: [[-25.150896]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 15. 29. 11. 10. 10. 10. 25. 29.  8. 10. 15.  8.  8.  8.  6. 10. 11.
  3. 11. 11.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  1.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [11. 15.  8.  0. 29.] 
adversary cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8] -> size -> 32 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: 221 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -19.92898178100586






Player: 1 
cards in hand: [11. 15.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  8.  0. 29.] 
cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  1.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 8. 10.  8.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15  8] -> size -> 26 
adversary victory points: 0
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  8.  0. 29.] 
cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  1.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 8. 10.  8.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15  8] -> size -> 26 
adversary victory points: 0
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8. 11.] 
expected returns: [[-42.074043]
 [-40.7139  ]
 [-42.426247]
 [-40.7139  ]
 [-34.997044]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  3. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  1.  8.  5. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 6.  6.  0. 15.  1.] 
adversary cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3. 11. 15.  8.  0. 29.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8] -> size -> 32 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -25.150896072387695



action possibilites: [-1] 
expected returns: [[-32.746742]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  3.] 
cards in discard: [15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15  8 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  1.  8.  5. 10.  9.  0. 10.  4.] 
adversary cards in hand: [ 6.  6.  0. 15.  1.] 
adversary cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3. 11. 15.  8.  0. 29.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8] -> size -> 32 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: -40.77475357055664





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-40.539463]
 [-32.52586 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.  3.] 
cards in discard: [15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15  8 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  1.  8.  5. 10.  9.  0. 10.  4.] 
adversary cards in hand: [ 6.  6.  0. 15.  1.] 
adversary cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3. 11. 15.  8.  0. 29.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8] -> size -> 32 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -32.746742248535156






Player: 1 
cards in hand: [ 6.  6.  0. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 15.  1.] 
cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3. 11. 15.  8.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  1.  8.  5. 10.  9.  0. 10.  4.] 
adversary cards in hand: [ 6. 29.  8. 10. 29.] 
adversary cards in discard: [15. 11.  8. 10.  8.  3.] 
adversary owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15  8 15] -> size -> 27 
adversary victory points: 0
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 15.  1.] 
cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3. 11. 15.  8.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 29. 30.  8.  0. 10.  4.  1.  8.  5. 10.  9.  0. 10.  4.] 
adversary cards in hand: [ 6. 29.  8. 10. 29.] 
adversary cards in discard: [15. 11.  8. 10.  8.  3.] 
adversary owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15  8 15] -> size -> 27 
adversary victory points: 0
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 15.  1.] 
cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3. 11. 15.  8.  0. 29.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  0. 10.  4.  1.  8.  5. 10.  9.  0. 10.  4.] 
adversary cards in hand: [ 6. 29.  8. 10. 29.] 
adversary cards in discard: [15. 11.  8. 10.  8.  3.] 
adversary owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15  8 15] -> size -> 27 
adversary victory points: 0
player victory points: -5 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 6. 29.  8. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10. 29.] 
expected returns: [[-9.150028 ]
 [-1.231029 ]
 [-7.7193136]
 [-9.519417 ]
 [-1.231029 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  8. 10. 29.] 
cards in discard: [15. 11.  8. 10.  8.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15  8 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  0. 10.  4.  1.  8.  5. 10.  9.  0. 10.  4.] 
adversary cards in hand: [ 0. 10.  6. 25. 23.] 
adversary cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3. 11. 15.  8.  0. 29.  1.
  6.  6.  0. 15.  1.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8  1] -> size -> 33 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -32.52587127685547



action possibilites: [-1. 29. 29.] 
expected returns: [[ 3.6142364]
 [12.674742 ]
 [12.674742 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 29.] 
cards in discard: [15. 11.  8. 10.  8.  3.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15  8 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  0. 10.  4.  1.  8.  5. 10.  9.  0. 10.  4.] 
adversary cards in hand: [ 0. 10.  6. 25. 23.] 
adversary cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3. 11. 15.  8.  0. 29.  1.
  6.  6.  0. 15.  1.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8  1] -> size -> 33 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -9.759834289550781



action possibilites: [-1.] 
expected returns: [[-7.6323175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [15. 11.  8. 10.  8.  3.  8. 10. 29. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15  8 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 29. 30.  8.  0. 10.  4.  1.  8.  5. 10.  9.  0. 10.  4.] 
adversary cards in hand: [ 0. 10.  6. 25. 23.] 
adversary cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3. 11. 15.  8.  0. 29.  1.
  6.  6.  0. 15.  1.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8  1] -> size -> 33 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 3.1312222480773926





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-16.390892 ]
 [ -9.913632 ]
 [ -5.634121 ]
 [ -7.4562387]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [15. 11.  8. 10.  8.  3.  8. 10. 29. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15  8 15] -> size -> 27 
action values: 1 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 29. 30.  8.  0. 10.  4.  1.  8.  5. 10.  9.  0. 10.  4.] 
adversary cards in hand: [ 0. 10.  6. 25. 23.] 
adversary cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3. 11. 15.  8.  0. 29.  1.
  6.  6.  0. 15.  1.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8  1] -> size -> 33 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -7.632317543029785



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 8 
Witch: 1 
Poacher: 4 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [6.] 
cards in discard: [15. 11.  8. 10.  8.  3.  8. 10. 29. 10.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 3 11 29 25 11 29 29  8 10  8 29 10 11 10  8 10  8 10 10 11 15  6 11  8
 15  8 15  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  0. 10.  4.  0.  8.  5. 10.  9.  0. 10.  4.] 
adversary cards in hand: [ 0. 10.  6. 25. 23.] 
adversary cards in discard: [ 6. 15.  6.  6.  6.  3.  8.  0.  3.  6.  0.  3. 11. 15.  8.  0. 29.  1.
  6.  6.  0. 15.  1.] 
adversary owned cards: [ 0  0  3  3  3 10  0  1  6 15  0  6 15 23  6 10  6  0 15 29  6 25  6  8
 11  6  3  6  0  0  6  8  1] -> size -> 33 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[     -5 3000000       0     150       0       0      40       0       0
       0       0       0       0       0       8       0] 
sum of rewards: 3000193 

action type: buy - action 8.0
Learning step: 120007.9453125
desired expected reward: 120002.3125



