 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[313.41626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -2  -60    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -567 

action type: buy - action -1
Learning step: -29.77286148071289
desired expected reward: -1.3156566619873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[290.00436]
 [298.8107 ]
 [297.7211 ]
 [278.61044]
 [308.70737]
 [299.95685]
 [299.00146]
 [316.8399 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.117915153503418
desired expected reward: 308.6871643066406



buy possibilites: [-1] 
expected returns: [[281.70035]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 11.0
Learning step: -8.297114372253418
desired expected reward: 300.4103088378906






Player: 1 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[309.26663]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.182166576385498
desired expected reward: 274.5181884765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[290.20212]
 [298.88486]
 [297.61545]
 [278.9052 ]
 [295.40854]
 [308.34268]
 [300.04462]
 [306.30316]
 [289.6302 ]
 [298.89   ]
 [299.08286]
 [316.3628 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.799203872680664
desired expected reward: 302.4386291503906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  3.  0.  3.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[311.20334]
 [306.81848]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.913159370422363
desired expected reward: 307.4496765136719



action possibilites: [-1] 
expected returns: [[326.02322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 27 

action type: gain_card_n - action 9
Learning step: -8.53009033203125
desired expected reward: 335.78216552734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[298.5312 ]
 [288.6379 ]
 [323.52432]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -8.404263496398926
desired expected reward: 317.61895751953125



buy possibilites: [-1] 
expected returns: [[337.00253]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [10.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -293.0 

action type: buy - action 6.0
Learning step: -21.499338150024414
desired expected reward: 267.1385803222656






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  6. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  6. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  6. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[348.0513]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  6. 11.  3.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 25.  3.  0.] 
adversary cards in discard: [8. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -9.65334701538086
desired expected reward: 327.34918212890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[327.0839 ]
 [335.74054]
 [334.52225]
 [318.77277]
 [315.84006]
 [332.2861 ]
 [344.79468]
 [336.88885]
 [351.6173 ]
 [342.9334 ]
 [326.55176]
 [331.38297]
 [335.7885 ]
 [321.93524]
 [335.9995 ]
 [352.27002]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  6. 11.  3.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 25.  3.  0.] 
adversary cards in discard: [8. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -10.419343948364258
desired expected reward: 338.326416015625



buy possibilites: [-1] 
expected returns: [[359.8218]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  6. 11.  3.  0.  3.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 25.  3.  0.] 
adversary cards in discard: [8. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 3.0
Learning step: -8.630125045776367
desired expected reward: 325.8921813964844






Player: 1 
cards in hand: [ 0.  3. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  3.  0.] 
cards in discard: [8. 0. 0. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[334.88068]
 [315.7592 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [25.  0.  3.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -10    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -313 

action type: buy - action -1
Learning step: -26.237140655517578
desired expected reward: 333.58465576171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[301.33072]
 [310.33453]
 [309.4381 ]
 [289.94427]
 [320.7839 ]
 [311.44778]
 [310.69656]
 [330.14856]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [25.  0.  3.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -10.253255844116211
desired expected reward: 324.82318115234375



buy possibilites: [-1] 
expected returns: [[284.95383]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [6. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [25.  0.  3.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -324.0 

action type: buy - action 6.0
Learning step: -24.285751342773438
desired expected reward: 265.65850830078125






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [25.  0.  3.  3.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  3.] 
adversary cards in discard: [ 6.  6. 10.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [25.  0.  3.  3.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  3.] 
adversary cards in discard: [ 6.  6. 10.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[293.86093]
 [285.55374]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  3.] 
cards in discard: [ 6.  6. 10.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -8.919625282287598
desired expected reward: 276.0342102050781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[261.21457]
 [268.23273]
 [250.79356]
 [270.31873]
 [286.63583]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  3.] 
cards in discard: [ 6.  6. 10.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -9.128497123718262
desired expected reward: 272.9955139160156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  6.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  6.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  6.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11.  6.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[303.79947]
 [297.15186]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [0. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -8.71131420135498
desired expected reward: 277.9245300292969



action possibilites: [-1] 
expected returns: [[273.5421]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [0. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: gain_card_n - action 0
Learning step: -9.737279891967773
desired expected reward: 274.1022644042969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[248.7964 ]
 [255.7292 ]
 [238.73822]
 [257.58844]
 [273.55695]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [0. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -7.986297607421875
desired expected reward: 265.5558166503906






Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [0. 3. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[293.0845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 3. 0.] 
cards in discard: [ 0. 11.  6.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  8.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3] -> size -> 13 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -8.810027122497559
desired expected reward: 264.7469482421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[272.3525 ]
 [278.17682]
 [263.37354]
 [280.2327 ]
 [294.8665 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 0.] 
cards in discard: [ 0. 11.  6.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  8.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3] -> size -> 13 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -9.902121543884277
desired expected reward: 282.0010681152344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  8.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  0. 25.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  3. 10.  0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  0.  3.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8.  0. 25.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  9.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  3. 10.  0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  0.  3.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8.  0. 25.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  9.  8.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  3. 10.  0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  0.  3.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[280.9677]
 [263.6654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 10.  0.] 
cards in discard: [ 0. 11.  6.  3.  0.  0.  3.  6.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  9.  8.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 8.  3.  0.  8.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -10.219889640808105
desired expected reward: 284.6466369628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[254.05107]
 [261.2548 ]
 [244.19186]
 [263.2667 ]
 [279.74417]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 10.  0.] 
cards in discard: [ 0. 11.  6.  3.  0.  0.  3.  6.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  9.  8.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 8.  3.  0.  8.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -9.779504776000977
desired expected reward: 272.2504577636719



buy possibilites: [-1] 
expected returns: [[238.8879]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 10.  0.] 
cards in discard: [ 0. 11.  6.  3.  0.  0.  3.  6.  0.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  6. 10.  9.  8.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 8.  3.  0.  8.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -345.0 

action type: buy - action 6.0
Learning step: -24.08461570739746
desired expected reward: 220.10726928710938






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 8.  3.  0.  8.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  6. 10.  9.  8.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6] -> size -> 18 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 8.  3.  0.  8.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  6. 10.  9.  8.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6] -> size -> 18 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 8.  3.  0.  8.  0. 25.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  6. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6] -> size -> 18 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[244.71887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  6. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8  8] -> size -> 15 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -8.671914100646973
desired expected reward: 230.21597290039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[223.61961]
 [230.74443]
 [213.01665]
 [232.86436]
 [248.69185]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  6. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8  8] -> size -> 15 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -9.194082260131836
desired expected reward: 236.24952697753906



buy possibilites: [-1] 
expected returns: [[213.23239]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  5. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8  8] -> size -> 15 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -356.0 

action type: buy - action 6.0
Learning step: -23.653104782104492
desired expected reward: 189.36354064941406






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  5. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0. 10.] 
adversary cards in discard: [6. 3. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6] -> size -> 19 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  5. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0. 10.] 
adversary cards in discard: [6. 3. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6] -> size -> 19 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8  8  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0. 10.] 
adversary cards in discard: [6. 3. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6] -> size -> 19 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[248.68352]
 [241.98808]
 [234.53151]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0. 10.] 
cards in discard: [6. 3. 0. 6. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 3. 8. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8  8  0] -> size -> 16 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -7.965649604797363
desired expected reward: 205.26673889160156



action possibilites: [-1] 
expected returns: [[335.3131]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 10.] 
cards in discard: [6. 3. 0. 6. 3. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  5. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 3. 8. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8  8  0] -> size -> 16 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: gain_card_n - action 0
Learning step: -6.802104473114014
desired expected reward: 220.79171752929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[308.89136]
 [316.0703 ]
 [297.36765]
 [318.52512]
 [334.57983]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 10.] 
cards in discard: [6. 3. 0. 6. 3. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 28. 30.  8.  5. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 3. 8. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8  8  0] -> size -> 16 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -11.313403129577637
desired expected reward: 323.99969482421875



buy possibilites: [-1] 
expected returns: [[291.02686]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 10.] 
cards in discard: [6. 3. 0. 6. 3. 0. 0. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 3. 8. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8  8  0] -> size -> 16 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -17 

action type: buy - action 3.0
Learning step: -10.105413436889648
desired expected reward: 305.9649353027344






Player: 1 
cards in hand: [8. 8. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 8. 3.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 25  8  0  3  8  8  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  0.  0.  3. 11.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3] -> size -> 21 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  0.  0.  3. 11.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3] -> size -> 21 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  0.  0.  3. 11.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3] -> size -> 21 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0. 0. 0. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  5. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3.  0.  0.  3. 11.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3] -> size -> 21 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[272.34418]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [ 6.  3.  0.  6.  3.  0.  0.  3. 11.  0.  6.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  5. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25.  0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -10.22098445892334
desired expected reward: 280.8058776855469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[247.8328 ]
 [254.88368]
 [237.42882]
 [256.91986]
 [272.61795]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [ 6.  3.  0.  6.  3.  0.  0.  3. 11.  0.  6.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 27. 30.  8.  5. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25.  0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -9.392313957214355
desired expected reward: 260.8458557128906



buy possibilites: [-1] 
expected returns: [[288.74146]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [ 6.  3.  0.  6.  3.  0.  0.  3. 11.  0.  6.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 27. 30.  8.  5. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25.  0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: -9.1449556350708
desired expected reward: 238.68780517578125






Player: 1 
cards in hand: [ 3.  0.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 25.  0.] 
cards in discard: [0. 0. 0. 3. 0. 0. 0. 8. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  5. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  4. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6] -> size -> 23 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 30. 30. 27. 30.  8.  4. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6] -> size -> 23 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[212.3709 ]
 [196.42851]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  6.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  4. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [25.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0] -> size -> 14 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -40    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -346 

action type: buy - action -1
Learning step: -27.06707763671875
desired expected reward: 261.67437744140625



action possibilites: [-1.] 
expected returns: [[216.53848]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  4. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [25.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0] -> size -> 14 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -25 

action type: take_action - action 10.0
Learning step: -6.209155559539795
desired expected reward: 190.41627502441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[193.61491]
 [201.57352]
 [200.60097]
 [183.50157]
 [210.62843]
 [202.60066]
 [201.75366]
 [218.5546 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 27. 30.  8.  4. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [25.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0] -> size -> 14 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -7.449275493621826
desired expected reward: 209.08920288085938






Player: 1 
cards in hand: [0. 3. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 8.] 
cards in discard: [25.  3.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  4. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6] -> size -> 23 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 8.] 
cards in discard: [25.  3.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 27. 30.  8.  4. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6] -> size -> 23 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 8.] 
cards in discard: [25.  3.  0.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  4. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6] -> size -> 23 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [0. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[233.95647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [ 6. 10.  3.  0.  0.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  4. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3] -> size -> 15 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -8.465178489685059
desired expected reward: 210.08941650390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[215.6378 ]
 [224.53476]
 [223.4579 ]
 [204.39594]
 [234.35037]
 [225.65508]
 [224.70596]
 [242.80922]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [ 6. 10.  3.  0.  0.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 26. 30.  8.  4. 10.  9.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3] -> size -> 15 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -9.291199684143066
desired expected reward: 224.59999084472656



buy possibilites: [-1] 
expected returns: [[188.81784]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [ 6. 10.  3.  0.  0.  6.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 26. 30.  8.  4. 10.  9.  6.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3] -> size -> 15 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -54.0 

action type: buy - action 8.0
Learning step: -9.734352111816406
desired expected reward: 215.92071533203125






Player: 1 
cards in hand: [25.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  4. 10.  9.  6.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6. 11.  0.  3.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  6.  0.  8.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8] -> size -> 24 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6. 11.  0.  3.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  6.  0.  8.  0.  6.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6] -> size -> 25 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 30. 30. 26. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6. 11.  0.  3.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  6.  0.  8.  0.  6.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6] -> size -> 25 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 26. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6. 11.  0.  3.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  6.  0.  8.  0.  6.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6] -> size -> 25 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[223.93303]
 [217.52953]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  0.  3.] 
cards in discard: [ 6. 10.  3.  0.  0.  6.  0.  8.  0.  6.  3.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10. 25.  3.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10] -> size -> 16 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -60    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -367 

action type: buy - action -1
Learning step: -22.876676559448242
desired expected reward: 165.941162109375



action possibilites: [-1] 
expected returns: [[207.88997]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [ 6. 10.  3.  0.  0.  6.  0.  8.  0.  6.  3.  0.  0.  6. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10. 25.  3.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10] -> size -> 16 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -38 

action type: gain_card_n - action 9
Learning step: -7.940956115722656
desired expected reward: 206.42864990234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[184.00372]
 [190.98692]
 [173.92007]
 [192.93695]
 [209.56625]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [ 6. 10.  3.  0.  0.  6.  0.  8.  0.  6.  3.  0.  0.  6. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 26. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10. 25.  3.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10] -> size -> 16 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: -8.302087783813477
desired expected reward: 199.58787536621094



buy possibilites: [-1] 
expected returns: [[155.91994]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [ 6. 10.  3.  0.  0.  6.  0.  8.  0.  6.  3.  0.  0.  6. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 26. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10. 25.  3.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10] -> size -> 16 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -60.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -77.0 

action type: buy - action 0.0
Learning step: -9.252482414245605
desired expected reward: 174.751220703125






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10. 25.  3.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  6.  0.  8.  0.  6.  3.  0.  0.  6. 10.  0. 11.  0.
  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0] -> size -> 27 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10. 25.  3.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 26. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  6.  0.  8.  0.  6.  3.  0.  0.  6. 10.  0. 11.  0.
  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0] -> size -> 27 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10. 25.  3.  0.  0.  0.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  6.  0.  8.  0.  6.  3.  0.  0.  6. 10.  0. 11.  0.
  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0] -> size -> 27 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[210.30626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [ 6. 10.  3.  0.  0.  6.  0.  8.  0.  6.  3.  0.  0.  6. 10.  0. 11.  0.
  6.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10] -> size -> 17 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -6.414106845855713
desired expected reward: 149.50582885742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[185.96367]
 [191.64177]
 [177.62988]
 [193.2605 ]
 [206.50676]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [ 6. 10.  3.  0.  0.  6.  0.  8.  0.  6.  3.  0.  0.  6. 10.  0. 11.  0.
  6.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 26. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10] -> size -> 17 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -9.438300132751465
desired expected reward: 200.8679656982422



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [25.  3.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0] -> size -> 27 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 26. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0] -> size -> 27 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.  0.  8.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0] -> size -> 27 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[228.51482]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3] -> size -> 18 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1.0
Learning step: -9.090496063232422
desired expected reward: 197.416259765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[204.3625 ]
 [211.08263]
 [193.77563]
 [213.14328]
 [227.97125]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 25. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3] -> size -> 18 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -10.273612022399902
desired expected reward: 215.71939086914062



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [ 3. 25.  3.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [6. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0] -> size -> 27 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [ 3. 25.  3.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 25. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [6. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0] -> size -> 27 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [ 3. 25.  3.  0.  0.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 24. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [6. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0] -> size -> 27 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[172.78261]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6. 0.] 
cards in discard: [6. 0. 0. 3. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 24. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  8.  3. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3] -> size -> 19 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -11.924099922180176
desired expected reward: 216.0471649169922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[154.84708]
 [160.00824]
 [147.46289]
 [161.30853]
 [173.68217]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 0.] 
cards in discard: [6. 0. 0. 3. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 24. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  8.  3. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3] -> size -> 19 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -9.142155647277832
desired expected reward: 160.8340301513672



buy possibilites: [-1] 
expected returns: [[165.53146]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 0.] 
cards in discard: [6. 0. 0. 3. 6. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 23. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  8.  3. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3] -> size -> 19 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -68 

action type: buy - action 3.0
Learning step: -7.6759538650512695
desired expected reward: 152.33229064941406






Player: 1 
cards in hand: [ 0.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 3. 25.  3.  0.  0.  8.  3. 10.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 23. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [6. 0. 0. 3. 6. 3. 3. 3. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0  3] -> size -> 28 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 3. 25.  3.  0.  0.  8.  3. 10.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 23. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [6. 0. 0. 3. 6. 3. 3. 3. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0  3] -> size -> 28 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 3. 25.  3.  0.  0.  8.  3. 10.  0.  3.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [6. 0. 0. 3. 6. 3. 3. 3. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0  3] -> size -> 28 
adversary victory points: -1
player victory points: 6 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[153.1053 ]
 [143.16977]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6. 0.] 
cards in discard: [6. 0. 0. 3. 6. 3. 3. 3. 0. 6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  3  6  6  0  6  6  0  3  0  6  8
  6 10  0  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1] -> size -> 20 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -8.701990127563477
desired expected reward: 156.8294677734375



action possibilites: [-1] 
expected returns: [[194.5031]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [6. 0. 0. 3. 6. 3. 3. 3. 0. 6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1] -> size -> 20 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: trash_cards_n_from_hand - action 2
Learning step: -4.606393337249756
desired expected reward: 130.0478515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[174.93002]
 [180.49918]
 [167.41023]
 [182.1325 ]
 [194.73996]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [6. 0. 0. 3. 6. 3. 3. 3. 0. 6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 23. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1] -> size -> 20 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: -7.802867889404297
desired expected reward: 186.70022583007812






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [6. 0. 0. 3. 6. 3. 3. 3. 0. 6. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3] -> size -> 26 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 23. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [6. 0. 0. 3. 6. 3. 3. 3. 0. 6. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3] -> size -> 26 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 22. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [6. 0. 0. 3. 6. 3. 3. 3. 0. 6. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3] -> size -> 26 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[155.47772]
 [141.97508]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  0.  0.] 
cards in discard: [6. 0. 0. 3. 6. 3. 3. 3. 0. 6. 0. 8. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 22. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1  3] -> size -> 21 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1.0
Learning step: -10.084269523620605
desired expected reward: 184.6556854248047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[134.20082]
 [139.91281]
 [139.21565]
 [126.94924]
 [147.3432 ]
 [140.71686]
 [140.09924]
 [154.17032]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  0.  0.] 
cards in discard: [6. 0. 0. 3. 6. 3. 3. 3. 0. 6. 0. 8. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 22. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1  3] -> size -> 21 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -8.250929832458496
desired expected reward: 147.22682189941406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [3. 0. 3. 0. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 22. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  3.  6.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  3.  3.  3.  0.  6.  0.  8.  0.  0.  0. 10.  6.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3] -> size -> 26 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [3. 0. 3. 0. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 22. 30.  8.  3. 10.  9.  6.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  3.  6.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  3.  3.  3.  0.  6.  0.  8.  0.  0.  0. 10.  6.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3] -> size -> 26 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [3. 0. 3. 0. 3. 0. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 22. 30.  8.  3. 10.  9.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  3.  6.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  3.  3.  3.  0.  6.  0.  8.  0.  0.  0. 10.  6.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3] -> size -> 26 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 10.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[205.83067]
 [200.06566]
 [192.96457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  3.  6.] 
cards in discard: [ 6.  0.  0.  3.  6.  3.  3.  3.  0.  6.  0.  8.  0.  0.  0. 10.  6.  0.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 22. 30.  8.  3. 10.  9.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 25. 10.  0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0. 8. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1.0
Learning step: -6.9151930809021
desired expected reward: 147.25514221191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[186.2571 ]
 [177.88588]
 [205.133  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.  3.  6.] 
cards in discard: [ 6.  0.  0.  3.  6.  3.  3.  3.  0.  6.  0.  8.  0.  0.  0. 10.  6.  0.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 22. 30.  8.  3. 10.  9.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 25. 10.  0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0. 8. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -9.643564224243164
desired expected reward: 196.18710327148438



buy possibilites: [-1] 
expected returns: [[173.62248]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.  3.  6.] 
cards in discard: [ 6.  0.  0.  3.  6.  3.  3.  3.  0.  6.  0.  8.  0.  0.  0. 10.  6.  0.
  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 22. 30.  8.  3. 10.  9.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 25. 10.  0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0. 8. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -105 

action type: buy - action 0.0
Learning step: -10.41477108001709
desired expected reward: 175.8423309326172






Player: 1 
cards in hand: [10.  0. 25. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25. 10.  0.] 
cards in discard: [3. 0. 3. 0. 3. 0. 8. 3. 0. 3. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 22. 30.  8.  3. 10.  9.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0] -> size -> 27 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 25. 10.  0.] 
cards in discard: [3. 0. 3. 0. 3. 0. 8. 3. 0. 3. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 22. 30.  8.  3. 10.  9.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0] -> size -> 27 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 25. 10.  0.] 
cards in discard: [3. 0. 3. 0. 3. 0. 8. 3. 0. 3. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 22. 30.  8.  3. 10.  9.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0] -> size -> 27 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [3. 6. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[189.08575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 22. 30.  8.  3. 10.  9.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 1. 8. 0.] 
adversary cards in discard: [ 3.  0.  3.  0.  3.  0.  8.  3.  0.  3.  3.  0.  0. 10.  0. 25. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0] -> size -> 23 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -8.235978126525879
desired expected reward: 165.38650512695312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[168.69688]
 [160.49458]
 [189.7344 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 22. 30.  8.  3. 10.  9.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 1. 8. 0.] 
adversary cards in discard: [ 3.  0.  3.  0.  3.  0.  8.  3.  0.  3.  3.  0.  0. 10.  0. 25. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0] -> size -> 23 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -9.040637016296387
desired expected reward: 177.41030883789062



buy possibilites: [-1] 
expected returns: [[157.88025]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 6.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 22. 30.  8.  2. 10.  9.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 1. 8. 0.] 
adversary cards in discard: [ 3.  0.  3.  0.  3.  0.  8.  3.  0.  3.  3.  0.  0. 10.  0. 25. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0] -> size -> 23 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -386.0 

action type: buy - action 6.0
Learning step: -23.772424697875977
desired expected reward: 136.72216796875






Player: 1 
cards in hand: [0. 3. 1. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 8. 0.] 
cards in discard: [ 3.  0.  3.  0.  3.  0.  8.  3.  0.  3.  3.  0.  0. 10.  0. 25. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 22. 30.  8.  2. 10.  9.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [6. 3. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6] -> size -> 28 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [ 3.  0.  3.  0.  3.  0.  8.  3.  0.  3.  3.  0.  0. 10.  0. 25. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 22. 30.  8.  2. 10.  9.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [6. 3. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6] -> size -> 28 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 3.  0.  3.  0.  3.  0.  8.  3.  0.  3.  3.  0.  0. 10.  0. 25. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 22. 30.  8.  2. 10.  9.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [6. 3. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6] -> size -> 28 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 3.  0.  3.  0.  3.  0.  8.  3.  0.  3.  3.  0.  0. 10.  0. 25. 10.  0.
 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 22. 30.  8.  2. 10.  8.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [6. 3. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6] -> size -> 28 
adversary victory points: -1
player victory points: 6 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[114.91591]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [6. 3. 6. 3. 0. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 22. 30.  8.  2. 10.  8.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11] -> size -> 22 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -9.145049095153809
desired expected reward: 148.73519897460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 98.283195]
 [102.78284 ]
 [102.32098 ]
 [ 92.464066]
 [101.062675]
 [107.38182 ]
 [103.28811 ]
 [106.306046]
 [ 98.0806  ]
 [102.88828 ]
 [102.97879 ]
 [111.341545]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [6. 3. 6. 3. 0. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 29. 30. 22. 30.  8.  2. 10.  8.  5.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11] -> size -> 22 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -7.085241794586182
desired expected reward: 106.20204162597656



buy possibilites: [-1] 
expected returns: [[168.62027]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [6. 3. 6. 3. 0. 6. 8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 22. 30.  8.  2. 10.  8.  4.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11] -> size -> 22 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -74.0 

action type: buy - action 8.0
Learning step: -5.070450305938721
desired expected reward: 98.2176742553711






Player: 1 
cards in hand: [ 3.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 22. 30.  8.  2. 10.  8.  4.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0.  8. 10.  0.] 
adversary cards in discard: [6. 3. 6. 3. 0. 6. 8. 0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8] -> size -> 29 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 22. 30.  8.  2. 10.  8.  4.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0.  8. 10.  0.] 
adversary cards in discard: [6. 3. 6. 3. 0. 6. 8. 0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8] -> size -> 29 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10.  0.] 
cards in discard: [8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 22. 30.  8.  2. 10.  8.  3.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0.  8. 10.  0.] 
adversary cards in discard: [6. 3. 6. 3. 0. 6. 8. 0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8] -> size -> 29 
adversary victory points: -1
player victory points: 6 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[118.76356 ]
 [109.40766 ]
 [108.986404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8. 10.  0.] 
cards in discard: [6. 3. 6. 3. 0. 6. 8. 0. 0. 0. 6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 22. 30.  8.  2. 10.  8.  3.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [ 8.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -9.649067878723145
desired expected reward: 158.97120666503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[102.94327 ]
 [106.98652 ]
 [ 97.172134]
 [108.12076 ]
 [117.86745 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  8. 10.  0.] 
cards in discard: [6. 3. 6. 3. 0. 6. 8. 0. 0. 0. 6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 22. 30.  8.  2. 10.  8.  3.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [ 8.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -7.245321750640869
desired expected reward: 111.51824188232422



buy possibilites: [-1] 
expected returns: [[161.69084]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  8. 10.  0.] 
cards in discard: [6. 3. 6. 3. 0. 6. 8. 0. 0. 0. 6. 0. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 22. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [ 8.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -68 

action type: buy - action 8.0
Learning step: -5.167994976043701
desired expected reward: 102.9527816772461






Player: 1 
cards in hand: [ 3. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [ 8.  3.  3.  0. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 22. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [ 6.  3.  6.  3.  0.  6.  8.  0.  0.  0.  6.  0.  8.  6.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8] -> size -> 30 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [ 8.  3.  3.  0. 10.  0. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 22. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [ 6.  3.  6.  3.  0.  6.  8.  0.  0.  0.  6.  0.  8.  6.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8] -> size -> 30 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [ 8.  3.  3.  0. 10.  0. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 22. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [ 6.  3.  6.  3.  0.  6.  8.  0.  0.  0.  6.  0.  8.  6.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8] -> size -> 30 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [ 8.  3.  3.  0. 10.  0. 15.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 21. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [ 6.  3.  6.  3.  0.  6.  8.  0.  0.  0.  6.  0.  8.  6.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8] -> size -> 30 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[130.82388]
 [124.79704]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.  0.] 
cards in discard: [ 6.  3.  6.  3.  0.  6.  8.  0.  0.  0.  6.  0.  8.  6.  0.  8. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 21. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8.  0. 25.  0.] 
adversary cards in discard: [ 8.  3.  3.  0. 10.  0. 15.  3. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15
  3] -> size -> 25 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -9.48363971710205
desired expected reward: 152.2071990966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[110.87159 ]
 [115.773544]
 [103.842964]
 [117.14741 ]
 [128.1686  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  3.  0.] 
cards in discard: [ 6.  3.  6.  3.  0.  6.  8.  0.  0.  0.  6.  0.  8.  6.  0.  8. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 21. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8.  0. 25.  0.] 
adversary cards in discard: [ 8.  3.  3.  0. 10.  0. 15.  3. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15
  3] -> size -> 25 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -8.141440391540527
desired expected reward: 122.68244171142578



buy possibilites: [-1] 
expected returns: [[121.65518]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  3.  0.] 
cards in discard: [ 6.  3.  6.  3.  0.  6.  8.  0.  0.  0.  6.  0.  8.  6.  0.  8. 10.  0.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 21. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8.  0. 25.  0.] 
adversary cards in discard: [ 8.  3.  3.  0. 10.  0. 15.  3. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15
  3] -> size -> 25 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -116.0 

action type: buy - action 0.0
Learning step: -8.606338500976562
desired expected reward: 102.2652587890625






Player: 1 
cards in hand: [ 3.  8.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 25.  0.] 
cards in discard: [ 8.  3.  3.  0. 10.  0. 15.  3. 11.  3.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 21. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10.  6.  3.  6.] 
adversary cards in discard: [ 6.  3.  6.  3.  0.  6.  8.  0.  0.  0.  6.  0.  8.  6.  0.  8. 10.  0.
  0. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0] -> size -> 31 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8.  3.  3.  0. 10.  0. 15.  3. 11.  3.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 21. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10.  6.  3.  6.] 
adversary cards in discard: [ 6.  3.  6.  3.  0.  6.  8.  0.  0.  0.  6.  0.  8.  6.  0.  8. 10.  0.
  0. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0] -> size -> 31 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  3.  3.  0. 10.  0. 15.  3. 11.  3.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 21. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10.  6.  3.  6.] 
adversary cards in discard: [ 6.  3.  6.  3.  0.  6.  8.  0.  0.  0.  6.  0.  8.  6.  0.  8. 10.  0.
  0. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0] -> size -> 31 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  3.  3.  0. 10.  0. 15.  3. 11.  3.  0.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 20. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10.  6.  3.  6.] 
adversary cards in discard: [ 6.  3.  6.  3.  0.  6.  8.  0.  0.  0.  6.  0.  8.  6.  0.  8. 10.  0.
  0. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0] -> size -> 31 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[149.55542]
 [139.54442]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6.  3.  6.] 
cards in discard: [ 6.  3.  6.  3.  0.  6.  8.  0.  0.  0.  6.  0.  8.  6.  0.  8. 10.  0.
  0. 11.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 20. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 8. 0. 0. 3.] 
adversary cards in discard: [ 8.  3.  3.  0. 10.  0. 15.  3. 11.  3.  0.  0.  3.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -7.0885820388793945
desired expected reward: 114.56659698486328



action possibilites: [-1.] 
expected returns: [[147.97453]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 6. 0.] 
cards in discard: [ 6.  3.  6.  3.  0.  6.  8.  0.  0.  0.  6.  0.  8.  6.  0.  8. 10.  0.
  0. 11.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 20. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 8. 0. 0. 3.] 
adversary cards in discard: [ 8.  3.  3.  0. 10.  0. 15.  3. 11.  3.  0.  0.  3.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -65 

action type: take_action - action 10.0
Learning step: -6.8977952003479
desired expected reward: 132.6466522216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[133.90651]
 [127.05682]
 [149.6553 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 6. 0.] 
cards in discard: [ 6.  3.  6.  3.  0.  6.  8.  0.  0.  0.  6.  0.  8.  6.  0.  8. 10.  0.
  0. 11.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 20. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 8. 0. 0. 3.] 
adversary cards in discard: [ 8.  3.  3.  0. 10.  0. 15.  3. 11.  3.  0.  0.  3.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -7.512332916259766
desired expected reward: 140.4622039794922






Player: 1 
cards in hand: [1. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 0. 3.] 
cards in discard: [ 8.  3.  3.  0. 10.  0. 15.  3. 11.  3.  0.  0.  3.  3.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 20. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0] -> size -> 31 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 0. 3.] 
cards in discard: [ 8.  3.  3.  0. 10.  0. 15.  3. 11.  3.  0.  0.  3.  3.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 29. 30. 20. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0] -> size -> 31 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 0. 3.] 
cards in discard: [ 8.  3.  3.  0. 10.  0. 15.  3. 11.  3.  0.  0.  3.  3.  8.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0] -> size -> 31 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[74.982544]
 [71.63546 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  8.  2.  9. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  1.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3
  1] -> size -> 25 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -10.15353012084961
desired expected reward: 139.50177001953125



action possibilites: [-1] 
expected returns: [[121.76978]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [14.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  8.  2.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  1.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3
  1] -> size -> 25 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -50 

action type: gain_card_n - action 8
Learning step: -2.729504108428955
desired expected reward: 56.65697479248047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[107.2816  ]
 [110.399445]
 [102.57596 ]
 [111.38805 ]
 [119.620995]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [14.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  8.  2.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  1.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3
  1] -> size -> 25 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -6.829556465148926
desired expected reward: 114.94022369384766






Player: 1 
cards in hand: [ 0.  1.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  8.  2.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 6. 6. 3. 0.] 
adversary cards in discard: [14. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14] -> size -> 32 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  8.  2.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 6. 6. 3. 0.] 
adversary cards in discard: [14. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14] -> size -> 32 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8.  0. 10.] 
cards in discard: [8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3
  1  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 6. 6. 3. 0.] 
adversary cards in discard: [14. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14] -> size -> 32 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [6. 6. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[52.039013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 3. 0.] 
cards in discard: [14. 11.  3.  3.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 8.  0.  1.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3
  1  8] -> size -> 26 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -9.1101713180542
desired expected reward: 110.51081085205078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.29813 ]
 [41.440987]
 [54.32531 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 3. 0.] 
cards in discard: [14. 11.  3.  3.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 8.  0.  1.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3
  1  8] -> size -> 26 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -5.787684917449951
desired expected reward: 46.25132751464844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 8.  0.  1.  8.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3
  1  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14] -> size -> 32 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 8.  0.  1.  8.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3
  1  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14] -> size -> 32 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 8.  0.  1.  8.  0. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3
  1  8  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 19. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14] -> size -> 32 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[76.0397  ]
 [66.443665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 19. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3.  8.  3. 11.] 
adversary cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3
  1  8  3] -> size -> 27 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -5.873256206512451
desired expected reward: 48.45204544067383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[61.259144]
 [64.34004 ]
 [56.90373 ]
 [65.14818 ]
 [73.95954 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 19. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3.  8.  3. 11.] 
adversary cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3
  1  8  3] -> size -> 27 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -7.074250221252441
desired expected reward: 68.96546936035156



buy possibilites: [-1] 
expected returns: [[112.57358]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 18. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3.  8.  3. 11.] 
adversary cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3
  1  8  3] -> size -> 27 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -77 

action type: buy - action 3.0
Learning step: -4.534096717834473
desired expected reward: 59.805946350097656






Player: 1 
cards in hand: [ 3.  3.  8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8.  3. 11.] 
cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  0  0  3 10 10  3  3  1  3  8  0 11  8 15  3  3
  1  8  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 18. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3] -> size -> 33 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.] 
cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  8  0  0 10 10  3  3  1  3  8  0 11  8 15  3  3  1  8
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 18. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3] -> size -> 33 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  8  0  0 10 10  3  3  1  3  8  0 11  8 15  3  3  1  8
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 18. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3] -> size -> 33 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  8  0  0 10 10  3  3  1  3  8  0 11  8 15  3  3  1  8
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 18. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3] -> size -> 33 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[35.7513]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 18. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10. 15.  8.  0.  1.] 
adversary cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.  0.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  8  0  0 10 10  3  3  1  3  8  0 11  8 15  3  3  1  8
  3  0] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -8.074275016784668
desired expected reward: 104.49930572509766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[28.513712]
 [30.555508]
 [25.617662]
 [31.086372]
 [36.357086]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 18. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10. 15.  8.  0.  1.] 
adversary cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.  0.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  8  0  0 10 10  3  3  1  3  8  0 11  8 15  3  3  1  8
  3  0] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -4.303444862365723
desired expected reward: 31.447856903076172



buy possibilites: [-1] 
expected returns: [[68.879524]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 28. 30. 18. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10. 15.  8.  0.  1.] 
adversary cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.  0.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  8  0  0 10 10  3  3  1  3  8  0 11  8 15  3  3  1  8
  3  0] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: -4.625895977020264
desired expected reward: 23.887813568115234






Player: 1 
cards in hand: [10. 15.  8.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  8.  0.  1.] 
cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.  0.  8.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  8  0  0 10 10  3  3  1  3  8  0 11  8 15  3  3  1  8
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 18. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  6. 10.] 
adversary cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.  0.
  3.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3  0] -> size -> 34 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.  0.  8.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  8  0  0 10  3  3  3  8  0 11  8  3  3  1  8  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 18. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  6. 10.] 
adversary cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.  0.
  3.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3  0] -> size -> 34 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.  0.  8.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  8  0  0 10  3  3  3  8  0 11  8  3  3  1  8  3  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 18. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  6. 10.] 
adversary cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.  0.
  3.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3  0] -> size -> 34 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.  0.  8.  3. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  8  0  0 10  3  3  3  8  0 11  8  3  3  1  8  3  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 18. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  6. 10.] 
adversary cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.  0.
  3.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3  0] -> size -> 34 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[64.32032]
 [56.66712]
 [56.18112]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  6. 10.] 
cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.  0.
  3.  0.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 18. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.  0.  8.  3. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  8  0  0 10  3  3  3  8  0 11  8  3  3  1  8  3  0  0] -> size -> 23 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -5.3212480545043945
desired expected reward: 63.55827713012695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[51.96611]
 [55.38453]
 [47.18129]
 [56.48849]
 [64.67416]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  6. 10.] 
cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.  0.
  3.  0.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 28. 30. 18. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.  0.  8.  3. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  8  0  0 10  3  3  3  8  0 11  8  3  3  1  8  3  0  0] -> size -> 23 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -5.145755290985107
desired expected reward: 59.174556732177734



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.  0.  8.  3. 11.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  0  0 10  3  3  3  8  0 11  8  3  3  1  8  3  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 18. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 8. 6. 8.] 
adversary cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.  0.
  3.  0.  6.  0.  6.  8.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3  0] -> size -> 34 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.  0.  8.  3. 11.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  0  0 10  3  3  3  8  0 11  8  3  3  1  8  3  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 28. 30. 18. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 8. 6. 8.] 
adversary cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.  0.
  3.  0.  6.  0.  6.  8.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3  0] -> size -> 34 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  1.  8.  0. 10.  3.  0.  0.  3.  3.  3.  0.  8.  3. 11.  0.  8.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  0  0 10  3  3  3  8  0 11  8  3  3  1  8  3  0  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 28. 30. 17. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 8. 6. 8.] 
adversary cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.  0.
  3.  0.  6.  0.  6.  8.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3  0] -> size -> 34 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[49.030544]
 [42.47812 ]
 [42.47812 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6. 8.] 
cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.  0.
  3.  0.  6.  0.  6.  8.  0.  0.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  8  6 10
  0  3  0  6  8  8  0 14  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 17. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  0  0 10  3  3  3  8  0 11  8  3  3  1  8  3  0  0  3] -> size -> 24 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1.0
Learning step: -5.942323684692383
desired expected reward: 58.7318115234375



action possibilites: [-1] 
expected returns: [[91.15122]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.  0.
  3.  0.  6.  0.  6.  8.  0.  0.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 17. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  0  0 10  3  3  3  8  0 11  8  3  3  1  8  3  0  0  3] -> size -> 24 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: trash_cards_n_from_hand - action 9
Learning step: -3.0056235790252686
desired expected reward: 47.45753479003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[76.12072 ]
 [70.782776]
 [90.68072 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.  0.
  3.  0.  6.  0.  6.  8.  0.  0.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 28. 30. 17. 30.  8.  2. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  0  0 10  3  3  3  8  0 11  8  3  3  1  8  3  0  0  3] -> size -> 24 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: -5.429753303527832
desired expected reward: 85.72146606445312



buy possibilites: [-1] 
expected returns: [[49.1658]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [14. 11.  3.  3.  0.  0.  6.  6.  6.  3.  0.  3.  3.  0.  3. 10.  0.  0.
  3.  0.  6.  0.  6.  8.  0.  0.  6. 10.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 17. 30.  8.  1. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  0  0 10  3  3  3  8  0 11  8  3  3  1  8  3  0  0  3] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -80    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -366 

action type: buy - action 6.0
Learning step: -20.732908248901367
desired expected reward: 50.04987335205078






Player: 1 
cards in hand: [3. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  0  0 10  3  3  3  8  0 11  8  3  3  1  8  3  0  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 17. 30.  8.  1. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6] -> size -> 32 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 17. 30.  8.  1. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6] -> size -> 32 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 17. 30.  8.  1. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6] -> size -> 32 
adversary victory points: -1
player victory points: 6 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[51.999187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 17. 30.  8.  1. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3] -> size -> 22 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -5.118194580078125
desired expected reward: 44.047603607177734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[45.23674 ]
 [48.40452 ]
 [47.882877]
 [41.106956]
 [51.495518]
 [48.825634]
 [48.346664]
 [53.754295]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 28. 30. 17. 30.  8.  1. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3] -> size -> 22 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -5.203624725341797
desired expected reward: 45.46726989746094



buy possibilites: [-1] 
expected returns: [[62.829132]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 17. 30.  8.  1. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3] -> size -> 22 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -58 

action type: buy - action 1.0
Learning step: -3.9065709114074707
desired expected reward: 44.497955322265625






Player: 1 
cards in hand: [1. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [8. 0. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 17. 30.  8.  1. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [14.  6. 11. 10.  0.] 
adversary cards in discard: [1. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1] -> size -> 33 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [8. 0. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 30. 17. 30.  8.  1. 10.  8.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [14.  6. 11. 10.  0.] 
adversary cards in discard: [1. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1] -> size -> 33 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [ 8.  0.  8. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 17. 30.  8.  1. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [14.  6. 11. 10.  0.] 
adversary cards in discard: [1. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1] -> size -> 33 
adversary victory points: -1
player victory points: 6 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [14.  6. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 10.] 
expected returns: [[45.167862]
 [37.44966 ]
 [42.952282]
 [40.22281 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6. 11. 10.  0.] 
cards in discard: [1. 6. 0. 0. 3. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 17. 30.  8.  1. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10. 11.  3.  8.] 
adversary cards in discard: [ 8.  0.  8. 11.  1.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3 11] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -5.977807521820068
desired expected reward: 56.85132598876953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.30432]
 [34.42161]
 [45.11593]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6. 11. 10.  0.] 
cards in discard: [1. 6. 0. 0. 3. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 17. 30.  8.  1. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10. 11.  3.  8.] 
adversary cards in discard: [ 8.  0.  8. 11.  1.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3 11] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -5.130561351776123
desired expected reward: 40.03730010986328



buy possibilites: [-1] 
expected returns: [[45.61071]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6. 11. 10.  0.] 
cards in discard: [1. 6. 0. 0. 3. 0. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 17. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10. 11.  3.  8.] 
adversary cards in discard: [ 8.  0.  8. 11.  1.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3 11] -> size -> 23 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -387.0 

action type: buy - action 6.0
Learning step: -20.04483985900879
desired expected reward: 14.376760482788086






Player: 1 
cards in hand: [ 3. 10. 11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  3.  8.] 
cards in discard: [ 8.  0.  8. 11.  1.  3.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 17. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6] -> size -> 34 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11.  3.  8.] 
cards in discard: [ 8.  0.  8. 11.  1.  3.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3 11] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 17. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6] -> size -> 34 
adversary victory points: -2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.137821]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 6.] 
cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 17. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 8.  0.  8. 11.  1.  3.  0.  0.  3.  3. 10. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3 11] -> size -> 23 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -5.929934978485107
desired expected reward: 39.6807746887207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[18.488754]
 [21.181461]
 [21.97025 ]
 [28.90337 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 6.] 
cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 17. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 8.  0.  8. 11.  1.  3.  0.  0.  3.  3. 10. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3 11] -> size -> 23 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -5.345239162445068
desired expected reward: 25.79258155822754



buy possibilites: [-1] 
expected returns: [[21.060951]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 6.] 
cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 16. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 8.  0.  8. 11.  1.  3.  0.  0.  3.  3. 10. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3 11] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -68 

action type: buy - action 3.0
Learning step: -3.985201597213745
desired expected reward: 17.196260452270508






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 8.  0.  8. 11.  1.  3.  0.  0.  3.  3. 10. 11.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 16. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 3.] 
adversary cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3] -> size -> 35 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 8.  0.  8. 11.  1.  3.  0.  0.  3.  3. 10. 11.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 30. 16. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 3.] 
adversary cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3] -> size -> 35 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 8.  0.  8. 11.  1.  3.  0.  0.  3.  3. 10. 11.  3.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3 11  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 27. 30. 15. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 3.] 
adversary cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3] -> size -> 35 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [6. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.786987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 0. 3.] 
cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 15. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3 11  3] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -4.885340690612793
desired expected reward: 16.175609588623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[18.696846]
 [20.68116 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 3.] 
cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 15. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3 11  3] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -4.888061046600342
desired expected reward: 15.89892578125



buy possibilites: [-1] 
expected returns: [[40.751842]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 3.] 
cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.
  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 15. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3 11  3] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -80.   0.   0.   0. -30.   0.   0.   0.  -1.   0.   0.
   0.   0.] 
sum of rewards: -117.0 

action type: buy - action 0.0
Learning step: -5.86792516708374
desired expected reward: 12.828916549682617






Player: 1 
cards in hand: [3. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  0  0 10  3  3  8  0 11  8  3  3  1  8  3  0  0  3 11  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 15. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.
  0.  6.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0] -> size -> 36 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  0  0 10  3  8  0 11  8  3  3  1  8  3  0  0  3 11  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 15. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.
  0.  6.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0] -> size -> 36 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  0  0 10  3  8  0 11  8  3  3  1  8  3  0  0  3 11  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 15. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.
  0.  6.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0] -> size -> 36 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  0  0 10  3  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 15. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.
  0.  6.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0] -> size -> 36 
adversary victory points: -1
player victory points: 6 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [3. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[42.86218]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.
  0.  6.  3.  6.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 15. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 3. 8. 0.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  8  0  0 10  3  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -4.873193264007568
desired expected reward: 35.8786506652832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[34.1059  ]
 [36.55977 ]
 [37.536503]
 [44.540333]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.
  0.  6.  3.  6.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 15. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 3. 8. 0.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  8  0  0 10  3  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -5.030860424041748
desired expected reward: 37.83131790161133



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 8. 0.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0  0 10  3  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 15. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.
  0.  6.  3.  6.  0.  3.  3.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0] -> size -> 36 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 15. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.
  0.  6.  3.  6.  0.  3.  3.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0] -> size -> 36 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 30. 15. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.
  0.  6.  3.  6.  0.  3.  3.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0] -> size -> 36 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [8. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[22.740335]
 [19.405273]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.
  0.  6.  3.  6.  0.  3.  3.  6.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 15. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10.  1.  3.  0.] 
adversary cards in discard: [0. 8. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0] -> size -> 20 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1.0
Learning step: -4.489036560058594
desired expected reward: 29.052989959716797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[13.732047]
 [14.726686]
 [15.230109]
 [18.031013]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.
  0.  6.  3.  6.  0.  3.  3.  6.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 15. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10.  1.  3.  0.] 
adversary cards in discard: [0. 8. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0] -> size -> 20 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -4.068120002746582
desired expected reward: 18.672218322753906



buy possibilites: [-1] 
expected returns: [[43.43258]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [ 1.  6.  0.  0.  3.  0.  6. 14.  6. 11. 10.  0.  3.  3.  0.  0.  6.  6.
  0.  6.  3.  6.  0.  3.  3.  6.  6.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 14. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10.  1.  3.  0.] 
adversary cards in discard: [0. 8. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0] -> size -> 20 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0  -2   0   0   8   0] 
sum of rewards: -49 

action type: buy - action 3.0
Learning step: -2.2091012001037598
desired expected reward: 12.517581939697266






Player: 1 
cards in hand: [ 3. 10.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1.  3.  0.] 
cards in discard: [0. 8. 3. 0. 8. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 14. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.  3.  0.] 
cards in discard: [0. 8. 3. 0. 8. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 27. 30. 14. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.  3.  0.] 
cards in discard: [0. 8. 3. 0. 8. 0. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 14. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[33.098522]
 [29.6046  ]
 [29.34856 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 14. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [ 0.  8.  3.  0.  8.  0.  1.  3. 10.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -4.218617916107178
desired expected reward: 39.21396255493164



action possibilites: [-1.  8.] 
expected returns: [[15.657207]
 [12.773271]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 14. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [ 0.  8.  3.  0.  8.  0.  1.  3. 10.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 10.0
Learning step: -2.8697710037231445
desired expected reward: 26.163360595703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 9.774835]
 [11.108138]
 [11.539008]
 [14.442525]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 14. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [ 0.  8.  3.  0.  8.  0.  1.  3. 10.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -2.2464773654937744
desired expected reward: 13.410721778869629






Player: 1 
cards in hand: [ 0. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [ 0.  8.  3.  0.  8.  0.  1.  3. 10.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 14. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 6. 3. 6. 6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  8.  3.  0.  8.  0.  1.  3. 10.  1.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 14. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 6. 3. 6. 6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  8.  3.  0.  8.  0.  1.  3. 10.  1.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 14. 30.  8.  0. 10.  7.  1.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 6. 3. 6. 6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  8.  3.  0.  8.  0.  1.  3. 10.  1.  3.  0. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 14. 30.  8.  0. 10.  7.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 6. 3. 6. 6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [0. 6. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[45.26114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6. 6.] 
cards in discard: [10.  0.  3.  0.  8.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 14. 30.  8.  0. 10.  7.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 1.  8.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8] -> size -> 23 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -2.4537503719329834
desired expected reward: 11.988768577575684





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[39.546307]
 [47.438396]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 6.] 
cards in discard: [10.  0.  3.  0.  8.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 14. 30.  8.  0. 10.  7.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 1.  8.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8] -> size -> 23 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -4.001523494720459
desired expected reward: 41.25961685180664



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  8.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 14. 30.  8.  0. 10.  7.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  1.  6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 14. 30.  8.  0. 10.  7.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  1.  6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0.  3. 11.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 13. 30.  8.  0. 10.  7.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  1.  6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  0.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[24.484987]
 [20.050642]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  1.  6.] 
cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 13. 30.  8.  0. 10.  7.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  1.  8.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3] -> size -> 24 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: -5.102377414703369
desired expected reward: 42.33602523803711



action possibilites: [-1.] 
expected returns: [[35.654163]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 6. 0.] 
cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 13. 30.  8.  0. 10.  7.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  1.  8.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3] -> size -> 24 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -44 

action type: take_action - action 10.0
Learning step: -2.40031361579895
desired expected reward: 17.650327682495117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[26.46815 ]
 [28.304657]
 [28.01608 ]
 [27.556112]
 [30.295275]
 [29.820986]
 [26.302937]
 [28.284761]
 [28.280313]
 [31.903376]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 6. 0.] 
cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 26. 30. 13. 30.  8.  0. 10.  7.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  1.  8.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3] -> size -> 24 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -3.3627052307128906
desired expected reward: 32.29145812988281






Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [ 3.  1.  8.  0.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 13. 30.  8.  0. 10.  7.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [14.  0.  0.  0.  6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 3.  1.  8.  0.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 13. 30.  8.  0. 10.  7.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [14.  0.  0.  0.  6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 3.  1.  8.  0.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 13. 30.  8.  0. 10.  7.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [14.  0.  0.  0.  6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 3.  1.  8.  0.  3. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 13. 30.  8.  0. 10.  7.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [14.  0.  0.  0.  6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [14.  0.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[9.714346]
 [6.171159]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.  6.] 
cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 13. 30.  8.  0. 10.  7.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 3.  1.  8.  0.  3. 11.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3  0] -> size -> 24 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: -4.651661396026611
desired expected reward: 27.251718521118164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ 8.4141  ]
 [ 9.572826]
 [ 9.322031]
 [11.037116]
 [ 9.49895 ]
 [12.308757]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  6.] 
cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 26. 30. 13. 30.  8.  0. 10.  7.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 3.  1.  8.  0.  3. 11.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3  0] -> size -> 24 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -3.491072416305542
desired expected reward: 6.223270416259766



buy possibilites: [-1] 
expected returns: [[7.693239]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  6.] 
cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 13. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 3.  1.  8.  0.  3. 11.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3  0] -> size -> 24 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0  -3   0   0  18   0] 
sum of rewards: -50 

action type: buy - action 11.0
Learning step: -2.878757953643799
desired expected reward: 8.158353805541992






Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [ 3.  1.  8.  0.  3. 11.  0.  8.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 13. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3 11] -> size -> 38 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [ 3.  1.  8.  0.  3. 11.  0.  8.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 26. 30. 13. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3 11] -> size -> 38 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [ 3.  1.  8.  0.  3. 11.  0.  8.  3.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3 11] -> size -> 38 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[2.4274566]
 [1.2197759]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  8. 11. 10.  3.] 
adversary cards in discard: [ 3.  1.  8.  0.  3. 11.  0.  8.  3.  0.  0.  3.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3  0
  3] -> size -> 25 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -4.088587760925293
desired expected reward: 3.60465145111084





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-0.21536744]
 [ 0.5767472 ]
 [ 2.7124798 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  8. 11. 10.  3.] 
adversary cards in discard: [ 3.  1.  8.  0.  3. 11.  0.  8.  3.  0.  0.  3.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3  0
  3] -> size -> 25 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -3.8342227935791016
desired expected reward: -1.406766653060913



buy possibilites: [-1] 
expected returns: [[19.395823]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3 11  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  8. 11. 10.  3.] 
adversary cards in discard: [ 3.  1.  8.  0.  3. 11.  0.  8.  3.  0.  0.  3.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3  0
  3] -> size -> 25 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -70.   0.   0.   0. -30.   0.   0.   0.  -4.   0.   0.
   0.   0.] 
sum of rewards: -109.0 

action type: buy - action 0.0
Learning step: -4.892434597015381
desired expected reward: -7.315629005432129






Player: 1 
cards in hand: [ 3.  8. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11. 10.  3.] 
cards in discard: [ 3.  1.  8.  0.  3. 11.  0.  8.  3.  0.  0.  3.  0.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [3. 8. 3. 3. 6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.  0.  0.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3 11  0] -> size -> 39 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1.  8. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  3. 10.] 
cards in discard: [ 3.  1.  8.  0.  3. 11.  0.  8.  3.  0.  0.  3.  0.  0.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3  0
  3] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [3. 8. 3. 3. 6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.  0.  0.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3 11  0] -> size -> 39 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  3.  1.] 
cards in discard: [ 3.  1.  8.  0.  3. 11.  0.  8.  3.  0.  0.  3.  0.  0.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0 10  8  0 11  8  3  3  1  8  3  0  0  3 11  3  0  1 10  8  3  0
  3] -> size -> 25 
action values: 3 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [3. 8. 3. 3. 6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.  0.  0.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3 11  0] -> size -> 39 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 3.  1.  8.  0.  3. 11.  0.  8.  3.  0.  0.  3.  0.  0.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [3. 8. 3. 3. 6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.  0.  0.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3 11  0] -> size -> 39 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 3.  1.  8.  0.  3. 11.  0.  8.  3.  0.  0.  3.  0.  0.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3] -> size -> 23 
action values: 2 
buys: 1 
player value: 0 
card supply: [13. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [3. 8. 3. 3. 6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.  0.  0.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3 11  0] -> size -> 39 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 3.  1.  8.  0.  3. 11.  0.  8.  3.  0.  0.  3.  0.  0.  0.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [3. 8. 3. 3. 6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.  0.  0.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3 11  0] -> size -> 39 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [3. 8. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[ 1.7582073 ]
 [-0.66361356]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 3. 6.] 
cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.  0.  0.  3. 11.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  6  0  6  6  0  3  0  6  6 10  0  3  0
  6  8  8  0 14  3  0  6  1  6  3  0  3 11  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 1. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0] -> size -> 24 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -4.69736385345459
desired expected reward: 14.698458671569824



action possibilites: [-1] 
expected returns: [[8.514374]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.  0.  0.  3. 11.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6
  8  8  0 14  3  0  6  1  6  3  0  3 11  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 1. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0] -> size -> 24 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: trash_cards_n_from_hand - action 0
Learning step: -1.9019052982330322
desired expected reward: -4.0323333740234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[2.792478 ]
 [7.6977916]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.  0.  0.  3. 11.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6
  8  8  0 14  3  0  6  1  6  3  0  3 11  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 1. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0] -> size -> 24 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1
Learning step: -2.4872195720672607
desired expected reward: 6.027153968811035



buy possibilites: [-1] 
expected returns: [[7.681195]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.  0.  0.  3. 11.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6
  8  8  0 14  3  0  6  1  6  3  0  3 11  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 1. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0] -> size -> 24 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20 -30   0   0   0  -4   0   0   0   0] 
sum of rewards: -78 

action type: buy - action 0.0
Learning step: -3.8667972087860107
desired expected reward: -1.0743191242218018






Player: 1 
cards in hand: [0. 1. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 0. 6. 6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.  0.  0.  3. 11.  0.  3.  0.  8.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6
  8  8  0 14  3  0  6  1  6  3  0  3 11  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 0. 6. 6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.  0.  0.  3. 11.  0.  3.  0.  8.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6
  8  8  0 14  3  0  6  1  6  3  0  3 11  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 3.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 6. 6.] 
adversary cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.  0.  0.  3. 11.  0.  3.  0.  8.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6
  8  8  0 14  3  0  6  1  6  3  0  3 11  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[12.550505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 6.] 
cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.  0.  0.  3. 11.  0.  3.  0.  8.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6
  8  8  0 14  3  0  6  1  6  3  0  3 11  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [10.  0.  1.  3.  3.  3.] 
adversary owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0
 10] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -3.301673650741577
desired expected reward: 4.379521369934082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 5.832458 ]
 [ 7.6854405]
 [12.550512 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 6.] 
cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.  0.  0.  3. 11.  0.  3.  0.  8.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6
  8  8  0 14  3  0  6  1  6  3  0  3 11  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 12. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [10.  0.  1.  3.  3.  3.] 
adversary owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0
 10] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -3.599766254425049
desired expected reward: 8.950738906860352



buy possibilites: [-1] 
expected returns: [[0.7851186]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 6.] 
cards in discard: [10.  0.  3.  0.  8.  3.  0.  6.  3.  6.  6. 10.  6.  0.  1.  6.  0. 11.
 14.  0.  0.  0.  6.  0.  0.  3. 11.  0.  3.  0.  8.  3.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6
  8  8  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [10.  0.  1.  3.  3.  3.] 
adversary owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0
 10] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0  -5   0   0   8   0] 
sum of rewards: -50 

action type: buy - action 3.0
Learning step: -2.8666067123413086
desired expected reward: 4.8188300132751465






Player: 1 
cards in hand: [ 8.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10.  0.] 
cards in discard: [10.  0.  1.  3.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6
  8  8  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 40 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [10.  0.  1.  3.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0
 10] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6
  8  8  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 40 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [10.  0.  1.  3.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 26. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6
  8  8  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 40 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-3.130237]
 [-3.130237]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6
  8  8  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 3. 8. 0.] 
adversary cards in discard: [10.  0.  1.  3.  3.  3. 10.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0
 10] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -2.759686231613159
desired expected reward: -1.9745676517486572



action possibilites: [-1] 
expected returns: [[29.141766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 3. 8. 0.] 
adversary cards in discard: [10.  0.  1.  3.  3.  3. 10.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0
 10] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: trash_cards_n_from_hand - action 2
Learning step: -1.3877984285354614
desired expected reward: -4.518035411834717





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[28.419085]
 [32.77562 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 3. 8. 0.] 
adversary cards in discard: [10.  0.  1.  3.  3.  3. 10.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0
 10] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1
Learning step: -2.950455904006958
desired expected reward: 26.191308975219727






Player: 1 
cards in hand: [8. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 8. 0.] 
cards in discard: [10.  0.  1.  3.  3.  3. 10.  8.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 14.  0.  0.  0.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 38 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [10.  0.  1.  3.  3.  3. 10.  8.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 14.  0.  0.  0.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 38 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [10.  0.  1.  3.  3.  3. 10.  8.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 26. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 14.  0.  0.  0.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 38 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [10.  0.  1.  3.  3.  3. 10.  8.  0.  0.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 14.  0.  0.  0.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 38 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [10. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
expected returns: [[ 1.3503072]
 [-1.8905025]
 [-2.4622467]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  0.  0.  0.] 
cards in discard: [8. 0. 3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10.  0.  8. 11.  3.] 
adversary cards in discard: [10.  0.  1.  3.  3.  3. 10.  8.  0.  0.  0.  3.  0.  8.  3.  8.] 
adversary owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0] -> size -> 24 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: -4.841663837432861
desired expected reward: 27.933956146240234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-1.5643137]
 [-0.4934696]
 [-0.7753638]
 [ 1.3873634]
 [-0.5388864]
 [ 3.1562214]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  0.  0.  0.] 
cards in discard: [8. 0. 3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 26. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10.  0.  8. 11.  3.] 
adversary cards in discard: [10.  0.  1.  3.  3.  3. 10.  8.  0.  0.  0.  3.  0.  8.  3.  8.] 
adversary owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0] -> size -> 24 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -3.2383930683135986
desired expected reward: -1.8880877494812012



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  0.  8. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 11.  3.] 
cards in discard: [10.  0.  1.  3.  3.  3. 10.  8.  0.  0.  0.  3.  0.  8.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 38 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  3.] 
cards in discard: [10.  0.  1.  3.  3.  3. 10.  8.  0.  0.  0.  3.  0.  8.  3.  8.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 38 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  3.] 
cards in discard: [10.  0.  1.  3.  3.  3. 10.  8.  0.  0.  0.  3.  0.  8.  3.  8.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 25. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 38 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.96484]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0
  1] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: -2.8636021614074707
desired expected reward: 0.2926168441772461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[13.6123295]
 [14.470406 ]
 [18.08753  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 25. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0
  1] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -3.703707218170166
desired expected reward: 13.74653434753418



buy possibilites: [-1] 
expected returns: [[23.18932]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 25. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0
  1] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -60.   0.   0.   0. -30.   0.   0.   0.  -4.   0.   0.
   0.   0.] 
sum of rewards: -98.0 

action type: buy - action 0.0
Learning step: -5.058856964111328
desired expected reward: 8.553478240966797






Player: 1 
cards in hand: [ 3. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 11. 30.  8.  0. 10.  6.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3  0] -> size -> 39 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0
  1 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3  0] -> size -> 39 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0
  1 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3  0] -> size -> 39 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[9.049099]
 [5.989579]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 3.] 
cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8
  0 14  3  0  6  1  6  3  0  3 11  0  0  3  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 8. 8. 3.] 
adversary cards in discard: [11. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0
  1 11] -> size -> 26 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -4.177505016326904
desired expected reward: 19.01181411743164



action possibilites: [-1] 
expected returns: [[29.352468]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 8. 8. 3.] 
adversary cards in discard: [11. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0
  1 11] -> size -> 26 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: trash_cards_n_from_hand - action 6
Learning step: -1.7418521642684937
desired expected reward: 2.3038015365600586





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[25.089489]
 [27.604458]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 8. 8. 3.] 
adversary cards in discard: [11. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0
  1 11] -> size -> 26 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1
Learning step: -3.064314603805542
desired expected reward: 26.28815460205078



buy possibilites: [-1] 
expected returns: [[10.595863]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 8. 8. 3.] 
adversary cards in discard: [11. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0
  1 11] -> size -> 26 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20 -30   0   0   0  -3   0   0   0   0] 
sum of rewards: -77 

action type: buy - action 0.0
Learning step: -4.866067886352539
desired expected reward: 20.22342300415039






Player: 1 
cards in hand: [0. 3. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 8. 3.] 
cards in discard: [11. 11.  3.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  8  0  8  3  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0
  1 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0] -> size -> 38 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [11. 11.  3.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0] -> size -> 38 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [11. 11.  3.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0] -> size -> 38 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [11. 11.  3.  0.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0] -> size -> 38 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[11.197853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10.  3.  3.  1.] 
adversary cards in discard: [11. 11.  3.  0.  0.  3.  0.  8.  8.  3.] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -2.97784161567688
desired expected reward: 7.6180219650268555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 8.737524]
 [ 9.282788]
 [10.69705 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10.  3.  3.  1.] 
adversary cards in discard: [11. 11.  3.  0.  0.  3.  0.  8.  8.  3.] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -3.0351202487945557
desired expected reward: 8.16273307800293



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10. 10.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  3.  1.] 
cards in discard: [11. 11.  3.  0.  0.  3.  0.  8.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 1. 6. 6.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.
  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0] -> size -> 38 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  1.  0.] 
cards in discard: [11. 11.  3.  0.  0.  3.  0.  8.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 1. 6. 6.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.
  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0] -> size -> 38 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0. 8.] 
cards in discard: [11. 11.  3.  0.  0.  3.  0.  8.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0] -> size -> 25 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 1. 6. 6.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.
  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0] -> size -> 38 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 8.] 
cards in discard: [11. 11.  3.  0.  0.  3.  0.  8.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 1. 6. 6.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.
  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0] -> size -> 38 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 8.] 
cards in discard: [11. 11.  3.  0.  0.  3.  0.  8.  8.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 1. 6. 6.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.
  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0] -> size -> 38 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [6. 3. 1. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.354729]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 1. 6. 6.] 
cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.
  3.  0.  6.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [11. 11.  3.  0.  0.  3.  0.  8.  8.  3.  0. 10. 10.  3.  3.  1.  0.  8.] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0] -> size -> 26 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1.0
Learning step: -2.641871213912964
desired expected reward: 8.055180549621582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[16.501247]
 [19.135899]
 [25.941475]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 1. 6. 6.] 
cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.
  3.  0.  6.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [11. 11.  3.  0.  0.  3.  0.  8.  8.  3.  0. 10. 10.  3.  3.  1.  0.  8.] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0] -> size -> 26 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -3.5106704235076904
desired expected reward: 22.844058990478516



buy possibilites: [-1] 
expected returns: [[6.718872]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 1. 6. 6.] 
cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.
  3.  0.  6.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [11. 11.  3.  0.  0.  3.  0.  8.  8.  3.  0. 10. 10.  3.  3.  1.  0.  8.] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0] -> size -> 26 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -50.   0.   0.   0. -30.   0.   0.   0.  -4.   0.   0.
   0.   0.] 
sum of rewards: -88.0 

action type: buy - action 0.0
Learning step: -5.073887825012207
desired expected reward: 11.427359580993652






Player: 1 
cards in hand: [ 0. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [11. 11.  3.  0.  0.  3.  0.  8.  8.  3.  0. 10. 10.  3.  3.  1.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  6.  6.  0. 10.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.
  3.  0.  6.  3.  0.  0.  6.  3.  1.  6.  6.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11. 11.  3.  0.  0.  3.  0.  8.  8.  3.  0. 10. 10.  3.  3.  1.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  6.  6.  0. 10.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.
  3.  0.  6.  3.  0.  0.  6.  3.  1.  6.  6.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11. 11.  3.  0.  0.  3.  0.  8.  8.  3.  0. 10. 10.  3.  3.  1.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9. 10.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  6.  6.  0. 10.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.
  3.  0.  6.  3.  0.  0.  6.  3.  1.  6.  6.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11. 11.  3.  0.  0.  3.  0.  8.  8.  3.  0. 10. 10.  3.  3.  1.  0.  8.
 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  9.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  6.  6.  0. 10.] 
adversary cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.
  3.  0.  6.  3.  0.  0.  6.  3.  1.  6.  6.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[24.088093]
 [21.485996]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6.  0. 10.] 
cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.
  3.  0.  6.  3.  0.  0.  6.  3.  1.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  9.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29] -> size -> 27 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -2.512369155883789
desired expected reward: 4.206502914428711



action possibilites: [-1.] 
expected returns: [[19.680422]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.
  3.  0.  6.  3.  0.  0.  6.  3.  1.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  9.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29] -> size -> 27 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -33 

action type: take_action - action 10.0
Learning step: -2.2814900875091553
desired expected reward: 19.204500198364258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[15.078064]
 [16.370762]
 [19.680428]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [ 8.  0.  3. 10. 14.  0.  0.  0.  0.  3.  0.  0.  3.  3.  0.  8.  6.  3.
  3.  0.  6.  3.  0.  0.  6.  3.  1.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  9.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29] -> size -> 27 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -2.2785255908966064
desired expected reward: 17.40189552307129






Player: 1 
cards in hand: [0. 3. 0. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  9.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  9.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 8.] 
cards in discard: [29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[-3.1332047]
 [-3.1332047]
 [-3.1332047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  6. 11.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10.  3.  1.  8.  0.] 
adversary cards in discard: [29.  0.  3.  0.  1.  8.] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29] -> size -> 28 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1.0
Learning step: -3.7545182704925537
desired expected reward: 15.9259033203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-3.13798]
 [-3.13798]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  6. 11.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10.  3.  1.  8.  0.] 
adversary cards in discard: [29.  0.  3.  0.  1.  8.] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29] -> size -> 28 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -2.6137053966522217
desired expected reward: -5.75168514251709



buy possibilites: [-1] 
expected returns: [[-3.13798]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  6. 11.] 
cards in discard: [0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10.  3.  1.  8.  0.] 
adversary cards in discard: [29.  0.  3.  0.  1.  8.] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29] -> size -> 28 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -50.   0.   0.   0. -30.   0.   0.   0.  -5.   0.   0.
   0.   0.] 
sum of rewards: -89.0 

action type: buy - action 0.0
Learning step: -4.363706111907959
desired expected reward: -7.501686096191406






Player: 1 
cards in hand: [10.  3.  1.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1.  8.  0.] 
cards in discard: [29.  0.  3.  0.  1.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 11.  6. 11.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0] -> size -> 40 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 8. 0. 0.] 
cards in discard: [29.  0.  3.  0.  1.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 11.  6. 11.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0] -> size -> 40 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 8. 0. 0.] 
cards in discard: [29.  0.  3.  0.  1.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 11.  6. 11.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0] -> size -> 40 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 8. 0. 0.] 
cards in discard: [29.  0.  3.  0.  1.  8. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 11.  6. 11.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0] -> size -> 40 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-3.13798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 11.  6. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11. 11.  0.  0.  3.] 
adversary cards in discard: [29.  0.  3.  0.  1.  8. 29. 10.  3.  1.  8.  0.  0.] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29 29] -> size -> 29 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -2.6137053966522217
desired expected reward: -5.75168514251709





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-3.13798]
 [-3.13798]
 [-3.13798]
 [-3.13798]
 [-3.13798]
 [-3.13798]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 11.  6. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11. 11.  0.  0.  3.] 
adversary cards in discard: [29.  0.  3.  0.  1.  8. 29. 10.  3.  1.  8.  0.  0.] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29 29] -> size -> 29 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -2.6137053966522217
desired expected reward: -5.75168514251709



buy possibilites: [-1] 
expected returns: [[-3.13798]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 11.  6. 11. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [11. 11.  0.  0.  3.] 
adversary cards in discard: [29.  0.  3.  0.  1.  8. 29. 10.  3.  1.  8.  0.  0.] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29 29] -> size -> 29 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0  -6   0   0  18   0] 
sum of rewards: -42 

action type: buy - action 10.0
Learning step: -2.0137054920196533
desired expected reward: -5.15168571472168






Player: 1 
cards in hand: [11. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  0.  3.] 
cards in discard: [29.  0.  3.  0.  1.  8. 29. 10.  3.  1.  8.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10] -> size -> 41 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  0.  3.] 
cards in discard: [29.  0.  3.  0.  1.  8. 29. 10.  3.  1.  8.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 25. 30. 11. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10] -> size -> 41 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  0.  3.] 
cards in discard: [29.  0.  3.  0.  1.  8. 29. 10.  3.  1.  8.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29 29  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10] -> size -> 41 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [6. 6. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-1.9111801]
 [-2.6702607]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 8. 0.] 
cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [29.  8.  3.  0.  3.] 
adversary cards in discard: [29.  0.  3.  0.  1.  8. 29. 10.  3.  1.  8.  0.  0.  3. 11. 11.  0.  0.
  3.] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29 29  3] -> size -> 30 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -3.0914723873138428
desired expected reward: -6.229452133178711





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-3.0992846]
 [-2.3480046]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 8. 0.] 
cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [29.  8.  3.  0.  3.] 
adversary cards in discard: [29.  0.  3.  0.  1.  8. 29. 10.  3.  1.  8.  0.  0.  3. 11. 11.  0.  0.
  3.] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29 29  3] -> size -> 30 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -3.162585973739624
desired expected reward: -5.073765754699707



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  8.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3.  0.  3.] 
cards in discard: [29.  0.  3.  0.  1.  8. 29. 10.  3.  1.  8.  0.  0.  3. 11. 11.  0.  0.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29 29  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.  6.  6.  6.  8.  0.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10] -> size -> 41 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  3.  0.  3.] 
cards in discard: [29.  0.  3.  0.  1.  8. 29. 10.  3.  1.  8.  0.  0.  3. 11. 11.  0.  0.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29 29  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.  6.  6.  6.  8.  0.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10] -> size -> 41 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  3.  0.  3.] 
cards in discard: [29.  0.  3.  0.  1.  8. 29. 10.  3.  1.  8.  0.  0.  3. 11. 11.  0.  0.
  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29 29  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.  6.  6.  6.  8.  0.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10] -> size -> 41 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-3.13798]
 [-3.13798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.  6.  6.  6.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10.  8.  3.  0. 10.] 
adversary cards in discard: [29.  0.  3.  0.  1.  8. 29. 10.  3.  1.  8.  0.  0.  3. 11. 11.  0.  0.
  3.  0. 29.  8.  3.  0.  3.] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29 29  3  0] -> size -> 31 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: -3.1532046794891357
desired expected reward: -5.501209735870361





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-3.13798]
 [-3.13798]
 [-3.13798]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.  6.  6.  6.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10.  8.  3.  0. 10.] 
adversary cards in discard: [29.  0.  3.  0.  1.  8. 29. 10.  3.  1.  8.  0.  0.  3. 11. 11.  0.  0.
  3.  0. 29.  8.  3.  0.  3.] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29 29  3  0] -> size -> 31 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -3.113705635070801
desired expected reward: -6.251685619354248



buy possibilites: [-1] 
expected returns: [[-1.3386327]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.  6.  6.  6.  8.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10.  8.  3.  0. 10.] 
adversary cards in discard: [29.  0.  3.  0.  1.  8. 29. 10.  3.  1.  8.  0.  0.  3. 11. 11.  0.  0.
  3.  0. 29.  8.  3.  0.  3.] 
adversary owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29 29  3  0] -> size -> 31 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -60.   0.   0.   0. -30.   0.   0.   0.  -7.   0.   0.
   0.   0.] 
sum of rewards: -101.0 

action type: buy - action 0.0
Learning step: -4.923220634460449
desired expected reward: -8.061201095581055






Player: 1 
cards in hand: [10.  8.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  0. 10.] 
cards in discard: [29.  0.  3.  0.  1.  8. 29. 10.  3.  1.  8.  0.  0.  3. 11. 11.  0.  0.
  3.  0. 29.  8.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  3  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11
  0  0 29 29 29  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  3.] 
adversary cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.  6.  6.  6.  8.  0.  0.
  0.  3.  3.  8.  0.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10  0] -> size -> 42 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [29.  0.  3.  0.  1.  8. 29. 10.  3.  1.  8.  0.  0.  3. 11. 11.  0.  0.
  3.  0. 29.  8.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11  0  0 29
 29 29  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  3.] 
adversary cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.  6.  6.  6.  8.  0.  0.
  0.  3.  3.  8.  0.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10  0] -> size -> 42 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [29.  0.  3.  0.  1.  8. 29. 10.  3.  1.  8.  0.  0.  3. 11. 11.  0.  0.
  3.  0. 29.  8.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11  0  0 29
 29 29  3  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  3.] 
adversary cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.  6.  6.  6.  8.  0.  0.
  0.  3.  3.  8.  0.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10  0] -> size -> 42 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-3.1038625]
 [-3.13798  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  3.] 
cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.  6.  6.  6.  8.  0.  0.
  0.  3.  3.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11  0  0 29
 29 29  3  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -2.7031466960906982
desired expected reward: -4.041779518127441





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-3.13798  ]
 [-3.13798  ]
 [-1.7986552]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  3.] 
cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.  6.  6.  6.  8.  0.  0.
  0.  3.  3.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11  0  0 29
 29 29  3  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -2.597909688949585
desired expected reward: -5.701772689819336



buy possibilites: [-1] 
expected returns: [[-3.13798]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  3.] 
cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.  6.  6.  6.  8.  0.  0.
  0.  3.  3.  8.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11  0  0 29
 29 29  3  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -50.   0.   0.   0. -30.   0.   0.   0.  -8.   0.   0.
   0.   0.] 
sum of rewards: -92.0 

action type: buy - action 0.0
Learning step: -4.513705730438232
desired expected reward: -7.65168571472168






Player: 1 
cards in hand: [ 3.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11  0  0 29
 29 29  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.  6.  6.  6.  8.  0.  0.
  0.  3.  3.  8.  0.  0.  0. 10.  0.  3.  3.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10  0  0] -> size -> 43 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11  0  0 29
 29 29  3  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.  6.  6.  6.  8.  0.  0.
  0.  3.  3.  8.  0.  0.  0. 10.  0.  3.  3.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10  0  0] -> size -> 43 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11  0  0 29
 29 29  3  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.  6.  6.  6.  8.  0.  0.
  0.  3.  3.  8.  0.  0.  0. 10.  0.  3.  3.] 
adversary owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10  0  0] -> size -> 43 
adversary victory points: 1
player victory points: 6 


Player 1 won the game! 



Player 0 bought cards:
Copper: 14 
Silver: 1 
Gold: 0 
Estate: 7 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 0 
Workshop: 2 
Chapel: 3 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [6. 0. 6. 6. 0.] 
cards in discard: [ 0.  3.  0. 11.  6. 11. 10.  3.  3.  0.  0.  0.  6.  6.  6.  8.  0.  0.
  0.  3.  3.  8.  0.  0.  0. 10.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10  3  6  0  6  6  0  3  0  6  6 10  0  3  0  6  8  8  0 14
  3  0  6  1  6  3  0  3 11  0  0  3  0  0  0  0 10  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 10. 30.  8.  0. 10.  5.  0.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 8.] 
adversary cards in discard: [0.] 
adversary owned cards: [ 8  8  8  3  0  0  3 11  3  0  1 10  8  3  0  3  0 10  0  1 11  0  0 29
 29 29  3  0  0] -> size -> 29 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5 -500    1  -50    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -554 

action type: buy - action -1
Learning step: -27.543100357055664
desired expected reward: -30.681079864501953



