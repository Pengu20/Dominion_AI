 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[53.084167]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 10.449736595153809
desired expected reward: -99.0476303100586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[52.04417 ]
 [79.2867  ]
 [70.71639 ]
 [35.378242]
 [86.85807 ]
 [66.47596 ]
 [58.569206]
 [51.31829 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 52.895668029785156



buy possibilites: [-1] 
expected returns: [[36.337124]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 86.85809326171875






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3.  3.  0.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[50.419846]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.33712387084961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[49.09346 ]
 [73.39354 ]
 [65.44069 ]
 [34.88498 ]
 [61.604477]
 [80.44355 ]
 [61.693336]
 [93.4685  ]
 [46.63182 ]
 [54.92013 ]
 [70.0618  ]
 [49.41515 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 49.807762145996094



buy possibilites: [-1] 
expected returns: [[18.991047]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 93.46849822998047






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[41.564934]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.991046905517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[42.721664]
 [63.822983]
 [57.546078]
 [34.796562]
 [29.01648 ]
 [54.38058 ]
 [69.2708  ]
 [54.420822]
 [89.92905 ]
 [80.4527  ]
 [40.150978]
 [61.170692]
 [48.14392 ]
 [40.06938 ]
 [61.21093 ]
 [42.121696]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 41.16057205200195



buy possibilites: [-1] 
expected returns: [[19.571075]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 215 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 89.9290542602539






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  3. 11.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  3. 11.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  3. 11.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3. 3. 0. 0. 0. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  3. 11.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3.  3.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[28.134048]
 [54.778   ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  3. 11.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.571075439453125



action possibilites: [-1] 
expected returns: [[29.16029]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 62.800682067871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.81467 ]
 [17.70581 ]
 [29.314163]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.160289764404297






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3. 11. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[-0.889935 ]
 [12.987561 ]
 [ 1.2761278]
 [17.845112 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 29.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [ 1.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.314159393310547



action possibilites: [-1. 11. 10.] 
expected returns: [[ 4.5763617]
 [24.463741 ]
 [ 8.521937 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [ 1.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 16.381607055664062



action possibilites: [-1] 
expected returns: [[10.317512]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [ 1.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 29.36083984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[10.008781 ]
 [24.445107 ]
 [20.06203  ]
 [ 1.2403216]
 [28.763004 ]
 [17.716873 ]
 [13.840358 ]
 [10.777318 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [ 1.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.317511558532715



buy possibilites: [-1] 
expected returns: [[7.0162926]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [ 1.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 28.76300811767578






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [ 1.  3.  0.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0.  3.] 
adversary cards in discard: [10. 11. 29. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [ 1.  3.  0.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0.  3.] 
adversary cards in discard: [10. 11. 29. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [ 1.  3.  0.  0. 10.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0.  3.] 
adversary cards in discard: [10. 11. 29. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 8.322119]
 [41.028675]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  0.  3.] 
cards in discard: [10. 11. 29. 11.  3. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.016292572021484



action possibilites: [-1] 
expected returns: [[26.710506]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0. 0.] 
cards in discard: [10. 11. 29. 11.  3. 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7. 10.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 37.09039306640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[34.058052]
 [54.864166]
 [48.122322]
 [27.25729 ]
 [22.080269]
 [45.381077]
 [60.547447]
 [45.301926]
 [81.49546 ]
 [71.901146]
 [31.745483]
 [52.035664]
 [39.5207  ]
 [31.640575]
 [51.848465]
 [33.32691 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0. 0.] 
cards in discard: [10. 11. 29. 11.  3. 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7. 10.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.710506439208984



buy possibilites: [-1] 
expected returns: [[33.027878]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0. 0.] 
cards in discard: [10. 11. 29. 11.  3. 10.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 81.49546813964844






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [6. 0. 1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 1.9407558]
 [24.375599 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [ 6.  0.  1. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.02787780761719



action possibilites: [-1. 10.] 
expected returns: [[ 9.583702]
 [12.816052]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 29. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [ 6.  0.  1. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 22.874561309814453



action possibilites: [-1.] 
expected returns: [[15.985753]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25] -> size -> 17 
action values: 2 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 29. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [ 6.  0.  1. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 12.816060066223145





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.472809 ]
 [37.64301  ]
 [31.778076 ]
 [ 7.0739717]
 [43.052853 ]
 [28.869968 ]
 [23.450111 ]
 [18.36827  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 29. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [ 6.  0.  1. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 15.985753059387207



buy possibilites: [-1] 
expected returns: [[20.13266]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10.  6. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [ 6.  0.  1. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 43.05286407470703






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [ 6.  0.  1. 11.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10.  6. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 11.  0. 11. 10.] 
adversary cards in discard: [11. 29. 10.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [ 6.  0.  1. 11.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 27. 30. 29. 30.  8.  9. 10.  6. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 11.  0. 11. 10.] 
adversary cards in discard: [11. 29. 10.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 11.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11. 10.] 
expected returns: [[ 4.287734]
 [29.500965]
 [17.13107 ]
 [17.13107 ]
 [ 6.306342]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0. 11. 10.] 
cards in discard: [11. 29. 10.  3.  0.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10.  6. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  3. 10.  0.  3.] 
adversary cards in discard: [ 6.  0.  1. 11.  3.  0.  0.  0.  0.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.132659912109375



action possibilites: [-1] 
expected returns: [[27.655369]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 10.  0.  0.] 
cards in discard: [11. 29. 10.  3.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  8. 10.  6. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  3. 10.  0.  3.] 
adversary cards in discard: [ 6.  0.  1. 11.  3.  0.  0.  0.  0.  3.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 23.301551818847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[27.134682]
 [42.02945 ]
 [37.988953]
 [17.999153]
 [46.273148]
 [35.56455 ]
 [31.502163]
 [28.402367]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11. 10.  0.  0.] 
cards in discard: [11. 29. 10.  3.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 29. 30.  8.  8. 10.  6. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  3. 10.  0.  3.] 
adversary cards in discard: [ 6.  0.  1. 11.  3.  0.  0.  0.  0.  3.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.65536880493164



buy possibilites: [-1] 
expected returns: [[45.409573]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11. 10.  0.  0.] 
cards in discard: [11. 29. 10.  3.  0.  0.  3.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  8. 10.  5. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  3. 10.  0.  3.] 
adversary cards in discard: [ 6.  0.  1. 11.  3.  0.  0.  0.  0.  3.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 46.273155212402344






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 1.  3. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10.  0.  3.] 
cards in discard: [ 6.  0.  1. 11.  3.  0.  0.  0.  0.  3.  0.  1.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  8. 10.  5. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 29. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  0.  3.] 
cards in discard: [ 6.  0.  1. 11.  3.  0.  0.  0.  0.  3.  0.  1.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 29. 30.  8.  8. 10.  5. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 29. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  0.  3.] 
cards in discard: [ 6.  0.  1. 11.  3.  0.  0.  0.  0.  3.  0.  1.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  5. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 29. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10. 29. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 25.] 
expected returns: [[-9.30209  ]
 [-9.190283 ]
 [ 2.98777  ]
 [ 7.0373926]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  5. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 45.40957260131836



action possibilites: [-1] 
expected returns: [[7.9595385]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  7. 10.  5. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 6.057723045349121





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[12.509671 ]
 [28.372696 ]
 [23.821453 ]
 [ 3.5557919]
 [33.377403 ]
 [21.210018 ]
 [16.658775 ]
 [13.171365 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  7. 10.  5. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.959538459777832



buy possibilites: [-1] 
expected returns: [[17.056305]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0.  0.  3.  0.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  7. 10.  4. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 33.377410888671875






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  7. 10.  4. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 25. 11.] 
adversary cards in discard: [11. 25. 10. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11] -> size -> 20 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  7. 10.  4. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 25. 11.] 
adversary cards in discard: [11. 25. 10. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11] -> size -> 20 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [6. 8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  7. 10.  4.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 25. 11.] 
adversary cards in discard: [11. 25. 10. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11] -> size -> 20 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 11.  0. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 11.] 
expected returns: [[ 4.207782]
 [17.411282]
 [26.780003]
 [17.411282]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 25. 11.] 
cards in discard: [11. 25. 10. 29.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  7. 10.  4.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  3. 11.] 
adversary cards in discard: [6. 8. 0. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.056304931640625



action possibilites: [-1] 
expected returns: [[19.711369]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 11.  3.  0.] 
cards in discard: [11. 25. 10. 29.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  6. 10.  4.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  3. 11.] 
adversary cards in discard: [6. 8. 0. 6. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 23.286766052246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[16.271023]
 [27.098568]
 [24.52211 ]
 [ 9.021105]
 [30.21257 ]
 [22.424572]
 [19.854534]
 [19.282063]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 11.  3.  0.] 
cards in discard: [11. 25. 10. 29.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  6. 10.  4.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  3. 11.] 
adversary cards in discard: [6. 8. 0. 6. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.711368560791016



buy possibilites: [-1] 
expected returns: [[10.910856]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 11.  3.  0.] 
cards in discard: [11. 25. 10. 29.  0.  0.  3.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  6. 10.  3.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  3. 11.] 
adversary cards in discard: [6. 8. 0. 6. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 30.212574005126953






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  3. 11.] 
cards in discard: [6. 8. 0. 6. 0. 3. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  6. 10.  3.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 11.  3. 10.] 
adversary cards in discard: [11. 25. 10. 29.  0.  0.  3.  0. 11. 25.  0. 11.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11] -> size -> 21 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 11.  0.] 
cards in discard: [6. 8. 0. 6. 0. 3. 0. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  6. 10.  3.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 11.  3. 10.] 
adversary cards in discard: [11. 25. 10. 29.  0.  0.  3.  0. 11. 25.  0. 11.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11] -> size -> 21 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 11.  0.] 
cards in discard: [6. 8. 0. 6. 0. 3. 0. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8.  6. 10.  3.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 11.  3. 10.] 
adversary cards in discard: [11. 25. 10. 29.  0.  0.  3.  0. 11. 25.  0. 11.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11] -> size -> 21 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 11.  0.] 
cards in discard: [6. 8. 0. 6. 0. 3. 0. 6. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 11.  3. 10.] 
adversary cards in discard: [11. 25. 10. 29.  0.  0.  3.  0. 11. 25.  0. 11.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11] -> size -> 21 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11.  0. 11.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[27.027405]
 [36.08526 ]
 [36.08526 ]
 [20.802029]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  3. 10.] 
cards in discard: [11. 25. 10. 29.  0.  0.  3.  0. 11. 25.  0. 11.  0. 11.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 1. 0. 0. 3.] 
adversary cards in discard: [ 6.  8.  0.  6.  0.  3.  0.  6.  3. 10.  0.  6.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.910856246948242



action possibilites: [-1] 
expected returns: [[10.999566]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 10.] 
cards in discard: [11. 25. 10. 29.  0.  0.  3.  0. 11. 25.  0. 11.  0. 11.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [1. 1. 0. 0. 3.] 
adversary cards in discard: [ 6.  8.  0.  6.  0.  3.  0.  6.  3. 10.  0.  6.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 38.473167419433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 4.396182 ]
 [-5.9966803]
 [11.267028 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3. 10.] 
cards in discard: [11. 25. 10. 29.  0.  0.  3.  0. 11. 25.  0. 11.  0. 11.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [1. 1. 0. 0. 3.] 
adversary cards in discard: [ 6.  8.  0.  6.  0.  3.  0.  6.  3. 10.  0.  6.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.999566078186035






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [1. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 0. 3.] 
cards in discard: [ 6.  8.  0.  6.  0.  3.  0.  6.  3. 10.  0.  6.  3. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 11.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10] -> size -> 22 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 3.] 
cards in discard: [ 6.  8.  0.  6.  0.  3.  0.  6.  3. 10.  0.  6.  3. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 11.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10] -> size -> 22 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 3.] 
cards in discard: [ 6.  8.  0.  6.  0.  3.  0.  6.  3. 10.  0.  6.  3. 11.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 27. 30. 27. 30.  8.  6. 10.  3.  9.  8.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 11.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10] -> size -> 22 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [11. 11.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[17.601246]
 [37.730164]
 [37.730164]
 [20.423195]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  6. 10.  3.  9.  8.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [6. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3
  3] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 11.267012596130371



action possibilites: [-1] 
expected returns: [[4.5890207]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  6. 10.  3.  9.  8.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3
  3] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 33.13983917236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[6.56138897e+00]
 [1.50763445e+01]
 [4.55164909e-03]
 [1.28982859e+01]
 [8.31920338e+00]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 10.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 27. 30.  8.  6. 10.  3.  9.  8.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3
  3] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.589020729064941



buy possibilites: [-1] 
expected returns: [[9.231537]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 10.] 
cards in discard: [10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  6. 10.  3.  9.  8.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3
  3] -> size -> 25 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 15.076348304748535






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [6. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  6. 10.  3.  9.  8.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29. 25.] 
adversary cards in discard: [10.  3. 11. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3] -> size -> 24 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 26. 30.  8.  6. 10.  3.  9.  8.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29. 25.] 
adversary cards in discard: [10.  3. 11. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3] -> size -> 24 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 1. 0.] 
cards in discard: [8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3
  3  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 26. 30.  8.  6. 10.  3.  8.  8.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29. 25.] 
adversary cards in discard: [10.  3. 11. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3] -> size -> 24 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [11.  0.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25.] 
expected returns: [[24.023605]
 [37.346107]
 [40.79914 ]
 [50.138664]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29. 25.] 
cards in discard: [10.  3. 11. 11.  0.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  6. 10.  3.  8.  8.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  8. 11.] 
adversary cards in discard: [8. 6. 3. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3
  3  8] -> size -> 26 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.231536865234375



action possibilites: [-1] 
expected returns: [[9.796238]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29. 11.  3.] 
cards in discard: [10.  3. 11. 11.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  5. 10.  3.  8.  8.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  8. 11.] 
adversary cards in discard: [8. 6. 3. 0. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3
  3  8  6] -> size -> 27 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 52.0472297668457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 5.9308205]
 [10.58201  ]
 [ 1.7182536]
 [ 8.700494 ]
 [12.867269 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 29. 11.  3.] 
cards in discard: [10.  3. 11. 11.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 26. 30.  8.  5. 10.  3.  8.  8.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  8. 11.] 
adversary cards in discard: [8. 6. 3. 0. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3
  3  8  6] -> size -> 27 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.79623794555664






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  8. 11.] 
cards in discard: [8. 6. 3. 0. 1. 0. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  1 11  6  0  1  6  0  6  8  6  3
  3  8  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  5. 10.  3.  8.  8.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  0. 11.] 
adversary cards in discard: [10.  3. 11. 11.  0.  0. 10. 25. 11.  0.  0. 29. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3] -> size -> 24 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [8. 6. 3. 0. 1. 0. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  5. 10.  3.  8.  8.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  0. 11.] 
adversary cards in discard: [10.  3. 11. 11.  0.  0. 10. 25. 11.  0.  0. 29. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3] -> size -> 24 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8. 6. 3. 0. 1. 0. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  5. 10.  3.  8.  8.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  0. 11.] 
adversary cards in discard: [10.  3. 11. 11.  0.  0. 10. 25. 11.  0.  0. 29. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3] -> size -> 24 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 3. 11. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[25.821777]
 [27.056496]
 [21.767464]
 [27.056496]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  0. 11.] 
cards in discard: [10.  3. 11. 11.  0.  0. 10. 25. 11.  0.  0. 29. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  5. 10.  3.  8.  8.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 0. 6. 3.] 
adversary cards in discard: [8. 6. 3. 0. 1. 0. 6. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 12.86727237701416



action possibilites: [-1] 
expected returns: [[23.662308]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 11.] 
cards in discard: [10.  3. 11. 11.  0.  0. 10. 25. 11.  0.  0. 29. 11.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  5. 10.  3.  8.  8.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [6. 6. 0. 6. 3.] 
adversary cards in discard: [8. 6. 3. 0. 1. 0. 6. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 27.48763656616211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.24096 ]
 [10.333005]
 [24.468655]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 11.] 
cards in discard: [10.  3. 11. 11.  0.  0. 10. 25. 11.  0.  0. 29. 11.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 26. 30.  8.  5. 10.  3.  8.  8.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [6. 6. 0. 6. 3.] 
adversary cards in discard: [8. 6. 3. 0. 1. 0. 6. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.662307739257812






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [6. 6. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6. 3.] 
cards in discard: [8. 6. 3. 0. 1. 0. 6. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  5. 10.  3.  8.  8.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 25.  0.] 
adversary cards in discard: [10.  3. 11. 11.  0.  0. 10. 25. 11.  0.  0. 29. 11.  3. 10. 11.  3. 10.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10] -> size -> 25 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 3.] 
cards in discard: [8. 6. 3. 0. 1. 0. 6. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 26. 30.  8.  5. 10.  3.  8.  8.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 25.  0.] 
adversary cards in discard: [10.  3. 11. 11.  0.  0. 10. 25. 11.  0.  0. 29. 11.  3. 10. 11.  3. 10.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10] -> size -> 25 
adversary victory points: 4
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  0. 10. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[49.50071 ]
 [46.512787]
 [62.350746]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 25.  0.] 
cards in discard: [10.  3. 11. 11.  0.  0. 10. 25. 11.  0.  0. 29. 11.  3. 10. 11.  3. 10.
  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  5. 10.  3.  8.  8.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [8. 6. 3. 0. 1. 0. 6. 8. 6. 6. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 24.46865463256836



action possibilites: [-1] 
expected returns: [[12.321862]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  4. 10.  3.  8.  8.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [8. 6. 3. 0. 1. 0. 6. 8. 6. 6. 0. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 62.35076141357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.497086]
 [39.133465]
 [33.68345 ]
 [ 5.416708]
 [43.94146 ]
 [30.562939]
 [24.610802]
 [20.049984]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 26. 30.  8.  4. 10.  3.  8.  8.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [8. 6. 3. 0. 1. 0. 6. 8. 6. 6. 0. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.32186222076416



buy possibilites: [-1] 
expected returns: [[18.25938]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.  3.] 
cards in discard: [11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  4. 10.  2.  8.  8.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [8. 6. 3. 0. 1. 0. 6. 8. 6. 6. 0. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 43.94145965576172






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [0. 1. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [8. 6. 3. 0. 1. 0. 6. 8. 6. 6. 0. 6. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  4. 10.  2.  8.  8.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11. 11.] 
adversary cards in discard: [11. 25.  3.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [8. 6. 3. 0. 1. 0. 6. 8. 6. 6. 0. 6. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 26. 30.  8.  4. 10.  2.  8.  8.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11. 11.] 
adversary cards in discard: [11. 25.  3.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [8. 6. 3. 0. 1. 0. 6. 8. 6. 6. 0. 6. 3. 6. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 26. 30.  8.  4. 10.  2.  7.  8.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11. 11.] 
adversary cards in discard: [11. 25.  3.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 0. 10. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 11.] 
expected returns: [[33.576748]
 [30.143223]
 [49.22512 ]
 [49.22512 ]
 [49.22512 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11. 11.] 
cards in discard: [11. 25.  3.  0. 10.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  4. 10.  2.  7.  8.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 10.] 
adversary cards in discard: [8. 6. 3. 0. 1. 0. 6. 8. 6. 6. 0. 6. 3. 6. 8. 0. 1. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.259380340576172



action possibilites: [-1] 
expected returns: [[54.620132]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11.] 
cards in discard: [11. 25.  3.  0. 10.  0.  0.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  4. 10.  2.  7.  8.  9. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 10.] 
adversary cards in discard: [8. 6. 3. 0. 1. 0. 6. 8. 6. 6. 0. 6. 3. 6. 8. 0. 1. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 53.084129333496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[40.218094]
 [29.993828]
 [55.36042 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 11.] 
cards in discard: [11. 25.  3.  0. 10.  0.  0.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 26. 30.  8.  4. 10.  2.  7.  8.  9. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 10.] 
adversary cards in discard: [8. 6. 3. 0. 1. 0. 6. 8. 6. 6. 0. 6. 3. 6. 8. 0. 1. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 54.62013244628906






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 10.] 
cards in discard: [8. 6. 3. 0. 1. 0. 6. 8. 6. 6. 0. 6. 3. 6. 8. 0. 1. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  4. 10.  2.  7.  8.  9. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 11.  0. 10.] 
adversary cards in discard: [11. 25.  3.  0. 10.  0.  0.  3. 10. 11.  0. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10] -> size -> 27 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  4. 10.  2.  7.  8.  9. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 11.  0. 10.] 
adversary cards in discard: [11. 25.  3.  0. 10.  0.  0.  3. 10. 11.  0. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10] -> size -> 27 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 26. 30.  8.  4. 10.  2.  7.  8.  9. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 11.  0. 10.] 
adversary cards in discard: [11. 25.  3.  0. 10.  0.  0.  3. 10. 11.  0. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10] -> size -> 27 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  4. 10.  2.  7.  8.  9. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 11.  0. 10.] 
adversary cards in discard: [11. 25.  3.  0. 10.  0.  0.  3. 10. 11.  0. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10] -> size -> 27 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [10.  0. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[39.82021 ]
 [34.917866]
 [44.27555 ]
 [34.917866]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  0. 10.] 
cards in discard: [11. 25.  3.  0. 10.  0.  0.  3. 10. 11.  0. 10. 11. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  4. 10.  2.  7.  8.  9. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 3. 10.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3] -> size -> 26 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 55.36040496826172



action possibilites: [-1] 
expected returns: [[77.74846]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [11. 25.  3.  0. 10.  0.  0.  3. 10. 11.  0. 10. 11. 11. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  4. 10.  2.  7.  8.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 3. 10.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3] -> size -> 26 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 45.028995513916016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[60.446983]
 [69.9665  ]
 [54.922157]
 [66.86113 ]
 [73.04601 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [11. 25.  3.  0. 10.  0.  0.  3. 10. 11.  0. 10. 11. 11. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 25. 30.  8.  4. 10.  2.  7.  8.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 3. 10.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3] -> size -> 26 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 77.74845886230469






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [ 3. 10.  3.  0.  3.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  4. 10.  2.  7.  8.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 25.  3.  3. 11.] 
adversary cards in discard: [11. 25.  3.  0. 10.  0.  0.  3. 10. 11.  0. 10. 11. 11. 10. 11. 10.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10] -> size -> 28 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [ 3. 10.  3.  0.  3.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 25. 30.  8.  4. 10.  2.  7.  8.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 25.  3.  3. 11.] 
adversary cards in discard: [11. 25.  3.  0. 10.  0.  0.  3. 10. 11.  0. 10. 11. 11. 10. 11. 10.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10] -> size -> 28 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [ 3. 10.  3.  0.  3.  0.  3.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  4. 10.  2.  6.  8.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 25.  3.  3. 11.] 
adversary cards in discard: [11. 25.  3.  0. 10.  0.  0.  3. 10. 11.  0. 10. 11. 11. 10. 11. 10.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10] -> size -> 28 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [11. 25.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 11.] 
expected returns: [[38.558136]
 [59.314774]
 [71.73717 ]
 [59.314774]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  3.  3. 11.] 
cards in discard: [11. 25.  3.  0. 10.  0.  0.  3. 10. 11.  0. 10. 11. 11. 10. 11. 10.  0.
  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  4. 10.  2.  6.  8.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [6. 0. 6. 1. 6.] 
adversary cards in discard: [ 3. 10.  3.  0.  3.  0.  3.  8.  8.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3  8] -> size -> 27 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 73.04600524902344



action possibilites: [-1] 
expected returns: [[131.3949]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3. 11.  0. 10.] 
cards in discard: [11. 25.  3.  0. 10.  0.  0.  3. 10. 11.  0. 10. 11. 11. 10. 11. 10.  0.
  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  3. 10.  2.  6.  8.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [6. 0. 6. 1. 6.] 
adversary cards in discard: [ 3. 10.  3.  0.  3.  0.  3.  8.  8.  0.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3  8  6] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 71.7371826171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[123.465935]
 [104.68715 ]
 [128.18372 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3. 11.  0. 10.] 
cards in discard: [11. 25.  3.  0. 10.  0.  0.  3. 10. 11.  0. 10. 11. 11. 10. 11. 10.  0.
  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 25. 30.  8.  3. 10.  2.  6.  8.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [6. 0. 6. 1. 6.] 
adversary cards in discard: [ 3. 10.  3.  0.  3.  0.  3.  8.  8.  0.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3  8  6] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 131.3948974609375






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [6. 0. 6. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 1. 6.] 
cards in discard: [ 3. 10.  3.  0.  3.  0.  3.  8.  8.  0.  3.  0.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3  8  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  3. 10.  2.  6.  8.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [10. 10. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10] -> size -> 28 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 1. 6.] 
cards in discard: [ 3. 10.  3.  0.  3.  0.  3.  8.  8.  0.  3.  0.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3  8  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 25. 30.  8.  3. 10.  2.  6.  8.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [10. 10. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10] -> size -> 28 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 1. 6.] 
cards in discard: [ 3. 10.  3.  0.  3.  0.  3.  8.  8.  0.  3.  0.  3.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3  8  6  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 24. 30.  8.  3. 10.  2.  6.  8.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [10. 10. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10] -> size -> 28 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [10. 10. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 29.] 
expected returns: [[60.811287]
 [51.14907 ]
 [51.14907 ]
 [61.45408 ]
 [61.164368]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.  0. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 24. 30.  8.  3. 10.  2.  6.  8.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [0. 1. 6. 6. 0.] 
adversary cards in discard: [ 3. 10.  3.  0.  3.  0.  3.  8.  8.  0.  3.  0.  3.  6.  3.  6.  0.  6.
  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3  8  6  3] -> size -> 29 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 128.1837158203125



action possibilites: [-1] 
expected returns: [[50.1055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 29.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 24. 30.  8.  3. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [0. 1. 6. 6. 0.] 
adversary cards in discard: [ 3. 10.  3.  0.  3.  0.  3.  8.  8.  0.  3.  0.  3.  6.  3.  6.  0.  6.
  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3  8  6  3] -> size -> 29 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 64.85832214355469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[36.706802]
 [30.915733]
 [52.63684 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 29.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 24. 30.  8.  3. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [0. 1. 6. 6. 0.] 
adversary cards in discard: [ 3. 10.  3.  0.  3.  0.  3.  8.  8.  0.  3.  0.  3.  6.  3.  6.  0.  6.
  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3  8  6  3] -> size -> 29 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.105499267578125






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [0. 1. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 6. 0.] 
cards in discard: [ 3. 10.  3.  0.  3.  0.  3.  8.  8.  0.  3.  0.  3.  6.  3.  6.  0.  6.
  1.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3  8  6  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 24. 30.  8.  3. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 11. 10. 25. 10.] 
adversary cards in discard: [10. 11. 10. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10] -> size -> 29 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 6. 0.] 
cards in discard: [ 3. 10.  3.  0.  3.  0.  3.  8.  8.  0.  3.  0.  3.  6.  3.  6.  0.  6.
  1.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3  8  6  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 24. 30.  8.  3. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 11. 10. 25. 10.] 
adversary cards in discard: [10. 11. 10. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10] -> size -> 29 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 6. 0.] 
cards in discard: [ 3. 10.  3.  0.  3.  0.  3.  8.  8.  0.  3.  0.  3.  6.  3.  6.  0.  6.
  1.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3  8  6  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 27. 30. 24. 30.  8.  3. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 11. 10. 25. 10.] 
adversary cards in discard: [10. 11. 10. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10] -> size -> 29 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 0. 11. 10. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 25. 10.] 
expected returns: [[15.807494]
 [39.292694]
 [12.642447]
 [58.393658]
 [12.642447]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 25. 10.] 
cards in discard: [10. 11. 10. 10.  0. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  3. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [0. 3. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3  8  6  3  0] -> size -> 30 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 52.63684844970703



action possibilites: [-1] 
expected returns: [[42.04769]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 10. 11.  3.] 
cards in discard: [10. 11. 10. 10.  0. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  2. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [0. 3. 6. 8. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3  8  6  3  0  6] -> size -> 31 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 58.39366912841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.257141]
 [21.125957]
 [46.18331 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10. 10. 11.  3.] 
cards in discard: [10. 11. 10. 10.  0. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 24. 30.  8.  2. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [0. 3. 6. 8. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3  8  6  3  0  6] -> size -> 31 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.047691345214844






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [0. 3. 6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 8. 8.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6
  8  3  8  6  3  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  2. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [10. 11. 10. 10.  0. 29. 25.  0. 11. 10. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10] -> size -> 29 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8
  3  8  6  3  0  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  2. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [10. 11. 10. 10.  0. 29. 25.  0. 11. 10. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10] -> size -> 29 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8
  3  8  6  3  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 24. 30.  8.  2. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [10. 11. 10. 10.  0. 29. 25.  0. 11. 10. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10] -> size -> 29 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[77.41058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [10. 11. 10. 10.  0. 29. 25.  0. 11. 10. 10. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  2. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [6. 8. 3. 3. 0.] 
adversary cards in discard: [6. 8. 0. 6. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8
  3  8  6  3  0  6] -> size -> 30 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 46.18330383300781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[60.88346 ]
 [81.93732 ]
 [42.226448]
 [76.853096]
 [76.56602 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [10. 11. 10. 10.  0. 29. 25.  0. 11. 10. 10. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 24. 30.  8.  2. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [6. 8. 3. 3. 0.] 
adversary cards in discard: [6. 8. 0. 6. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8
  3  8  6  3  0  6] -> size -> 30 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 77.41058349609375



buy possibilites: [-1] 
expected returns: [[105.19357]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [10. 11. 10. 10.  0. 29. 25.  0. 11. 10. 10. 11.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 23. 30.  8.  2. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [6. 8. 3. 3. 0.] 
adversary cards in discard: [6. 8. 0. 6. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8
  3  8  6  3  0  6] -> size -> 30 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0  16   0] 
sum of rewards: 191 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 81.93730926513672






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [6. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 3. 0.] 
cards in discard: [6. 8. 0. 6. 8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8
  3  8  6  3  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 23. 30.  8.  2. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [25. 11. 11. 10. 11.] 
adversary cards in discard: [10. 11. 10. 10.  0. 29. 25.  0. 11. 10. 10. 11.  3.  3.  3.  0.  3.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3] -> size -> 30 
adversary victory points: 5
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [6. 8. 0. 6. 8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 23. 30.  8.  2. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [25. 11. 11. 10. 11.] 
adversary cards in discard: [10. 11. 10. 10.  0. 29. 25.  0. 11. 10. 10. 11.  3.  3.  3.  0.  3.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3] -> size -> 30 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [6. 8. 0. 6. 8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 23. 30.  8.  2. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [25. 11. 11. 10. 11.] 
adversary cards in discard: [10. 11. 10. 10.  0. 29. 25.  0. 11. 10. 10. 11.  3.  3.  3.  0.  3.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3] -> size -> 30 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [6. 8. 0. 6. 8. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8.  2. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [25. 11. 11. 10. 11.] 
adversary cards in discard: [10. 11. 10. 10.  0. 29. 25.  0. 11. 10. 10. 11.  3.  3.  3.  0.  3.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3] -> size -> 30 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [25. 11. 11. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11. 10. 11.] 
expected returns: [[17.427917]
 [33.025352]
 [26.281868]
 [26.281868]
 [13.704488]
 [26.281868]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 11. 10. 11.] 
cards in discard: [10. 11. 10. 10.  0. 29. 25.  0. 11. 10. 10. 11.  3.  3.  3.  0.  3.  3.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8.  2. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  1.] 
adversary cards in discard: [6. 8. 0. 6. 8. 0. 8. 6. 3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0] -> size -> 29 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 105.19357299804688



action possibilites: [-1] 
expected returns: [[62.83477]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10. 11. 11. 10.] 
cards in discard: [10. 11. 10. 10.  0. 29. 25.  0. 11. 10. 10. 11.  3.  3.  3.  0.  3.  3.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8.  1. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  1.] 
adversary cards in discard: [6. 8. 0. 6. 8. 0. 8. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6] -> size -> 30 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 33.025360107421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[54.5513  ]
 [47.45613 ]
 [63.787437]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 10. 11. 11. 10.] 
cards in discard: [10. 11. 10. 10.  0. 29. 25.  0. 11. 10. 10. 11.  3.  3.  3.  0.  3.  3.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8.  1. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  1.] 
adversary cards in discard: [6. 8. 0. 6. 8. 0. 8. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6] -> size -> 30 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.83477020263672






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 6. 10.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.  1.] 
cards in discard: [6. 8. 0. 6. 8. 0. 8. 6. 3. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8.  1. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3] -> size -> 30 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  0.  1.] 
cards in discard: [6. 8. 0. 6. 8. 0. 8. 6. 3. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 23. 30.  8.  1. 10.  2.  6.  8.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3] -> size -> 30 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  0.  1.] 
cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8.  1. 10.  2.  6.  8.  9. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3] -> size -> 30 
adversary victory points: 5
player victory points: -3 





Player: 0 
cards in hand: [11. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[113.204575]
 [116.11951 ]
 [101.818726]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8.  1. 10.  2.  6.  8.  9. 10. 10.  1. 10.  9.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15] -> size -> 31 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 63.78746032714844



action possibilites: [-1] 
expected returns: [[116.38277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8.  1. 10.  2.  6.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15] -> size -> 31 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 116.68659210205078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[107.486206]
 [126.247345]
 [122.8421  ]
 [ 93.6394  ]
 [139.36601 ]
 [118.4305  ]
 [123.622375]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 23. 30.  8.  1. 10.  2.  6.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15] -> size -> 31 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 116.38276672363281



buy possibilites: [-1] 
expected returns: [[97.46506]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8.  1. 10.  1.  6.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15] -> size -> 31 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 309 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 139.36605834960938






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8.  1. 10.  1.  6.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 10. 29.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11] -> size -> 32 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 23. 30.  8.  1. 10.  1.  6.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 10. 29.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11] -> size -> 32 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8.  1. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 10. 29.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11] -> size -> 32 
adversary victory points: 5
player victory points: -3 





Player: 0 
cards in hand: [ 0. 11. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 29.] 
expected returns: [[ 86.8893  ]
 [107.030045]
 [ 84.21008 ]
 [ 84.21008 ]
 [113.083305]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 10. 29.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8.  1. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 6. 3. 1.] 
adversary cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.  8.  3.
  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15  8] -> size -> 32 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 97.46505737304688



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[139.62543]
 [139.71136]
 [139.71136]
 [139.71136]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 10.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 23. 30.  8.  1. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 6. 3. 1.] 
adversary cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.  8.  3.
  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15  8] -> size -> 32 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 97.90170288085938



action possibilites: [-1. 10. 10.] 
expected returns: [[104.691246]
 [103.8824  ]
 [103.8824  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  3.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11] -> size -> 32 
action values: 2 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 23. 30.  8.  1. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 6. 3. 1.] 
adversary cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.  8.  3.
  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15  8] -> size -> 32 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 139.71142578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 90.65232 ]
 [107.323616]
 [ 77.5907  ]
 [103.051094]
 [ 99.15428 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  3.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 23. 30.  8.  1. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 6. 3. 1.] 
adversary cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.  8.  3.
  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15  8] -> size -> 32 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 104.6912612915039



buy possibilites: [-1] 
expected returns: [[67.731735]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  3.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 22. 30.  8.  1. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 6. 3. 1.] 
adversary cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.  8.  3.
  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15  8] -> size -> 32 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 321 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 107.32362365722656






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [3. 3. 6. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 3. 1.] 
cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.  8.  3.
  0.  3.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 22. 30.  8.  1. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3. 10. 25.  0.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.  3. 29. 10.  0. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3] -> size -> 33 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 3. 1.] 
cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.  8.  3.
  0.  3.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 22. 30.  8.  1. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3. 10. 25.  0.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.  3. 29. 10.  0. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3] -> size -> 33 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 3. 1.] 
cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.  8.  3.
  0.  3.  6.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15  8  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  1. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3. 10. 25.  0.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.  3. 29. 10.  0. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3] -> size -> 33 
adversary victory points: 6
player victory points: -2 





Player: 0 
cards in hand: [11.  3. 10. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 25.] 
expected returns: [[52.943893]
 [65.38585 ]
 [43.91086 ]
 [74.712105]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10. 25.  0.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.  3. 29. 10.  0. 10. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  1. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 6. 6. 0.] 
adversary cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.  8.  3.
  0.  3.  6.  0.  3.  3.  3.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15  8  3] -> size -> 33 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.73173522949219



action possibilites: [-1] 
expected returns: [[72.692444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.  0. 11. 11.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.  3. 29. 10.  0. 10. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  0. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 6. 6. 0.] 
adversary cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.  8.  3.
  0.  3.  6.  0.  3.  3.  3.  6.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15  8  3  6] -> size -> 34 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 74.71214294433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[67.12581 ]
 [79.637245]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 10.  0. 11. 11.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.  3. 29. 10.  0. 10. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 21. 30.  8.  0. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 6. 6. 0.] 
adversary cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.  8.  3.
  0.  3.  6.  0.  3.  3.  3.  6.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15  8  3  6] -> size -> 34 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 72.69244384765625






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [0. 8. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 6. 0.] 
cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.  8.  3.
  0.  3.  6.  0.  3.  3.  3.  6.  3.  1.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8
  6  3  0  6  0  6 15  8  3  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  0. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 10.  3.  3. 11.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.  3. 29. 10.  0. 10. 10.  3. 25. 11.  3.
 10.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3] -> size -> 33 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.  8.  3.
  0.  3.  6.  0.  3.  3.  3.  6.  3.  1.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6
  3  0  6  0  6 15  8  3  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  0. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 10.  3.  3. 11.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.  3. 29. 10.  0. 10. 10.  3. 25. 11.  3.
 10.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3] -> size -> 33 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 6.  8.  0.  6.  8.  0.  8.  6.  3.  6. 15.  6. 10.  0.  0.  1.  8.  3.
  0.  3.  6.  0.  3.  3.  3.  6.  3.  1.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6
  3  0  6  0  6 15  8  3  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 21. 30.  8.  0. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 10.  3.  3. 11.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.  3. 29. 10.  0. 10. 10.  3. 25. 11.  3.
 10.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3] -> size -> 33 
adversary victory points: 6
player victory points: -3 





Player: 0 
cards in hand: [10. 10.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[78.07887 ]
 [75.322395]
 [75.322395]
 [98.33179 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  3. 11.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.  3. 29. 10.  0. 10. 10.  3. 25. 11.  3.
 10.  0. 11. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  0. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [1. 3. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6
  3  0  6  0  6 15  8  3  6] -> size -> 33 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 79.63726806640625



action possibilites: [-1] 
expected returns: [[-20.741947]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  3.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.  3. 29. 10.  0. 10. 10.  3. 25. 11.  3.
 10.  0. 11. 11.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [1. 3. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6
  3  0  6  0  6 15  8  3  6] -> size -> 33 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 312 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 90.42814636230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-21.58551 ]
 [-18.306986]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  3.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.  3. 29. 10.  0. 10. 10.  3. 25. 11.  3.
 10.  0. 11. 11.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [1. 3. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6
  3  0  6  0  6 15  8  3  6] -> size -> 33 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: -20.741947174072266






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [1. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6
  3  0  6  0  6 15  8  3  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0. 10. 25.  0.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.  3. 29. 10.  0. 10. 10.  3. 25. 11.  3.
 10.  0. 11. 11.  1. 11. 10. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1] -> size -> 34 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6
  3  0  6  0  6 15  8  3  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  1.  5.  8.  9. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0. 10. 25.  0.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.  3. 29. 10.  0. 10. 10.  3. 25. 11.  3.
 10.  0. 11. 11.  1. 11. 10. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1] -> size -> 34 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 6. 0.] 
cards in discard: [29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6
  3  0  6  0  6 15  8  3  6 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0. 10. 25.  0.] 
adversary cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.  3. 29. 10.  0. 10. 10.  3. 25. 11.  3.
 10.  0. 11. 11.  1. 11. 10. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1] -> size -> 34 
adversary victory points: 6
player victory points: -3 





Player: 0 
cards in hand: [ 3.  0. 10. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[101.12984 ]
 [ 99.389046]
 [125.47098 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 25.  0.] 
cards in discard: [10. 11. 11. 10.  0.  0.  0. 11.  3. 29. 10.  0. 10. 10.  3. 25. 11.  3.
 10.  0. 11. 11.  1. 11. 10. 10.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 1. 6. 0. 3.] 
adversary cards in discard: [29.  1.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6
  3  0  6  0  6 15  8  3  6 29] -> size -> 34 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -18.306987762451172



action possibilites: [-1] 
expected returns: [[120.340225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 1. 6. 0. 3.] 
adversary cards in discard: [29.  1.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6
  3  0  6  0  6 15  8  3  6 29] -> size -> 34 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 125.47099304199219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[101.52125 ]
 [122.942276]
 [116.308266]
 [122.96954 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 1. 6. 0. 3.] 
adversary cards in discard: [29.  1.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6
  3  0  6  0  6 15  8  3  6 29] -> size -> 34 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 120.34022521972656






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [3. 1. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 6. 0. 3.] 
cards in discard: [29.  1.  3.  0.  6.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6
  3  0  6  0  6 15  8  3  6 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3. 10. 11. 11.] 
adversary cards in discard: [25.  3.  0. 10.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1] -> size -> 34 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6. 0. 3.] 
cards in discard: [29.  1.  3.  0.  6.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6
  3  0  6  0  6 15  8  3  6 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3. 10. 11. 11.] 
adversary cards in discard: [25.  3.  0. 10.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1] -> size -> 34 
adversary victory points: 6
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  3. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[126.242615]
 [120.493996]
 [138.01    ]
 [138.01    ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 11. 11.] 
cards in discard: [25.  3.  0. 10.  0. 10. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 8. 3. 8. 8.] 
adversary cards in discard: [29.  1.  3.  0.  6.  0.  3.  1.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6
  3  0  6  0  6 15  8  3  6 29] -> size -> 34 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 122.96958923339844



action possibilites: [-1] 
expected returns: [[108.146866]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 11.] 
cards in discard: [25.  3.  0. 10.  0. 10. 11.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 8. 3. 8. 8.] 
adversary cards in discard: [29.  1.  3.  0.  6.  0.  3.  1.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6
  3  0  6  0  6 15  8  3  6 29] -> size -> 34 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 312 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 130.1547088623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 85.10629]
 [108.49394]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 11.] 
cards in discard: [25.  3.  0. 10.  0. 10. 11.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 25. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 8. 3. 8. 8.] 
adversary cards in discard: [29.  1.  3.  0.  6.  0.  3.  1.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6
  3  0  6  0  6 15  8  3  6 29] -> size -> 34 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 108.14686584472656






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [6. 8. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 8. 8.] 
cards in discard: [29.  1.  3.  0.  6.  0.  3.  1.  6.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6
  3  0  6  0  6 15  8  3  6 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  3. 11.  1.] 
adversary cards in discard: [25.  3.  0. 10.  0. 10. 11.  1. 11.  3.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1  1] -> size -> 35 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8.] 
cards in discard: [29.  1.  3.  0.  6.  0.  3.  1.  6.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6  3
  0  6  0  6 15  8  3  6 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  3. 11.  1.] 
adversary cards in discard: [25.  3.  0. 10.  0. 10. 11.  1. 11.  3.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1  1] -> size -> 35 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8.] 
cards in discard: [29.  1.  3.  0.  6.  0.  3.  1.  6.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6  3
  0  6  0  6 15  8  3  6 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 25. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  3. 11.  1.] 
adversary cards in discard: [25.  3.  0. 10.  0. 10. 11.  1. 11.  3.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1  1] -> size -> 35 
adversary victory points: 6
player victory points: -4 





Player: 0 
cards in hand: [10.  3.  3. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[ 93.37546 ]
 [ 81.84835 ]
 [100.444885]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 11.  1.] 
cards in discard: [25.  3.  0. 10.  0. 10. 11.  1. 11.  3.  3. 10. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [29.  1.  3.  0.  6.  0.  3.  1.  6.  0.  3.  8.  6.  8.  8.] 
adversary owned cards: [ 0  0  0  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6  3
  0  6  0  6 15  8  3  6 29] -> size -> 33 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 108.49392700195312



action possibilites: [-1] 
expected returns: [[146.62695]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  1.] 
cards in discard: [25.  3.  0. 10.  0. 10. 11.  1. 11.  3.  3. 10. 11.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1  1  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [29.  1.  3.  0.  6.  0.  3.  1.  6.  0.  3.  8.  6.  8.  8.] 
adversary owned cards: [ 0  0  0  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6  3
  0  6  0  6 15  8  3  6 29] -> size -> 33 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -10   0   0  27   0] 
sum of rewards: 332 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 89.64061737060547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[134.54099]
 [148.85934]
 [144.61163]
 [150.38103]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  1.] 
cards in discard: [25.  3.  0. 10.  0. 10. 11.  1. 11.  3.  3. 10. 11.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1  1  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 24. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [29.  1.  3.  0.  6.  0.  3.  1.  6.  0.  3.  8.  6.  8.  8.] 
adversary owned cards: [ 0  0  0  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6  3
  0  6  0  6 15  8  3  6 29] -> size -> 33 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 146.626953125






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 8.] 
cards in discard: [29.  1.  3.  0.  6.  0.  3.  1.  6.  0.  3.  8.  6.  8.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6  3
  0  6  0  6 15  8  3  6 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [25.  3.  0. 10.  0. 10. 11.  1. 11.  3.  3. 10. 11.  1. 11. 10.  3.  3.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1  1  1] -> size -> 36 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [29.  1.  3.  0.  6.  0.  3.  1.  6.  0.  3.  8.  6.  8.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6  3  0
  6  0  6 15  8  3  6 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [25.  3.  0. 10.  0. 10. 11.  1. 11.  3.  3. 10. 11.  1. 11. 10.  3.  3.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1  1  1] -> size -> 36 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [29.  1.  3.  0.  6.  0.  3.  1.  6.  0.  3.  8.  6.  8.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6  3  0
  6  0  6 15  8  3  6 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 24. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [25.  3.  0. 10.  0. 10. 11.  1. 11.  3.  3. 10. 11.  1. 11. 10.  3.  3.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1  1  1] -> size -> 36 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [29.  1.  3.  0.  6.  0.  3.  1.  6.  0.  3.  8.  6.  8.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6  3  0
  6  0  6 15  8  3  6 29  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [25.  3.  0. 10.  0. 10. 11.  1. 11.  3.  3. 10. 11.  1. 11. 10.  3.  3.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1  1  1] -> size -> 36 
adversary victory points: 6
player victory points: -4 





Player: 0 
cards in hand: [ 0.  0. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[128.15172]
 [128.10855]
 [128.10855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [25.  3.  0. 10.  0. 10. 11.  1. 11.  3.  3. 10. 11.  1. 11. 10.  3.  3.
  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1  1  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 10.  6.] 
adversary cards in discard: [29.  1.  3.  0.  6.  0.  3.  1.  6.  0.  3.  8.  6.  8.  8.  0.  8.  6.
  0.  6.] 
adversary owned cards: [ 0  0  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6  3  0
  6  0  6 15  8  3  6 29  0] -> size -> 33 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 150.38104248046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[119.524956]
 [143.3191  ]
 [137.8456  ]
 [152.12888 ]
 [132.99715 ]
 [127.73172 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [25.  3.  0. 10.  0. 10. 11.  1. 11.  3.  3. 10. 11.  1. 11. 10.  3.  3.
  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1  1  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 21. 30.  8.  0. 10.  1.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 10.  6.] 
adversary cards in discard: [29.  1.  3.  0.  6.  0.  3.  1.  6.  0.  3.  8.  6.  8.  8.  0.  8.  6.
  0.  6.] 
adversary owned cards: [ 0  0  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6  3  0
  6  0  6 15  8  3  6 29  0] -> size -> 33 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 128.15170288085938



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 9 
Chapel: 0 
Witch: 2 
Poacher: 1 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [25.  3.  0. 10.  0. 10. 11.  1. 11.  3.  3. 10. 11.  1. 11. 10.  3.  3.
  1. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 10 11 25 11 11 11 11 10 10  3
 10 11 10 10 10  3 10 11  3  1  1  1 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 21. 30.  8.  0. 10.  0.  5.  8.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 10.  6.] 
adversary cards in discard: [29.  1.  3.  0.  6.  0.  3.  1.  6.  0.  3.  8.  6.  8.  8.  0.  8.  6.
  0.  6.] 
adversary owned cards: [ 0  0  3 10  1  6  0  1  6  0  6  8  6  3  3  8  6  6  8  3  8  6  3  0
  6  0  6 15  8  3  6 29  0] -> size -> 33 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[     -5 3000000       0     300       0       0       0       0       0
       0       0     -20       0       0      27       0] 
sum of rewards: 3000302 

action type: buy - action 11.0
Learning step: 300014.96875
desired expected reward: 300167.09375



