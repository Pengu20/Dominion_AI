 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -150        0        0        0        0
        0        0        0     -390        0        0       27        0] 
sum of rewards: -3000518 

action type: buy - action 1.0
Learning step: -300050.09375
desired expected reward: -300067.1875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 1.  0.  3.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [ 0.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 5 
card supply: [26. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 3.  0.  0.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 3.  0.  0.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 3.  0.  0.  3.  0. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [ 3. 10.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  3.  0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
action values: 0 
buys: 0 
player value: 5 
card supply: [23. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  3. 10.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  3. 10.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  3. 10.  3.  3.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [22. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [ 8.  0. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  1.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  1.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  1.  0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 10.] 
adversary cards in discard: [10.  8.  0. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 10.] 
adversary cards in discard: [10.  8.  0. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 10.] 
adversary cards in discard: [10.  8.  0. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [ 0.  3.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 10.] 
cards in discard: [10.  8.  0. 10.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [10.  8.  0. 10.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8 10] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [10.  8.  0. 10.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [10.  8.  0. 10.  1.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8 10  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  8.  0. 10.  1.  0.  3. 10.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  8.  0. 10.  1.  0.  3. 10.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  8.  0. 10.  1.  0.  3. 10.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  8.  0. 10.  1.  0.  3. 10.  0.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8 10  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  8.  0. 10.  1.  0.  3. 10.  0.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8 10  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
action values: 0 
buys: 0 
player value: 5 
card supply: [19. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [0. 0. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  3 10  0  8 10  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
action values: 0 
buys: 0 
player value: 4 
card supply: [18. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [8. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [8. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [18. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 8.  3. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3. 10.  0.  3.] 
adversary cards in discard: [ 8.  3. 29.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3. 10.  0.  3.] 
adversary cards in discard: [ 8.  3. 29.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3. 10.  0.  3.] 
adversary cards in discard: [ 8.  3. 29.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [10.  3. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  0.  3.] 
cards in discard: [ 8.  3. 29.  0.  0.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.  0.] 
cards in discard: [ 8.  3. 29.  0.  0.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 8.  3. 29.  0.  0.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29] -> size -> 16 
action values: 3 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 8.  3. 29.  0.  0.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
action values: 0 
buys: 0 
player value: 4 
card supply: [16. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [ 3.  0.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29. 10.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29] -> size -> 16 
action values: 3 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.  1.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 29. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [ 3. 10. 10.  3.  0.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 29. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [ 3. 10. 10.  3.  0.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [15. 29. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [ 3. 10. 10.  3.  0.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [ 0. 10.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.  0.] 
cards in discard: [ 3. 10. 10.  3.  0.  0. 29.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.  0.] 
cards in discard: [ 3. 10. 10.  3.  0.  0. 29.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 29. 30. 27. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.  0.] 
cards in discard: [ 3. 10. 10.  3.  0.  0. 29.  1.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 27. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 3. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 27. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 3. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 29. 30. 27. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 3. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 25 
action values: 0 
buys: 0 
player value: 5 
card supply: [14. 29. 30. 27. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [10.  8.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 27. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 25 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 29. 30. 27. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 25 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  0.  0.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 26. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 25 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 26. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  1.  0.] 
adversary cards in discard: [ 3. 10.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8  3] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 29. 30. 26. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  1.  0.] 
adversary cards in discard: [ 3. 10.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8  3] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
action values: 0 
buys: 0 
player value: 4 
card supply: [13. 29. 30. 26. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  1.  0.] 
adversary cards in discard: [ 3. 10.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8  3] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [ 0.  3. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  1.  0.] 
cards in discard: [ 3. 10.  8.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 26. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [ 3. 10.  8.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8  3] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 26. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [ 3. 10.  8.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 29. 30. 26. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [ 3. 10.  8.  3.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8  3  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 29. 30. 26. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 26. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 10.  0.] 
adversary cards in discard: [ 3. 10.  8.  3.  0.  0.  8. 10.  0.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8  3  8] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 29. 30. 26. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 10.  0.] 
adversary cards in discard: [ 3. 10.  8.  3.  0.  0.  8. 10.  0.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8  3  8] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
action values: 0 
buys: 0 
player value: 5 
card supply: [12. 29. 30. 26. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 10.  0.] 
adversary cards in discard: [ 3. 10.  8.  3.  0.  0.  8. 10.  0.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8  3  8] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [ 3.  0. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 10.  0.] 
cards in discard: [ 3. 10.  8.  3.  0.  0.  8. 10.  0.  3.  1.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8  3  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 26. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  8.] 
cards in discard: [ 3. 10.  8.  3.  0.  0.  8. 10.  0.  3.  1.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  1 10  3 10  0  8 10  3 29  3  8  3  8] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 26. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 10.  8.  3.  0.  0.  8. 10.  0.  3.  1.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  1 10  3 10  0  8 10  3  3  8  3  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 26. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 10.  8.  3.  0.  0.  8. 10.  0.  3.  1.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  1 10  3 10  0  8 10  3  3  8  3  8] -> size -> 16 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 29. 30. 26. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 10.  8.  3.  0.  0.  8. 10.  0.  3.  1.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  1 10  3 10  0  8 10  3  3  8  3  8  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 26. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 26. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 10.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1 10  3 10  0  8 10  3  3  8  3  8  0] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 29. 30. 26. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 10.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1 10  3 10  0  8 10  3  3  8  3  8  0] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
action values: 0 
buys: 0 
player value: 5 
card supply: [10. 29. 30. 26. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 10.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1 10  3 10  0  8 10  3  3  8  3  8  0] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [10. 10.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1 10  3 10  0  8 10  3  3  8  3  8  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 26. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1 10  3 10  0  8 10  3  3  8  3  8  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 26. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1 10  3 10  0  8 10  3  3  8  3  8  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 29. 30. 26. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  3.  0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1 10  3 10  0  8 10  3  3  8  3  8  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 0. 3. 3.] 
adversary cards in discard: [ 8. 10. 10.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  1 10  3 10  0  8 10  3  3  8  3  8  0  8] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 0. 3. 3.] 
adversary cards in discard: [ 8. 10. 10.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  1 10  3 10  0  8 10  3  3  8  3  8  0  8] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 0. 3. 3.] 
adversary cards in discard: [ 8. 10. 10.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  1 10  3 10  0  8 10  3  3  8  3  8  0  8] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 3. 3.] 
cards in discard: [ 8. 10. 10.  0.  8.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1 10  3 10  0  8 10  3  3  8  3  8  0  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 8. 10. 10.  0.  8.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1 10  3 10  0  8 10  3  3  8  3  8  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 8. 10. 10.  0.  8.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1 10  3 10  0  8 10  3  3  8  3  8  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 8. 10. 10.  0.  8.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1 10  3 10  0  8 10  3  3  8  3  8  0  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  3.] 
adversary cards in discard: [ 8. 10. 10.  0.  8.  3.  0.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  1 10  3 10  0  8 10  3  3  8  3  8  0  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 8. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  3.] 
adversary cards in discard: [ 8. 10. 10.  0.  8.  3.  0.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  1 10  3 10  0  8 10  3  3  8  3  8  0  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 7. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  3.] 
adversary cards in discard: [ 8. 10. 10.  0.  8.  3.  0.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  1 10  3 10  0  8 10  3  3  8  3  8  0  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [10.  8.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0.  3.] 
cards in discard: [ 8. 10. 10.  0.  8.  3.  0.  0.  8.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 10  3 10  0  8 10  3  3  8  3  8  0  8  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8. 10. 10.  0.  8.  3.  0.  0.  8.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8. 10. 10.  0.  8.  3.  0.  0.  8.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 31 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 6. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [ 3.  3. 10.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  8.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 31 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  8.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 31 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  8.  1.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 31 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 10.  8.] 
adversary cards in discard: [ 0.  3.  3. 10.  8.  1.] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 10.  8.] 
adversary cards in discard: [ 0.  3.  3. 10.  8.  1.] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 10.  8.] 
adversary cards in discard: [ 0.  3.  3. 10.  8.  1.] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [ 0.  8.  8. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 10.  8.] 
cards in discard: [ 0.  3.  3. 10.  8.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 8. 3.] 
cards in discard: [ 0.  3.  3. 10.  8.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 8. 3.] 
cards in discard: [ 0.  3.  3. 10.  8.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 4. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 3. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 29. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  8.  8.  0. 10.] 
adversary cards in discard: [1. 3. 8. 0. 0. 0.] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 28. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  8.  8.  0. 10.] 
adversary cards in discard: [1. 3. 8. 0. 0. 0.] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 2. 28. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  8.  8.  0. 10.] 
adversary cards in discard: [1. 3. 8. 0. 0. 0.] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [ 1.  8.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  8.  0. 10.] 
cards in discard: [1. 3. 8. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  8.  0. 10.] 
cards in discard: [1. 3. 8. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 28. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  8.  0. 10.] 
cards in discard: [1. 3. 8. 0. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 28. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  3. 10.] 
adversary cards in discard: [ 1.  3.  8.  0.  0.  0.  0.  1.  8.  8.  0. 10.] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 1. 28. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  3. 10.] 
adversary cards in discard: [ 1.  3.  8.  0.  0.  0.  0.  1.  8.  8.  0. 10.] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0. 28. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  3. 10.] 
adversary cards in discard: [ 1.  3.  8.  0.  0.  0.  0.  1.  8.  8.  0. 10.] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [ 0.  8.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3.  3. 10.] 
cards in discard: [ 1.  3.  8.  0.  0.  0.  0.  1.  8.  8.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 1. 0. 1. 0.] 
adversary cards in discard: [10.  0.  8.  3.  3.  3.] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 28. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 1. 0. 1. 0.] 
adversary cards in discard: [10.  0.  8.  3.  3.  3.] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 27. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 1. 0. 1. 0.] 
adversary cards in discard: [10.  0.  8.  3.  3.  3.] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  -10.
   0.    0.   13.5   0. ] 
sum of rewards: -1.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8. 1. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 1. 0.] 
cards in discard: [10.  0.  8.  3.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] -> size -> 36 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 1. 0.] 
cards in discard: [10.  0.  8.  3.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 27. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] -> size -> 36 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 1. 0.] 
cards in discard: [10.  0.  8.  3.  3.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1  0 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 27. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] -> size -> 36 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [10.  0.  8.  3.  3.  3. 10.  8.  1.  0.  1.  0.] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1  0 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 27. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [10.  0.  8.  3.  3.  3. 10.  8.  1.  0.  1.  0.] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1  0 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 26. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [10.  0.  8.  3.  3.  3. 10.  8.  1.  0.  1.  0.] 
adversary owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1  0 10] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  -20.
   0.    0.   13.5   0. ] 
sum of rewards: -11.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [10.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0.  0.] 
cards in discard: [10.  0.  8.  3.  3.  3. 10.  8.  1.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  8 10  3  3  8  3  8  0  8  0  0  1  0 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] -> size -> 37 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [10.  0.  8.  3.  3.  3. 10.  8.  1.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 10  8 10  3  3  8  3  8  8  0  0  1  0 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] -> size -> 37 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [10.  0.  8.  3.  3.  3. 10.  8.  1.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 10  8 10  3  3  8  3  8  8  0  0  1  0 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 26. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] -> size -> 37 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 10  8 10  3  3  8  3  8  8  0  0  1  0 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 26. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 10  8 10  3  3  8  3  8  8  0  0  1  0 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 25. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 10  8 10  3  3  8  3  8  8  0  0  1  0 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  -30.
   0.    0.   13.5   0. ] 
sum of rewards: -21.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [10.  8.  8. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8. 10.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10  8 10  3  3  8  3  8  8  0  0  1  0 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1] -> size -> 38 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1 10  8 10  3  3  8  3  8  8  0  0  1  0 10] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1] -> size -> 38 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 1 10  3  3  8  3  8  8  0  0  1  0 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1] -> size -> 38 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [ 1 10  3  8  3  8  8  0  0  1  0 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1] -> size -> 38 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [ 1 10  3  8  3  8  8  0  0  1  0 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 25. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1] -> size -> 38 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  3.  8.  0. 10.] 
adversary cards in discard: [10.  8.  8.] 
adversary owned cards: [ 1 10  3  8  3  8  8  0  0  1  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 25. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  3.  8.  0. 10.] 
adversary cards in discard: [10.  8.  8.] 
adversary owned cards: [ 1 10  3  8  3  8  8  0  0  1  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 24. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  3.  8.  0. 10.] 
adversary cards in discard: [10.  8.  8.] 
adversary owned cards: [ 1 10  3  8  3  8  8  0  0  1  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.   30.    0.    0.    0.    0.    0.    0.    0.  -40.
   0.    0.   13.5   0. ] 
sum of rewards: -1.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [ 1.  3.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  8.  0. 10.] 
cards in discard: [10.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10  3  8  3  8  8  0  0  1  0 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1] -> size -> 39 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [10.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  3  8  8  0  1  0 10] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1] -> size -> 39 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [10.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  3  8  8  0  1  0 10] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 24. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1] -> size -> 39 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  3  8  8  0  1  0 10] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 24. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  3  8  8  0  1  0 10] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 23. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  3  8  8  0  1  0 10] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.   30.    0.    0.    0.    0.    0.    0.    0.  -50.
   0.    0.   13.5   0. ] 
sum of rewards: -11.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  3  8  8  0  1  0 10] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1] -> size -> 40 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  3  8  8  0  1  0 10] -> size -> 9 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 23. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1] -> size -> 40 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 0. 3.] 
cards in discard: [10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  3  8  8  0  1  0 10 10] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1] -> size -> 40 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  3  8  8  0  1  0 10 10] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 23. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  3  8  8  0  1  0 10 10] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  3  8  8  0  1  0 10 10] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0 -60   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [10. 10.  8.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.  8.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  3  8  8  0  1  0 10 10] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1] -> size -> 41 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 10.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.  3.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8  3  8  8  0  1  0 10 10] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1] -> size -> 41 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  3  8  0  1  0 10] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1] -> size -> 41 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  3  8  0  1  0 10] -> size -> 7 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 22. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1] -> size -> 41 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0  1  0 10] -> size -> 7 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 22. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0  1  0 10] -> size -> 7 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.
 1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 21. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0  1  0 10] -> size -> 7 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.   30.    0.    0.    0.    0.    0.    0.    0.  -70.
   0.    0.   13.5   0. ] 
sum of rewards: -31.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [3. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0  1  0 10] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.
 1. 0. 3. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1] -> size -> 42 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0  1  0 10] -> size -> 7 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 21. 30. 26. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.
 1. 0. 3. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1] -> size -> 42 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0  1  0 10  3] -> size -> 8 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 21. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.
 1. 0. 3. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1] -> size -> 42 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.
 1. 0. 3. 0. 0. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  3.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0  1  0 10  3] -> size -> 8 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.
 1. 0. 3. 0. 0. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1] -> size -> 42 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 21. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  3.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0  1  0 10  3] -> size -> 8 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.
 1. 0. 3. 0. 0. 1. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 20. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  3.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0  1  0 10  3] -> size -> 8 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  -80.
   0.    0.   13.5   0. ] 
sum of rewards: -71.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [ 1.  3.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3. 10.  8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0  1  0 10  3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.
 1. 0. 3. 0. 0. 1. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1] -> size -> 43 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  3. 10.  8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0  1  0 10  3] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 20. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.
 1. 0. 3. 0. 0. 1. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1] -> size -> 43 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.
 1. 0. 3. 0. 0. 1. 1. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0  1  0 10  3] -> size -> 8 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.
 1. 0. 3. 0. 0. 1. 1. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1] -> size -> 43 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 20. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0  1  0 10  3] -> size -> 8 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0.
 1. 0. 3. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1] -> size -> 44 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 19. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0  1  0 10  3] -> size -> 8 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  -90.
   0.    0.   13.5   0. ] 
sum of rewards: -81.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0  1  0 10  3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1] -> size -> 44 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  0 10  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1] -> size -> 44 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  0 10  3] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 19. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1] -> size -> 44 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [1. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  0 10  3] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1] -> size -> 44 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0. 19. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  0 10  3] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1] -> size -> 45 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0. 18. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  0 10  3] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    60.     0.     0.     0.     0.     0.     0.
    0.  -100.     0.     0.    13.5    0. ] 
sum of rewards: -31.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [ 8.  0.  3. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10.  1.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  0 10  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1] -> size -> 45 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  1  0 10  3] -> size -> 5 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1] -> size -> 45 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  1 10] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1] -> size -> 45 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  1 10] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 18. 30. 25. 30.  8. 10. 10. 10.  6. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1] -> size -> 45 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  1 10  8] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1] -> size -> 45 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [0. 3. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 10  8] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1] -> size -> 45 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 18. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 10  8] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 17. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 10  8] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -110.     0.     0.    13.5    0. ] 
sum of rewards: -11.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [ 1. 10.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  8.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 10  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1] -> size -> 46 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1] -> size -> 46 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 17. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1] -> size -> 46 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1] -> size -> 46 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 17. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 16. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -120.     0.     0.    13.5    0. ] 
sum of rewards: -21.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [ 8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 16. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 16. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 16. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [0. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 16. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 16. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 15. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -130.     0.     0.    13.5    0. ] 
sum of rewards: -31.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 15. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1] -> size -> 48 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 15. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1] -> size -> 48 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 15. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1] -> size -> 48 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 15. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 14. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -140.     0.     0.    13.5    0. ] 
sum of rewards: -41.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 14. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 14. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 14. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 14. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 14. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 13. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -150.     0.     0.    13.5    0. ] 
sum of rewards: -51.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 13. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 50 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 13. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 50 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 13. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 50 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 3. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 13. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 3. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 50 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 13. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 3. 0. 0. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 12. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -160.     0.     0.    13.5    0. ] 
sum of rewards: -61.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 12. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 3. 0. 0. 1. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 12. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 3. 0. 0. 1. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 12. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 3. 0. 0. 1. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 3. 0. 0. 1. 1. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 12. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 3. 0. 0. 1. 1. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 12. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 0. 0. 0. 1. 0. 3. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 3. 1. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 3. 0. 0. 1. 1. 0. 0. 0. 0. 1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 52 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 11. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -170.     0.     0.    13.5    0. ] 
sum of rewards: -71.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 11. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 1. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 52 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 11. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 1. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 52 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [3. 1. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 11. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 52 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 11. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1. 0. 0.] 
cards in discard: [1.] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 53 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 10. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -180.     0.     0.    13.5    0. ] 
sum of rewards: -81.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 10. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 1.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 53 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 10. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 1.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 53 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [1. 3. 1. 1. 0. 0.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 10. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [1. 3. 1. 1. 0. 0.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 53 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0. 10. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 54 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0.  9. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -190.     0.     0.    13.5    0. ] 
sum of rewards: -91.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  9. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 54 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  9. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 54 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  9. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 54 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  9. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 54 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  9. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 55 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  8. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -200.     0.     0.    13.5    0. ] 
sum of rewards: -101.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  8. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 1. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 55 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  8. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 1. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 55 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  8. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 1. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 55 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  8. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 55 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  8. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 56 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0.  7. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -210.     0.     0.    13.5    0. ] 
sum of rewards: -111.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  7. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 1. 1.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 56 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  7. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 1. 1.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 56 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1. 1.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  7. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 1.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 56 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  7. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 1.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 57 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0.  6. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -220.     0.     0.    13.5    0. ] 
sum of rewards: -121.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  6. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 57 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  6. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 57 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  6. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 57 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0.  6. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 58 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  5. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -230.     0.     0.    13.5    0. ] 
sum of rewards: -131.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  5. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 58 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  5. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 58 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  5. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 58 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  5. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 59 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  4. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -240.     0.     0.    13.5    0. ] 
sum of rewards: -141.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  4. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1. 1. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 59 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  4. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1. 1. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 59 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1. 1. 0. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  4. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1. 1. 0. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 59 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  4. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1. 1. 0. 0. 0. 3. 1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 60 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  3. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -250.     0.     0.    13.5    0. ] 
sum of rewards: -151.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  3. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 1. 1. 1.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1. 1. 0. 0. 0. 3. 1. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 60 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  3. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 1. 1. 1.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1. 1. 0. 0. 0. 3. 1. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 60 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  3. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 1. 1. 1.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1. 1. 0. 0. 0. 3. 1. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 60 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [0. 1. 1. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 1. 1.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1. 1. 0. 0. 0. 3. 1. 1. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  3. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 1. 1.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1. 1. 0. 0. 0. 3. 1. 1. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 60 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0.  3. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 1. 1.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1. 1. 0. 0. 0. 3. 1. 1. 0. 0. 0. 0.
 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 61 
action values: 0 
buys: 0 
player value: 6 
card supply: [ 0.  2. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -260.     0.     0.    13.5    0. ] 
sum of rewards: -161.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  2. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 1. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1. 1. 0. 0. 0. 3. 1. 1. 0. 0. 0. 0.
 1. 0. 1. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 61 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  2. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 1. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1. 1. 0. 0. 0. 3. 1. 1. 0. 0. 0. 0.
 1. 0. 1. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 61 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  2. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 1. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1. 1. 0. 0. 0. 3. 1. 1. 0. 0. 0. 0.
 1. 0. 1. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 61 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1. 1. 0. 0. 0. 3. 1. 1. 0. 0. 0. 0.
 1. 0. 1. 1. 1. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  2. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1. 1. 0. 0. 0. 3. 1. 1. 0. 0. 0. 0.
 1. 0. 1. 1. 1. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 61 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  2. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [1. 3. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.
 1. 0. 0. 1. 1. 1. 1. 3. 0. 0. 0. 0. 1. 1. 0. 0. 0. 3. 1. 1. 0. 0. 0. 0.
 1. 0. 1. 1. 1. 1. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 62 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0.  1. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -270.     0.     0.    13.5    0. ] 
sum of rewards: -171.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  1. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 62 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  1. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 62 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  1. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 62 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 57 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  1. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 57 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 62 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  1. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 57 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 63 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.     0.     0.     0.     0.
    0.  -280.     0.     0.    13.5    0. ] 
sum of rewards: -181.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 63 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 63 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 63 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0.] 
cards in deck: 52 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0.] 
cards in deck: 52 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 63 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0. 30. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2.] 
cards in deck: 52 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2] -> size -> 64 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   90    0    0    0    0    0 1500    0 -290    0    0
  432    0] 
sum of rewards: 1727 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2] -> size -> 64 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 29. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2] -> size -> 64 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1.] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1.] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2] -> size -> 64 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 29. 25. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3.] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3] -> size -> 65 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 29. 24. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.  120.    0.    0.    0.    0.    0.    0.    0. -300.
    0.    0.    4.    0.] 
sum of rewards: -181.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 24. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 1. 1. 3.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3] -> size -> 65 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 24. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 1. 1. 3.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3] -> size -> 65 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 29. 24. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 1. 1. 3.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3] -> size -> 65 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [1. 0. 1. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 1. 3.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3] -> size -> 65 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 24. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 3.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3] -> size -> 65 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 29. 24. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 3.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2] -> size -> 66 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 28. 24. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.  120.    0.    0.    0.    0.    0. 1500.    0. -310.
    0.    0.  108.    0.] 
sum of rewards: 1413.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 24. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2] -> size -> 66 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 28. 24. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2] -> size -> 66 
adversary victory points: 4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2] -> size -> 66 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 24. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2] -> size -> 66 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 28. 24. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2] -> size -> 67 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 27. 24. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.  120.    0.    0.    0.    0.    0. 1500.    0. -320.
    0.    0.  108.    0.] 
sum of rewards: 1403.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 27. 24. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2] -> size -> 67 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 27. 24. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2] -> size -> 67 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 27. 24. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2] -> size -> 67 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2] -> size -> 67 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 27. 24. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2] -> size -> 67 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 27. 24. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3] -> size -> 68 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 27. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.  150.    0.    0.    0.    0.    0.    0.    0. -330.
    0.    0.    4.    0.] 
sum of rewards: -181.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 27. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 1. 1. 1. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3] -> size -> 68 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 27. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 1. 1. 1. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3] -> size -> 68 
adversary victory points: 5
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [1. 1. 1. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1. 1. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3] -> size -> 68 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 27. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 1. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3] -> size -> 68 
action values: 0 
buys: 1 
player value: 10 
card supply: [ 0.  0. 27. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 1. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2] -> size -> 69 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0.  0. 26. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.  150.    0.    0.    0.    0.    0. 1500.    0. -340.
    0.    0.  108.    0.] 
sum of rewards: 1413.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 1. 1. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2] -> size -> 69 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 26. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 1. 1. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2] -> size -> 69 
adversary victory points: 5
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [0. 1. 1. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 1. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2] -> size -> 69 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 1. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2] -> size -> 69 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0.  0. 26. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 1. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2] -> size -> 70 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 25. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.  150.    0.    0.    0.    0.    0. 1500.    0. -350.
    0.    0.  108.    0.] 
sum of rewards: 1403.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 25. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 1. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2] -> size -> 70 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 25. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 1. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2] -> size -> 70 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 25. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 1. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2] -> size -> 70 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2] -> size -> 70 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 25. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2] -> size -> 70 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 25. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2] -> size -> 71 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 24. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.  150.    0.    0.    0.    0.    0. 1500.    0. -360.
    0.    0.  108.    0.] 
sum of rewards: 1393.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 24. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 1. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2. 0. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2] -> size -> 71 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 24. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 1. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2. 0. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2] -> size -> 71 
adversary victory points: 5
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [0. 1. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2. 0. 0. 1. 1. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2] -> size -> 71 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 24. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2. 0. 0. 1. 1. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2] -> size -> 71 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 24. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2. 0. 0. 1. 1. 0. 2.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2] -> size -> 72 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 23. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.  150.    0.    0.    0.    0.    0. 1500.    0. -370.
    0.    0.  108.    0.] 
sum of rewards: 1383.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 23. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 1. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2. 0. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2] -> size -> 72 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 23. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 1. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2. 0. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2] -> size -> 72 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 23. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 1. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2. 0. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2] -> size -> 72 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 1. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2. 0. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2] -> size -> 72 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 23. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2. 0. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2] -> size -> 72 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 23. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2. 0. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2] -> size -> 73 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 22. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.  150.    0.    0.    0.    0.    0. 1500.    0. -380.
    0.    0.  108.    0.] 
sum of rewards: 1373.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2. 0. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 0. 1. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2] -> size -> 73 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2. 0. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 0. 1. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2] -> size -> 73 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 22. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2. 0. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 0. 1. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2] -> size -> 73 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [0. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2. 0. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 0. 1. 0. 1. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2] -> size -> 73 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2. 0. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 0. 1. 0. 1. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2] -> size -> 73 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 22. 23. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 1. 3. 0. 1. 0. 0. 3. 2. 1. 0. 1. 1. 3.
 2. 0. 0. 1. 0. 1. 3. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 2. 0. 1. 1. 1. 1.
 2. 0. 0. 1. 1. 0. 2. 0. 1. 1. 0. 1. 2. 0. 1. 0. 1. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3] -> size -> 74 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 22. 22. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[  -5.    0.    0.  180.    0.    0.    0.    0.    0.    0.    0. -390.
    0.    0.    4.    0.] 
sum of rewards: -211.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 22. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3] -> size -> 74 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 22. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3] -> size -> 74 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 22. 22. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3] -> size -> 74 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 1.] 
cards in discard: [] 
cards in deck: 69 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3] -> size -> 74 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 22. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 1.] 
cards in discard: [] 
cards in deck: 69 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3] -> size -> 74 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0. 22. 22. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 1.] 
cards in discard: [2.] 
cards in deck: 69 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2] -> size -> 75 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 22. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  180    0    0    0    0    0 1500    0 -400    0    0
  432    0] 
sum of rewards: 1707 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 22. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2] -> size -> 75 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 22. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2] -> size -> 75 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 21. 22. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2] -> size -> 75 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [0. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [2. 3. 0. 0. 1. 1.] 
cards in deck: 64 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2] -> size -> 75 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 22. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [2. 3. 0. 0. 1. 1.] 
cards in deck: 64 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2] -> size -> 75 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 21. 22. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3.] 
cards in deck: 64 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3] -> size -> 76 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 21. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.  210.    0.    0.    0.    0.    0.    0.    0. -410.
    0.    0.    4.    0.] 
sum of rewards: -201.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3] -> size -> 76 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3] -> size -> 76 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 21. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3] -> size -> 76 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0.] 
cards in deck: 59 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3] -> size -> 76 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0.] 
cards in deck: 59 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3] -> size -> 76 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 21. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2.] 
cards in deck: 59 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2] -> size -> 77 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 20. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.  210.    0.    0.    0.    0.    0. 1500.    0. -420.
    0.    0.  108.    0.] 
sum of rewards: 1393.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 20. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 1. 1. 0. 3.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2] -> size -> 77 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 20. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 1. 1. 0. 3.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2] -> size -> 77 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 20. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 1. 1. 0. 3.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2] -> size -> 77 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [1. 1. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1. 0. 3.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1.] 
cards in deck: 54 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2] -> size -> 77 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 20. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0. 3.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1.] 
cards in deck: 54 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2] -> size -> 77 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 20. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0. 3.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2.] 
cards in deck: 54 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2] -> size -> 78 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 19. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.  210.    0.    0.    0.    0.    0. 1500.    0. -430.
    0.    0.  108.    0.] 
sum of rewards: 1383.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 19. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 3. 1. 0.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2] -> size -> 78 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 19. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 3. 1. 0.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2] -> size -> 78 
adversary victory points: 7
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [1. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 1. 0.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2] -> size -> 78 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 19. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 1. 0.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2] -> size -> 78 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0. 19. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 1. 0.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2.] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2] -> size -> 79 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 18. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  210    0    0    0    0    0 1500    0 -440    0    0
  432    0] 
sum of rewards: 1697 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 18. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2] -> size -> 79 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 18. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2] -> size -> 79 
adversary victory points: 7
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2] -> size -> 79 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 18. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2] -> size -> 79 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0. 18. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2] -> size -> 80 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 17. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  210    0    0    0    0    0 1500    0 -450    0    0
  432    0] 
sum of rewards: 1687 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 17. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 2. 1. 0. 1.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2] -> size -> 80 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 17. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 2. 1. 0. 1.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2] -> size -> 80 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 17. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 2. 1. 0. 1.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2] -> size -> 80 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 71 -------------------- 
Player: 0 
cards in hand: [0. 2. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 2. 1. 0. 1.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2] -> size -> 80 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 17. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 1. 0. 1.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2] -> size -> 80 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0.  0. 17. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 1. 0. 1.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2] -> size -> 81 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 16. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.  210.    0.    0.    0.    0.    0. 1500.    0. -460.
    0.    0.  108.    0.] 
sum of rewards: 1353.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 16. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 0. 3. 1. 2.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2] -> size -> 81 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 16. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 0. 3. 1. 2.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2] -> size -> 81 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 16. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 0. 3. 1. 2.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2] -> size -> 81 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 72 -------------------- 
Player: 0 
cards in hand: [2. 0. 3. 1. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0. 3. 1. 2.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2] -> size -> 81 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 16. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 3. 1. 2.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2] -> size -> 81 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0.  0. 16. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 3. 1. 2.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2] -> size -> 82 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 15. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.  210.    0.    0.    0.    0.    0. 1500.    0. -470.
    0.    0.  108.    0.] 
sum of rewards: 1343.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 15. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2] -> size -> 82 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 15. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2] -> size -> 82 
adversary victory points: 7
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 73 -------------------- 
Player: 0 
cards in hand: [1. 0. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2] -> size -> 82 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 15. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2] -> size -> 82 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 15. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2] -> size -> 83 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 14. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.  210.    0.    0.    0.    0.    0. 1500.    0. -480.
    0.    0.  108.    0.] 
sum of rewards: 1333.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 14. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2] -> size -> 83 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 14. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2] -> size -> 83 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 14. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2] -> size -> 83 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 74 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2] -> size -> 83 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 14. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2] -> size -> 83 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 14. 21. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3] -> size -> 84 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 14. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  240.    0.    0.    0.    0.    0.    0.    0. -490.
    0.    0.    4.    0.] 
sum of rewards: -251.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 14. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 2.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3] -> size -> 84 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 14. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 2.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3] -> size -> 84 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 14. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 2.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3] -> size -> 84 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 75 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 0. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 2.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3] -> size -> 84 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 14. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 2.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3] -> size -> 84 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 14. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 2.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3. 2.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2] -> size -> 85 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 13. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  240.    0.    0.    0.    0.    0. 1500.    0. -500.
    0.    0.  108.    0.] 
sum of rewards: 1343.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 13. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 2. 0. 0. 1.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 0. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2] -> size -> 85 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 13. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 2. 0. 0. 1.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 0. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2] -> size -> 85 
adversary victory points: 8
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 76 -------------------- 
Player: 0 
cards in hand: [1. 2. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 2. 0. 0. 1.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 0. 2.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2] -> size -> 85 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 13. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 2. 0. 0. 1.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 0. 2.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2] -> size -> 85 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0.  0. 13. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 2. 0. 0. 1.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 0. 2. 2.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2] -> size -> 86 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 12. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  240.    0.    0.    0.    0.    0. 1500.    0. -510.
    0.    0.  108.    0.] 
sum of rewards: 1333.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 12. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 0. 1. 0. 0.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 0. 2. 2. 1. 2. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2] -> size -> 86 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 12. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 0. 1. 0. 0.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 0. 2. 2. 1. 2. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2] -> size -> 86 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 12. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 0. 1. 0. 0.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 0. 2. 2. 1. 2. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2] -> size -> 86 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 77 -------------------- 
Player: 0 
cards in hand: [2. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0. 1. 0. 0.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 0. 2. 2. 1. 2. 0. 0. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2] -> size -> 86 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 12. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 1. 0. 0.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 0. 2. 2. 1. 2. 0. 0. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2] -> size -> 86 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 12. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 1. 0. 0.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 0. 2. 2. 1. 2. 0. 0. 1.
 2.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2] -> size -> 87 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 11. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  240.    0.    0.    0.    0.    0. 1500.    0. -520.
    0.    0.  108.    0.] 
sum of rewards: 1323.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 11. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 1. 1. 1. 1.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 0. 2. 2. 1. 2. 0. 0. 1.
 2. 2. 0. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2] -> size -> 87 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 11. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 1. 1. 1. 1.] 
adversary cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 0. 2. 2. 1. 2. 0. 0. 1.
 2. 2. 0. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2] -> size -> 87 
adversary victory points: 8
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 78 -------------------- 
Player: 0 
cards in hand: [2. 1. 1. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 1. 1. 1. 1.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 0. 2. 2. 1. 2. 0. 0. 1.
 2. 2. 0. 1. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2] -> size -> 87 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 11. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 1. 1. 1. 1.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 0. 2. 2. 1. 2. 0. 0. 1.
 2. 2. 0. 1. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2] -> size -> 87 
action values: 0 
buys: 1 
player value: 11 
card supply: [ 0.  0. 11. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 1. 1. 1. 1.] 
cards in discard: [2. 3. 0. 0. 1. 1. 3. 0. 1. 3. 0. 0. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 0. 0. 2. 0. 2. 1. 0. 1. 2. 2. 0. 3. 1. 2.
 2. 1. 0. 1. 1. 0. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 0. 2. 2. 1. 2. 0. 0. 1.
 2. 2. 0. 1. 0. 0. 2.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2] -> size -> 88 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0.  0. 10. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  240.    0.    0.    0.    0.    0. 1500.    0. -530.
    0.    0.  108.    0.] 
sum of rewards: 1313.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 10. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 2. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2] -> size -> 88 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 10. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 2. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2] -> size -> 88 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 10. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 2. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2] -> size -> 88 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 79 -------------------- 
Player: 0 
cards in hand: [1. 2. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 2. 1. 1. 0.] 
cards in discard: [] 
cards in deck: 83 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2] -> size -> 88 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 10. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 2. 1. 1. 0.] 
cards in discard: [] 
cards in deck: 83 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2] -> size -> 88 
action values: 0 
buys: 1 
player value: 10 
card supply: [ 0.  0. 10. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 2. 1. 1. 0.] 
cards in discard: [2.] 
cards in deck: 83 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2] -> size -> 89 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0.  0.  9. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  240.    0.    0.    0.    0.    0. 1500.    0. -540.
    0.    0.  108.    0.] 
sum of rewards: 1303.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  9. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 2. 1. 1. 3.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2] -> size -> 89 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0.  9. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 2. 1. 1. 3.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2] -> size -> 89 
adversary victory points: 8
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 80 -------------------- 
Player: 0 
cards in hand: [2. 2. 1. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 2. 1. 1. 3.] 
cards in discard: [2. 1. 2. 1. 1. 0.] 
cards in deck: 78 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2] -> size -> 89 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  9. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 2. 1. 1. 3.] 
cards in discard: [2. 1. 2. 1. 1. 0.] 
cards in deck: 78 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2] -> size -> 89 
action values: 0 
buys: 1 
player value: 10 
card supply: [ 0.  0.  9. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 2. 1. 1. 3.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2.] 
cards in deck: 78 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2] -> size -> 90 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0.  0.  8. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  240.    0.    0.    0.    0.    0. 1500.    0. -550.
    0.    0.  108.    0.] 
sum of rewards: 1293.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  8. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 1. 0. 2. 2.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2] -> size -> 90 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0.  8. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 1. 0. 2. 2.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2] -> size -> 90 
adversary victory points: 8
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 81 -------------------- 
Player: 0 
cards in hand: [1. 1. 0. 2. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 2. 2.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3.] 
cards in deck: 73 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2] -> size -> 90 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  8. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 2. 2.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3.] 
cards in deck: 73 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2] -> size -> 90 
action values: 0 
buys: 1 
player value: 11 
card supply: [ 0.  0.  8. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 2. 2.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2.] 
cards in deck: 73 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2] -> size -> 91 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0.  0.  7. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  240.    0.    0.    0.    0.    0. 1500.    0. -560.
    0.    0.  108.    0.] 
sum of rewards: 1283.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  7. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 1.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2] -> size -> 91 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0.  7. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 1.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2] -> size -> 91 
adversary victory points: 8
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 82 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 1.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2.] 
cards in deck: 68 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2] -> size -> 91 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  7. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 1.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2.] 
cards in deck: 68 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2] -> size -> 91 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0.  7. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 1.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2.] 
cards in deck: 68 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2] -> size -> 92 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  6. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  240    0    0    0    0    0 1500    0 -570    0    0
  432    0] 
sum of rewards: 1597 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  6. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 1. 0. 0. 0.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2] -> size -> 92 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0.  6. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 1. 0. 0. 0.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2] -> size -> 92 
adversary victory points: 8
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 83 -------------------- 
Player: 0 
cards in hand: [2. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 1. 0. 0. 0.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.] 
cards in deck: 63 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2] -> size -> 92 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  6. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 1. 0. 0. 0.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.] 
cards in deck: 63 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2] -> size -> 92 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0.  6. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 1. 0. 0. 0.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2.] 
cards in deck: 63 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2] -> size -> 93 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0.  5. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  240.    0.    0.    0.    0.    0. 1500.    0. -580.
    0.    0.  108.    0.] 
sum of rewards: 1263.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  5. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 1. 1. 0. 0.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2] -> size -> 93 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0.  5. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 1. 1. 0. 0.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2] -> size -> 93 
adversary victory points: 8
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 84 -------------------- 
Player: 0 
cards in hand: [1. 1. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1. 0. 0.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0.] 
cards in deck: 58 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2] -> size -> 93 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  5. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0. 0.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0.] 
cards in deck: 58 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2] -> size -> 93 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0.  5. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0. 0.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2.] 
cards in deck: 58 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2] -> size -> 94 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0.  4. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  240.    0.    0.    0.    0.    0. 1500.    0. -590.
    0.    0.  108.    0.] 
sum of rewards: 1253.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  4. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 2. 1.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2] -> size -> 94 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  4. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 2. 1.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2] -> size -> 94 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0.  4. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 2. 1.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2] -> size -> 94 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 85 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 2. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 2. 1.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0.] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2] -> size -> 94 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  4. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 2. 1.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0.] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2] -> size -> 94 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0.  0.  4. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 2. 1.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2.] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2] -> size -> 95 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0.  3. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  240.    0.    0.    0.    0.    0. 1500.    0. -600.
    0.    0.  108.    0.] 
sum of rewards: 1243.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  3. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 2.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2. 0. 1. 0. 2. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2] -> size -> 95 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0.  3. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 2.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2. 0. 1. 0. 2. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2] -> size -> 95 
adversary victory points: 8
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 86 -------------------- 
Player: 0 
cards in hand: [1. 0. 3. 0. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 2.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2. 0. 1. 0. 2. 1.] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2] -> size -> 95 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  3. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 2.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2. 0. 1. 0. 2. 1.] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2] -> size -> 95 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0.  3. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 2.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2. 0. 1. 0. 2. 1. 2.] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2] -> size -> 96 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0.  2. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  240.    0.    0.    0.    0.    0. 1500.    0. -610.
    0.    0.  108.    0.] 
sum of rewards: 1233.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  2. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 2. 0. 2. 0.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2. 0. 1. 0. 2. 1. 2. 1. 0. 3. 0. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2] -> size -> 96 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  2. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 2. 0. 2. 0.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2. 0. 1. 0. 2. 1. 2. 1. 0. 3. 0. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2] -> size -> 96 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0.  2. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 2. 0. 2. 0.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2. 0. 1. 0. 2. 1. 2. 1. 0. 3. 0. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2] -> size -> 96 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 87 -------------------- 
Player: 0 
cards in hand: [2. 2. 0. 2. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 2. 0. 2. 0.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2. 0. 1. 0. 2. 1. 2. 1. 0. 3. 0. 2.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2] -> size -> 96 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  2. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 2. 0. 2. 0.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2. 0. 1. 0. 2. 1. 2. 1. 0. 3. 0. 2.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2] -> size -> 96 
action values: 0 
buys: 1 
player value: 11 
card supply: [ 0.  0.  2. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



buy possibilites: [-1] 
expected returns: [[-16.236362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 2. 0. 2. 0.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2. 0. 1. 0. 2. 1. 2. 1. 0. 3. 0. 2.
 2.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2] -> size -> 97 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0.  0.  1. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  240.    0.    0.    0.    0.    0. 1500.    0. -620.
    0.    0.  108.    0.] 
sum of rewards: 1223.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -16.23636245727539






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  1. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 0. 2. 0. 1.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2. 0. 1. 0. 2. 1. 2. 1. 0. 3. 0. 2.
 2. 2. 2. 0. 2. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2] -> size -> 97 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  1. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 0. 2. 0. 1.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2. 0. 1. 0. 2. 1. 2. 1. 0. 3. 0. 2.
 2. 2. 2. 0. 2. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2] -> size -> 97 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0.  1. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [2. 0. 2. 0. 1.] 
adversary cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2. 0. 1. 0. 2. 1. 2. 1. 0. 3. 0. 2.
 2. 2. 2. 0. 2. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2] -> size -> 97 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 88 -------------------- 
Player: 0 
cards in hand: [2. 0. 2. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-16.236362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0. 2. 0. 1.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2. 0. 1. 0. 2. 1. 2. 1. 0. 3. 0. 2.
 2. 2. 2. 0. 2. 0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2] -> size -> 97 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  1. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.23636245727539





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]
 [-16.236364]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 2. 0. 1.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2. 0. 1. 0. 2. 1. 2. 1. 0. 3. 0. 2.
 2. 2. 2. 0. 2. 0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2] -> size -> 97 
action values: 0 
buys: 1 
player value: 10 
card supply: [ 0.  0.  1. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.23636245727539



Player 0 won the game! 



Player 0 bought cards:
Copper: 25 
Silver: 28 
Gold: 30 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [2. 0. 2. 0. 1.] 
cards in discard: [2. 1. 2. 1. 1. 0. 2. 2. 2. 1. 1. 3. 2. 1. 1. 0. 2. 2. 2. 0. 0. 1. 3. 1.
 2. 2. 1. 0. 0. 0. 2. 1. 1. 1. 0. 0. 2. 0. 1. 0. 2. 1. 2. 1. 0. 3. 0. 2.
 2. 2. 2. 0. 2. 0. 2.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 2 2 3 2 2 2 2 2 3
 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2] -> size -> 98 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0.  0.  0. 20. 30.  8. 10. 10. 10.  5. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[     -5 3000000       0     240       0       0       0       0       0
    1500       0    -630       0       0     216       0] 
sum of rewards: 3001321 

action type: buy - action 2.0
Learning step: 300133.71875
desired expected reward: 300117.46875



