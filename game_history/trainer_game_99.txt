 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[330.99765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    6  -20    0    0   20  -30    0    0    0   -2    0    0
    0    0] 
sum of rewards: -531 

action type: buy - action 0.0
Learning step: -25.623947143554688
desired expected reward: -44.144996643066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[294.11172]
 [315.2974 ]
 [306.20224]
 [251.57019]
 [303.5144 ]
 [325.0299 ]
 [308.7828 ]
 [306.86362]
 [273.061  ]
 [303.95233]
 [292.4451 ]
 [326.02115]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.035764694213867
desired expected reward: 325.74322509765625



buy possibilites: [-1] 
expected returns: [[314.4844]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 1.0
Learning step: -8.563972473144531
desired expected reward: 306.73345947265625






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[298.3654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.099126815795898
desired expected reward: 305.3852844238281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[267.75732]
 [288.8146 ]
 [280.21985]
 [226.56996]
 [298.80515]
 [281.38318]
 [277.14322]
 [301.53952]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.710284233093262
desired expected reward: 290.1827697753906



buy possibilites: [-1] 
expected returns: [[282.97202]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1. 0. 0. 0. 0. 3. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -7.7022905349731445
desired expected reward: 273.680908203125






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [1. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 3. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[283.819]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [1. 1. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.859733581542969
desired expected reward: 275.1122741699219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[257.95074]
 [272.6076 ]
 [266.00067]
 [228.73912]
 [278.647  ]
 [267.93585]
 [264.43665]
 [279.8087 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [1. 1. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.291594505310059
desired expected reward: 275.6580810546875



buy possibilites: [-1] 
expected returns: [[295.20892]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [1. 1. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -7.855340003967285
desired expected reward: 250.095458984375






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [29.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [1. 1. 3. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [1. 1. 3. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [ 1.  1.  3.  3.  3.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 8. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[267.9639 ]
 [251.65329]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 1.] 
cards in discard: [0. 0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.01190185546875
desired expected reward: 286.197021484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[246.20741]
 [265.9425 ]
 [258.29886]
 [222.12227]
 [210.94191]
 [254.77109]
 [274.1273 ]
 [258.63992]
 [287.6832 ]
 [257.02655]
 [228.28862]
 [238.36624]
 [254.82465]
 [219.3707 ]
 [244.90231]
 [275.99026]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 1.] 
cards in discard: [0. 0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 27. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.688662052154541
desired expected reward: 259.2006530761719



buy possibilites: [-1] 
expected returns: [[286.20535]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 1.] 
cards in discard: [ 0.  0.  0.  0.  3.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8  0 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 48 

action type: buy - action 25.0
Learning step: -5.544536113739014
desired expected reward: 282.13861083984375






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8  0 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 30. 30.  8. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8  0 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8. 10.  9. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8  0 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[274.7175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8  0 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8. 10.  9. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  0.  3.] 
adversary cards in discard: [10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.220972061157227
desired expected reward: 277.984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[247.16728]
 [266.17346]
 [258.1471 ]
 [210.50491]
 [273.87094]
 [259.38806]
 [255.30206]
 [276.3404 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8  0 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 30. 30.  8. 10.  9. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  0.  3.] 
adversary cards in discard: [10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.02441120147705
desired expected reward: 267.055419921875



buy possibilites: [-1] 
expected returns: [[246.23776]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8  0 25  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8. 10.  9. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  0.  3.] 
adversary cards in discard: [10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 1.0
Learning step: -6.968325138092041
desired expected reward: 259.2051696777344






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  0.  3.] 
cards in discard: [10.  0.  3.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8. 10.  9. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25.  1.  0.  8.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8  0 25  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1.  0.  3.] 
cards in discard: [10.  0.  3.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 26. 30. 30. 30.  8. 10.  9. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25.  1.  0.  8.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8  0 25  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1.  0.  3.] 
cards in discard: [10.  0.  3.  3.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 26. 30. 30. 30.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25.  1.  0.  8.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8  0 25  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 25.  1.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[329.0227 ]
 [344.44012]
 [315.3765 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1.  0.  8.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8  0 25  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -5.046594142913818
desired expected reward: 241.191162109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[298.95938]
 [318.44077]
 [309.2519 ]
 [259.8774 ]
 [308.05896]
 [325.22498]
 [312.5025 ]
 [310.57373]
 [278.68628]
 [306.6647 ]
 [295.6431 ]
 [325.68958]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  1.  0.  8.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8  0 25  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 26. 30. 30. 30.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.404419898986816
desired expected reward: 315.0734558105469



buy possibilites: [-1] 
expected returns: [[200.75137]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  1.  0.  8.] 
cards in discard: [ 1.  0.  3.  0.  0.  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8  0 25  1 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 15.0
Learning step: -7.825898170471191
desired expected reward: 269.0301818847656






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8  0 25  1 15] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 26. 30. 30. 30.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8  0 25  1 15] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1.  0.  0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 26. 30. 29. 30.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8  0 25  1 15] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [15.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[233.13036]
 [209.73305]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8  0 25  1 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [ 3.  0. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -5.634688854217529
desired expected reward: 195.11668395996094



action possibilites: [-1] 
expected returns: [[213.56471]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 25  1 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 26. 30. 29. 30.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [ 3.  0. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action 15.0
Learning step: -5.282566547393799
desired expected reward: 204.47288513183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[193.40437]
 [211.02855]
 [203.25848]
 [171.31131]
 [160.199  ]
 [201.234  ]
 [216.57219]
 [204.76987]
 [228.12549]
 [203.01434]
 [176.51224]
 [185.2043 ]
 [200.1888 ]
 [168.21323]
 [190.81563]
 [217.42372]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 25  1 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 26. 30. 29. 30.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [ 3.  0. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -5.759799003601074
desired expected reward: 207.80491638183594






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 3.] 
cards in discard: [ 3.  0. 16.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  1.  0. 25.  0.] 
adversary cards in discard: [15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 25  1 15] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 3.] 
cards in discard: [ 3.  0. 16.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 29. 30.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  1.  0. 25.  0.] 
adversary cards in discard: [15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 25  1 15] -> size -> 15 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  1.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[203.53195]
 [213.79626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 25.  0.] 
cards in discard: [15.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 25  1 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0. 10.  3.  0.] 
adversary cards in discard: [ 3.  0. 16.  1.  0.  0.  0.  3.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -6.880053997039795
desired expected reward: 210.54367065429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[194.703  ]
 [207.72147]
 [201.29869]
 [176.09383]
 [166.48972]
 [200.57625]
 [212.71513]
 [204.20476]
 [223.10625]
 [202.76505]
 [179.95862]
 [186.89526]
 [199.28845]
 [172.90776]
 [192.18826]
 [211.3573 ]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 25.  0.] 
cards in discard: [15.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 25  1 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 26. 30. 29. 30.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0. 10.  3.  0.] 
adversary cards in discard: [ 3.  0. 16.  1.  0.  0.  0.  3.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -6.011532783508301
desired expected reward: 192.2550811767578



buy possibilites: [-1] 
expected returns: [[213.233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 25.  0.] 
cards in discard: [15.  3.  0.  0.  4.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 25  1 15  4] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 29.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0. 10.  3.  0.] 
adversary cards in discard: [ 3.  0. 16.  1.  0.  0.  0.  3.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 71 

action type: buy - action 4.0
Learning step: -0.45694658160209656
desired expected reward: 175.63685607910156






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 1.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  3.  0.] 
cards in discard: [ 3.  0. 16.  1.  0.  0.  0.  3.  8.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 29.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 1. 8.] 
adversary cards in discard: [15.  3.  0.  0.  4.  0.  1.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 25  1 15  4] -> size -> 16 
adversary victory points: 6
player victory points: 4 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  0. 29.] 
cards in discard: [ 3.  0. 16.  1.  0.  0.  0.  3.  8.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 29.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 1. 8.] 
adversary cards in discard: [15.  3.  0.  0.  4.  0.  1.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 25  1 15  4] -> size -> 16 
adversary victory points: 6
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3] -> size -> 17 
action values: 2 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 29. 29.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 1. 8.] 
adversary cards in discard: [15.  3.  0.  0.  4.  0.  1.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 25  1 15  4] -> size -> 16 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 26. 30. 29. 29.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 1. 8.] 
adversary cards in discard: [15.  3.  0.  0.  4.  0.  1.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 25  1 15  4] -> size -> 16 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 25. 30. 29. 29.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 1. 8.] 
adversary cards in discard: [15.  3.  0.  0.  4.  0.  1.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 25  1 15  4] -> size -> 16 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [3. 3. 0. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[179.60922]
 [165.92888]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 1. 8.] 
cards in discard: [15.  3.  0.  0.  4.  0.  1.  0. 25.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  8  0 25  1 15  4] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 29. 29.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 1. 10. 29.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1] -> size -> 18 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: buy - action -1
Learning step: -5.659592628479004
desired expected reward: 207.5734100341797



action possibilites: [-1] 
expected returns: [[257.97183]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [15.  3.  0.  0.  4.  0.  1.  0. 25.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  8  0 25  1 15  4] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 29. 29.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 1. 10. 29.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: trash_cards_n_from_hand - action 9
Learning step: -2.956439256668091
desired expected reward: 191.25965881347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[238.88586]
 [206.64052]
 [259.84058]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15.  3.  0.  0.  4.  0.  1.  0. 25.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  8  0 25  1 15  4] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 25. 30. 29. 29.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 1. 10. 29.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -6.570599555969238
desired expected reward: 251.40122985839844



buy possibilites: [-1] 
expected returns: [[289.69556]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15.  3.  0.  0.  4.  0.  1.  0. 25.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  8  0 25  1 15  4  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 29. 29.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 1. 10. 29.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.   0.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -11.0 

action type: buy - action 0.0
Learning step: -5.976142883300781
desired expected reward: 232.90969848632812






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [ 1. 10. 29.  1.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 4. 15. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  0 25  1 15  4  0] -> size -> 14 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [ 1. 10. 29.  1.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 30. 29. 29.  8. 10.  9. 10.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 4. 15. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  0 25  1 15  4  0] -> size -> 14 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [ 1. 10. 29.  1.  0.  3.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 29. 29.  8. 10.  9. 10.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 4. 15. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  0 25  1 15  4  0] -> size -> 14 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 4. 15. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[251.86371]
 [224.55292]
 [259.9047 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 15. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  0 25  1 15  4  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8. 10.  9. 10.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  1.  3.  3.] 
adversary cards in discard: [ 1. 10. 29.  1.  0.  3.  0.  0.  8.  3.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -8.913286209106445
desired expected reward: 280.7822570800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[219.20589]
 [229.96461]
 [176.36674]
 [231.63472]
 [246.12184]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 15. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  0 25  1 15  4  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 25. 30. 29. 29.  8. 10.  9. 10.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  1.  3.  3.] 
adversary cards in discard: [ 1. 10. 29.  1.  0.  3.  0.  0.  8.  3.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -7.708197116851807
desired expected reward: 246.5598602294922



buy possibilites: [-1] 
expected returns: [[245.82689]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 15. 25.  0.  0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  0 25  1 15  4  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8. 10.  9. 10.  6.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  1.  3.  3.] 
adversary cards in discard: [ 1. 10. 29.  1.  0.  3.  0.  0.  8.  3.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 7 

action type: buy - action 8.0
Learning step: -5.700629711151123
desired expected reward: 225.93406677246094






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  1.  3.  3.] 
cards in discard: [ 1. 10. 29.  1.  0.  3.  0.  0.  8.  3.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 29.  8. 10.  9. 10.  6.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 8. 0. 3. 0.] 
adversary cards in discard: [ 8.  4. 15. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  0 25  1 15  4  0  8] -> size -> 15 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1.  3.  3.] 
cards in discard: [ 1. 10. 29.  1.  0.  3.  0.  0.  8.  3.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 30. 29. 29.  8. 10.  9. 10.  6.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 8. 0. 3. 0.] 
adversary cards in discard: [ 8.  4. 15. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  0 25  1 15  4  0  8] -> size -> 15 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1.  3.  3.] 
cards in discard: [ 1. 10. 29.  1.  0.  3.  0.  0.  8.  3.  0.  0.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 25. 30. 29. 29.  8. 10.  9. 10.  6.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 8. 0. 3. 0.] 
adversary cards in discard: [ 8.  4. 15. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  0 25  1 15  4  0  8] -> size -> 15 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [1. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[234.81346]
 [225.42052]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 3. 0.] 
cards in discard: [ 8.  4. 15. 25.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  0 25  1 15  4  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 29.  8. 10.  9. 10.  6.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  3.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -7.248165130615234
desired expected reward: 238.57872009277344



action possibilites: [-1] 
expected returns: [[176.98474]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3.] 
cards in discard: [ 8.  4. 15. 25.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  0 25  1 15  4  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 29.  8. 10.  9. 10.  6.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  3.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: trash_cards_n_from_hand - action 3
Learning step: -5.38375997543335
desired expected reward: 200.9345703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[162.13628]
 [166.99985]
 [134.86198]
 [170.40277]
 [175.34952]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [ 8.  4. 15. 25.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  0 25  1 15  4  0  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 29. 29.  8. 10.  9. 10.  6.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  3.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -4.207797527313232
desired expected reward: 172.77694702148438



buy possibilites: [-1] 
expected returns: [[135.08315]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [ 8.  4. 15. 25.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  0 25  1 15  4  0  8  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 29.  8. 10.  9. 10.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  3.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 27 

action type: buy - action 8.0
Learning step: -4.130767345428467
desired expected reward: 166.27198791503906






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  1.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 29.  8. 10.  9. 10.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  0 25  1 15  4  0  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 29.  8. 10.  9. 10.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  0 25  1 15  4  0  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 25. 30. 29. 29.  8. 10.  9. 10.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  0 25  1 15  4  0  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [25.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[146.26912]
 [156.95274]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  0 25  1 15  4  0  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 29.  8. 10.  9. 10.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [10.  0.  3.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -3.3905980587005615
desired expected reward: 131.6925506591797



action possibilites: [-1] 
expected returns: [[195.23566]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  8  0 25  1 15  4  0  8  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 29.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [10.  0.  3.  1.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6] -> size -> 21 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 20 

action type: take_action - action 25.0
Learning step: -2.398378372192383
desired expected reward: 153.42523193359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[180.77138]
 [191.59518]
 [185.29819]
 [164.66005]
 [156.0476 ]
 [185.77414]
 [193.45471]
 [188.58246]
 [204.37279]
 [187.14206]
 [167.16594]
 [173.40202]
 [183.25227]
 [161.52974]
 [177.3093 ]
 [191.3331 ]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  8  0 25  1 15  4  0  8  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 25. 30. 29. 29.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [10.  0.  3.  1.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6] -> size -> 21 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -4.661422252655029
desired expected reward: 190.57423400878906



buy possibilites: [-1] 
expected returns: [[151.78966]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0. 3.] 
cards in discard: [4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  8  0 25  1 15  4  0  8  8  4] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [10.  0.  3.  1.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6] -> size -> 21 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 102 

action type: buy - action 4.0
Learning step: 0.28226396441459656
desired expected reward: 164.94232177734375






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 3. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [10.  0.  3.  1.  0.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  8.  1.  8.] 
adversary cards in discard: [ 4. 25.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  8  0 25  1 15  4  0  8  8  4] -> size -> 15 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [10.  0.  3.  1.  0.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 25. 30. 29. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  8.  1.  8.] 
adversary cards in discard: [ 4. 25.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  8  0 25  1 15  4  0  8  8  4] -> size -> 15 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [10.  0.  3.  1.  0.  8.  6. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 29. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [15.  0.  8.  1.  8.] 
adversary cards in discard: [ 4. 25.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  8  0 25  1 15  4  0  8  8  4] -> size -> 15 
adversary victory points: 7
player victory points: 3 





Player: 0 
cards in hand: [15.  0.  8.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
expected returns: [[187.97311]
 [168.3398 ]
 [175.74838]
 [175.74838]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8.  1.  8.] 
cards in discard: [ 4. 25.  0.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  0 25  1 15  4  0  8  8  4] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [10.  0.  3.  1.  0.  8.  6. 15.  0.  3.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15] -> size -> 22 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: buy - action -1
Learning step: -1.5301369428634644
desired expected reward: 150.259521484375



action possibilites: [-1] 
expected returns: [[145.84703]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.] 
cards in discard: [ 4. 25.  0.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 25  1 15  4  0  8  8  4] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [10.  0.  3.  1.  0.  8.  6. 15.  0.  3.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15] -> size -> 22 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: trash_cards_n_from_hand - action 9
Learning step: -2.5686118602752686
desired expected reward: 176.43478393554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[135.2116  ]
 [142.68468 ]
 [116.424095]
 [142.94153 ]
 [154.42998 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.] 
cards in discard: [ 4. 25.  0.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 25  1 15  4  0  8  8  4] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 29. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [10.  0.  3.  1.  0.  8.  6. 15.  0.  3.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15] -> size -> 22 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: take_action - action -1
Learning step: -1.022619605064392
desired expected reward: 144.8244171142578






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  0.] 
cards in discard: [10.  0.  3.  1.  0.  8.  6. 15.  0.  3.  1.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [4. 8. 0. 4. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 25  1 15  4  0  8  8  4] -> size -> 13 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [10.  0.  3.  1.  0.  8.  6. 15.  0.  3.  1.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 29. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [4. 8. 0. 4. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 25  1 15  4  0  8  8  4] -> size -> 13 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [10.  0.  3.  1.  0.  8.  6. 15.  0.  3.  1.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 25. 30. 29. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [4. 8. 0. 4. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 25  1 15  4  0  8  8  4] -> size -> 13 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [10.  0.  3.  1.  0.  8.  6. 15.  0.  3.  1.  1.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  7.] 
adversary cards in hand: [4. 8. 0. 4. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 25  1 15  4  0  8  8  4] -> size -> 13 
adversary victory points: 7
player victory points: 3 





Player: 0 
cards in hand: [4. 8. 0. 4. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[110.82378]
 [103.65429]
 [103.65429]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 8. 0. 4. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 25  1 15  4  0  8  8  4] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  7.] 
adversary cards in hand: [15.  0.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15] -> size -> 23 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: buy - action -1.0
Learning step: -3.239938497543335
desired expected reward: 151.1900177001953



action possibilites: [-1] 
expected returns: [[133.96454]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 25  1 15  0  8  4] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  7.] 
adversary cards in hand: [15.  0.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15] -> size -> 23 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: trash_cards_n_from_hand - action 8
Learning step: -0.504743218421936
desired expected reward: 98.87416076660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[112.20256]
 [ 79.81033]
 [132.25311]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 25  1 15  0  8  4] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 25. 30. 29. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  7.] 
adversary cards in hand: [15.  0.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15] -> size -> 23 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1
Learning step: -2.7304577827453613
desired expected reward: 131.2340850830078






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [15.  0.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  7.] 
adversary cards in hand: [25.  0.  0. 15.  0.] 
adversary cards in discard: [8. 4.] 
adversary owned cards: [ 0  0  3  0 25  1 15  0  8  4] -> size -> 10 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  7.] 
adversary cards in hand: [25.  0.  0. 15.  0.] 
adversary cards in discard: [8. 4.] 
adversary owned cards: [ 0  0  3  0 25  1 15  0  8  4] -> size -> 10 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 25. 30. 28. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  7.] 
adversary cards in hand: [25.  0.  0. 15.  0.] 
adversary cards in discard: [8. 4.] 
adversary owned cards: [ 0  0  3  0 25  1 15  0  8  4] -> size -> 10 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [25.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
expected returns: [[157.00475]
 [165.66594]
 [134.04478]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 15.  0.] 
cards in discard: [8. 4.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 25  1 15  0  8  4] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  7.] 
adversary cards in hand: [ 1.  3.  1.  0. 29.] 
adversary cards in discard: [ 3. 16. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -3.0192058086395264
desired expected reward: 125.70386505126953



action possibilites: [-1] 
expected returns: [[94.39195]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.] 
cards in discard: [8. 4.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0 25  1 15  0  8  4] -> size -> 9 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 25. 30. 28. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  7.] 
adversary cards in hand: [ 1.  3.  1.  0. 29.] 
adversary cards in discard: [ 3. 16. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action 15.0
Learning step: -3.6411049365997314
desired expected reward: 130.65737915039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 70.83775 ]
 [ 86.94999 ]
 [ 79.116714]
 [ 44.776237]
 [ 31.884874]
 [ 76.80728 ]
 [ 92.61817 ]
 [ 79.822174]
 [101.53871 ]
 [ 78.15605 ]
 [ 51.89379 ]
 [ 63.57551 ]
 [ 75.54283 ]
 [ 40.3189  ]
 [ 68.39373 ]
 [ 92.34681 ]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.] 
cards in discard: [8. 4.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0 25  1 15  0  8  4] -> size -> 9 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 25. 30. 28. 28.  8.  9.  9. 10.  5.  9.  9. 10. 10.  9. 10.  7.] 
adversary cards in hand: [ 1.  3.  1.  0. 29.] 
adversary cards in discard: [ 3. 16. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -2.0653798580169678
desired expected reward: 92.32657623291016



buy possibilites: [-1] 
expected returns: [[92.74356]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.] 
cards in discard: [ 8.  4. 23.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0 25  1 15  0  8  4 23] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 28.  8.  9.  9. 10.  5.  9.  9. 10.  9.  9. 10.  7.] 
adversary cards in hand: [ 1.  3.  1.  0. 29.] 
adversary cards in discard: [ 3. 16. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 69 

action type: buy - action 23.0
Learning step: 2.357954740524292
desired expected reward: 65.93346405029297






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  1.  0. 29.] 
cards in discard: [ 3. 16. 15.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 28.  8.  9.  9. 10.  5.  9.  9. 10.  9.  9. 10.  7.] 
adversary cards in hand: [ 0. 23.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0 25  1 15  0  8  4 23] -> size -> 10 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  1.  0. 29.] 
cards in discard: [ 3. 16. 15.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 25. 30. 28. 28.  8.  9.  9. 10.  5.  9.  9. 10.  9.  9. 10.  7.] 
adversary cards in hand: [ 0. 23.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0 25  1 15  0  8  4 23] -> size -> 10 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 23.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[124.32813]
 [ 94.52838]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  0.  1.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 25  1 15  0  8  4 23] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 28.  8.  9.  9. 10.  5.  9.  9. 10.  9.  9. 10.  7.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [ 3. 16. 15.  0.  3.  1.  3.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -2.2123348712921143
desired expected reward: 90.5312271118164



action possibilites: [-1.] 
expected returns: [[133.3374]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 4.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  3  0 25  1 15  0  8  4 23] -> size -> 10 
action values: 1 
buys: 1 
player value: 1 
card supply: [27. 25. 30. 28. 28.  8.  9.  9. 10.  5.  9.  9. 10.  9.  9. 10.  7.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [ 3. 16. 15.  0.  3.  1.  3.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action 23.0
Learning step: -0.7151603698730469
desired expected reward: 92.58987426757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[113.238976]
 [133.86612 ]
 [124.50988 ]
 [ 85.90437 ]
 [ 75.42081 ]
 [122.3601  ]
 [140.28702 ]
 [126.615944]
 [157.1374  ]
 [124.45519 ]
 [ 91.36305 ]
 [103.03189 ]
 [120.12995 ]
 [ 82.48355 ]
 [109.323784]
 [138.88527 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 4.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  3  0 25  1 15  0  8  4 23] -> size -> 10 
action values: 0 
buys: 2 
player value: 5 
card supply: [27. 25. 30. 28. 28.  8.  9.  9. 10.  5.  9.  9. 10.  9.  9. 10.  7.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [ 3. 16. 15.  0.  3.  1.  3.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -2.9691243171691895
desired expected reward: 130.36827087402344



buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 93.2995  ]
 [ 97.68472 ]
 [ 71.85363 ]
 [100.33949 ]
 [105.821785]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 4.] 
cards in discard: [10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  3  0 25  1 15  0  8  4 23 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 28. 28.  8.  9.  9. 10.  5.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [ 3. 16. 15.  0.  3.  1.  3.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 28 

action type: buy - action 10.0
Learning step: -2.4533278942108154
desired expected reward: 117.6766128540039



buy possibilites: [-1] 
expected returns: [[84.849464]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 4.] 
cards in discard: [10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  3  0 25  1 15  0  8  4 23 10  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [ 3. 16. 15.  0.  3.  1.  3.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 27 

action type: buy - action 8.0
Learning step: -1.7578617334365845
desired expected reward: 98.58163452148438






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0.  0.] 
cards in discard: [ 3. 16. 15.  0.  3.  1.  3.  1.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  1 16 10  8  3  1  8  0  6 15 15  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [23.  8.  0. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0 25  1 15  0  8  4 23 10  8] -> size -> 12 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 16. 15.  0.  3.  1.  3.  1.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [23.  8.  0. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0 25  1 15  0  8  4 23 10  8] -> size -> 12 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 16. 15.  0.  3.  1.  3.  1.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 25. 30. 28. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [23.  8.  0. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0 25  1 15  0  8  4 23 10  8] -> size -> 12 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 16. 15.  0.  3.  1.  3.  1.  0. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [23.  8.  0. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0 25  1 15  0  8  4 23 10  8] -> size -> 12 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [23.  8.  0. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 15. 25.] 
expected returns: [[25.133842]
 [17.934595]
 [24.424925]
 [18.933256]
 [32.254326]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.  0. 15. 25.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 25  1 15  0  8  4 23 10  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  3. 15.  0.  6.] 
adversary cards in discard: [ 3. 16. 15.  0.  3.  1.  3.  1.  0. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -3.738176107406616
desired expected reward: 81.11128997802734



action possibilites: [-1.  8. 15. 25.] 
expected returns: [[63.824333]
 [58.9684  ]
 [51.950462]
 [70.76667 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15. 25.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  3  0 25  1 15  0  8  4 23 10  8] -> size -> 12 
action values: 1 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 28. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  3. 15.  0.  6.] 
adversary cards in discard: [ 3. 16. 15.  0.  3.  1.  3.  1.  0. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 20 

action type: take_action - action 23.0
Learning step: 1.5400152206420898
desired expected reward: 19.02613067626953



action possibilites: [-1] 
expected returns: [[102.33104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 3  0  1  0  8  4 23 10  8] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 28. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  3. 15.  0.  6.] 
adversary cards in discard: [ 3. 16. 15.  0.  3.  1.  3.  1.  0. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.7952720522880554
desired expected reward: 69.93879699707031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[77.41518 ]
 [85.5859  ]
 [51.085083]
 [86.25851 ]
 [95.69045 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 3  0  1  0  8  4 23 10  8] -> size -> 9 
action values: 0 
buys: 2 
player value: 2 
card supply: [26. 25. 30. 28. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  3. 15.  0.  6.] 
adversary cards in discard: [ 3. 16. 15.  0.  3.  1.  3.  1.  0. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1
Learning step: -1.325884222984314
desired expected reward: 101.00515747070312






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 15.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 15.  0.  6.] 
cards in discard: [ 3. 16. 15.  0.  3.  1.  3.  1.  0. 29.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 1.  8.  4. 10.  3.] 
adversary cards in discard: [23.  8.  0.] 
adversary owned cards: [ 3  0  1  0  8  4 23 10  8] -> size -> 9 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6.] 
cards in discard: [ 3. 16. 15.  0.  3.  1.  3.  1.  0. 29.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 25. 30. 28. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 1.  8.  4. 10.  3.] 
adversary cards in discard: [23.  8.  0.] 
adversary owned cards: [ 3  0  1  0  8  4 23 10  8] -> size -> 9 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6.] 
cards in discard: [ 3. 16. 15.  0.  3.  1.  3.  1.  0. 29.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 28. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 1.  8.  4. 10.  3.] 
adversary cards in discard: [23.  8.  0.] 
adversary owned cards: [ 3  0  1  0  8  4 23 10  8] -> size -> 9 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6.] 
cards in discard: [ 3. 16. 15.  0.  3.  1.  3.  1.  0. 29.  0.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 27. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 1.  8.  4. 10.  3.] 
adversary cards in discard: [23.  8.  0.] 
adversary owned cards: [ 3  0  1  0  8  4 23 10  8] -> size -> 9 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 1.  8.  4. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[119.314926]
 [114.06456 ]
 [108.90525 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  4. 10.  3.] 
cards in discard: [23.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1  0  8  4 23 10  8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [8. 3. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -2.796919584274292
desired expected reward: 92.8935317993164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[106.71501 ]
 [112.87022 ]
 [ 81.244865]
 [115.0849  ]
 [120.09987 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  4. 10.  3.] 
cards in discard: [23.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1  0  8  4 23 10  8] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 27. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [8. 3. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -3.9510979652404785
desired expected reward: 113.22776794433594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [8. 3. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 1.  8. 23. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  1  0  8  4 23 10  8] -> size -> 9 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 1.  8. 23. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  1  0  8  4 23 10  8] -> size -> 9 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 27. 28.  8.  9.  9. 10.  4.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 1.  8. 23. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  1  0  8  4 23 10  8] -> size -> 9 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 27. 28.  8.  9.  9. 10.  3.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 1.  8. 23. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  1  0  8  4 23 10  8] -> size -> 9 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 1.  8. 23. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 10.] 
expected returns: [[71.77083 ]
 [63.716545]
 [42.74462 ]
 [56.932724]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 23. 10.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1  0  8  4 23 10  8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 28.  8.  9.  9. 10.  3.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 3. 15.  0. 29.  0.] 
adversary cards in discard: [8. 8. 3. 0. 1.] 
adversary owned cards: [ 0  0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -4.539731025695801
desired expected reward: 111.28057861328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[52.374863]
 [69.842674]
 [60.761444]
 [25.006075]
 [74.98229 ]
 [64.27263 ]
 [57.560837]
 [72.54814 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 23. 10.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1  0  8  4 23 10  8] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 27. 28.  8.  9.  9. 10.  3.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 3. 15.  0. 29.  0.] 
adversary cards in discard: [8. 8. 3. 0. 1.] 
adversary owned cards: [ 0  0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -2.055989980697632
desired expected reward: 66.0018310546875



buy possibilites: [-1] 
expected returns: [[41.617455]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 23. 10.  0.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1  0  8  4 23 10  8  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 26. 28.  8.  9.  9. 10.  3.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 3. 15.  0. 29.  0.] 
adversary cards in discard: [8. 8. 3. 0. 1.] 
adversary owned cards: [ 0  0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 12.0 

action type: buy - action 3.0
Learning step: -1.501678705215454
desired expected reward: 59.25975036621094






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0. 29.  0.] 
cards in discard: [8. 8. 3. 0. 1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 28.  8.  9.  9. 10.  3.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [3. 3. 8. 4. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  1  0  8  4 23 10  8  3] -> size -> 10 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.] 
cards in discard: [8. 8. 3. 0. 1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 25. 30. 26. 28.  8.  9.  9. 10.  3.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [3. 3. 8. 4. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  1  0  8  4 23 10  8  3] -> size -> 10 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.] 
cards in discard: [8. 8. 3. 0. 1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 30. 26. 28.  8.  9.  9. 10.  3.  9.  9. 10.  9.  8. 10.  7.] 
adversary cards in hand: [3. 3. 8. 4. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  1  0  8  4 23 10  8  3] -> size -> 10 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.] 
cards in discard: [ 8.  8.  3.  0.  1. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 26. 28.  8.  9.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [3. 3. 8. 4. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  1  0  8  4 23 10  8  3] -> size -> 10 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [3. 3. 8. 4. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[63.51449 ]
 [58.199745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 4. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1  0  8  4 23 10  8  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 28.  8.  9.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [6. 0. 1. 8. 3.] 
adversary cards in discard: [ 8.  8.  3.  0.  1. 10. 15.  3. 29.  0.] 
adversary owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10] -> size -> 20 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1
Learning step: -0.23771095275878906
desired expected reward: 41.37974548339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[50.004654]
 [31.099146]
 [63.009552]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 4. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1  0  8  4 23 10  8  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 26. 28.  8.  9.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [6. 0. 1. 8. 3.] 
adversary cards in discard: [ 8.  8.  3.  0.  1. 10. 15.  3. 29.  0.] 
adversary owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10] -> size -> 20 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: take_action - action -1.0
Learning step: -1.4776630401611328
desired expected reward: 60.75547790527344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [6. 0. 1. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 8. 3.] 
cards in discard: [ 8.  8.  3.  0.  1. 10. 15.  3. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 28.  8.  9.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [10. 23.  1.  8.  0.] 
adversary cards in discard: [3. 3. 8. 4. 0.] 
adversary owned cards: [ 3  0  1  0  8  4 23 10  8  3] -> size -> 10 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 8. 3.] 
cards in discard: [ 8.  8.  3.  0.  1. 10. 15.  3. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 26. 28.  8.  9.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [10. 23.  1.  8.  0.] 
adversary cards in discard: [3. 3. 8. 4. 0.] 
adversary owned cards: [ 3  0  1  0  8  4 23 10  8  3] -> size -> 10 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 8. 3.] 
cards in discard: [ 8.  8.  3.  0.  1. 10. 15.  3. 29.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 25. 30. 26. 28.  8.  9.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [10. 23.  1.  8.  0.] 
adversary cards in discard: [3. 3. 8. 4. 0.] 
adversary owned cards: [ 3  0  1  0  8  4 23 10  8  3] -> size -> 10 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [10. 23.  1.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23.  8.] 
expected returns: [[105.0386  ]
 [ 89.170876]
 [ 77.55837 ]
 [ 93.48589 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 23.  1.  8.  0.] 
cards in discard: [3. 3. 8. 4. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1  0  8  4 23 10  8  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 28.  8.  9.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [16.  3. 15.  3.  1.] 
adversary cards in discard: [ 8.  8.  3.  0.  1. 10. 15.  3. 29.  0.  0.  6.  0.  1.  8.  3.] 
adversary owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1.0
Learning step: -0.5727882385253906
desired expected reward: 62.4367561340332



action possibilites: [-1] 
expected returns: [[56.710526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 23.] 
cards in discard: [3. 3. 8. 4. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  8  4 23 10  8  3] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 28.  8.  9.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [16.  3. 15.  3.  1.] 
adversary cards in discard: [ 8.  8.  3.  0.  1. 10. 15.  3. 29.  0.  0.  6.  0.  1.  8.  3.] 
adversary owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5   0   5  10   0   0  20   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -30 

action type: trash_cards_n_from_hand - action 9
Learning step: -5.3564276695251465
desired expected reward: 97.29185485839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[39.927025]
 [21.48641 ]
 [53.606133]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 23.] 
cards in discard: [3. 3. 8. 4. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  8  4 23 10  8  3] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 25. 30. 26. 28.  8.  9.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [16.  3. 15.  3.  1.] 
adversary cards in discard: [ 8.  8.  3.  0.  1. 10. 15.  3. 29.  0.  0.  6.  0.  1.  8.  3.] 
adversary owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5   0   5  10   0   0  20   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1
Learning step: -3.4186904430389404
desired expected reward: 53.29183578491211



buy possibilites: [-1] 
expected returns: [[88.46174]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 23.] 
cards in discard: [3. 3. 8. 4. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 28.  8.  8.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [16.  3. 15.  3.  1.] 
adversary cards in discard: [ 8.  8.  3.  0.  1. 10. 15.  3. 29.  0.  0.  6.  0.  1.  8.  3.] 
adversary owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0] -> size -> 21 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    4    0    0    0   20    0    0    0  -60    0    0 -300
    0    0] 
sum of rewards: -341 

action type: buy - action 6.0
Learning step: -16.133930206298828
desired expected reward: 5.352474212646484






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [16.  3. 15.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 15.  3.  1.] 
cards in discard: [ 8.  8.  3.  0.  1. 10. 15.  3. 29.  0.  0.  6.  0.  1.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 28.  8.  8.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [23.  3.  3.  0.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3.  1.] 
cards in discard: [ 8.  8.  3.  0.  1. 10. 15.  3. 29.  0.  0.  6.  0.  1.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 28.  8.  8.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [23.  3.  3.  0.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  3.  1.] 
cards in discard: [ 8.  8.  3.  0.  1. 10. 15.  3. 29.  0.  0.  6.  0.  1.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 30. 26. 28.  8.  8.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [23.  3.  3.  0.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  3.  1.] 
cards in discard: [ 8.  8.  3.  0.  1. 10. 15.  3. 29.  0.  0.  6.  0.  1.  8.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [23.  3.  3.  0.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [23.  3.  3.  0.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[43.526268]
 [28.819765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  3.  0.  4.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  8. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3] -> size -> 22 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -71 

action type: buy - action -1
Learning step: -7.1459197998046875
desired expected reward: 81.3158187866211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[34.463936]
 [14.523394]
 [42.095337]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  3.  0.  4.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 3.  8. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3] -> size -> 22 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -71 

action type: take_action - action -1.0
Learning step: -4.9847564697265625
desired expected reward: 38.20582580566406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 4.  6.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 4.  6.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 4.  6.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 4.  6.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 4.  6.  8. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
expected returns: [[54.172653]
 [52.119232]
 [45.595284]
 [52.119232]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  6.  8. 10.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 1.  0. 15. 10.  0.] 
adversary cards in discard: [10. 29.  3.  8.  0.  0.  3.] 
adversary owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -71 

action type: buy - action -1.0
Learning step: -4.49459171295166
desired expected reward: 37.600746154785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.10791]
 [21.74915]
 [54.86817]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  6.  8. 10.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 1.  0. 15. 10.  0.] 
adversary cards in discard: [10. 29.  3.  8.  0.  0.  3.] 
adversary owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -71 

action type: take_action - action -1.0
Learning step: -5.309569835662842
desired expected reward: 49.028968811035156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 1.  0. 15. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15. 10.  0.] 
cards in discard: [10. 29.  3.  8.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  3. 23.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15.  0.  3.] 
cards in discard: [10. 29.  3.  8.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  3. 23.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3.] 
cards in discard: [10. 29.  3.  8.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  3. 23.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3.] 
cards in discard: [10. 29.  3.  8.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  3. 23.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3.] 
cards in discard: [10. 29.  3.  8.  0.  0.  3. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  3. 23.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 6.  3. 23.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[112.53477]
 [ 92.45235]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 23.  0.  3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [1. 3. 6. 1. 3.] 
adversary cards in discard: [10. 29.  3.  8.  0.  0.  3. 14. 10. 15.  1.  0.  3.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -71 

action type: buy - action -1.0
Learning step: -3.956622362136841
desired expected reward: 50.91154098510742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[101.18436]
 [ 78.3158 ]
 [115.16226]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 23.  0.  3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8  4 23 10  8  3  6] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [1. 3. 6. 1. 3.] 
adversary cards in discard: [10. 29.  3.  8.  0.  0.  3. 14. 10. 15.  1.  0.  3.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -71 

action type: take_action - action -1.0
Learning step: -6.879080295562744
desired expected reward: 105.10459899902344



buy possibilites: [-1] 
expected returns: [[69.20213]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 23.  0.  3.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8  4 23 10  8  3  6  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [1. 3. 6. 1. 3.] 
adversary cards in discard: [10. 29.  3.  8.  0.  0.  3. 14. 10. 15.  1.  0.  3.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -10.   0.   0.   0. -30.   0.   0. -30.   0.   0.   0.
   0.   0.] 
sum of rewards: -71.0 

action type: buy - action 0.0
Learning step: -6.8424072265625
desired expected reward: 90.1467056274414






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [1. 3. 6. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 6. 1. 3.] 
cards in discard: [10. 29.  3.  8.  0.  0.  3. 14. 10. 15.  1.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [23.  8. 10.  4.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8  4 23 10  8  3  6  0] -> size -> 10 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 1. 3.] 
cards in discard: [10. 29.  3.  8.  0.  0.  3. 14. 10. 15.  1.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 25. 30. 25. 28.  8.  8.  9. 10.  3.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [23.  8. 10.  4.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8  4 23 10  8  3  6  0] -> size -> 10 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 1. 3.] 
cards in discard: [10. 29.  3.  8.  0.  0.  3. 14. 10. 15.  1.  0.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 30. 25. 28.  8.  8.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [23.  8. 10.  4.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8  4 23 10  8  3  6  0] -> size -> 10 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [23.  8. 10.  4.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 10.  8.] 
expected returns: [[33.31339 ]
 [19.330872]
 [31.696514]
 [27.465744]
 [31.696514]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8. 10.  4.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8  4 23 10  8  3  6  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 25. 28.  8.  8.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8.  8. 15. 16.] 
adversary cards in discard: [10. 29.  3.  8.  0.  0.  3. 14. 10. 15.  1.  0.  3.  8.  1.  3.  6.  1.
  3.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -41 

action type: buy - action -1
Learning step: -4.8888468742370605
desired expected reward: 64.31328582763672



action possibilites: [-1.  8. 10.  8.] 
expected returns: [[51.775597]
 [44.509277]
 [41.4416  ]
 [44.509277]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  4.  8.  3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  0  8  4 23 10  8  3  6  0] -> size -> 10 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 25. 28.  8.  8.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8.  8. 15. 16.] 
adversary cards in discard: [10. 29.  3.  8.  0.  0.  3. 14. 10. 15.  1.  0.  3.  8.  1.  3.  6.  1.
  3.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action 23.0
Learning step: -0.8896824717521667
desired expected reward: 16.846820831298828



action possibilites: [-1.  8.  8.] 
expected returns: [[25.437305]
 [19.98404 ]
 [19.98404 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 4. 8. 3. 6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 3  0  8  4 23 10  8  3  6  0] -> size -> 10 
action values: 2 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 25. 28.  8.  8.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8.  8. 15. 16.] 
adversary cards in discard: [10. 29.  3.  8.  0.  0.  3. 14. 10. 15.  1.  0.  3.  8.  1.  3.  6.  1.
  3.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  40   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action 10.0
Learning step: -1.6186360120773315
desired expected reward: 39.82298278808594



action possibilites: [-1.  8.] 
expected returns: [[59.07691 ]
 [52.808437]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 8. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 10.  8.] 
owned cards: [ 3  0  8  4 23 10  8  3  0] -> size -> 9 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 25. 28.  8.  8.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8.  8. 15. 16.] 
adversary cards in discard: [10. 29.  3.  8.  0.  0.  3. 14. 10. 15.  1.  0.  3.  8.  1.  3.  6.  1.
  3.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[ -5   0   5   0   0   0  60   0   0   0 -30   0   0   0   0   0] 
sum of rewards: 30 

action type: trash_cards_n_from_hand - action 0
Learning step: 1.9866790771484375
desired expected reward: 17.64980697631836



action possibilites: [-1] 
expected returns: [[19.502712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 10.  8.  8.] 
owned cards: [ 3  0  8 23 10  8  3  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 25. 28.  8.  8.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8.  8. 15. 16.] 
adversary cards in discard: [10. 29.  3.  8.  0.  0.  3. 14. 10. 15.  1.  0.  3.  8.  1.  3.  6.  1.
  3.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  80   0   0   0 -30   0   0   0   0   0] 
sum of rewards: 17 

action type: trash_cards_n_from_hand - action 1
Learning step: -1.3516278266906738
desired expected reward: 51.457149505615234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.679219 ]
 [ 1.1992311]
 [18.808407 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 10.  8.  8.] 
owned cards: [ 3  0  8 23 10  8  3  0] -> size -> 8 
action values: 0 
buys: 2 
player value: 1 
card supply: [24. 25. 30. 25. 28.  8.  8.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8.  8. 15. 16.] 
adversary cards in discard: [10. 29.  3.  8.  0.  0.  3. 14. 10. 15.  1.  0.  3.  8.  1.  3.  6.  1.
  3.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  80   0   0   0 -30   0   0   0   0   0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: 0.15441980957984924
desired expected reward: 19.65713119506836



buy possibilites: [ 0.  6. -1.] 
expected returns: [[45.872562]
 [29.935375]
 [57.785828]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 10.  8.  8.] 
owned cards: [ 3  0  8 23 10  8  3  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 25. 28.  8.  8.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8.  8. 15. 16.] 
adversary cards in discard: [10. 29.  3.  8.  0.  0.  3. 14. 10. 15.  1.  0.  3.  8.  1.  3.  6.  1.
  3.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  80 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 17 

action type: buy - action 0.0
Learning step: 1.2150405645370483
desired expected reward: 14.894261360168457



buy possibilites: [-1] 
expected returns: [[30.160076]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 10.  8.  8.] 
owned cards: [ 3  0  8 23 10  8  3  0  0  6] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 25. 28.  8.  7.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8.  8. 15. 16.] 
adversary cards in discard: [10. 29.  3.  8.  0.  0.  3. 14. 10. 15.  1.  0.  3.  8.  1.  3.  6.  1.
  3.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -40.    0.    0.   80.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -264.0 

action type: buy - action 6.0
Learning step: -14.018167495727539
desired expected reward: 15.917207717895508






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  8. 15. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  8. 15. 16.] 
cards in discard: [10. 29.  3.  8.  0.  0.  3. 14. 10. 15.  1.  0.  3.  8.  1.  3.  6.  1.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 25. 28.  8.  7.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [23. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8 23 10  8  3  0  0  6] -> size -> 10 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  8. 15. 16.] 
cards in discard: [10. 29.  3.  8.  0.  0.  3. 14. 10. 15.  1.  0.  3.  8.  1.  3.  6.  1.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 25. 30. 25. 28.  8.  7.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [23. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8 23 10  8  3  0  0  6] -> size -> 10 
adversary victory points: 1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [23. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10.] 
expected returns: [[83.57038]
 [67.0944 ]
 [77.32529]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8 23 10  8  3  0  0  6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 25. 28.  8.  7.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  3. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -1.961326241493225
desired expected reward: 28.198749542236328



action possibilites: [-1. 23.] 
expected returns: [[13.555566 ]
 [ 2.4537106]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  0  8 23 10  8  3  0  0  6] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 25. 28.  8.  7.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  3. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action 10.0
Learning step: -4.870751857757568
desired expected reward: 72.54045104980469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[  5.2665052]
 [  7.378175 ]
 [-15.635862 ]
 [  8.574961 ]
 [ 11.48705  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  0  8 23 10  8  3  0  0  6] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 25. 28.  8.  7.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  3. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -1.772304892539978
desired expected reward: 11.783276557922363



buy possibilites: [-1] 
expected returns: [[34.802475]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  0.  3.  3.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  0  8 23 10  8  3  0  0  6  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 25. 30. 25. 28.  8.  7.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  3. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -54.0 

action type: buy - action 0.0
Learning step: -2.180269956588745
desired expected reward: 3.0862438678741455






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  3. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 29. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 28.  8.  7.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [0. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8 23 10  8  3  0  0  6  0] -> size -> 11 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 25. 28.  8.  7.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [0. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8 23 10  8  3  0  0  6  0] -> size -> 11 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
action values: 2 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 25. 28.  8.  7.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [0. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8 23 10  8  3  0  0  6  0] -> size -> 11 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 25. 30. 25. 28.  8.  7.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [0. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  8 23 10  8  3  0  0  6  0] -> size -> 11 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[39.11283 ]
 [35.099037]
 [35.099037]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8 23 10  8  3  0  0  6  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 28.  8.  7.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [3. 1. 3. 3. 1.] 
adversary cards in discard: [29. 10.  0.  6.  3.  3.  8.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -3.061861515045166
desired expected reward: 31.74061393737793



action possibilites: [-1] 
expected returns: [[40.607475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 23 10  8  3  0  6  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 28.  8.  7.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [3. 1. 3. 3. 1.] 
adversary cards in discard: [29. 10.  0.  6.  3.  3.  8.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -54 

action type: trash_cards_n_from_hand - action 9
Learning step: -3.969170331954956
desired expected reward: 39.68759536743164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.410452]
 [18.454763]
 [39.913853]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 23 10  8  3  0  6  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 25. 30. 25. 28.  8.  7.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [3. 1. 3. 3. 1.] 
adversary cards in discard: [29. 10.  0.  6.  3.  3.  8.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1
Learning step: -4.027896404266357
desired expected reward: 36.5795783996582



buy possibilites: [-1] 
expected returns: [[63.13718]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 23 10  8  3  0  6  0  6] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 28.  8.  6.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [3. 1. 3. 3. 1.] 
adversary cards in discard: [29. 10.  0.  6.  3.  3.  8.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -50    0    0   20    0    0    0  -30    0    0 -300
    0    0] 
sum of rewards: -365 

action type: buy - action 6.0
Learning step: -17.752151489257812
desired expected reward: 0.7026081085205078






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [3. 1. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 3. 1.] 
cards in discard: [29. 10.  0.  6.  3.  3.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 28.  8.  6.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  3.  0. 23.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 3 23 10  8  3  0  6  0  6] -> size -> 9 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 3. 1.] 
cards in discard: [29. 10.  0.  6.  3.  3.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 25. 30. 25. 28.  8.  6.  9. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  3.  0. 23.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 3 23 10  8  3  0  6  0  6] -> size -> 9 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 3. 1.] 
cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 28.  8.  6.  8. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  3.  0. 23.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 3 23 10  8  3  0  6  0  6] -> size -> 9 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 3.  0.  3.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[35.871292]
 [19.644499]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 23.] 
cards in discard: [6. 8. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 23 10  8  3  0  6  0  6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 28.  8.  6.  8. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [15.  8.  0.  0. 10.] 
adversary cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8
 16] -> size -> 25 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -6.732056617736816
desired expected reward: 56.40512466430664



action possibilites: [-1. 10.] 
expected returns: [[35.290787]
 [27.45727 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 10.] 
cards in discard: [6. 8. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3 23 10  8  3  0  6  0  6] -> size -> 9 
action values: 1 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 25. 28.  8.  6.  8. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [15.  8.  0.  0. 10.] 
adversary cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8
 16] -> size -> 25 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action 23.0
Learning step: -3.542327642440796
desired expected reward: 16.700590133666992



action possibilites: [-1.] 
expected returns: [[19.305712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 3 23 10  8  3  0  6  0  6] -> size -> 9 
action values: 2 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 25. 28.  8.  6.  8. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [15.  8.  0.  0. 10.] 
adversary cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8
 16] -> size -> 25 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  40   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 10.0
Learning step: -3.1884849071502686
desired expected reward: 24.268781661987305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 6.213516 ]
 [12.520466 ]
 [10.431405 ]
 [-3.2028677]
 [16.165888 ]
 [ 9.695562 ]
 [ 8.756061 ]
 [17.68478  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 3 23 10  8  3  0  6  0  6] -> size -> 9 
action values: 0 
buys: 2 
player value: 3 
card supply: [22. 25. 30. 25. 28.  8.  6.  8. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [15.  8.  0.  0. 10.] 
adversary cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8
 16] -> size -> 25 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  40   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -2.96711802482605
desired expected reward: 16.338594436645508



buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[27.896057 ]
 [36.003094 ]
 [32.534836 ]
 [ 7.4538164]
 [38.044193 ]
 [32.95838  ]
 [30.447996 ]
 [37.01196  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 3 23 10  8  3  0  6  0  6  6] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 30. 25. 28.  8.  5.  8. 10.  2.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [15.  8.  0.  0. 10.] 
adversary cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8
 16] -> size -> 25 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -60    0    0   40    0    0    0  -30    0    0 -300
    0    0] 
sum of rewards: -356 

action type: buy - action 6.0
Learning step: -16.930734634399414
desired expected reward: -20.133602142333984



buy possibilites: [-1] 
expected returns: [[27.780928]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [6. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 3 23 10  8  3  0  6  0  6  6  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 25. 28.  8.  5.  8. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [15.  8.  0.  0. 10.] 
adversary cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8
 16] -> size -> 25 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -60.   0.   0.  40.   0.   0.   0. -30.   0.   0.   0.
   2.   0.] 
sum of rewards: -54.0 

action type: buy - action 8.0
Learning step: -3.7228477001190186
desired expected reward: 29.235530853271484






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [15.  8.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  0. 10.] 
cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  0  6 15 15  3  0  3  8 10  0  3 10 14  8
 16] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 28.  8.  5.  8. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  6. 23.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 23 10  8  3  0  6  0  6  6  8] -> size -> 11 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.] 
cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 25. 30. 25. 28.  8.  5.  8. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  6. 23.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 23 10  8  3  0  6  0  6  6  8] -> size -> 11 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.] 
cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 25. 30. 25. 28.  8.  5.  8. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  6. 23.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 23 10  8  3  0  6  0  6  6  8] -> size -> 11 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.] 
cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  6. 23.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 23 10  8  3  0  6  0  6  6  8] -> size -> 11 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [ 3.  6. 23.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
expected returns: [[35.267883]
 [15.992695]
 [30.297968]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 23.  8.  6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 23 10  8  3  0  6  0  6  6  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 25. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  3.  8.  1. 14.] 
adversary cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1. 16. 15.  8.  0. 10.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16] -> size -> 25 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -5.568366527557373
desired expected reward: 22.212560653686523



action possibilites: [-1.  8.] 
expected returns: [[-0.5041187]
 [-5.867818 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 6. 6.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3 23 10  8  3  0  6  0  6  6  8] -> size -> 11 
action values: 1 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 25. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  3.  8.  1. 14.] 
adversary cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1. 16. 15.  8.  0. 10.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16] -> size -> 25 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action 23.0
Learning step: -4.772270679473877
desired expected reward: 13.429845809936523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-18.398232]
 [-38.74757 ]
 [  0.711221]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 6. 6.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3 23 10  8  3  0  6  0  6  6  8] -> size -> 11 
action values: 1 
buys: 2 
player value: 1 
card supply: [22. 25. 30. 25. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  3.  8.  1. 14.] 
adversary cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1. 16. 15.  8.  0. 10.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16] -> size -> 25 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -4.128756046295166
desired expected reward: -4.632871627807617



buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.63324  ]
 [-2.0772142]
 [19.692984 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 6. 6.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3 23 10  8  3  0  6  0  6  6  8  0] -> size -> 12 
action values: 1 
buys: 1 
player value: 1 
card supply: [21. 25. 30. 25. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  3.  8.  1. 14.] 
adversary cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1. 16. 15.  8.  0. 10.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16] -> size -> 25 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action 0.0
Learning step: -2.612794876098633
desired expected reward: -21.01097869873047



buy possibilites: [-1] 
expected returns: [[30.199366]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 6. 6.] 
cards in discard: [0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3 23 10  8  3  0  6  0  6  6  8  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 25. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  3.  8.  1. 14.] 
adversary cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1. 16. 15.  8.  0. 10.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16] -> size -> 25 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -60.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -76.0 

action type: buy - action 0.0
Learning step: -3.8021762371063232
desired expected reward: 9.831061363220215






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  8.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8.  1. 14.] 
cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1. 16. 15.  8.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [10.  3.  0.  0.  8.] 
adversary cards in discard: [ 0.  0. 23.  3.  6.  8.  6.  6.] 
adversary owned cards: [ 3 23 10  8  3  0  6  0  6  6  8  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  8.  1. 14.] 
cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1. 16. 15.  8.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 25. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [10.  3.  0.  0.  8.] 
adversary cards in discard: [ 0.  0. 23.  3.  6.  8.  6.  6.] 
adversary owned cards: [ 3 23 10  8  3  0  6  0  6  6  8  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  8.  1. 14.] 
cards in discard: [29. 10.  0.  6.  3.  3.  8. 16.  3.  1.  3.  3.  1. 16. 15.  8.  0. 10.
  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [10.  3.  0.  0.  8.] 
adversary cards in discard: [ 0.  0. 23.  3.  6.  8.  6.  6.] 
adversary owned cards: [ 3 23 10  8  3  0  6  0  6  6  8  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 6 





Player: 0 
cards in hand: [10.  3.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[75.56374]
 [67.16338]
 [69.72558]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  8.] 
cards in discard: [ 0.  0. 23.  3.  6.  8.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 23 10  8  3  0  6  0  6  6  8  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [10. 10. 29. 16. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3] -> size -> 26 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -3.7451131343841553
desired expected reward: 26.454252243041992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[60.118275]
 [65.83793 ]
 [40.93988 ]
 [65.937996]
 [71.435326]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  8.] 
cards in discard: [ 0.  0. 23.  3.  6.  8.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 23 10  8  3  0  6  0  6  6  8  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 24. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [10. 10. 29. 16. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3] -> size -> 26 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -5.901130199432373
desired expected reward: 64.25691986083984



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [10. 10. 29. 16. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 16. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29. 16. 15.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 23 10  8  3  0  6  0  6  6  8  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1. 10. 29. 16. 15. 14.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 16. 15. 14.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 23 10  8  3  0  6  0  6  6  8  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1. 10. 29. 16. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 16. 14.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  8.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 23 10  8  3  0  6  0  6  6  8  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 15. 14.] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 25. 30. 24. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  8. 10.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 3 23 10  8  3  0  6  0  6  6  8  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 15. 14.] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 24. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  8. 10.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 3 23 10  8  3  0  6  0  6  6  8  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 16.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 15. 14.] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 23. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  8. 10.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 3 23 10  8  3  0  6  0  6  6  8  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 7 





Player: 0 
cards in hand: [ 8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
expected returns: [[7.476935 ]
 [3.1920242]
 [3.1920242]
 [1.768569 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.] 
cards in discard: [3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 23 10  8  3  0  6  0  6  6  8  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 23. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [16.  8. 15.  8.  3.] 
adversary cards in discard: [ 3. 10. 15. 14. 10. 29. 16.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3  3] -> size -> 27 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: discard_down_to_3_cards - action 6
Learning step: -3.8041481971740723
desired expected reward: -12.83065414428711



action possibilites: [-1.  8.  8. 23.] 
expected returns: [[26.472641]
 [19.168835]
 [19.168835]
 [13.114935]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 23.] 
cards in discard: [3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 23 10  8  3  0  6  0  6  6  8  0  0] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 23. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [16.  8. 15.  8.  3.] 
adversary cards in discard: [ 3. 10. 15. 14. 10. 29. 16.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3  3] -> size -> 27 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action 10.0
Learning step: -2.836399555206299
desired expected reward: -2.845493793487549



action possibilites: [-1.  8.] 
expected returns: [[39.564682]
 [34.11102 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 23. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [16.  8. 15.  8.  3.] 
adversary cards in discard: [ 3. 10. 15. 14. 10. 29. 16.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3  3] -> size -> 27 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: trash_cards_n_from_hand - action 0
Learning step: -2.3306987285614014
desired expected reward: 15.053894996643066





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.155798]
 [12.162209]
 [38.180904]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0] -> size -> 12 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 25. 30. 23. 28.  8.  5.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [16.  8. 15.  8.  3.] 
adversary cards in discard: [ 3. 10. 15. 14. 10. 29. 16.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3  3] -> size -> 27 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -3.6468453407287598
desired expected reward: 35.91783905029297



buy possibilites: [-1] 
expected returns: [[20.422201]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [3. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 23. 28.  8.  4.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [16.  8. 15.  8.  3.] 
adversary cards in discard: [ 3. 10. 15. 14. 10. 29. 16.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3  3] -> size -> 27 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -90    0    0   40    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -357 

action type: buy - action 6.0
Learning step: -17.99860954284668
desired expected reward: -5.836399078369141






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [16.  8. 15.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8. 15.  8.  3.] 
cards in discard: [ 3. 10. 15. 14. 10. 29. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 23. 28.  8.  4.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 3.  0.  6. 10.  8.  8.] 
adversary owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6] -> size -> 13 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  8.  3.] 
cards in discard: [ 3. 10. 15. 14. 10. 29. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 23. 28.  8.  4.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 3.  0.  6. 10.  8.  8.] 
adversary owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6] -> size -> 13 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  8.  3.] 
cards in discard: [ 3. 10. 15. 14. 10. 29. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 25. 30. 23. 28.  8.  4.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 3.  0.  6. 10.  8.  8.] 
adversary owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6] -> size -> 13 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  8.  3.] 
cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 23. 28.  8.  4.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 3.  0.  6. 10.  8.  8.] 
adversary owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6] -> size -> 13 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.984251]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [ 3.  0.  6. 10.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 23. 28.  8.  4.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  0.  1. 16.  3.] 
adversary cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3  3  0] -> size -> 28 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -5.440743923187256
desired expected reward: 14.981456756591797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[13.979017 ]
 [18.06531  ]
 [15.8132305]
 [ 3.721002 ]
 [19.39229  ]
 [16.173195 ]
 [14.646183 ]
 [18.247896 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [ 3.  0.  6. 10.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 25. 30. 23. 28.  8.  4.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  0.  1. 16.  3.] 
adversary cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3  3  0] -> size -> 28 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -5.453188419342041
desired expected reward: 13.674200057983398



buy possibilites: [-1] 
expected returns: [[53.610916]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [ 3.  0.  6. 10.  8.  8.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 23. 28.  8.  4.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  0.  1. 16.  3.] 
adversary cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3.] 
adversary owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3  3  0] -> size -> 28 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -79 

action type: buy - action 1.0
Learning step: -3.647020101547241
desired expected reward: 14.418298721313477






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  1. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1. 16.  3.] 
cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16
 16  3  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 23. 28.  8.  4.  7. 10.  1.  9.  9.  9.  9.  6. 10.  7.] 
adversary cards in hand: [8. 1. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1] -> size -> 14 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1.] 
cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16 16
  3  3  0 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 23. 28.  8.  4.  7. 10.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [8. 1. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1] -> size -> 14 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1.] 
cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16 16
  3  3  0 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 30. 23. 28.  8.  4.  7. 10.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [8. 1. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1] -> size -> 14 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [8. 1. 8. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[36.419067]
 [32.723995]
 [32.723995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 8. 6. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 23. 28.  8.  4.  7. 10.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [3. 3. 3. 6. 1.] 
adversary cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3. 14. 16.  8.  0.  1.] 
adversary owned cards: [ 3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16 16
  3  3  0 14] -> size -> 28 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -6.317827224731445
desired expected reward: 47.2930908203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.607592]
 [35.541683]
 [13.965143]
 [37.433617]
 [41.109337]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 8. 6. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 30. 23. 28.  8.  4.  7. 10.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [3. 3. 3. 6. 1.] 
adversary cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3. 14. 16.  8.  0.  1.] 
adversary owned cards: [ 3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16 16
  3  3  0 14] -> size -> 28 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -5.286641597747803
desired expected reward: 28.46689796447754



buy possibilites: [-1] 
expected returns: [[47.189877]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 8. 6. 3.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 22. 28.  8.  4.  7. 10.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [3. 3. 3. 6. 1.] 
adversary cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3. 14. 16.  8.  0.  1.] 
adversary owned cards: [ 3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16 16
  3  3  0 14] -> size -> 28 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -68 

action type: buy - action 3.0
Learning step: -4.115311622619629
desired expected reward: 31.42635726928711






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [3. 3. 3. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 6. 1.] 
cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3. 14. 16.  8.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16 16
  3  3  0 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 22. 28.  8.  4.  7. 10.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  0. 10.  0.] 
adversary cards in discard: [3. 8. 1. 8. 6. 3.] 
adversary owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3] -> size -> 15 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 6. 1.] 
cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3. 14. 16.  8.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16 16
  3  3  0 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 30. 22. 28.  8.  4.  7. 10.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  0. 10.  0.] 
adversary cards in discard: [3. 8. 1. 8. 6. 3.] 
adversary owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3] -> size -> 15 
adversary victory points: -1
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  6.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[39.07924]
 [28.09894]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 10.  0.] 
cards in discard: [3. 8. 1. 8. 6. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 22. 28.  8.  4.  7. 10.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [1. 8. 3. 3. 0.] 
adversary cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3. 14. 16.  8.  0.  1.
  3.  3.  3.  6.  1.] 
adversary owned cards: [ 3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16 16
  3  3  0 14] -> size -> 28 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -5.441251277923584
desired expected reward: 41.748626708984375



action possibilites: [-1.] 
expected returns: [[62.898277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [3. 8. 1. 8. 6. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 22. 28.  8.  4.  7. 10.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [1. 8. 3. 3. 0.] 
adversary cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3. 14. 16.  8.  0.  1.
  3.  3.  3.  6.  1.] 
adversary owned cards: [ 3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16 16
  3  3  0 14] -> size -> 28 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action 10.0
Learning step: -2.6089284420013428
desired expected reward: 23.71975326538086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[51.79793 ]
 [62.663246]
 [58.389145]
 [29.37827 ]
 [65.59043 ]
 [58.302208]
 [55.570286]
 [64.603264]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [3. 8. 1. 8. 6. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 30. 22. 28.  8.  4.  7. 10.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [1. 8. 3. 3. 0.] 
adversary cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3. 14. 16.  8.  0.  1.
  3.  3.  3.  6.  1.] 
adversary owned cards: [ 3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16 16
  3  3  0 14] -> size -> 28 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -4.654911041259766
desired expected reward: 58.24336624145508



buy possibilites: [-1] 
expected returns: [[14.313508]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [ 3.  8.  1.  8.  6.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 22. 28.  8.  4.  7.  9.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [1. 8. 3. 3. 0.] 
adversary cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3. 14. 16.  8.  0.  1.
  3.  3.  3.  6.  1.] 
adversary owned cards: [ 3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16 16
  3  3  0 14] -> size -> 28 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -38 

action type: buy - action 11.0
Learning step: -4.857467174530029
desired expected reward: 60.73295593261719






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [1. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 3. 3. 0.] 
cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3. 14. 16.  8.  0.  1.
  3.  3.  3.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  1  1 16  8  3  1  8  6 15 15  3  0  3  8 10  0  3 10 14  8 16 16
  3  3  0 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 22. 28.  8.  4.  7.  9.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [3. 3. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3 11] -> size -> 16 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3. 14. 16.  8.  0.  1.
  3.  3.  3.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8 10  0  3 10 14  8 16 16  3  3
  0 14] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 22. 28.  8.  4.  7.  9.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [3. 3. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3 11] -> size -> 16 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3. 14. 16.  8.  0.  1.
  3.  3.  3.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8 10  0  3 10 14  8 16 16  3  3
  0 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 24. 30. 22. 28.  8.  4.  7.  9.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [3. 3. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3 11] -> size -> 16 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 3. 10. 15. 14. 10. 29. 16.  0. 15. 16.  8.  8.  3. 14. 16.  8.  0.  1.
  3.  3.  3.  6.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8 10  0  3 10 14  8 16 16  3  3
  0 14  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 22. 28.  8.  4.  7.  9.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [3. 3. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3 11] -> size -> 16 
adversary victory points: -1
player victory points: 6 





Player: 0 
cards in hand: [3. 3. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[48.006878]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 22. 28.  8.  4.  7.  9.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [16.  3.  3.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8 10  0  3 10 14  8 16 16  3  3
  0 14  0] -> size -> 27 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -3.4952266216278076
desired expected reward: 10.818281173706055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[41.14626 ]
 [30.796856]
 [46.336132]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 24. 30. 22. 28.  8.  4.  7.  9.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [16.  3.  3.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8 10  0  3 10 14  8 16 16  3  3
  0 14  0] -> size -> 27 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -5.15604305267334
desired expected reward: 40.197235107421875



buy possibilites: [-1] 
expected returns: [[-8.352581]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 6.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3 11  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 24. 30. 22. 28.  8.  4.  7.  9.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [16.  3.  3.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8 10  0  3 10 14  8 16 16  3  3
  0 14  0] -> size -> 27 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -106.0 

action type: buy - action 0.0
Learning step: -7.5452470779418945
desired expected reward: 33.60102462768555






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [16.  3.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3.  6. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8 10  0  3 10 14  8 16 16  3  3
  0 14  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 22. 28.  8.  4.  7.  9.  1.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  8.  1. 11.  0.] 
adversary cards in discard: [0. 3. 3. 6. 0. 6.] 
adversary owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3 11  0] -> size -> 17 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6.] 
cards in discard: [25.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 22. 28.  8.  4.  7.  9.  1.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  8.  1. 11.  0.] 
adversary cards in discard: [0. 3. 3. 6. 0. 6.] 
adversary owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3 11  0] -> size -> 17 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6.] 
cards in discard: [25.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 24. 30. 22. 28.  8.  4.  7.  9.  1.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  8.  1. 11.  0.] 
adversary cards in discard: [0. 3. 3. 6. 0. 6.] 
adversary owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3 11  0] -> size -> 17 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6.] 
cards in discard: [25.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 22. 28.  8.  4.  7.  9.  1.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  8.  1. 11.  0.] 
adversary cards in discard: [0. 3. 3. 6. 0. 6.] 
adversary owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3 11  0] -> size -> 17 
adversary victory points: -1
player victory points: 6 





Player: 0 
cards in hand: [ 0.  8.  1. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[57.431328]
 [50.537895]
 [57.48778 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1. 11.  0.] 
cards in discard: [0. 3. 3. 6. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  8  3  0  6  0  6  6  8  0  0  6  1  3 11  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 22. 28.  8.  4.  7.  9.  1.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 29. 10.  0. 14.] 
adversary cards in discard: [25.  0. 16.  3.  3.  6.] 
adversary owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0] -> size -> 28 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -2.14656925201416
desired expected reward: -10.499150276184082



action possibilites: [-1] 
expected returns: [[28.029396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 3. 3. 6. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  8  3  6  0  6  6  8  0  0  6  3  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 22. 28.  8.  4.  7.  9.  1.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 29. 10.  0. 14.] 
adversary cards in discard: [25.  0. 16.  3.  3.  6.] 
adversary owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0] -> size -> 28 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: trash_cards_n_from_hand - action 9
Learning step: -4.816987991333008
desired expected reward: 48.13600158691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.151344]
 [ 9.356452]
 [26.28999 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 3. 3. 6. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  8  3  6  0  6  6  8  0  0  6  3  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 22. 28.  8.  4.  7.  9.  1.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 29. 10.  0. 14.] 
adversary cards in discard: [25.  0. 16.  3.  3.  6.] 
adversary owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0] -> size -> 28 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1
Learning step: -3.7683212757110596
desired expected reward: 24.26107406616211



buy possibilites: [-1] 
expected returns: [[15.369855]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 3. 3. 6. 0. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  8  3  6  0  6  6  8  0  0  6  3  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 24. 30. 22. 28.  8.  4.  7.  9.  1.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 29. 10.  0. 14.] 
adversary cards in discard: [25.  0. 16.  3.  3.  6.] 
adversary owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0] -> size -> 28 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -70.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -86.0 

action type: buy - action 0.0
Learning step: -4.861745357513428
desired expected reward: 13.289602279663086






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 0. 29. 10.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  0. 14.] 
cards in discard: [25.  0. 16.  3.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 28.  8.  4.  7.  9.  1.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  3.  6. 10.] 
adversary cards in discard: [0. 3. 3. 6. 0. 6. 0. 8. 0.] 
adversary owned cards: [ 3 10  8  3  6  0  6  6  8  0  0  6  3  0  0] -> size -> 15 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  0. 14.] 
cards in discard: [25.  0. 16.  3.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 30. 22. 28.  8.  4.  7.  9.  1.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  3.  6. 10.] 
adversary cards in discard: [0. 3. 3. 6. 0. 6. 0. 8. 0.] 
adversary owned cards: [ 3 10  8  3  6  0  6  6  8  0  0  6  3  0  0] -> size -> 15 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  0. 14.] 
cards in discard: [25.  0. 16.  3.  3.  6.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  3.  6. 10.] 
adversary cards in discard: [0. 3. 3. 6. 0. 6. 0. 8. 0.] 
adversary owned cards: [ 3 10  8  3  6  0  6  6  8  0  0  6  3  0  0] -> size -> 15 
adversary victory points: -1
player victory points: 6 





Player: 0 
cards in hand: [ 6.  0.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[44.897453]
 [38.216267]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  6. 10.] 
cards in discard: [0. 3. 3. 6. 0. 6. 0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  8  3  6  0  6  6  8  0  0  6  3  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [15.  3.  8.  3.  1.] 
adversary cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.] 
adversary owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0  8] -> size -> 29 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -3.6154744625091553
desired expected reward: 11.754380226135254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[34.768677]
 [16.354588]
 [44.879707]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  6. 10.] 
cards in discard: [0. 3. 3. 6. 0. 6. 0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  8  3  6  0  6  6  8  0  0  6  3  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [15.  3.  8.  3.  1.] 
adversary cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.] 
adversary owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0  8] -> size -> 29 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -5.291991710662842
desired expected reward: 39.86256790161133



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [15.  3.  8.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  8.  3.  1.] 
cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [6. 6. 3. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  8  3  6  0  6  6  8  0  0  6  3  0  0] -> size -> 15 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 1.] 
cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [6. 6. 3. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  8  3  6  0  6  6  8  0  0  6  3  0  0] -> size -> 15 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 1.] 
cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [6. 6. 3. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  8  3  6  0  6  6  8  0  0  6  3  0  0] -> size -> 15 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 1.] 
cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0  8  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [6. 6. 3. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  8  3  6  0  6  6  8  0  0  6  3  0  0] -> size -> 15 
adversary victory points: -1
player victory points: 6 





Player: 0 
cards in hand: [6. 6. 3. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[66.47879 ]
 [57.906784]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 6. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  8  3  6  0  6  6  8  0  0  6  3  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  3. 16. 15. 14.] 
adversary cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.  0. 15.  3.  8.  3.  1.] 
adversary owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0  8  0] -> size -> 30 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1.0
Learning step: -4.672872066497803
desired expected reward: 40.20683670043945



action possibilites: [-1] 
expected returns: [[61.042557]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  3  0  8  0  0  6  3  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  3. 16. 15. 14.] 
adversary cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.  0. 15.  3.  8.  3.  1.] 
adversary owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0  8  0] -> size -> 30 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: trash_cards_n_from_hand - action 8
Learning step: -3.046732187271118
desired expected reward: 51.357059478759766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[46.904568]
 [21.25667 ]
 [59.85023 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  3  0  8  0  0  6  3  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  3. 16. 15. 14.] 
adversary cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.  0. 15.  3.  8.  3.  1.] 
adversary owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0  8  0] -> size -> 30 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1
Learning step: -3.731060743331909
desired expected reward: 57.31149673461914






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 16. 15. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 15. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 16. 15. 14.] 
cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.  0. 15.  3.  8.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  1 16  8  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0
 14  0 25  0  8  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [8.] 
adversary owned cards: [10  8  3  0  8  0  0  6  3  0  0] -> size -> 11 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 14.] 
cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.  0. 15.  3.  8.  3.  1.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14
  0 25  0  8  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [8.] 
adversary owned cards: [10  8  3  0  8  0  0  6  3  0  0] -> size -> 11 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 14.] 
cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.  0. 15.  3.  8.  3.  1.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14
  0 25  0  8  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [8.] 
adversary owned cards: [10  8  3  0  8  0  0  6  3  0  0] -> size -> 11 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [0. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[43.393417]
 [37.286472]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  8  0  0  6  3  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 16.  1.  3.  8.] 
adversary cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.  0. 15.  3.  8.  3.  1.
  0. 16.  3. 15. 14.] 
adversary owned cards: [ 3 29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14
  0 25  0  8  0  0] -> size -> 30 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1.0
Learning step: -4.446053504943848
desired expected reward: 48.77352523803711



action possibilites: [-1] 
expected returns: [[33.71467]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  8  0  0  6  3  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 16.  1.  3.  8.] 
adversary cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.  0. 15.  3.  8.  3.  1.
  0. 16.  3. 15. 14.] 
adversary owned cards: [ 3 29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14
  0 25  0  8  0  0] -> size -> 30 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: trash_cards_n_from_hand - action 1
Learning step: -3.463552474975586
desired expected reward: 35.979095458984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[23.476984]
 [27.757053]
 [ 8.565573]
 [32.926235]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  8  0  0  6  3  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 16.  1.  3.  8.] 
adversary cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.  0. 15.  3.  8.  3.  1.
  0. 16.  3. 15. 14.] 
adversary owned cards: [ 3 29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14
  0 25  0  8  0  0] -> size -> 30 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: -3.3795604705810547
desired expected reward: 30.335107803344727






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 8. 16.  1.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  1.  3.  8.] 
cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.  0. 15.  3.  8.  3.  1.
  0. 16.  3. 15. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14
  0 25  0  8  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  0.  6.] 
adversary cards in discard: [8. 8. 0. 3. 0.] 
adversary owned cards: [10  8  0  8  0  0  6  3  0  0] -> size -> 10 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  8.] 
cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.  0. 15.  3.  8.  3.  1.
  0. 16.  3. 15. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14  0
 25  0  8  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  0.  6.] 
adversary cards in discard: [8. 8. 0. 3. 0.] 
adversary owned cards: [10  8  0  8  0  0  6  3  0  0] -> size -> 10 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  8.] 
cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.  0. 15.  3.  8.  3.  1.
  0. 16.  3. 15. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14  0
 25  0  8  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 24. 30. 22. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  0.  6.] 
adversary cards in discard: [8. 8. 0. 3. 0.] 
adversary owned cards: [10  8  0  8  0  0  6  3  0  0] -> size -> 10 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  8.] 
cards in discard: [25.  0. 16.  3.  3.  6.  8.  0. 29. 10.  0. 14.  0. 15.  3.  8.  3.  1.
  0. 16.  3. 15. 14.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14  0
 25  0  8  0  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  0.  6.] 
adversary cards in discard: [8. 8. 0. 3. 0.] 
adversary owned cards: [10  8  0  8  0  0  6  3  0  0] -> size -> 10 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [ 0. 10.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[10.164497 ]
 [ 1.2001176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  6.] 
cards in discard: [8. 8. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  0  0  6  3  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 10. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14  0
 25  0  8  0  0  3] -> size -> 30 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: -4.788028240203857
desired expected reward: 28.13821792602539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[ -6.6706886 ]
 [  0.12431931]
 [ -2.1303945 ]
 [-12.694099  ]
 [  4.264337  ]
 [ -4.904914  ]
 [  1.9247236 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  6.] 
cards in discard: [8. 8. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  0  0  6  3  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 24. 30. 21. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 0. 10. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14  0
 25  0  8  0  0  3] -> size -> 30 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -3.7228386402130127
desired expected reward: 4.949091911315918



buy possibilites: [-1] 
expected returns: [[9.586008]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  6.] 
cards in discard: [ 8.  8.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  0  0  6  3  0  0 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  5. 10.  7.] 
adversary cards in hand: [ 0. 10. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14  0
 25  0  8  0  0  3] -> size -> 30 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -47 

action type: buy - action 10.0
Learning step: -1.8890694379806519
desired expected reward: -6.793977737426758






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0. 10. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14  0
 25  0  8  0  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8  0  0  6  3  0  0 10] -> size -> 11 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14  0
 25  0  8  0  0  3] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8  0  0  6  3  0  0 10] -> size -> 11 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14  0
 25  0  8  0  0  3] -> size -> 30 
action values: 2 
buys: 0 
player value: 1 
card supply: [13. 24. 30. 21. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8  0  0  6  3  0  0 10] -> size -> 11 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14  0
 25  0  8  0  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 24. 30. 21. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8  0  0  6  3  0  0 10] -> size -> 11 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [3. 1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14  0
 25  0  8  0  0  3  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 23. 30. 21. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  5. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8  0  0  6  3  0  0 10] -> size -> 11 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [ 0.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[52.898136]
 [42.327904]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  0  0  6  3  0  0 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 21. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  5. 10.  7.] 
adversary cards in hand: [ 8.  0.  8. 16. 15.] 
adversary cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14  0
 25  0  8  0  0  3  1] -> size -> 31 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -2.5835025310516357
desired expected reward: 7.002505302429199





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[32.04756  ]
 [44.015785 ]
 [39.298862 ]
 [ 5.1857057]
 [48.148094 ]
 [37.43569  ]
 [47.945553 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  0  0  6  3  0  0 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 23. 30. 21. 28.  8.  4.  7.  9.  0.  8.  9.  8.  9.  5. 10.  7.] 
adversary cards in hand: [ 8.  0.  8. 16. 15.] 
adversary cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14  0
 25  0  8  0  0  3  1] -> size -> 31 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -5.1661834716796875
desired expected reward: 50.332374572753906



buy possibilites: [-1] 
expected returns: [[17.529627]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  0  0  6  3  0  0 10 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 21. 28.  8.  4.  7.  8.  0.  8.  9.  8.  9.  5. 10.  7.] 
adversary cards in hand: [ 8.  0.  8. 16. 15.] 
adversary cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14  0
 25  0  8  0  0  3  1] -> size -> 31 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -47 

action type: buy - action 11.0
Learning step: -4.3629889488220215
desired expected reward: 43.785118103027344






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  8. 16. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 16. 15.] 
cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  0  3 10 14  8 16 16  3  3  0 14  0
 25  0  8  0  0  3  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 21. 28.  8.  4.  7.  8.  0.  8.  9.  8.  9.  5. 10.  7.] 
adversary cards in hand: [10.  8.  0.  6.  0.] 
adversary cards in discard: [11.  0.  0.  3.  0. 10.] 
adversary owned cards: [10  8  0  8  0  0  6  3  0  0 10 11] -> size -> 12 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 16.] 
cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 23. 30. 21. 28.  8.  4.  7.  8.  0.  8.  9.  8.  9.  5. 10.  7.] 
adversary cards in hand: [10.  8.  0.  6.  0.] 
adversary cards in discard: [11.  0.  0.  3.  0. 10.] 
adversary owned cards: [10  8  0  8  0  0  6  3  0  0 10 11] -> size -> 12 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 16.] 
cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 23. 30. 21. 28.  8.  4.  7.  8.  0.  8.  9.  8.  9.  5. 10.  7.] 
adversary cards in hand: [10.  8.  0.  6.  0.] 
adversary cards in discard: [11.  0.  0.  3.  0. 10.] 
adversary owned cards: [10  8  0  8  0  0  6  3  0  0 10 11] -> size -> 12 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 16.] 
cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 21. 28.  8.  4.  7.  8.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [10.  8.  0.  6.  0.] 
adversary cards in discard: [11.  0.  0.  3.  0. 10.] 
adversary owned cards: [10  8  0  8  0  0  6  3  0  0 10 11] -> size -> 12 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [10.  8.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[46.675003]
 [40.276093]
 [41.400146]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  6.  0.] 
cards in discard: [11.  0.  0.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  0  0  6  3  0  0 10 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 21. 28.  8.  4.  7.  8.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [1. 8. 0. 0. 3.] 
adversary cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10] -> size -> 31 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -3.2073819637298584
desired expected reward: 14.322244644165039



action possibilites: [-1.  8.  8.] 
expected returns: [[62.690384]
 [60.71736 ]
 [60.71736 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0. 8.] 
cards in discard: [11.  0.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  8  0  0  6  3  0  0 10 11] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 21. 28.  8.  4.  7.  8.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [1. 8. 0. 0. 3.] 
adversary cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10] -> size -> 31 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 10.0
Learning step: -2.7451846599578857
desired expected reward: 34.87065505981445



action possibilites: [-1.] 
expected returns: [[52.40596]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [11.  0.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  0  8  0  0  3  0  0 10 11] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 21. 28.  8.  4.  7.  8.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [1. 8. 0. 0. 3.] 
adversary cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10] -> size -> 31 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 4
Learning step: -1.732937216758728
desired expected reward: 42.50849151611328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[36.89282 ]
 [42.512978]
 [27.806387]
 [47.86861 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [11.  0.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  0  8  0  0  3  0  0 10 11] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 23. 30. 21. 28.  8.  4.  7.  8.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [1. 8. 0. 0. 3.] 
adversary cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10] -> size -> 31 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -2.415673017501831
desired expected reward: 49.99028778076172



buy possibilites: [-1] 
expected returns: [[92.24472]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [11.  0.  0.  3.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  0  8  0  0  3  0  0 10 11  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 23. 30. 21. 28.  8.  4.  7.  8.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [1. 8. 0. 0. 3.] 
adversary cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10] -> size -> 31 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -50.   0.   0.  40. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -44.0 

action type: buy - action 0.0
Learning step: -1.7980562448501587
desired expected reward: 35.09477233886719






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [1. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 0. 3.] 
cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 21. 28.  8.  4.  7.  8.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [ 0.  0. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  8  0  0  3  0  0 10 11  0] -> size -> 11 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 0. 3.] 
cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 23. 30. 21. 28.  8.  4.  7.  8.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [ 0.  0. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  8  0  0  3  0  0 10 11  0] -> size -> 11 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 0. 3.] 
cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 22. 30. 21. 28.  8.  4.  7.  8.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [ 0.  0. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  8  0  0  3  0  0 10 11  0] -> size -> 11 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [ 0.  0. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[48.358807]
 [41.06871 ]
 [53.228455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  8  0  0  3  0  0 10 11  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 21. 28.  8.  4.  7.  8.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [ 6. 14. 16.  3. 16.] 
adversary cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.  1.  1.  8.  0.  0.
  3.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1] -> size -> 32 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -6.222468376159668
desired expected reward: 86.02225494384766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[30.31194 ]
 [42.809372]
 [35.658134]
 [13.98329 ]
 [44.534615]
 [32.518658]
 [39.999264]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  8  0  0  3  0  0 10 11  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 22. 30. 21. 28.  8.  4.  7.  8.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [ 6. 14. 16.  3. 16.] 
adversary cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.  1.  1.  8.  0.  0.
  3.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1] -> size -> 32 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -4.298351764678955
desired expected reward: 43.81483840942383



buy possibilites: [-1] 
expected returns: [[32.935974]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11.  0.] 
cards in discard: [11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  8  0  0  3  0  0 10 11  0 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [ 6. 14. 16.  3. 16.] 
adversary cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.  1.  1.  8.  0.  0.
  3.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1] -> size -> 32 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -36 

action type: buy - action 11.0
Learning step: -3.2856709957122803
desired expected reward: 41.248931884765625






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 6. 14. 16.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14. 16.  3. 16.] 
cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.  1.  1.  8.  0.  0.
  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0. 10. 11.  0.] 
adversary owned cards: [10  0  8  0  0  3  0  0 10 11  0 11] -> size -> 12 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14. 16.  3. 16.] 
cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.  1.  1.  8.  0.  0.
  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0. 10. 11.  0.] 
adversary owned cards: [10  0  8  0  0  3  0  0 10 11  0 11] -> size -> 12 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14. 16.  3. 16.] 
cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.  1.  1.  8.  0.  0.
  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0. 10. 11.  0.] 
adversary owned cards: [10  0  8  0  0  3  0  0 10 11  0 11] -> size -> 12 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[72.25664]
 [66.01264]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0. 10. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  8  0  0  3  0  0 10 11  0 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [14.  8.  3.  1.  3.] 
adversary cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.  1.  1.  8.  0.  0.
  3.  0.  6. 14. 16.  3. 16.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1  0] -> size -> 33 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -2.835984468460083
desired expected reward: 30.09998893737793



action possibilites: [-1] 
expected returns: [[26.463049]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [11.  0.  0. 10. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  0  0 10 11  0 11] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [14.  8.  3.  1.  3.] 
adversary cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.  1.  1.  8.  0.  0.
  3.  0.  6. 14. 16.  3. 16.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1  0] -> size -> 33 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: trash_cards_n_from_hand - action 3
Learning step: -4.359226226806641
desired expected reward: 60.73366928100586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[15.511318]
 [18.944492]
 [10.845873]
 [22.179634]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [11.  0.  0. 10. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  0  0 10 11  0 11] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [14.  8.  3.  1.  3.] 
adversary cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.  1.  1.  8.  0.  0.
  3.  0.  6. 14. 16.  3. 16.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1  0] -> size -> 33 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: -3.1747243404388428
desired expected reward: 23.2883243560791






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [14.  8.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3.  1.  3.] 
cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.  1.  1.  8.  0.  0.
  3.  0.  6. 14. 16.  3. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11] -> size -> 10 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  3.  1.  3.] 
cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.  1.  1.  8.  0.  0.
  3.  0.  6. 14. 16.  3. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11] -> size -> 10 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  3.  1.  3.] 
cards in discard: [ 3.  1. 10. 29.  0.  0.  0. 15. 10. 15.  8.  8. 16.  1.  1.  8.  0.  0.
  3.  0.  6. 14. 16.  3. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11] -> size -> 10 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [ 8.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[24.944416]
 [23.293276]
 [21.303652]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0 10 11  0 11] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [ 3.  0.  3. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1  0  0] -> size -> 34 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: -3.9266154766082764
desired expected reward: 18.253021240234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[ 7.370428]
 [14.002079]
 [12.355503]
 [ 5.220957]
 [16.421007]
 [ 9.460428]
 [16.703   ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0 10 11  0 11] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  4. 10.  7.] 
adversary cards in hand: [ 3.  0.  3. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1  0  0] -> size -> 34 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -4.011420249938965
desired expected reward: 16.817302703857422



buy possibilites: [-1] 
expected returns: [[10.24497]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 10.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  3. 10.  7.] 
adversary cards in hand: [ 3.  0.  3. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1  0  0] -> size -> 34 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -47 

action type: buy - action 10.0
Learning step: -2.5925099849700928
desired expected reward: 6.867921829223633






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 25.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  3. 10.  7.] 
adversary cards in hand: [11. 10. 11.  0.  0.] 
adversary cards in discard: [10.  8.  0.  0.  0. 10.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10] -> size -> 11 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 25.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  3. 10.  7.] 
adversary cards in hand: [11. 10. 11.  0.  0.] 
adversary cards in discard: [10.  8.  0.  0.  0. 10.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10] -> size -> 11 
adversary victory points: 0
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[10.414054]
 [11.404807]
 [ 7.18629 ]
 [11.404807]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  0.  0.] 
cards in discard: [10.  8.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  3. 10.  7.] 
adversary cards in hand: [14.  8. 16.  0.  1.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1  0  0] -> size -> 34 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -3.5401337146759033
desired expected reward: 6.704836845397949



action possibilites: [-1] 
expected returns: [[20.093786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0.] 
cards in discard: [10.  8.  0.  0.  0. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [14.  8. 16.  0.  1.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1  0  0] -> size -> 34 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -36 

action type: gain_card_n - action 8
Learning step: -1.7006113529205322
desired expected reward: 5.353821754455566





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[12.572617 ]
 [16.779526 ]
 [ 4.6456804]
 [21.556704 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  0.] 
cards in discard: [10.  8.  0.  0.  0. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 22. 30. 21. 28.  8.  4.  7.  7.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [14.  8. 16.  0.  1.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1  0  0] -> size -> 34 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: -2.9149765968322754
desired expected reward: 17.178810119628906



buy possibilites: [-1] 
expected returns: [[1.7994959]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  0.] 
cards in discard: [10.  8.  0.  0.  0. 10. 10.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 22. 30. 21. 28.  8.  3.  7.  7.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [14.  8. 16.  0.  1.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.] 
adversary owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1  0  0] -> size -> 34 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -70.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -356.0 

action type: buy - action 6.0
Learning step: -17.991796493530273
desired expected reward: -13.346111297607422






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [14.  8. 16.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 16.  0.  1.] 
cards in discard: [ 3.  0.  3. 25.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [29  1 16  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25
  0  8  0  0  3  1 10  1  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 21. 28.  8.  3.  7.  7.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10.  0. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6] -> size -> 13 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  1.] 
cards in discard: [ 3.  0.  3. 25.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25  0
  8  0  0  3  1 10  1  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 21. 28.  8.  3.  7.  7.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10.  0. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6] -> size -> 13 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  1.] 
cards in discard: [ 3.  0.  3. 25.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25  0
  8  0  0  3  1 10  1  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 22. 30. 21. 28.  8.  3.  7.  7.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10.  0. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6] -> size -> 13 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  1.] 
cards in discard: [ 3.  0.  3. 25.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25  0
  8  0  0  3  1 10  1  0  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 22. 30. 21. 28.  8.  3.  7.  7.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10.  0. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6] -> size -> 13 
adversary victory points: -1
player victory points: 6 





Player: 0 
cards in hand: [10.  0. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 10.] 
expected returns: [[13.006905 ]
 [ 5.6187057]
 [ 5.6187057]
 [15.310381 ]
 [ 5.6187057]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 11. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 21. 28.  8.  3.  7.  7.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 3.  1.  0.  0. 15.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1.] 
adversary owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25  0
  8  0  0  3  1 10  1  0  0  0] -> size -> 34 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -3.6064891815185547
desired expected reward: -1.8069932460784912



action possibilites: [-1] 
expected returns: [[-23.890572]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 21. 28.  8.  3.  7.  7.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 3.  1.  0.  0. 15.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1.] 
adversary owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25  0
  8  0  0  3  1 10  1  0  0  0] -> size -> 34 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: gain_card_n - action 0
Learning step: -5.023834705352783
desired expected reward: -1.297895908355713





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-20.20735 ]
 [-24.060322]
 [-20.897459]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 22. 30. 21. 28.  8.  3.  7.  7.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 3.  1.  0.  0. 15.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1.] 
adversary owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25  0
  8  0  0  3  1 10  1  0  0  0] -> size -> 34 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1
Learning step: -2.088834524154663
desired expected reward: -25.979406356811523



buy possibilites: [-1] 
expected returns: [[12.102865]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [0. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 22. 30. 21. 28.  8.  2.  7.  7.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 3.  1.  0.  0. 15.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1.] 
adversary owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25  0
  8  0  0  3  1 10  1  0  0  0] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -80.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -367.0 

action type: buy - action 6.0
Learning step: -16.874670028686523
desired expected reward: -40.93498992919922






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 3.  1.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  0. 15.] 
cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3  0 14  0 25  0
  8  0  0  3  1 10  1  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 21. 28.  8.  2.  7.  7.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 8.  0. 11.  6. 10.] 
adversary cards in discard: [ 0.  6. 11. 10.  0. 10. 10.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6] -> size -> 15 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0.] 
cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 22. 30. 21. 28.  8.  2.  7.  7.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 8.  0. 11.  6. 10.] 
adversary cards in discard: [ 0.  6. 11. 10.  0. 10. 10.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6] -> size -> 15 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 8. 22. 30. 21. 28.  8.  2.  7.  7.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 8.  0. 11.  6. 10.] 
adversary cards in discard: [ 0.  6. 11. 10.  0. 10. 10.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6] -> size -> 15 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 22. 30. 21. 28.  8.  2.  7.  6.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 8.  0. 11.  6. 10.] 
adversary cards in discard: [ 0.  6. 11. 10.  0. 10. 10.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6] -> size -> 15 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [ 8.  0. 11.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[4.491202  ]
 [0.04428983]
 [3.9396992 ]
 [0.8245101 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  6. 10.] 
cards in discard: [ 0.  6. 11. 10.  0. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 21. 28.  8.  2.  7.  6.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 3.  1.  8. 29. 10.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.] 
adversary owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -4.898094654083252
desired expected reward: 7.204770565032959



action possibilites: [-1] 
expected returns: [[12.75498]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 10.] 
cards in discard: [ 0.  6. 11. 10.  0. 10. 10.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 21. 28.  8.  2.  7.  6.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 3.  1.  8. 29. 10.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.] 
adversary owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -58 

action type: gain_card_n - action 1
Learning step: -2.7788915634155273
desired expected reward: 0.5386810302734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 4.1798105]
 [-4.618865 ]
 [12.260372 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  6. 10.] 
cards in discard: [ 0.  6. 11. 10.  0. 10. 10.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 21. 30. 21. 28.  8.  2.  7.  6.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 3.  1.  8. 29. 10.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.] 
adversary owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -3.8695569038391113
desired expected reward: 8.88542366027832






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 3.  1.  8. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  8. 29. 10.] 
cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 21. 28.  8.  2.  7.  6.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1] -> size -> 16 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  0.] 
cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 21. 30. 21. 28.  8.  2.  7.  6.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1] -> size -> 16 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 1.] 
cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11] -> size -> 34 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 8. 21. 30. 21. 28.  8.  2.  7.  6.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1] -> size -> 16 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 1.] 
cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 21. 30. 21. 28.  8.  2.  7.  6.  0.  8.  9.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1] -> size -> 16 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 1.] 
cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 21. 28.  8.  2.  7.  6.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1] -> size -> 16 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [ 6. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-31.725368]
 [-32.117676]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 21. 28.  8.  2.  7.  6.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6. 14. 10.  3. 16.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1. 29. 29.
 10.  3.  8.  0.  1.] 
adversary owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11 29] -> size -> 35 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -5.71888542175293
desired expected reward: 6.541482925415039



action possibilites: [-1.] 
expected returns: [[-6.0384173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 21. 28.  8.  2.  7.  6.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6. 14. 10.  3. 16.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1. 29. 29.
 10.  3.  8.  0.  1.] 
adversary owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11 29] -> size -> 35 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -65 

action type: take_action - action 10.0
Learning step: -1.6985464096069336
desired expected reward: -35.44490432739258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-5.6754713]
 [-6.292189 ]
 [-3.6498666]
 [-3.5665548]
 [-3.7249541]
 [-6.407111 ]
 [-4.6279407]
 [-6.091715 ]
 [-6.89738  ]
 [-2.1340399]
 [-1.4276083]
 [-3.8201509]
 [-2.6127152]
 [-2.2073894]
 [-2.649504 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 8. 21. 30. 21. 28.  8.  2.  7.  6.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6. 14. 10.  3. 16.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1. 29. 29.
 10.  3.  8.  0.  1.] 
adversary owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11 29] -> size -> 35 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -3.1312029361724854
desired expected reward: -9.169620513916016



buy possibilites: [-1] 
expected returns: [[-3.6850219]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 1.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 21. 30. 20. 28.  8.  2.  7.  6.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6. 14. 10.  3. 16.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1. 29. 29.
 10.  3.  8.  0.  1.] 
adversary owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11 29] -> size -> 35 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -70.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -54.0 

action type: buy - action 3.0
Learning step: -2.600419044494629
desired expected reward: -6.250299453735352






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 6. 14. 10.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14. 10.  3. 16.] 
cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1. 29. 29.
 10.  3.  8.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 20. 28.  8.  2.  7.  6.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10.  0.  0.  8. 11.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  1.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3] -> size -> 17 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14. 10.  3. 16.] 
cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1. 29. 29.
 10.  3.  8.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11 29] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 21. 30. 20. 28.  8.  2.  7.  6.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10.  0.  0.  8. 11.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  1.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3] -> size -> 17 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14. 10.  3. 16.] 
cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1. 29. 29.
 10.  3.  8.  0.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11 29  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 20. 28.  8.  2.  7.  6.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10.  0.  0.  8. 11.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  1.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3] -> size -> 17 
adversary victory points: -1
player victory points: 6 





Player: 0 
cards in hand: [10.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
expected returns: [[34.244522]
 [29.32515 ]
 [29.667782]
 [33.918465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8. 11.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 20. 28.  8.  2.  7.  6.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  0. 16.  8. 15.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1. 29. 29.
 10.  3.  8.  0.  1.  0.  6. 14. 10.  3. 16.] 
adversary owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11 29  0] -> size -> 36 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -2.8917808532714844
desired expected reward: -6.576802730560303





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[23.278978]
 [27.689846]
 [18.91335 ]
 [31.83181 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  8. 11.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 21. 30. 20. 28.  8.  2.  7.  6.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  0. 16.  8. 15.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1. 29. 29.
 10.  3.  8.  0.  1.  0.  6. 14. 10.  3. 16.] 
adversary owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11 29  0] -> size -> 36 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -4.917356014251709
desired expected reward: 29.327173233032227



buy possibilites: [-1] 
expected returns: [[30.442451]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  8. 11.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  1.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 21. 30. 20. 28.  8.  1.  7.  6.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  0. 16.  8. 15.] 
adversary cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1. 29. 29.
 10.  3.  8.  0.  1.  0.  6. 14. 10.  3. 16.] 
adversary owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11 29  0] -> size -> 36 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -387.0 

action type: buy - action 6.0
Learning step: -19.6107120513916
desired expected reward: -0.6973667144775391






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 16.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  8. 15.] 
cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1. 29. 29.
 10.  3.  8.  0.  1.  0.  6. 14. 10.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14  0 25  0  8
  0  0  3  1 10  1  0  0  0 11 29  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 20. 28.  8.  1.  7.  6.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6. 11.  0. 10. 10.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  1.  6. 10.  0.  0.  8. 11.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6] -> size -> 18 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8.] 
cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1. 29. 29.
 10.  3.  8.  0.  1.  0.  6. 14. 10.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  0  8  0
  0  3  1 10  1  0  0  0 11 29  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 21. 30. 20. 28.  8.  1.  7.  6.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6. 11.  0. 10. 10.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  1.  6. 10.  0.  0.  8. 11.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6] -> size -> 18 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  8.] 
cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1. 29. 29.
 10.  3.  8.  0.  1.  0.  6. 14. 10.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  0  8  0
  0  3  1 10  1  0  0  0 11 29  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 21. 30. 20. 28.  8.  1.  7.  6.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6. 11.  0. 10. 10.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  1.  6. 10.  0.  0.  8. 11.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6] -> size -> 18 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  8.] 
cards in discard: [ 3.  0.  3. 25.  3.  0.  8. 14.  0.  1. 11. 15.  3.  1.  0.  1. 29. 29.
 10.  3.  8.  0.  1.  0.  6. 14. 10.  3. 16. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  0  8  0
  0  3  1 10  1  0  0  0 11 29  0 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 21. 30. 20. 28.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6. 11.  0. 10. 10.] 
adversary cards in discard: [ 3. 10.  6.  0.  0.  0.  1.  6. 10.  0.  0.  8. 11.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6] -> size -> 18 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [ 6. 11.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[-12.528158 ]
 [-11.452545 ]
 [-11.5145645]
 [-11.5145645]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0. 10. 10.] 
cards in discard: [ 3. 10.  6.  0.  0.  0.  1.  6. 10.  0.  0.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 20. 28.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 3.  0. 29.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  0  8  0
  0  3  1 10  1  0  0  0 11 29  0 11] -> size -> 36 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -6.135488033294678
desired expected reward: 24.306962966918945



action possibilites: [-1. 11. 10.] 
expected returns: [[ -9.3541765]
 [-10.321062 ]
 [-10.925212 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 20. 28.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 3.  0. 29.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  0  8  0
  0  3  1 10  1  0  0  0 11 29  0 11] -> size -> 36 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action 10.0
Learning step: -2.8916146755218506
desired expected reward: -16.589340209960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-10.65484  ]
 [ -5.9203515]
 [ -8.558535 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 21. 30. 20. 28.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 3.  0. 29.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  0  8  0
  0  3  1 10  1  0  0  0 11 29  0 11] -> size -> 36 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -3.062070846557617
desired expected reward: -12.41624927520752






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 29.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3.  8.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [29  1  3  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  0  8  0
  0  3  1 10  1  0  0  0 11 29  0 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 20. 28.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [1. 0. 6. 0. 8.] 
adversary cards in discard: [10.  6. 11.  0. 10.  3.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6] -> size -> 18 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  0  8  0  0  3
  1 10  1  0  0  0 11 29  0 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 20. 28.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [1. 0. 6. 0. 8.] 
adversary cards in discard: [10.  6. 11.  0. 10.  3.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6] -> size -> 18 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  0  8  0  0  3
  1 10  1  0  0  0 11 29  0 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 21. 30. 20. 28.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [1. 0. 6. 0. 8.] 
adversary cards in discard: [10.  6. 11.  0. 10.  3.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6] -> size -> 18 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  0  8  0  0  3
  1 10  1  0  0  0 11 29  0 11  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 21. 30. 20. 28.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [1. 0. 6. 0. 8.] 
adversary cards in discard: [10.  6. 11.  0. 10.  3.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6] -> size -> 18 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [1. 0. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-16.921263]
 [-15.427073]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 0. 8.] 
cards in discard: [10.  6. 11.  0. 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 20. 28.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [11. 15.  0.  1.  3.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  0  8  0  0  3
  1 10  1  0  0  0 11 29  0 11  0] -> size -> 35 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1.0
Learning step: -3.7833404541015625
desired expected reward: -12.341876029968262





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-14.402243]
 [-15.003866]
 [-13.727565]
 [-13.06161 ]
 [-14.977874]
 [-15.690893]
 [-15.224249]
 [-12.521266]
 [-14.91941 ]
 [-13.686456]
 [-16.93061 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 0. 8.] 
cards in discard: [10.  6. 11.  0. 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 21. 30. 20. 28.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [11. 15.  0.  1.  3.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  0  8  0  0  3
  1 10  1  0  0  0 11 29  0 11  0] -> size -> 35 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -3.3242759704589844
desired expected reward: -20.24553871154785



buy possibilites: [-1] 
expected returns: [[2.0475304]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 0. 8.] 
cards in discard: [10.  6. 11.  0. 10.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 21. 30. 19. 28.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [11. 15.  0.  1.  3.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  0  8  0  0  3
  1 10  1  0  0  0 11 29  0 11  0] -> size -> 35 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -64.0 

action type: buy - action 3.0
Learning step: -2.4675521850585938
desired expected reward: -16.195117950439453






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [11. 15.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0.  1.  3.] 
cards in discard: [0. 8. 0. 3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  0  8  0  0  3
  1 10  1  0  0  0 11 29  0 11  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 19. 28.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  6. 10.  0. 10.] 
adversary cards in discard: [10.  6. 11.  0. 10.  3.  3.  1.  0.  6.  0.  8.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3] -> size -> 19 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.] 
cards in discard: [0. 8. 0. 3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 21. 30. 19. 28.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  6. 10.  0. 10.] 
adversary cards in discard: [10.  6. 11.  0. 10.  3.  3.  1.  0.  6.  0.  8.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3] -> size -> 19 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.] 
cards in discard: [0. 8. 0. 3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 6. 21. 30. 19. 28.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  6. 10.  0. 10.] 
adversary cards in discard: [10.  6. 11.  0. 10.  3.  3.  1.  0.  6.  0.  8.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3] -> size -> 19 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.] 
cards in discard: [0. 8. 0. 3. 4.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 19. 27.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  6. 10.  0. 10.] 
adversary cards in discard: [10.  6. 11.  0. 10.  3.  3.  1.  0.  6.  0.  8.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3] -> size -> 19 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [ 0.  6. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[-14.676091]
 [-17.174494]
 [-17.174494]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  0. 10.] 
cards in discard: [10.  6. 11.  0. 10.  3.  3.  1.  0.  6.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 19. 27.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 1.  3.  3. 14. 16.] 
adversary cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -5.264152526855469
desired expected reward: -3.2166221141815186



action possibilites: [-1. 10. 11.] 
expected returns: [[-17.854284]
 [-19.458548]
 [-17.72554 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 10. 11.] 
cards in discard: [10.  6. 11.  0. 10.  3.  3.  1.  0.  6.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 19. 27.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 1.  3.  3. 14. 16.] 
adversary cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action 10.0
Learning step: -3.351860523223877
desired expected reward: -20.52635383605957



action possibilites: [-1. 11.] 
expected returns: [[-9.662817]
 [-8.456725]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11.  0.] 
cards in discard: [10.  6. 11.  0. 10.  3.  3.  1.  0.  6.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3] -> size -> 19 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 19. 27.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 1.  3.  3. 14. 16.] 
adversary cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  40   0   0   0   0   0   0   0   0   1] 
sum of rewards: -55 

action type: take_action - action 10.0
Learning step: -1.9787765741348267
desired expected reward: -21.437328338623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[-14.383868 ]
 [-12.296688 ]
 [-11.7098675]
 [-14.386342 ]
 [-10.110388 ]
 [-13.410087 ]
 [-10.679504 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.  0.] 
cards in discard: [10.  6. 11.  0. 10.  3.  3.  1.  0.  6.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 21. 30. 19. 27.  8.  1.  7.  5.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 1.  3.  3. 14. 16.] 
adversary cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -2.588210105895996
desired expected reward: -12.251032829284668



buy possibilites: [-1] 
expected returns: [[-9.528412]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.  0.] 
cards in discard: [10.  6. 11.  0. 10.  3.  3.  1.  0.  6.  0.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 19. 27.  8.  1.  7.  4.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 1.  3.  3. 14. 16.] 
adversary cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  40   0   0   0   0   0   0   0  18   0] 
sum of rewards: -38 

action type: buy - action 11.0
Learning step: -1.608869194984436
desired expected reward: -11.719271659851074






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  3. 14. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3. 14. 16.] 
cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 19. 27.  8.  1.  7.  4.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3 11] -> size -> 20 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3. 16.] 
cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 21. 30. 19. 27.  8.  1.  7.  4.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  1. 10.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3 11] -> size -> 20 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  3. 16.] 
cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 21. 30. 19. 27.  8.  1.  7.  4.  0.  8.  8.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  1. 10.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3 11] -> size -> 20 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  3. 16.] 
cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 19. 27.  8.  1.  7.  4.  0.  8.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0.  1. 10.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3 11] -> size -> 20 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [ 0.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-14.281253]
 [-11.380527]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10.] 
cards in discard: [0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 19. 27.  8.  1.  7.  4.  0.  8.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10. 25.  1.  6. 10.] 
adversary cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29] -> size -> 36 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: discard_down_to_3_cards - action 3
Learning step: -4.190103054046631
desired expected reward: -21.72786521911621



action possibilites: [-1. 10.] 
expected returns: [[-1.2320576]
 [-1.9284286]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10.] 
cards in discard: [0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3 11] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 19. 27.  8.  1.  7.  4.  0.  8.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10. 25.  1.  6. 10.] 
adversary cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29] -> size -> 36 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action 10.0
Learning step: -3.294943332672119
desired expected reward: -14.082473754882812



action possibilites: [-1.] 
expected returns: [[-13.619398]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3 11] -> size -> 20 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 19. 27.  8.  1.  7.  4.  0.  8.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10. 25.  1.  6. 10.] 
adversary cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29] -> size -> 36 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  40   0   0   0   0   0   0   0   0   1] 
sum of rewards: -55 

action type: take_action - action 10.0
Learning step: -2.9600155353546143
desired expected reward: -4.888436317443848





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-15.131283]
 [-15.763723]
 [-14.946341]
 [-24.374655]
 [-15.441658]
 [-15.118828]
 [-15.508535]
 [-15.854827]
 [-14.586155]
 [-14.176779]
 [-14.089187]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 21. 30. 19. 27.  8.  1.  7.  4.  0.  8.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10. 25.  1.  6. 10.] 
adversary cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29] -> size -> 36 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -2.470510959625244
desired expected reward: -16.089908599853516



buy possibilites: [-1] 
expected returns: [[-6.6107802]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [0. 0. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3 11  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 21. 30. 18. 27.  8.  1.  7.  4.  0.  8.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [10. 25.  1.  6. 10.] 
adversary cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29] -> size -> 36 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -80.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -43.0 

action type: buy - action 3.0
Learning step: -1.5302635431289673
desired expected reward: -16.476608276367188






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [10. 25.  1.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  1.  6. 10.] 
cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 18. 27.  8.  1.  7.  4.  0.  8.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6.  0.  8. 11. 10.] 
adversary cards in discard: [ 0.  0.  3. 10. 10.  0.  1.  0.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3 11  3] -> size -> 21 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 25.  1.  6. 10.] 
cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 21. 30. 18. 27.  8.  1.  7.  4.  0.  8.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6.  0.  8. 11. 10.] 
adversary cards in discard: [ 0.  0.  3. 10. 10.  0.  1.  0.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3 11  3] -> size -> 21 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 25.  1.  6. 10.] 
cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 17. 27.  8.  1.  7.  4.  0.  8.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6.  0.  8. 11. 10.] 
adversary cards in discard: [ 0.  0.  3. 10. 10.  0.  1.  0.] 
adversary owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3 11  3] -> size -> 21 
adversary victory points: 0
player victory points: 9 





Player: 0 
cards in hand: [ 6.  0.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[-1.6393683 ]
 [-0.9876461 ]
 [-1.1408293 ]
 [-0.45947766]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8. 11. 10.] 
cards in discard: [ 0.  0.  3. 10. 10.  0.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3 11  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 17. 27.  8.  1.  7.  4.  0.  8.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 1. 29.  0.  3. 11.] 
adversary cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.  3. 10. 25.
  1.  6. 10.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29  3] -> size -> 37 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: -4.44111967086792
desired expected reward: -11.051899909973145



action possibilites: [-1.  8. 11.] 
expected returns: [[ 2.496814 ]
 [-0.730855 ]
 [ 3.6691754]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8. 11.  3.] 
cards in discard: [ 0.  0.  3. 10. 10.  0.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  0  0 10 11  0 11 10 10  6  0  6  1  3  6  3 11  3] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 17. 27.  8.  1.  7.  4.  0.  8.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 1. 29.  0.  3. 11.] 
adversary cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.  3. 10. 25.
  1.  6. 10.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29  3] -> size -> 37 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 10.0
Learning step: -3.679669141769409
desired expected reward: -4.139153480529785



action possibilites: [-1.] 
expected returns: [[-28.838297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [ 0.  0.  3. 10. 10.  0.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  0  0  0 10  0 11 10 10  6  0  6  1  3  6  3 11  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 17. 27.  8.  1.  7.  4.  0.  8.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 1. 29.  0.  3. 11.] 
adversary cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.  3. 10. 25.
  1.  6. 10.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29  3] -> size -> 37 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: trash_cards_n_from_hand - action 9
Learning step: -3.601334810256958
desired expected reward: 0.4481236934661865





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-27.21236 ]
 [-32.351536]
 [-28.120396]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 0.  0.  3. 10. 10.  0.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  0  0  0 10  0 11 10 10  6  0  6  1  3  6  3 11  3] -> size -> 19 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 6. 21. 30. 17. 27.  8.  1.  7.  4.  0.  8.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 1. 29.  0.  3. 11.] 
adversary cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.  3. 10. 25.
  1.  6. 10.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29  3] -> size -> 37 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -1.9585624933242798
desired expected reward: -30.796859741210938



buy possibilites: [-1] 
expected returns: [[-20.549274]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 0.  0.  3. 10. 10.  0.  1.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  0  0  0 10  0 11 10 10  6  0  6  1  3  6  3 11  3  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 17. 27.  8.  0.  7.  4.  0.  8.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 1. 29.  0.  3. 11.] 
adversary cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.  3. 10. 25.
  1.  6. 10.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29  3] -> size -> 37 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   40    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -366 

action type: buy - action 6.0
Learning step: -17.1447811126709
desired expected reward: -49.496307373046875






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 1. 29.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  3. 11.] 
cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.  3. 10. 25.
  1.  6. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 17. 27.  8.  0.  7.  4.  0.  8.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 0. 11. 10.  3.  6.] 
adversary cards in discard: [ 0.  0.  3. 10. 10.  0.  1.  0.  6. 10.  8.  6.  3.] 
adversary owned cards: [10  8  0  0  0 10  0 11 10 10  6  0  6  1  3  6  3 11  3  6] -> size -> 20 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  3.] 
cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.  3. 10. 25.
  1.  6. 10. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29  3 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 17. 27.  8.  0.  7.  4.  0.  8.  7.  8.  9.  2. 10.  6.] 
adversary cards in hand: [ 0. 11. 10.  3.  6.] 
adversary cards in discard: [ 0.  0.  3. 10. 10.  0.  1.  0.  6. 10.  8.  6.  3.] 
adversary owned cards: [10  8  0  0  0 10  0 11 10 10  6  0  6  1  3  6  3 11  3  6] -> size -> 20 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0.  3.] 
cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.  3. 10. 25.
  1.  6. 10. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29  3 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 21. 30. 17. 27.  8.  0.  7.  4.  0.  8.  7.  8.  9.  2. 10.  6.] 
adversary cards in hand: [ 0. 11. 10.  3.  6.] 
adversary cards in discard: [ 0.  0.  3. 10. 10.  0.  1.  0.  6. 10.  8.  6.  3.] 
adversary owned cards: [10  8  0  0  0 10  0 11 10 10  6  0  6  1  3  6  3 11  3  6] -> size -> 20 
adversary victory points: -1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0.  3.] 
cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.  3. 10. 25.
  1.  6. 10. 15. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29  3 15 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 17. 27.  8.  0.  7.  4.  0.  8.  7.  8.  9.  1. 10.  6.] 
adversary cards in hand: [ 0. 11. 10.  3.  6.] 
adversary cards in discard: [ 0.  0.  3. 10. 10.  0.  1.  0.  6. 10.  8.  6.  3.] 
adversary owned cards: [10  8  0  0  0 10  0 11 10 10  6  0  6  1  3  6  3 11  3  6] -> size -> 20 
adversary victory points: -1
player victory points: 9 





Player: 0 
cards in hand: [ 0. 11. 10.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[-15.530368]
 [-15.411594]
 [-14.249858]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3.  6.] 
cards in discard: [ 0.  0.  3. 10. 10.  0.  1.  0.  6. 10.  8.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  0 10  0 11 10 10  6  0  6  1  3  6  3 11  3  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 17. 27.  8.  0.  7.  4.  0.  8.  7.  8.  9.  1. 10.  6.] 
adversary cards in hand: [ 8. 15.  8.  8.  3.] 
adversary cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.  3. 10. 25.
  1.  6. 10. 15. 10. 11.  1. 29.  0.  3.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29  3 15 10] -> size -> 39 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: buy - action -1
Learning step: -4.608585357666016
desired expected reward: -25.157859802246094



Player 1 won the game! 



Player 0 bought cards:
Copper: 10 
Silver: 3 
Gold: 0 
Estate: 5 
Duchy: 2 
Province: 0 
Curse: 9 

Remodel: 0 
Workshop: 4 
Chapel: 5 
Witch: 1 
Poacher: 0 
Militia: 0 
Market: 1 
Village: 3 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 10.  3.  6.] 
cards in discard: [ 0.  0.  3. 10. 10.  0.  1.  0.  6. 10.  8.  6.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  0  0 10  0 11 10 10  6  0  6  1  3  6  3 11  3  6 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 17. 27.  8.  0.  7.  4.  0.  8.  7.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 8. 15.  8.  8.  3.] 
adversary cards in discard: [ 0.  8.  0.  3.  4. 15. 11.  1.  3. 29. 14.  1.  3.  3. 16.  3. 10. 25.
  1.  6. 10. 15. 10. 11.  1. 29.  0.  3.] 
adversary owned cards: [ 1  1  8  6 15 15  3  3  8  3 10 14  8 16 16  3  3 14 25  8  0  0  3  1
 10  1  0  0  0 11 29  0 11  0  4 29  3 15 10] -> size -> 39 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5 -500   -1 -100    0    0   20    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -577 

action type: gain_card_n - action 7
Learning step: -28.3337459564209
desired expected reward: -38.658817291259766



