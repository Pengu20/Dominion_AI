 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[291.67014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: 0.5138273239135742
desired expected reward: -12.76271915435791





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[263.49982]
 [277.41837]
 [271.1735 ]
 [235.34015]
 [284.82544]
 [272.64117]
 [269.5312 ]
 [291.06284]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.508854866027832
desired expected reward: 283.4027404785156



buy possibilites: [-1] 
expected returns: [[272.5736]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -21.284103393554688
desired expected reward: 214.05609130859375






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[304.73257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -7.953044414520264
desired expected reward: 264.6205749511719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[283.76852]
 [297.9894 ]
 [290.37405]
 [254.65144]
 [289.8739 ]
 [304.1685 ]
 [293.79877]
 [294.8154 ]
 [267.7352 ]
 [288.4333 ]
 [282.31833]
 [308.20193]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -9.742436408996582
desired expected reward: 293.61920166015625



buy possibilites: [-1] 
expected returns: [[286.38754]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6. 0. 0. 3. 0. 3. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -18.5 

action type: buy - action 1.0
Learning step: -9.380752563476562
desired expected reward: 288.60870361328125






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[274.4712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -9.308562278747559
desired expected reward: 277.0789794921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[246.32121]
 [258.64117]
 [252.25983]
 [222.99144]
 [264.8505 ]
 [254.86098]
 [250.78072]
 [269.1218 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -9.08129596710205
desired expected reward: 264.73272705078125



buy possibilites: [-1] 
expected returns: [[287.51575]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -10.0 

action type: buy - action 3.0
Learning step: -6.643886566162109
desired expected reward: 245.6159210205078






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 1. 0. 3.] 
adversary cards in discard: [3. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 3] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 1. 0. 3.] 
adversary cards in discard: [3. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 3] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 1. 0. 3.] 
adversary cards in discard: [3. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 3] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 6. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[332.67618]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1. 0. 3.] 
cards in discard: [3. 0. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -7.559190273284912
desired expected reward: 279.95654296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[301.69995]
 [317.46057]
 [310.05765]
 [269.2312 ]
 [308.56393]
 [325.15866]
 [312.20667]
 [313.7183 ]
 [284.97015]
 [308.03162]
 [301.41806]
 [330.8078 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 0. 3.] 
cards in discard: [3. 0. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 3] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.062335968017578
desired expected reward: 319.564208984375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 3] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 3] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 3] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[298.77136]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -10.425341606140137
desired expected reward: 320.3824768066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[266.02515]
 [279.85693]
 [273.20453]
 [247.6747 ]
 [236.81548]
 [272.07108]
 [286.1142 ]
 [275.19757]
 [297.5936 ]
 [276.44742]
 [250.56406]
 [259.91092]
 [271.17096]
 [244.28693]
 [265.34897]
 [291.02005]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 3] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.346611022949219
desired expected reward: 289.10003662109375



buy possibilites: [-1] 
expected returns: [[268.57227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -4.0 

action type: buy - action 14.0
Learning step: -6.685327053070068
desired expected reward: 243.87872314453125






Player: 1 
cards in hand: [ 0.  3.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 29.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 29.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 29.  3.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[293.36172]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -7.497796535491943
desired expected reward: 261.074462890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[273.96533]
 [286.33554]
 [279.36853]
 [243.5565 ]
 [291.66592]
 [282.76282]
 [278.00253]
 [295.90073]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.756550788879395
desired expected reward: 281.501953125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  0.  3.  3. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  0.  3.  3. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  0.  3.  3. 29.  3. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[271.6032 ]
 [221.36661]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  6.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -9.769001007080078
desired expected reward: 286.1317443847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[224.7296 ]
 [232.7779 ]
 [192.33646]
 [235.65392]
 [254.6684 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  6.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.894373416900635
desired expected reward: 243.12509155273438



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 29.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 0. 14.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 0. 14.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  8.  0.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 0. 14.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[237.5022]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 0. 14.  3.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 15.] 
adversary cards in discard: [ 1.  0. 29.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -8.02564525604248
desired expected reward: 246.6427764892578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[214.66112]
 [220.70154]
 [190.22151]
 [223.14091]
 [236.56078]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 0. 14.  3.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 15.] 
adversary cards in discard: [ 1.  0. 29.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.4191179275512695
desired expected reward: 228.48207092285156



buy possibilites: [-1] 
expected returns: [[245.0374]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 0. 14.  3.  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 15.] 
adversary cards in discard: [ 1.  0. 29.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -42.0 

action type: buy - action 0.0
Learning step: -7.319714546203613
desired expected reward: 207.34140014648438






Player: 1 
cards in hand: [ 0.  3.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 15.] 
cards in discard: [ 1.  0. 29.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 15.] 
cards in discard: [ 1.  0. 29.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0] -> size -> 15 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [3. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[250.82713]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 1.  0. 29.  0.  8.  0.  0.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -7.278800964355469
desired expected reward: 237.75860595703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[221.77316]
 [235.2569 ]
 [227.89383]
 [203.1411 ]
 [193.01382]
 [227.5106 ]
 [240.376  ]
 [231.00479]
 [252.28519]
 [231.82144]
 [205.25359]
 [214.32047]
 [225.89867]
 [199.44527]
 [219.75523]
 [242.77274]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 1.  0. 29.  0.  8.  0.  0.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.824812412261963
desired expected reward: 239.86717224121094



buy possibilites: [-1] 
expected returns: [[243.25177]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 1.  0. 29.  0.  8.  0.  0.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -7.5 

action type: buy - action 1.0
Learning step: -6.664677619934082
desired expected reward: 228.59217834472656






Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 1.  0. 29.  0.  8.  0.  0.  3.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 14.  3.  0.  0.] 
adversary cards in discard: [1. 3. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 1.  0. 29.  0.  8.  0.  0.  3.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 14.  3.  0.  0.] 
adversary cards in discard: [1. 3. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 1.  0. 29.  0.  8.  0.  0.  3.  0.  0. 15.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 14.  3.  0.  0.] 
adversary cards in discard: [1. 3. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3. 14.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[247.57458]
 [206.40437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  3.  0.  0.] 
cards in discard: [1. 3. 0. 1. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -7.613494873046875
desired expected reward: 235.63827514648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[219.24507]
 [223.9614 ]
 [196.6743 ]
 [227.41968]
 [243.60007]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  3.  0.  0.] 
cards in discard: [1. 3. 0. 1. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.7609381675720215
desired expected reward: 237.46307373046875



buy possibilites: [-1] 
expected returns: [[201.65236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  3.  0.  0.] 
cards in discard: [1. 3. 0. 1. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 28. 30.  8.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1  8] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -323.0 

action type: buy - action 6.0
Learning step: -21.446537017822266
desired expected reward: 175.22776794433594






Player: 1 
cards in hand: [ 0. 15.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 1.  3.  0.  1.  0.  0.  6.  3. 14.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6] -> size -> 17 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 28. 30.  8.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 1.  3.  0.  1.  0.  0.  6.  3. 14.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6] -> size -> 17 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  3.  0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1  8  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 1.  3.  0.  1.  0.  0.  6.  3. 14.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6] -> size -> 17 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[151.00943]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 1.  3.  0.  1.  0.  0.  6.  3. 14.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [ 3.  0. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1  8  3] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -8.261479377746582
desired expected reward: 193.39088439941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[135.1915 ]
 [147.01382]
 [141.66432]
 [110.72102]
 [153.45898]
 [142.70117]
 [139.92238]
 [157.00432]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 1.  3.  0.  1.  0.  0.  6.  3. 14.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 27. 30.  8.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [ 3.  0. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1  8  3] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -6.116237163543701
desired expected reward: 148.15658569335938



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [ 3.  0. 15.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  8  0 15  1  8  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 1. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6] -> size -> 17 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 3.  0. 15.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 1. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6] -> size -> 17 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 3.  0. 15.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 27. 30.  8.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 1. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6] -> size -> 17 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 1. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[226.35796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [ 3.  0. 15.  3.  3.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -3.8920280933380127
desired expected reward: 153.11227416992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[194.18512]
 [209.11366]
 [201.14128]
 [167.59879]
 [200.6225 ]
 [214.83458]
 [204.43384]
 [205.32137]
 [179.04698]
 [198.79463]
 [192.36935]
 [218.27414]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 27. 30.  8.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [ 3.  0. 15.  3.  3.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -7.936309814453125
desired expected reward: 219.09423828125



buy possibilites: [-1] 
expected returns: [[244.89]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0. 3.] 
cards in discard: [16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [ 3.  0. 15.  3.  3.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 9 

action type: buy - action 16.0
Learning step: -4.071098327636719
desired expected reward: 196.55136108398438






Player: 1 
cards in hand: [ 0. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [ 3.  0. 15.  3.  3.  0.  8.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  1. 14.  0.  3.] 
adversary cards in discard: [16.  0.  1.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16] -> size -> 18 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [ 3.  0. 15.  3.  3.  0.  8.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  1. 14.  0.  3.] 
adversary cards in discard: [16.  0.  1.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16] -> size -> 18 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [ 3.  0. 15.  3.  3.  0.  8.  3.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  1. 14.  0.  3.] 
adversary cards in discard: [16.  0.  1.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16] -> size -> 18 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3.  1. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[218.40387]
 [194.34955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 14.  0.  3.] 
cards in discard: [16.  0.  1.  6.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  0.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -8.734816551208496
desired expected reward: 236.15518188476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[191.93654]
 [201.64766]
 [195.75842]
 [172.90277]
 [205.29053]
 [199.08556]
 [194.87328]
 [207.03978]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 14.  0.  3.] 
cards in discard: [16.  0.  1.  6.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  0.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -7.000655651092529
desired expected reward: 199.2794647216797



buy possibilites: [-1] 
expected returns: [[174.58464]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 14.  0.  3.] 
cards in discard: [16.  0.  1.  6.  0.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  0.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -5 

action type: buy - action 1.0
Learning step: -6.404228210449219
desired expected reward: 195.24343872070312






Player: 1 
cards in hand: [29.  0.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  1.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [16.  0.  1.  6.  0.  3.  1.  3.  1. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1] -> size -> 19 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 8. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [16.  0.  1.  6.  0.  3.  1.  3.  1. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1] -> size -> 19 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 25. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [16.  0.  1.  6.  0.  3.  1.  3.  1. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1] -> size -> 19 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8. 0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 25. 30. 27. 30.  8.  8.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [16.  0.  1.  6.  0.  3.  1.  3.  1. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1] -> size -> 19 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[182.68056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [16.  0.  1.  6.  0.  3.  1.  3.  1. 14.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  8.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  3.] 
adversary cards in discard: [ 8. 29.  0.  0.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -5.851617336273193
desired expected reward: 168.73301696777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[161.72154]
 [174.02742]
 [168.57559]
 [139.19124]
 [167.29327]
 [179.48337]
 [169.67175]
 [170.60747]
 [149.32344]
 [166.27614]
 [160.93292]
 [181.56345]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [16.  0.  1.  6.  0.  3.  1.  3.  1. 14.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 25. 30. 27. 30.  8.  8.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  3.] 
adversary cards in discard: [ 8. 29.  0.  0.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -6.2966532707214355
desired expected reward: 172.7084503173828



buy possibilites: [-1] 
expected returns: [[182.52817]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [16.  0.  1.  6.  0.  3.  1.  3.  1. 14.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 24. 30. 27. 30.  8.  8.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  3.] 
adversary cards in discard: [ 8. 29.  0.  0.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -18.5 

action type: buy - action 1.0
Learning step: -5.519484996795654
desired expected reward: 168.5078887939453






Player: 1 
cards in hand: [ 0.  0. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0.  3.] 
cards in discard: [ 8. 29.  0.  0.  1.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 27. 30.  8.  8.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1] -> size -> 20 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.  3.] 
cards in discard: [ 8. 29.  0.  0.  1.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 24. 30. 27. 30.  8.  8.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1] -> size -> 20 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.  3.] 
cards in discard: [ 8. 29.  0.  0.  1.  8.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  8.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1] -> size -> 20 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[153.38527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 27. 30.  8.  8.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 8. 3. 0.] 
adversary cards in discard: [ 8. 29.  0.  0.  1.  8.  0.  1.  0.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8  1] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -6.860854625701904
desired expected reward: 175.6673126220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[131.36716 ]
 [139.34999 ]
 [ 97.757835]
 [141.5092  ]
 [155.36848 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 23. 30. 27. 30.  8.  8.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 8. 3. 0.] 
adversary cards in discard: [ 8. 29.  0.  0.  1.  8.  0.  1.  0.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8  1] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -5.640674114227295
desired expected reward: 146.16172790527344



buy possibilites: [-1] 
expected returns: [[204.43468]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 23. 30. 27. 30.  8.  8.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 8. 3. 0.] 
adversary cards in discard: [ 8. 29.  0.  0.  1.  8.  0.  1.  0.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8  1] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -53.0 

action type: buy - action 0.0
Learning step: -4.618577003479004
desired expected reward: 126.74856567382812






Player: 1 
cards in hand: [3. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 3. 0.] 
cards in discard: [ 8. 29.  0.  0.  1.  8.  0.  1.  0.  0. 15.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 27. 30.  8.  8.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  0. 16.] 
adversary cards in discard: [0. 6. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0] -> size -> 21 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 3. 0.] 
cards in discard: [ 8. 29.  0.  0.  1.  8.  0.  1.  0.  0. 15.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 23. 30. 27. 30.  8.  8.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  0. 16.] 
adversary cards in discard: [0. 6. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0] -> size -> 21 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 3. 0.] 
cards in discard: [ 8. 29.  0.  0.  1.  8.  0.  1.  0.  0. 15.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8  1  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 27. 30.  8.  8.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  0. 16.] 
adversary cards in discard: [0. 6. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0] -> size -> 21 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 14.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
expected returns: [[202.33005]
 [172.80531]
 [185.9231 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  0. 16.] 
cards in discard: [0. 6. 3. 0. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 27. 30.  8.  8.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 1. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8  1  0] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -7.032783508300781
desired expected reward: 197.40188598632812



action possibilites: [-1] 
expected returns: [[215.97113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 16.] 
cards in discard: [0. 6. 3. 0. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 23. 30. 27. 30.  8.  8.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [1. 8. 1.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8  1  0] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action 14.0
Learning step: -4.068718433380127
desired expected reward: 171.49264526367188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[197.83812]
 [208.93315]
 [203.51549]
 [174.00948]
 [202.76852]
 [214.67996]
 [205.46873]
 [206.57402]
 [185.0903 ]
 [202.21352]
 [197.18701]
 [218.65526]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 16.] 
cards in discard: [0. 6. 3. 0. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 23. 30. 27. 30.  8.  8.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [1. 8. 1.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8  1  0] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -6.335326671600342
desired expected reward: 209.63580322265625



buy possibilites: [-1] 
expected returns: [[220.75829]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 16.] 
cards in discard: [ 0.  6.  3.  0.  0.  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 27. 30.  8.  8.  9.  9.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [1. 8. 1.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8  1  0] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 1.5 

action type: buy - action 11.0
Learning step: -5.691936016082764
desired expected reward: 208.98800659179688






Player: 1 
cards in hand: [1. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 1.] 
cards in discard: [3. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  1  8  3  1  8  1  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 27. 30.  8.  8.  9.  9.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [1. 0. 0. 1. 1.] 
adversary cards in discard: [ 0.  6.  3.  0.  0.  3. 11. 14.  3.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11] -> size -> 22 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [3. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 27. 30.  8.  8.  9.  9.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [1. 0. 0. 1. 1.] 
adversary cards in discard: [ 0.  6.  3.  0.  0.  3. 11. 14.  3.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11] -> size -> 22 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 23. 30. 27. 30.  8.  8.  9.  9.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [1. 0. 0. 1. 1.] 
adversary cards in discard: [ 0.  6.  3.  0.  0.  3. 11. 14.  3.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11] -> size -> 22 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 3. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  8.  9.  9.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [1. 0. 0. 1. 1.] 
adversary cards in discard: [ 0.  6.  3.  0.  0.  3. 11. 14.  3.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11] -> size -> 22 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[179.23877]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 1. 1.] 
cards in discard: [ 0.  6.  3.  0.  0.  3. 11. 14.  3.  0.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  8.  9.  9.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -8.234369277954102
desired expected reward: 212.52391052246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[146.68677 ]
 [157.50168 ]
 [140.54875 ]
 [152.19048 ]
 [132.49998 ]
 [141.72911 ]
 [124.527695]
 [151.37247 ]
 [162.29643 ]
 [154.02074 ]
 [170.8988  ]
 [154.72682 ]
 [134.77191 ]
 [141.5306  ]
 [150.61456 ]
 [130.0345  ]
 [145.87508 ]
 [165.01466 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 1.] 
cards in discard: [ 0.  6.  3.  0.  0.  3. 11. 14.  3.  0.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 8 
card supply: [25. 23. 30. 27. 30.  8.  8.  9.  9.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -6.504528999328613
desired expected reward: 169.20860290527344



buy possibilites: [-1] 
expected returns: [[181.37436]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 1.] 
cards in discard: [ 0.  6.  3.  0.  0.  3. 11. 14.  3.  0.  0. 16. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 23. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.   12.5   0. ] 
sum of rewards: -10.5 

action type: buy - action 25.0
Learning step: -4.989017009735107
desired expected reward: 165.9097900390625






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 1.] 
adversary cards in discard: [ 0.  6.  3.  0.  0.  3. 11. 14.  3.  0.  0. 16. 25.  1.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11 25] -> size -> 23 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 23. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 1.] 
adversary cards in discard: [ 0.  6.  3.  0.  0.  3. 11. 14.  3.  0.  0. 16. 25.  1.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11 25] -> size -> 23 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  3.  0.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 1.] 
adversary cards in discard: [ 0.  6.  3.  0.  0.  3. 11. 14.  3.  0.  0. 16. 25.  1.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11 25] -> size -> 23 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[134.31041]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 1.] 
cards in discard: [ 0.  6.  3.  0.  0.  3. 11. 14.  3.  0.  0. 16. 25.  1.  0.  0.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 15. 29.  0.] 
adversary cards in discard: [ 3.  3.  0.  8. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0 10] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -7.1967339515686035
desired expected reward: 174.17762756347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[107.109665]
 [118.192474]
 [112.16248 ]
 [ 84.53417 ]
 [111.871414]
 [121.9901  ]
 [114.655045]
 [115.163864]
 [ 94.313034]
 [110.21432 ]
 [105.396545]
 [123.5317  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 1.] 
cards in discard: [ 0.  6.  3.  0.  0.  3. 11. 14.  3.  0.  0. 16. 25.  1.  0.  0.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 23. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 15. 29.  0.] 
adversary cards in discard: [ 3.  3.  0.  8. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0 10] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -5.073626518249512
desired expected reward: 124.15202331542969



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 15. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 29.  0.] 
cards in discard: [ 3.  3.  0.  8. 10.  0.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0. 16.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11 25] -> size -> 23 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 3.  3.  0.  8. 10.  0.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 23. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0. 16.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11 25] -> size -> 23 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 3.  3.  0.  8. 10.  0.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 23. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0. 16.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11 25] -> size -> 23 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 3.  3.  0.  8. 10.  0.  3.  0.  0.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0 10 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0. 16.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11 25] -> size -> 23 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [14.  0. 16.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
expected returns: [[185.75104]
 [151.44678]
 [169.36644]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 16.  1.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3 14  0  1  6 16  1  1  0 11 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [1. 0. 8. 3. 8.] 
adversary cards in discard: [ 3.  3.  0.  8. 10.  0.  3.  0.  0.  0. 14. 15.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0 10 14] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -3.541827917098999
desired expected reward: 119.98989868164062



action possibilites: [-1] 
expected returns: [[221.4833]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [1. 0. 8. 3. 8.] 
adversary cards in discard: [ 3.  3.  0.  8. 10.  0.  3.  0.  0.  0. 14. 15.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0 10 14] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 6 

action type: gain_card_n - action 13
Learning step: -3.296830415725708
desired expected reward: 168.30726623535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[205.67221]
 [219.3305 ]
 [212.75305]
 [187.6931 ]
 [177.65276]
 [211.56223]
 [225.57056]
 [214.75702]
 [236.57568]
 [215.73349]
 [190.8373 ]
 [199.4681 ]
 [210.8442 ]
 [184.752  ]
 [204.9567 ]
 [229.68893]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 23. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [1. 0. 8. 3. 8.] 
adversary cards in discard: [ 3.  3.  0.  8. 10.  0.  3.  0.  0.  0. 14. 15.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0 10 14] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -6.409312725067139
desired expected reward: 215.07398986816406



buy possibilites: [-1] 
expected returns: [[214.83049]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [10.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 22. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [1. 0. 8. 3. 8.] 
adversary cards in discard: [ 3.  3.  0.  8. 10.  0.  3.  0.  0.  0. 14. 15.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0 10 14] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 1.5 

action type: buy - action 1.0
Learning step: -6.057839393615723
desired expected reward: 213.2726593017578






Player: 1 
cards in hand: [1. 0. 8. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 3. 8.] 
cards in discard: [ 3.  3.  0.  8. 10.  0.  3.  0.  0.  0. 14. 15.  0. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8  0 15  8  3  8  1  0  0 10 14] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 3.] 
adversary cards in discard: [10.  1. 16.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1] -> size -> 24 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  3.  0.  8. 10.  0.  3.  0.  0.  0. 14. 15.  0. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 3.] 
adversary cards in discard: [10.  1. 16.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1] -> size -> 24 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  3.  0.  8. 10.  0.  3.  0.  0.  0. 14. 15.  0. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 22. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 3.] 
adversary cards in discard: [10.  1. 16.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1] -> size -> 24 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[113.35919]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [10.  1. 16.  0.  1.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.84946346282959
desired expected reward: 205.9810333251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 92.943474]
 [ 99.167625]
 [ 71.79747 ]
 [ 99.55542 ]
 [113.35937 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [10.  1. 16.  0.  1.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 22. 30. 27. 30.  8.  8.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -4.068295478820801
desired expected reward: 108.91222381591797



buy possibilites: [-1] 
expected returns: [[121.91988]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [10.  1. 16.  0.  1.  1.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 22. 30. 27. 30.  8.  7.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -324.0 

action type: buy - action 6.0
Learning step: -17.046676635742188
desired expected reward: 54.75079345703125






Player: 1 
cards in hand: [ 0. 15.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 27. 30.  8.  7.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  6.  3.  0. 11.] 
adversary cards in discard: [10.  1. 16.  0.  1.  1.  6.  3.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 22. 30. 27. 30.  8.  7.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [10.  1. 16.  0.  1.  1.  6.  3.  0.  0.  6.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 22. 30. 27. 30.  8.  7.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [10.  1. 16.  0.  1.  1.  6.  3.  0.  0.  6.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0.] 
cards in discard: [4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14  4] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 27. 29.  8.  7.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [10.  1. 16.  0.  1.  1.  6.  3.  0.  0.  6.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6] -> size -> 25 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[182.54948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [10.  1. 16.  0.  1.  1.  6.  3.  0.  0.  6.  3.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 27. 29.  8.  7.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [ 4. 14.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14  4] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -50    0    0    0  -30    0    0    0    0    0 -900
   99    0] 
sum of rewards: -885 

action type: discard_down_to_3_cards - action 7
Learning step: -42.11178207397461
desired expected reward: -4.319793701171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[164.41603]
 [136.91772]
 [183.50113]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [10.  1. 16.  0.  1.  1.  6.  3.  0.  0.  6.  3.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 22. 30. 27. 29.  8.  7.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [ 4. 14.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14  4] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -7.911013126373291
desired expected reward: 171.10305786132812



buy possibilites: [-1] 
expected returns: [[161.51979]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [10.  1. 16.  0.  1.  1.  6.  3.  0.  0.  6.  3.  3. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 22. 30. 27. 29.  8.  7.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [ 4. 14.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14  4] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -84.0 

action type: buy - action 0.0
Learning step: -8.78660774230957
desired expected reward: 155.62945556640625






Player: 1 
cards in hand: [ 8.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10.  0.] 
cards in discard: [ 4. 14.  0. 15.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14  4] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 29.  8.  7.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  1. 16.  0.  1.  1.  6.  3.  0.  0.  6.  3.  3. 11.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0] -> size -> 26 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 10.  0.] 
cards in discard: [ 4. 14.  0. 15.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14  4] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 22. 30. 27. 29.  8.  7.  9.  9.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  1. 16.  0.  1.  1.  6.  3.  0.  0.  6.  3.  3. 11.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0] -> size -> 26 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 10.  0.] 
cards in discard: [ 4. 14.  0. 15.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14  4 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 29.  8.  7.  9.  8.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  1. 16.  0.  1.  1.  6.  3.  0.  0.  6.  3.  3. 11.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0] -> size -> 26 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[132.57701]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  1. 16.  0.  1.  1.  6.  3.  0.  0.  6.  3.  3. 11.  0.  6.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 29.  8.  7.  9.  8.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  3.  0.] 
adversary cards in discard: [ 4. 14.  0. 15.  0.  0. 11.  8.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14  4 11] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -7.793006896972656
desired expected reward: 153.72677612304688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[117.33807 ]
 [125.290726]
 [121.5587  ]
 [107.1276  ]
 [101.518425]
 [120.72849 ]
 [129.11954 ]
 [122.360504]
 [135.4969  ]
 [122.95902 ]
 [108.77662 ]
 [113.89483 ]
 [120.18063 ]
 [105.5473  ]
 [116.73264 ]
 [131.64217 ]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  1. 16.  0.  1.  1.  6.  3.  0.  0.  6.  3.  3. 11.  0.  6.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 22. 30. 27. 29.  8.  7.  9.  8.  7.  9.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  3.  0.] 
adversary cards in discard: [ 4. 14.  0. 15.  0.  0. 11.  8.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14  4 11] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -6.57754373550415
desired expected reward: 125.99946594238281



buy possibilites: [-1] 
expected returns: [[120.5004]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  1. 16.  0.  1.  1.  6.  3.  0.  0.  6.  3.  3. 11.  0.  6.  3.  0.
 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 29.  8.  7.  9.  8.  7.  9.  9.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 8. 29.  0.  3.  0.] 
adversary cards in discard: [ 4. 14.  0. 15.  0.  0. 11.  8.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14  4 11] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: -4 

action type: buy - action 22.0
Learning step: -2.4719862937927246
desired expected reward: 97.19291687011719






Player: 1 
cards in hand: [ 8. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  3.  0.] 
cards in discard: [ 4. 14.  0. 15.  0.  0. 11.  8.  0.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0 15  8  3  8  0  0 10 14  4 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 29.  8.  7.  9.  8.  7.  9.  9.  8. 10.  8.  9.  9.] 
adversary cards in hand: [16.  0.  1. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22] -> size -> 27 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.] 
cards in discard: [ 4. 14.  0. 15.  0.  0. 11.  8.  0.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 29.  8.  7.  9.  8.  7.  9.  9.  8. 10.  8.  9.  9.] 
adversary cards in hand: [16.  0.  1. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22] -> size -> 27 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.] 
cards in discard: [ 4. 14.  0. 15.  0.  0. 11.  8.  0.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 22. 30. 27. 29.  8.  7.  9.  8.  7.  9.  9.  8. 10.  8.  9.  9.] 
adversary cards in hand: [16.  0.  1. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22] -> size -> 27 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.] 
cards in discard: [ 4. 14.  0. 15.  0.  0. 11.  8.  0.  0. 10.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 26. 29.  8.  7.  9.  8.  7.  9.  9.  8. 10.  8.  9.  9.] 
adversary cards in hand: [16.  0.  1. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22] -> size -> 27 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [16.  0.  1. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.] 
expected returns: [[149.61723]
 [135.49564]
 [155.60011]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1. 25.  1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 26. 29.  8.  7.  9.  8.  7.  9.  9.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -5.4236321449279785
desired expected reward: 115.07676696777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[152.52809]
 [162.8553 ]
 [156.92632]
 [140.54112]
 [133.31017]
 [156.70605]
 [167.83458]
 [159.49565]
 [177.13643]
 [160.30342]
 [142.61142]
 [147.5113 ]
 [156.01215]
 [138.03479]
 [151.78831]
 [171.1352 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  1. 25.  1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 22. 30. 26. 29.  8.  7.  9.  8.  7.  9.  9.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -6.491761684417725
desired expected reward: 141.06829833984375



buy possibilites: [-1] 
expected returns: [[89.50549]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  1. 25.  1.] 
cards in discard: [14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 22. 30. 26. 29.  8.  7.  9.  8.  7.  9.  9.  7. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -46.0 

action type: buy - action 14.0
Learning step: -7.416698455810547
desired expected reward: 135.19473266601562






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 26. 29.  8.  7.  9.  8.  7.  9.  9.  7. 10.  8.  9.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  1.] 
adversary cards in discard: [14. 16.  0.  1. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14] -> size -> 28 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 22. 30. 26. 29.  8.  7.  9.  8.  7.  9.  9.  7. 10.  8.  9.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  1.] 
adversary cards in discard: [14. 16.  0.  1. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14] -> size -> 28 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 26. 29.  8.  7.  9.  8.  7.  9.  9.  7. 10.  7.  9.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  1.] 
adversary cards in discard: [14. 16.  0.  1. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14] -> size -> 28 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[97.531456]
 [94.90668 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0.  1.] 
cards in discard: [14. 16.  0.  1. 25.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 26. 29.  8.  7.  9.  8.  7.  9.  9.  7. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 11.  4.  3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3 10] -> size -> 20 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -5.068665981292725
desired expected reward: 84.43682861328125



action possibilites: [-1] 
expected returns: [[103.25702]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 1.] 
cards in discard: [14. 16.  0.  1. 25.  1. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 26. 29.  8.  7.  9.  8.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 11.  4.  3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3 10] -> size -> 20 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -18 

action type: gain_card_n - action 8
Learning step: -2.836846113204956
desired expected reward: 82.36573028564453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 96.86744 ]
 [104.057045]
 [100.36577 ]
 [ 82.00246 ]
 [ 99.97629 ]
 [106.86999 ]
 [101.646095]
 [102.007034]
 [ 88.56166 ]
 [ 99.06445 ]
 [ 95.89421 ]
 [108.81842 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1.] 
cards in discard: [14. 16.  0.  1. 25.  1. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 22. 30. 26. 29.  8.  7.  9.  8.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 11.  4.  3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3 10] -> size -> 20 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1
Learning step: -4.591727256774902
desired expected reward: 98.66529083251953



buy possibilites: [-1] 
expected returns: [[93.8553]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1.] 
cards in discard: [14. 16.  0.  1. 25.  1. 14. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 22. 30. 26. 29.  8.  7.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 11.  4.  3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3 10] -> size -> 20 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -50.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -29.5 

action type: buy - action 11.0
Learning step: -4.7067551612854
desired expected reward: 102.1632308959961






Player: 1 
cards in hand: [ 0.  0. 11.  4.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  4.  3.] 
cards in discard: [10.  0.  0.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 26. 29.  8.  7.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11] -> size -> 30 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 4. 3.] 
cards in discard: [10.  0.  0.  0.  3.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3 10  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 25. 29.  8.  7.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11] -> size -> 30 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 3.] 
cards in discard: [10.  0.  0.  0.  3.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3 10  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 22. 30. 25. 29.  8.  7.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11] -> size -> 30 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 3.] 
cards in discard: [10.  0.  0.  0.  3.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3 10  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 22. 30. 25. 29.  8.  7.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11] -> size -> 30 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[37.22914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 25. 29.  8.  7.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [14.  0.  8. 10.  8.] 
adversary cards in discard: [10.  0.  0.  0.  3.  3.  3.  0. 11.  0.  0.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3 10  3  0] -> size -> 22 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -7.05510950088501
desired expected reward: 86.8001937866211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.71569 ]
 [33.016743]
 [29.547453]
 [13.779341]
 [37.045414]
 [30.005056]
 [28.419928]
 [40.018757]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 22. 30. 25. 29.  8.  7.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [14.  0.  8. 10.  8.] 
adversary cards in discard: [10.  0.  0.  0.  3.  3.  3.  0. 11.  0.  0.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3 10  3  0] -> size -> 22 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -4.344565391540527
desired expected reward: 32.88457489013672



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  0.  8. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  8. 10.  8.] 
cards in discard: [10.  0.  0.  0.  3.  3.  3.  0. 11.  0.  0.  4.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  0 15  8  3  8  0  0 10 14  4 11  3 10  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 25. 29.  8.  7.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  3.  0. 10.  3.] 
adversary cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11] -> size -> 30 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.] 
cards in discard: [10.  0.  0.  0.  3.  3.  3.  0. 11.  0.  0.  4.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 25. 29.  8.  7.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  3.  0. 10.  3.] 
adversary cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11] -> size -> 30 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.] 
cards in discard: [10.  0.  0.  0.  3.  3.  3.  0. 11.  0.  0.  4.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 22. 30. 25. 29.  8.  7.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  3.  0. 10.  3.] 
adversary cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11] -> size -> 30 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.] 
cards in discard: [10.  0.  0.  0.  3.  3.  3.  0. 11.  0.  0.  4.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 25. 29.  8.  7.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  3.  0. 10.  3.] 
adversary cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11] -> size -> 30 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[67.79222 ]
 [62.613964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 10.  3.] 
cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.  6.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 25. 29.  8.  7.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [10.  0.  0. 15. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0] -> size -> 21 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: -3.7216339111328125
desired expected reward: 36.29711151123047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[63.362988]
 [67.48648 ]
 [64.514435]
 [55.076458]
 [68.93604 ]
 [66.69479 ]
 [64.49014 ]
 [69.573784]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 10.  3.] 
cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.  6.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 22. 30. 25. 29.  8.  7.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [10.  0.  0. 15. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0] -> size -> 21 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -5.105199813842773
desired expected reward: 62.68702697753906



buy possibilites: [-1] 
expected returns: [[69.2735]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 10.  3.] 
cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.  6.  0.  3.  0.  0.
  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 22. 30. 25. 29.  8.  6.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [10.  0.  0. 15. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0] -> size -> 21 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -70.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -375.0 

action type: buy - action 6.0
Learning step: -19.94516944885254
desired expected reward: 35.13128662109375






Player: 1 
cards in hand: [10.  0.  0. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 15. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 25. 29.  8.  6.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 22.  1.] 
adversary cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.  6.  0.  3.  0.  0.
  6.  1.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6] -> size -> 31 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 22. 30. 25. 29.  8.  6.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 22.  1.] 
adversary cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.  6.  0.  3.  0.  0.
  6.  1.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6] -> size -> 31 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 22. 30. 25. 29.  8.  6.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 22.  1.] 
adversary cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.  6.  0.  3.  0.  0.
  6.  1.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6] -> size -> 31 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 22. 30. 24. 29.  8.  6.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 22.  1.] 
adversary cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.  6.  0.  3.  0.  0.
  6.  1.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6] -> size -> 31 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 22.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[21.564486]
 [ 7.769369]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 22.  1.] 
cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.  6.  0.  3.  0.  0.
  6.  1.  3.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 24. 29.  8.  6.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [10.  0.  0.  0. 14.] 
adversary cards in discard: [ 3. 15. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3] -> size -> 21 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -7.351078033447266
desired expected reward: 61.922420501708984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.581022 ]
 [18.894072 ]
 [16.744946 ]
 [ 6.4726915]
 [16.442865 ]
 [21.111977 ]
 [17.433344 ]
 [17.615463 ]
 [ 9.935727 ]
 [15.916855 ]
 [14.047455 ]
 [22.023678 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 22.  1.] 
cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.  6.  0.  3.  0.  0.
  6.  1.  3.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 22. 30. 24. 29.  8.  6.  9.  7.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [10.  0.  0.  0. 14.] 
adversary cards in discard: [ 3. 15. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3] -> size -> 21 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -4.940916538238525
desired expected reward: 16.62355613708496



buy possibilites: [-1] 
expected returns: [[71.97823]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 22.  1.] 
cards in discard: [14. 16.  0.  1. 25.  1. 14. 11. 11.  6.  0.  0.  1.  6.  0.  3.  0.  0.
  6.  1.  3.  0. 10.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 22. 30. 24. 29.  8.  6.  9.  6.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [10.  0.  0.  0. 14.] 
adversary cards in discard: [ 3. 15. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3] -> size -> 21 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -80.5 

action type: buy - action 11.0
Learning step: -3.2451813220977783
desired expected reward: 13.548653602600098






Player: 1 
cards in hand: [10.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 14.] 
cards in discard: [ 3. 15. 10.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 24. 29.  8.  6.  9.  6.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [11.  0.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11] -> size -> 32 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.  4.] 
cards in discard: [ 3. 15. 10.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 24. 29.  8.  6.  9.  6.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [11.  0.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11] -> size -> 32 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.  4.] 
cards in discard: [ 3. 15. 10.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 22. 30. 24. 29.  8.  6.  9.  6.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [11.  0.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11] -> size -> 32 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.  4.] 
cards in discard: [ 3. 15. 10.  0. 29.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 24. 29.  8.  6.  9.  6.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [11.  0.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11] -> size -> 32 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[156.35315]
 [152.21558]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  6.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 24. 29.  8.  6.  9.  6.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 3. 15. 10.  0. 29.  1. 10.  0.  0.  0. 14.  4.] 
adversary owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1] -> size -> 22 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -4.412452697753906
desired expected reward: 67.56578063964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[137.1178 ]
 [147.88626]
 [143.21115]
 [116.7324 ]
 [153.45998]
 [143.86342]
 [141.61687]
 [158.05556]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  6.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 21. 30. 24. 29.  8.  6.  9.  6.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 3. 15. 10.  0. 29.  1. 10.  0.  0.  0. 14.  4.] 
adversary owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1] -> size -> 22 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -8.684226036071777
desired expected reward: 145.68167114257812



buy possibilites: [-1] 
expected returns: [[79.15974]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  6.  0.] 
cards in discard: [11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 24. 29.  8.  6.  9.  5.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 3. 15. 10.  0. 29.  1. 10.  0.  0.  0. 14.  4.] 
adversary owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1] -> size -> 22 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -67 

action type: buy - action 11.0
Learning step: -9.241907119750977
desired expected reward: 144.2180938720703






Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 3. 15. 10.  0. 29.  1. 10.  0.  0.  0. 14.  4.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 24. 29.  8.  6.  9.  5.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [25.  3.  3.  6.  0.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11] -> size -> 33 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 3. 15. 10.  0. 29.  1. 10.  0.  0.  0. 14.  4.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 21. 30. 24. 29.  8.  6.  9.  5.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [25.  3.  3.  6.  0.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11] -> size -> 33 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 3. 15. 10.  0. 29.  1. 10.  0.  0.  0. 14.  4.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 23. 29.  8.  6.  9.  5.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [25.  3.  3.  6.  0.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11] -> size -> 33 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [25.  3.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[63.9045 ]
 [69.15424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  3.  6.  0.] 
cards in discard: [11. 11.  0.  0.  6.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 23. 29.  8.  6.  9.  5.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [11.  0.  0.  8.  3.] 
adversary cards in discard: [ 3. 15. 10.  0. 29.  1. 10.  0.  0.  0. 14.  4.  3.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3] -> size -> 23 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: -7.198674201965332
desired expected reward: 71.9610595703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[50.383595]
 [33.88086 ]
 [64.31883 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  3.  6.  0.] 
cards in discard: [11. 11.  0.  0.  6.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 21. 30. 23. 29.  8.  6.  9.  5.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [11.  0.  0.  8.  3.] 
adversary cards in discard: [ 3. 15. 10.  0. 29.  1. 10.  0.  0.  0. 14.  4.  3.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3] -> size -> 23 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -6.760962009429932
desired expected reward: 57.14352798461914



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8.  3.] 
cards in discard: [ 3. 15. 10.  0. 29.  1. 10.  0.  0.  0. 14.  4.  3.  3.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 23. 29.  8.  6.  9.  5.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [14.  0.  0.  1. 11.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11] -> size -> 33 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [ 3. 15. 10.  0. 29.  1. 10.  0.  0.  0. 14.  4.  3.  3.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 23. 29.  8.  6.  9.  5.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [14.  0.  0.  1. 11.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11] -> size -> 33 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [ 3. 15. 10.  0. 29.  1. 10.  0.  0.  0. 14.  4.  3.  3.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 21. 30. 23. 29.  8.  6.  9.  5.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [14.  0.  0.  1. 11.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11] -> size -> 33 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [ 3. 15. 10.  0. 29.  1. 10.  0.  0.  0. 14.  4.  3.  3.  0.  3.  3.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 23. 29.  8.  6.  9.  5.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [14.  0.  0.  1. 11.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11] -> size -> 33 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [14.  0.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[ -8.070236]
 [-16.40966 ]
 [ -9.571659]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  1. 11.] 
cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 23. 29.  8.  6.  9.  5.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 0. 10.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0] -> size -> 22 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1.0
Learning step: -7.70582914352417
desired expected reward: 56.61300277709961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -9.89899  ]
 [ -7.663674 ]
 [ -9.069234 ]
 [-13.836712 ]
 [ -9.112198 ]
 [ -5.4562664]
 [ -8.09911  ]
 [ -7.8226705]
 [-11.829115 ]
 [ -8.634798 ]
 [ -9.468967 ]
 [ -4.681217 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  1. 11.] 
cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 21. 30. 23. 29.  8.  6.  9.  5.  7.  9.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 0. 10.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0] -> size -> 22 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -4.024986267089844
desired expected reward: -12.095226287841797



buy possibilites: [-1] 
expected returns: [[12.948854]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  1. 11.] 
cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 23. 29.  8.  6.  9.  5.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 0. 10.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0] -> size -> 22 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -53 

action type: buy - action 14.0
Learning step: -1.7671959400177002
desired expected reward: -13.596293449401855






Player: 1 
cards in hand: [ 0. 10.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 23. 29.  8.  6.  9.  5.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  3.  0. 16.  0.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14] -> size -> 34 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 23. 29.  8.  6.  9.  5.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  3.  0. 16.  0.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14] -> size -> 34 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0] -> size -> 22 
action values: 2 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 23. 29.  8.  6.  9.  5.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  3.  0. 16.  0.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14] -> size -> 34 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 29. 15.] 
owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 4 
card supply: [21. 21. 30. 23. 29.  8.  6.  9.  5.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  3.  0. 16.  0.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14] -> size -> 34 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 29. 15.] 
owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 7 
card supply: [21. 21. 30. 23. 29.  8.  6.  9.  5.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  3.  0. 16.  0.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14] -> size -> 34 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 29. 15.] 
owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 21. 30. 23. 29.  8.  6.  8.  5.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  3.  0. 16.  0.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14] -> size -> 34 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[27.676596]
 [23.646812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 16.  0.] 
cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 23. 29.  8.  6.  8.  5.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [16. 10. 29. 15.  0.  0.  0.] 
adversary owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16] -> size -> 22 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -4.3105340003967285
desired expected reward: 8.638320922851562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.29203 ]
 [27.710516]
 [25.139273]
 [15.229559]
 [25.13983 ]
 [29.023739]
 [26.412462]
 [26.46321 ]
 [17.982594]
 [24.379803]
 [22.380077]
 [29.046389]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 16.  0.] 
cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 21. 30. 23. 29.  8.  6.  8.  5.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [16. 10. 29. 15.  0.  0.  0.] 
adversary owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16] -> size -> 22 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -5.0637640953063965
desired expected reward: 22.612808227539062



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [16. 10. 29. 15.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 23. 29.  8.  6.  8.  5.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [22. 11. 10.  1.  3.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.  1.
  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14] -> size -> 34 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [16. 10. 29. 15.  0.  0.  0. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16 16] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 23. 29.  8.  6.  7.  5.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [22. 11. 10.  1.  3.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.  1.
  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14] -> size -> 34 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [16. 10. 29. 15.  0.  0.  0. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16 16] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 21. 30. 23. 29.  8.  6.  7.  5.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [22. 11. 10.  1.  3.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.  1.
  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14] -> size -> 34 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [16. 10. 29. 15.  0.  0.  0. 16.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16 16  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 23. 29.  8.  6.  7.  5.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [22. 11. 10.  1.  3.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.  1.
  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14] -> size -> 34 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [22. 11. 10.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11. 10.] 
expected returns: [[-8.059408 ]
 [-6.678488 ]
 [-7.2442393]
 [-6.3502088]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 11. 10.  1.  3.] 
cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.  1.
  3.  0. 16.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 23. 29.  8.  6.  7.  5.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  4. 14.  1.  3.] 
adversary cards in discard: [16. 10. 29. 15.  0.  0.  0. 16.  1. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16 16  1] -> size -> 24 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1.0
Learning step: -5.858225345611572
desired expected reward: 23.188142776489258



action possibilites: [-1] 
expected returns: [[3.8910513]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 10.  1.  3.] 
cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.  1.
  3.  0. 16.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 23. 29.  8.  6.  7.  4.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  4. 14.  1.  3.] 
adversary cards in discard: [16. 10. 29. 15.  0.  0.  0. 16.  1. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16 16  1] -> size -> 24 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -56 

action type: gain_card_n - action 5
Learning step: -2.368713140487671
desired expected reward: -9.24348258972168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-8.831942 ]
 [-5.773327 ]
 [-9.528637 ]
 [-7.676978 ]
 [-1.3177818]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 10.  1.  3.] 
cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.  1.
  3.  0. 16.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 20. 30. 23. 29.  8.  6.  7.  4.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  4. 14.  1.  3.] 
adversary cards in discard: [16. 10. 29. 15.  0.  0.  0. 16.  1. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16 16  1] -> size -> 24 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: -3.5685513019561768
desired expected reward: 0.32249999046325684



buy possibilites: [-1] 
expected returns: [[57.336353]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 10.  1.  3.] 
cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.  1.
  3.  0. 16.  0. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 20. 30. 23. 29.  8.  6.  7.  4.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  4. 14.  1.  3.] 
adversary cards in discard: [16. 10. 29. 15.  0.  0.  0. 16.  1. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16 16  1] -> size -> 24 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -80.   0.   0.  20. -30.   0.   0.   0.  -1.   0.   0.
   0.   0.] 
sum of rewards: -96.0 

action type: buy - action 0.0
Learning step: -2.908998489379883
desired expected reward: -11.740945816040039






Player: 1 
cards in hand: [ 0.  4. 14.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4. 14.  1.  3.] 
cards in discard: [16. 10. 29. 15.  0.  0.  0. 16.  1. 11.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16 16  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 23. 29.  8.  6.  7.  4.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 0. 14.  6.  0.  1.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.  1.
  3.  0. 16.  0. 11.  0. 11. 22. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0] -> size -> 36 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 1. 3.] 
cards in discard: [16. 10. 29. 15.  0.  0.  0. 16.  1. 11.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16 16  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 20. 30. 23. 29.  8.  6.  7.  4.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.  1.
  3.  0. 16.  0. 11.  0. 11. 22. 10.  1.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0] -> size -> 36 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 1. 3.] 
cards in discard: [16. 10. 29. 15.  0.  0.  0. 16.  1. 11.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16 16  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 20. 30. 23. 29.  8.  6.  7.  4.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.  1.
  3.  0. 16.  0. 11.  0. 11. 22. 10.  1.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0] -> size -> 36 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 1. 3.] 
cards in discard: [16. 10. 29. 15.  0.  0.  0. 16.  1. 11.  0.  0.  0.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16 16  1
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 20. 30. 23. 29.  8.  6.  7.  3.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.  1.
  3.  0. 16.  0. 11.  0. 11. 22. 10.  1.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0] -> size -> 36 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[8.3677635]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.  1.
  3.  0. 16.  0. 11.  0. 11. 22. 10.  1.  3. 14.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 23. 29.  8.  6.  7.  3.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  8.  3.  3. 10.] 
adversary cards in discard: [16. 10. 29. 15.  0.  0.  0. 16.  1. 11.  0.  0.  0.  3. 11. 14.  0.  4.
  1.  3.] 
adversary owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16 16  1
 11] -> size -> 25 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[   -5     0     0   -80     0     0     0  -120     0     0     0    -1
     0 -1200   145     0] 
sum of rewards: -1261 

action type: discard_down_to_3_cards - action 5
Learning step: -62.75136947631836
desired expected reward: -64.95858001708984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-12.911673 ]
 [ -9.816046 ]
 [-10.171951 ]
 [-13.611208 ]
 [-11.529232 ]
 [ -6.9870725]
 [-11.355656 ]
 [-10.876603 ]
 [-13.081305 ]
 [-10.646778 ]
 [-11.99556  ]
 [ -4.223874 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.  1.
  3.  0. 16.  0. 11.  0. 11. 22. 10.  1.  3. 14.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 20. 30. 23. 29.  8.  6.  7.  3.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  8.  3.  3. 10.] 
adversary cards in discard: [16. 10. 29. 15.  0.  0.  0. 16.  1. 11.  0.  0.  0.  3. 11. 14.  0.  4.
  1.  3.] 
adversary owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16 16  1
 11] -> size -> 25 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -4.876770973205566
desired expected reward: 3.490992546081543



buy possibilites: [-1] 
expected returns: [[-2.5133078]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [11. 11.  0.  0.  6.  0. 25.  3.  3.  6.  0. 14. 14.  0.  0.  1. 11.  1.
  3.  0. 16.  0. 11.  0. 11. 22. 10.  1.  3. 14.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 20. 30. 22. 29.  8.  6.  7.  3.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  8.  3.  3. 10.] 
adversary cards in discard: [16. 10. 29. 15.  0.  0.  0. 16.  1. 11.  0.  0.  0.  3. 11. 14.  0.  4.
  1.  3.] 
adversary owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16 16  1
 11] -> size -> 25 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -70.   0.   0.   0.   0.   0.   0.   0.  -2.   0.   0.
   2.   0.] 
sum of rewards: -74.0 

action type: buy - action 3.0
Learning step: -3.2479522228240967
desired expected reward: -13.419896125793457






Player: 1 
cards in hand: [ 3.  8.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3.  3. 10.] 
cards in discard: [16. 10. 29. 15.  0.  0.  0. 16.  1. 11.  0.  0.  0.  3. 11. 14.  0.  4.
  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  0 15  3  8  0  0 10 14  4 11  3 10  3  0  0  3  1  3  0 16 16  1
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 22. 29.  8.  6.  7.  3.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [11.  0.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3] -> size -> 37 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [16. 10. 29. 15.  0.  0.  0. 16.  1. 11.  0.  0.  0.  3. 11. 14.  0.  4.
  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 22. 29.  8.  6.  7.  3.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [11.  0.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3] -> size -> 37 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [16. 10. 29. 15.  0.  0.  0. 16.  1. 11.  0.  0.  0.  3. 11. 14.  0.  4.
  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 20. 30. 22. 29.  8.  6.  7.  3.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [11.  0.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3] -> size -> 37 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[68.15946 ]
 [63.766914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  6.  1.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 22. 29.  8.  6.  7.  3.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  0. 11.  0.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11] -> size -> 22 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -1.0797854661941528
desired expected reward: -3.5930933952331543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[57.11731 ]
 [62.553436]
 [60.797325]
 [49.05963 ]
 [59.557003]
 [66.49289 ]
 [60.303764]
 [61.022686]
 [52.445534]
 [60.245617]
 [57.89745 ]
 [70.79578 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  6.  1.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 20. 30. 22. 29.  8.  6.  7.  3.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  0. 11.  0.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11] -> size -> 22 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -4.709496974945068
desired expected reward: 63.449951171875



buy possibilites: [-1] 
expected returns: [[108.80001]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  6.  1.] 
cards in discard: [16.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 22. 29.  8.  6.  6.  3.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  0. 11.  0.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11] -> size -> 22 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0  -3   0   0  32   0] 
sum of rewards: -25 

action type: buy - action 16.0
Learning step: -1.779849886894226
desired expected reward: 57.77714920043945






Player: 1 
cards in hand: [ 1.  0. 11.  0.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  0.  4.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 22. 29.  8.  6.  6.  3.  7.  9.  9.  5. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  1.  0.  1. 11.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16] -> size -> 38 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 4.] 
cards in discard: [15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 22. 29.  8.  6.  6.  3.  7.  9.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  1.  0.  1. 11.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16] -> size -> 38 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 4.] 
cards in discard: [15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 20. 30. 22. 29.  8.  6.  6.  3.  7.  9.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  1.  0.  1. 11.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16] -> size -> 38 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 4.] 
cards in discard: [15.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [19. 20. 30. 22. 29.  8.  6.  6.  3.  7.  9.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  1.  0.  1. 11.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16] -> size -> 38 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 3.  1.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[103.23853]
 [100.87561]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  1. 11.] 
cards in discard: [16. 11.  0.  0.  6.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 22. 29.  8.  6.  6.  3.  7.  9.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [16. 16. 10. 29.  0.] 
adversary cards in discard: [15.  0. 11.  1.  0.  0.  4.] 
adversary owned cards: [ 0 29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -5.838134288787842
desired expected reward: 102.96187591552734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 90.49162 ]
 [ 97.26729 ]
 [ 94.60089 ]
 [ 82.72223 ]
 [ 79.178406]
 [ 93.462845]
 [100.686066]
 [ 94.59479 ]
 [105.44117 ]
 [ 95.02675 ]
 [ 84.28473 ]
 [ 87.90789 ]
 [ 93.32814 ]
 [ 81.94373 ]
 [ 90.27167 ]
 [103.04901 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  1. 11.] 
cards in discard: [16. 11.  0.  0.  6.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 20. 30. 22. 29.  8.  6.  6.  3.  7.  9.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [16. 16. 10. 29.  0.] 
adversary cards in discard: [15.  0. 11.  1.  0.  0.  4.] 
adversary owned cards: [ 0 29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -5.725909233093262
desired expected reward: 97.51263427734375



buy possibilites: [-1] 
expected returns: [[39.481045]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  1. 11.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 22. 29.  8.  6.  6.  3.  7.  8.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [16. 16. 10. 29.  0.] 
adversary cards in discard: [15.  0. 11.  1.  0.  0.  4.] 
adversary owned cards: [ 0 29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0  -4   0   0  50   0] 
sum of rewards: -8 

action type: buy - action 25.0
Learning step: -4.7837347984313965
desired expected reward: 100.65743255615234






Player: 1 
cards in hand: [16. 16. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16. 10. 29.  0.] 
cards in discard: [15.  0. 11.  1.  0.  0.  4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 22. 29.  8.  6.  6.  3.  7.  8.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 6. 10.  0.  1.  0.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25] -> size -> 39 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1. 16. 16. 10. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16. 10.  0. 14.] 
cards in discard: [15.  0. 11.  1.  0.  0.  4.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 20. 30. 22. 29.  8.  6.  6.  3.  7.  8.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 6. 10.  0.  1.  0.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25] -> size -> 39 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10. 14.] 
cards in discard: [15.  0. 11.  1.  0.  0.  4.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 20. 30. 22. 29.  8.  6.  6.  3.  7.  8.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 6. 10.  0.  1.  0.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25] -> size -> 39 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 10. 14.] 
cards in discard: [15.  0. 11.  1.  0.  0.  4.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 20. 30. 22. 29.  8.  6.  6.  3.  7.  8.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 6. 10.  0.  1.  0.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25] -> size -> 39 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 10. 14.] 
cards in discard: [15.  0. 11.  1.  0.  0.  4.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 20. 30. 22. 29.  8.  6.  6.  3.  7.  8.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 6. 10.  0.  1.  0.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25] -> size -> 39 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[28.623524]
 [24.207596]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  1.  0.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 22. 29.  8.  6.  6.  3.  7.  8.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  8. 15. 11.  0.] 
adversary cards in discard: [15.  0. 11.  1.  0.  0.  4.  0.  0. 29. 16. 16. 10. 14.] 
adversary owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -4.06926965713501
desired expected reward: 35.411773681640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.546293]
 [25.364288]
 [23.022558]
 [14.871777]
 [23.208202]
 [26.79192 ]
 [24.540438]
 [24.606096]
 [17.179216]
 [22.85376 ]
 [20.843943]
 [27.418447]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  1.  0.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 20. 30. 22. 29.  8.  6.  6.  3.  7.  8.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  8. 15. 11.  0.] 
adversary cards in discard: [15.  0. 11.  1.  0.  0.  4.  0.  0. 29. 16. 16. 10. 14.] 
adversary owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -3.5983574390411377
desired expected reward: 25.025150299072266



buy possibilites: [-1] 
expected returns: [[29.067791]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  1.  0.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6] -> size -> 40 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 20. 30. 22. 29.  8.  5.  6.  3.  7.  8.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  8. 15. 11.  0.] 
adversary cards in discard: [15.  0. 11.  1.  0.  0.  4.  0.  0. 29. 16. 16. 10. 14.] 
adversary owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0] -> size -> 25 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -60.    0.    0.    0.    0.    0.    0.    0.   -5.
    0. -300.    0.    0.] 
sum of rewards: -370.0 

action type: buy - action 6.0
Learning step: -18.589563369750977
desired expected reward: -3.7178096771240234






Player: 1 
cards in hand: [ 3.  8. 15. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 15. 11.  0.] 
cards in discard: [15.  0. 11.  1.  0.  0.  4.  0.  0. 29. 16. 16. 10. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 22. 29.  8.  5.  6.  3.  7.  8.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 1.  0.  3.  3. 14.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6] -> size -> 40 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 15.  0.] 
cards in discard: [15.  0. 11.  1.  0.  0.  4.  0.  0. 29. 16. 16. 10. 14.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 19. 30. 22. 29.  8.  5.  6.  3.  7.  8.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 1.  0.  3.  3. 14.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6] -> size -> 40 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 15.  0.] 
cards in discard: [15.  0. 11.  1.  0.  0.  4.  0.  0. 29. 16. 16. 10. 14.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 19. 30. 22. 29.  8.  5.  6.  3.  7.  8.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 1.  0.  3.  3. 14.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6] -> size -> 40 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 1.  0.  3.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-3.7339082]
 [-2.5247188]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  3. 14.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 19. 30. 22. 29.  8.  5.  6.  3.  7.  8.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [15.  0. 11.  1.  0.  0.  4.  0.  0. 29. 16. 16. 10. 14.  1. 11.  3.  8.
 15.  0.] 
adversary owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0  1] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -4.770942687988281
desired expected reward: 24.29684829711914



action possibilites: [-1] 
expected returns: [[1.2396564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 19. 30. 22. 29.  8.  5.  6.  3.  7.  8.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [15.  0. 11.  1.  0.  0.  4.  0.  0. 29. 16. 16. 10. 14.  1. 11.  3.  8.
 15.  0.  0.  3.] 
adversary owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0  1] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 14.0
Learning step: -2.095872402191162
desired expected reward: -4.62058162689209





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-3.840207  ]
 [-2.7604413 ]
 [-2.7633793 ]
 [-5.8586984 ]
 [-6.5088587 ]
 [-3.4024487 ]
 [-1.4310408 ]
 [-3.4026546 ]
 [ 0.2176776 ]
 [-3.2945561 ]
 [-5.040052  ]
 [-3.7329855 ]
 [-3.0622327 ]
 [-6.038041  ]
 [-3.5017493 ]
 [-0.34918118]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 19. 30. 22. 29.  8.  5.  6.  3.  7.  8.  9.  5. 10.  7.  9.  8.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [15.  0. 11.  1.  0.  0.  4.  0.  0. 29. 16. 16. 10. 14.  1. 11.  3.  8.
 15.  0.  0.  3.] 
adversary owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0  1] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: -2.3717992305755615
desired expected reward: -1.1321427822113037



buy possibilites: [-1] 
expected returns: [[17.278873]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 19. 30. 22. 29.  8.  5.  6.  3.  7.  8.  9.  5. 10.  7.  8.  8.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [15.  0. 11.  1.  0.  0.  4.  0.  0. 29. 16. 16. 10. 14.  1. 11.  3.  8.
 15.  0.  0.  3.] 
adversary owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0  1] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0  -6   0   0  50   0] 
sum of rewards: -1 

action type: buy - action 22.0
Learning step: 0.7283496260643005
desired expected reward: -7.063149929046631






Player: 1 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [15.  0. 11.  1.  0.  0.  4.  0.  0. 29. 16. 16. 10. 14.  1. 11.  3.  8.
 15.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 19. 30. 22. 29.  8.  5.  6.  3.  7.  8.  9.  5. 10.  7.  8.  8.] 
adversary cards in hand: [14.  6. 16.  6. 22.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22] -> size -> 41 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [15.  0. 11.  1.  0.  0.  4.  0.  0. 29. 16. 16. 10. 14.  1. 11.  3.  8.
 15.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 19. 30. 22. 29.  8.  5.  6.  3.  7.  8.  9.  5. 10.  7.  8.  8.] 
adversary cards in hand: [14.  6. 16.  6. 22.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22] -> size -> 41 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [15.  0. 11.  1.  0.  0.  4.  0.  0. 29. 16. 16. 10. 14.  1. 11.  3.  8.
 15.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0  1  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 19. 30. 22. 29.  8.  5.  6.  3.  7.  8.  9.  5. 10.  7.  8.  8.] 
adversary cards in hand: [14.  6. 16.  6. 22.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22] -> size -> 41 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [14.  6. 16.  6. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 22.] 
expected returns: [[17.86542  ]
 [-1.557488 ]
 [ 9.847441 ]
 [-3.3041277]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6. 16.  6. 22.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 19. 30. 22. 29.  8.  5.  6.  3.  7.  8.  9.  5. 10.  7.  8.  8.] 
adversary cards in hand: [11. 16.  3.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0  1  0] -> size -> 27 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -3.9279839992523193
desired expected reward: 13.350889205932617



action possibilites: [-1] 
expected returns: [[-8.258631]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  6. 22.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 19. 30. 22. 29.  8.  5.  6.  3.  7.  8.  9.  5. 10.  7.  8.  8.] 
adversary cards in hand: [16.  3.  3.] 
adversary cards in discard: [11.  1.] 
adversary owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0  1  0] -> size -> 27 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 14.0
Learning step: -2.3579463958740234
desired expected reward: -3.9154038429260254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-12.411894]
 [-11.536314]
 [-16.446524]
 [-11.662664]
 [ -9.395583]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  6. 22.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 19. 30. 22. 29.  8.  5.  6.  3.  7.  8.  9.  5. 10.  7.  8.  8.] 
adversary cards in hand: [16.  3.  3.] 
adversary cards in discard: [11.  1.] 
adversary owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0  1  0] -> size -> 27 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: -2.0999279022216797
desired expected reward: -10.358558654785156



buy possibilites: [-1] 
expected returns: [[-0.05339622]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  6. 22.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 19. 30. 22. 29.  8.  4.  6.  3.  7.  8.  9.  5. 10.  7.  8.  8.] 
adversary cards in hand: [16.  3.  3.] 
adversary cards in discard: [11.  1.] 
adversary owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0  1  0] -> size -> 27 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -70.    0.    0.   20.    0.    0.    0.    0.   -7.
    0. -300.    0.    0.] 
sum of rewards: -363.0 

action type: buy - action 6.0
Learning step: -17.328876495361328
desired expected reward: -33.775390625






Player: 1 
cards in hand: [16.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3.] 
cards in discard: [11.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [29  0 15  8  0  0 14  4 11 10  3  0  0  3  1  3  0 16 16  1 11 15  0  0
  0  1  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 19. 30. 22. 29.  8.  4.  6.  3.  7.  8.  9.  5. 10.  7.  8.  8.] 
adversary cards in hand: [11.  0.  3.  0. 11.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.  6. 14.  6. 16.  6. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6] -> size -> 42 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [11.  1. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [29  0 15  8  0  0 14  4 11 10  0  0  3  1  3  0 16 16  1 11 15  0  0  0
  1  0 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 19. 30. 22. 29.  8.  4.  6.  3.  7.  8.  9.  5. 10.  6.  8.  8.] 
adversary cards in hand: [11.  0.  3.  0. 11.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.  6. 14.  6. 16.  6. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6] -> size -> 42 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.  1. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [29  0 15  8  0  0 14  4 11 10  0  0  3  1  3  0 16 16  1 11 15  0  0  0
  1  0 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 19. 30. 22. 29.  8.  4.  6.  3.  7.  8.  9.  5. 10.  6.  8.  8.] 
adversary cards in hand: [11.  0.  3.  0. 11.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.  6. 14.  6. 16.  6. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6] -> size -> 42 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[25.379065]
 [24.20404 ]
 [24.20404 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 11.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.  6. 14.  6. 16.  6. 22.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 19. 30. 22. 29.  8.  4.  6.  3.  7.  8.  9.  5. 10.  6.  8.  8.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [11.  1. 10. 16.  3.] 
adversary owned cards: [29  0 15  8  0  0 14  4 11 10  0  0  3  1  3  0 16 16  1 11 15  0  0  0
  1  0 10] -> size -> 27 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -2.740225315093994
desired expected reward: -2.79362154006958





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.139004]
 [22.030136]
 [15.530134]
 [21.504274]
 [25.379065]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0. 11.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.  6. 14.  6. 16.  6. 22.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 19. 30. 22. 29.  8.  4.  6.  3.  7.  8.  9.  5. 10.  6.  8.  8.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [11.  1. 10. 16.  3.] 
adversary owned cards: [29  0 15  8  0  0 14  4 11 10  0  0  3  1  3  0 16 16  1 11 15  0  0  0
  1  0 10] -> size -> 27 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -4.077247142791748
desired expected reward: 21.30183982849121



buy possibilites: [-1] 
expected returns: [[21.404177]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0. 11.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.  6. 14.  6. 16.  6. 22.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 19. 30. 22. 29.  8.  3.  6.  3.  7.  8.  9.  5. 10.  6.  8.  8.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [11.  1. 10. 16.  3.] 
adversary owned cards: [29  0 15  8  0  0 14  4 11 10  0  0  3  1  3  0 16 16  1 11 15  0  0  0
  1  0 10] -> size -> 27 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -70.    0.    0.    0.    0.    0.    0.    0.   -8.
    0. -300.    0.    0.] 
sum of rewards: -385.0 

action type: buy - action 6.0
Learning step: -19.54491424560547
desired expected reward: -4.01475715637207






Player: 1 
cards in hand: [ 0.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [11.  1. 10. 16.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [29  0 15  8  0  0 14  4 11 10  0  0  3  1  3  0 16 16  1 11 15  0  0  0
  1  0 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 19. 30. 22. 29.  8.  3.  6.  3.  7.  8.  9.  5. 10.  6.  8.  8.] 
adversary cards in hand: [ 0. 11. 25.  3.  0.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.  6. 14.  6. 16.  6. 22.  6. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6] -> size -> 43 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [11.  1. 10. 16.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [29  0 15  8  0  0 14  4 11 10  0  0  3  1  3  0 16 16  1 11 15  0  0  0
  1  0 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 19. 30. 22. 29.  8.  3.  6.  3.  7.  8.  9.  5. 10.  6.  8.  8.] 
adversary cards in hand: [ 0. 11. 25.  3.  0.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.  6. 14.  6. 16.  6. 22.  6. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6] -> size -> 43 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [11.  1. 10. 16.  3.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [29  0 15  8  0  0 14  4 11 10  0  0  3  1  3  0 16 16  1 11 15  0  0  0
  1  0 10  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 18. 30. 22. 29.  8.  3.  6.  3.  7.  8.  9.  5. 10.  6.  8.  8.] 
adversary cards in hand: [ 0. 11. 25.  3.  0.] 
adversary cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.  6. 14.  6. 16.  6. 22.  6. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6] -> size -> 43 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[19.965647]
 [20.064014]
 [22.92403 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25.  3.  0.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.  6. 14.  6. 16.  6. 22.  6. 11.  0.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 22. 29.  8.  3.  6.  3.  7.  8.  9.  5. 10.  6.  8.  8.] 
adversary cards in hand: [ 0.  8.  1. 14.  1.] 
adversary cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.] 
adversary owned cards: [29  0 15  8  0  0 14  4 11 10  0  0  3  1  3  0 16 16  1 11 15  0  0  0
  1  0 10  1] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -4.438891887664795
desired expected reward: 16.96528434753418





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[16.953932]
 [17.964626]
 [11.27033 ]
 [18.687138]
 [19.965647]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 25.  3.  0.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.  6. 14.  6. 16.  6. 22.  6. 11.  0.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 18. 30. 22. 29.  8.  3.  6.  3.  7.  8.  9.  5. 10.  6.  8.  8.] 
adversary cards in hand: [ 0.  8.  1. 14.  1.] 
adversary cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.] 
adversary owned cards: [29  0 15  8  0  0 14  4 11 10  0  0  3  1  3  0 16 16  1 11 15  0  0  0
  1  0 10  1] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -4.452332496643066
desired expected reward: 15.51331615447998



buy possibilites: [-1] 
expected returns: [[12.500963]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 25.  3.  0.] 
cards in discard: [16. 11.  0.  0.  6.  1. 25.  3.  1.  0.  1. 11.  6.  6. 10.  0.  1.  0.
 22. 14.  1.  0.  3.  3.  6. 14.  6. 16.  6. 22.  6. 11.  0.  3.  0. 11.
  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 22. 29.  8.  3.  6.  3.  6.  8.  9.  5. 10.  6.  8.  8.] 
adversary cards in hand: [ 0.  8.  1. 14.  1.] 
adversary cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.] 
adversary owned cards: [29  0 15  8  0  0 14  4 11 10  0  0  3  1  3  0 16 16  1 11 15  0  0  0
  1  0 10  1] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0  -9   0   0   8   0] 
sum of rewards: -78 

action type: buy - action 8.0
Learning step: -4.5530853271484375
desired expected reward: 14.134057998657227






Player: 1 
cards in hand: [ 0.  8.  1. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1. 14.  1.] 
cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [29  0 15  8  0  0 14  4 11 10  0  0  3  1  3  0 16 16  1 11 15  0  0  0
  1  0 10  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 22. 29.  8.  3.  6.  3.  6.  8.  9.  5. 10.  6.  8.  8.] 
adversary cards in hand: [ 8.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8] -> size -> 44 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 22. 29.  8.  3.  6.  3.  6.  8.  9.  5. 10.  6.  8.  8.] 
adversary cards in hand: [ 8.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8] -> size -> 44 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 18. 30. 22. 29.  8.  3.  6.  3.  6.  8.  9.  5. 10.  6.  8.  8.] 
adversary cards in hand: [ 8.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8] -> size -> 44 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 18. 30. 22. 29.  8.  3.  6.  3.  6.  8.  9.  5. 10.  6.  8.  8.] 
adversary cards in hand: [ 8.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8] -> size -> 44 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[31.477503]
 [23.185747]
 [15.605528]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 18. 30. 22. 29.  8.  3.  6.  3.  6.  8.  9.  5. 10.  6.  8.  8.] 
adversary cards in hand: [15.  0.  0.  0. 10.] 
adversary cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.  0.  8.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0] -> size -> 25 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -3.9099738597869873
desired expected reward: 8.590989112854004





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.859951]
 [25.476254]
 [23.21409 ]
 [11.710842]
 [29.269346]
 [23.35036 ]
 [22.37467 ]
 [31.857729]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 18. 30. 22. 29.  8.  3.  6.  3.  6.  8.  9.  5. 10.  6.  8.  8.] 
adversary cards in hand: [15.  0.  0.  0. 10.] 
adversary cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.  0.  8.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0] -> size -> 25 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -4.857605457305908
desired expected reward: 26.619909286499023



buy possibilites: [-1] 
expected returns: [[-7.707183]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 14.] 
cards in discard: [10.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 18. 30. 22. 29.  8.  3.  6.  3.  6.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [15.  0.  0.  0. 10.] 
adversary cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.  0.  8.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0] -> size -> 25 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0 -10   0   0  18   0] 
sum of rewards: -69 

action type: buy - action 10.0
Learning step: -4.742146968841553
desired expected reward: 17.632553100585938






Player: 1 
cards in hand: [15.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0. 10.] 
cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 18. 30. 22. 29.  8.  3.  6.  3.  6.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  6.  3.  6. 11.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10] -> size -> 45 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0. 10.] 
cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 18. 30. 22. 29.  8.  3.  6.  3.  6.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  6.  3.  6. 11.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10] -> size -> 45 
adversary victory points: -2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[46.944515]
 [44.513626]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  6. 11.] 
cards in discard: [10.  8.  0.  0.  0. 14.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 18. 30. 22. 29.  8.  3.  6.  3.  6.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 3. 29.  0.  0. 15.] 
adversary cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.  0.  8. 15.  0.  0.  0. 10.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0] -> size -> 25 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -2.4299938678741455
desired expected reward: -10.137176513671875



action possibilites: [-1] 
expected returns: [[74.1972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 18. 30. 22. 29.  8.  3.  6.  3.  5.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 3. 29.  0.  0. 15.] 
adversary cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.  0.  8. 15.  0.  0.  0. 10.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0] -> size -> 25 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0 -11   0   0   4   0] 
sum of rewards: -64 

action type: gain_card_n - action 6
Learning step: -2.296682834625244
desired expected reward: 13.025711059570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[64.68919]
 [54.11916]
 [72.61881]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 18. 30. 22. 29.  8.  3.  6.  3.  5.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 3. 29.  0.  0. 15.] 
adversary cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.  0.  8. 15.  0.  0.  0. 10.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0] -> size -> 25 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1
Learning step: -5.0825300216674805
desired expected reward: 69.11466979980469



buy possibilites: [-1] 
expected returns: [[79.56389]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 18. 30. 22. 29.  8.  2.  6.  3.  5.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 3. 29.  0.  0. 15.] 
adversary cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.  0.  8. 15.  0.  0.  0. 10.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0] -> size -> 25 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -80.    0.    0.   20.    0.    0.    0.    0.  -12.
    0. -300.    0.    0.] 
sum of rewards: -380.0 

action type: buy - action 6.0
Learning step: -19.915769577026367
desired expected reward: 34.20337677001953






Player: 1 
cards in hand: [ 3. 29.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0. 15.] 
cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.  0.  8. 15.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 18. 30. 22. 29.  8.  2.  6.  3.  5.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  6.  1. 10. 25.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6] -> size -> 47 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0. 15.] 
cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.  0.  8. 15.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 18. 30. 22. 29.  8.  2.  6.  3.  5.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  6.  1. 10. 25.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6] -> size -> 47 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0. 15.] 
cards in discard: [11.  1. 10. 16.  3.  1.  0.  0. 11.  0.  0.  0.  8. 15.  0.  0.  0. 10.
  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 18. 30. 22. 29.  8.  2.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  6.  1. 10. 25.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6] -> size -> 47 
adversary victory points: -3
player victory points: 5 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  1. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[-11.691162]
 [ -8.664068]
 [-10.51413 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  1. 10. 25.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 18. 30. 22. 29.  8.  2.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [15.  0. 11. 16.  4.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8] -> size -> 26 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: buy - action -1
Learning step: -8.602033615112305
desired expected reward: 70.96185302734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -8.217891 ]
 [ -9.012931 ]
 [ -8.360356 ]
 [ -9.365088 ]
 [ -9.725238 ]
 [ -8.785012 ]
 [ -8.7202635]
 [-11.709648 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  1. 10. 25.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 18. 30. 22. 29.  8.  2.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [15.  0. 11. 16.  4.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8] -> size -> 26 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: take_action - action -1.0
Learning step: -4.018460273742676
desired expected reward: -15.709624290466309



buy possibilites: [-1] 
expected returns: [[-18.30228]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  1. 10. 25.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6] -> size -> 48 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 18. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [15.  0. 11. 16.  4.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8] -> size -> 26 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4.  -90.    0.    0.    0.    0.    0.    0.    0.  -13.
    0. -300.    0.    0.] 
sum of rewards: -412.0 

action type: buy - action 6.0
Learning step: -20.543546676635742
desired expected reward: -29.908634185791016






Player: 1 
cards in hand: [15.  0. 11. 16.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11. 16.  4.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 18. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 3.  0.  6.  0. 14.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6] -> size -> 48 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 11. 16.  4.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 18. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 3.  0.  6.  0. 14.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6] -> size -> 48 
adversary victory points: -4
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  6.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-12.662941]
 [ -9.484122]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6.  0. 14.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 18. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  0.  1. 16. 29.] 
adversary cards in discard: [15.  0. 11. 16.  4.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8] -> size -> 26 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: buy - action -1
Learning step: -4.276530742645264
desired expected reward: -22.578811645507812



action possibilites: [-1] 
expected returns: [[38.08238]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 18. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  1. 16.] 
adversary cards in discard: [15.  0. 11. 16.  4.  0. 29.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8] -> size -> 26 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: take_action - action 14.0
Learning step: -2.6189403533935547
desired expected reward: -12.103062629699707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[32.563457]
 [35.38584 ]
 [34.00358 ]
 [26.92114 ]
 [33.73666 ]
 [36.99062 ]
 [34.50116 ]
 [34.662563]
 [29.556725]
 [33.862366]
 [32.58508 ]
 [38.082382]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 18. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  1. 16.] 
adversary cards in discard: [15.  0. 11. 16.  4.  0. 29.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8] -> size -> 26 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: take_action - action -1
Learning step: -5.077455997467041
desired expected reward: 33.004920959472656






Player: 1 
cards in hand: [ 0.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 16.] 
cards in discard: [15.  0. 11. 16.  4.  0. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 18. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [11.  6.  3. 22.  1.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6] -> size -> 48 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 16.] 
cards in discard: [15.  0. 11. 16.  4.  0. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 18. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [11.  6.  3. 22.  1.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6] -> size -> 48 
adversary victory points: -4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 16.] 
cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 17. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [11.  6.  3. 22.  1.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6] -> size -> 48 
adversary victory points: -4
player victory points: 5 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [11.  6.  3. 22.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.] 
expected returns: [[-28.42833 ]
 [-27.79705 ]
 [-22.631077]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3. 22.  1.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 17. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  8. 11.  1.  0.] 
adversary cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1] -> size -> 27 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: buy - action -1.0
Learning step: -7.4282755851745605
desired expected reward: 30.654102325439453



action possibilites: [-1] 
expected returns: [[-11.6285925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3.  1.  1.  6.  0.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [22. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 17. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  8. 11.  1.  0.] 
adversary cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1] -> size -> 27 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: LIBRARY: skip_action_card - action 0
Learning step: -1.9286068677902222
desired expected reward: -27.589332580566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-13.109371]
 [-12.254884]
 [-12.306212]
 [-14.523079]
 [-15.420428]
 [-12.757308]
 [-11.725437]
 [-12.675859]
 [-11.417771]
 [-12.711341]
 [-14.385383]
 [-13.475416]
 [-12.590881]
 [-14.838748]
 [-13.121765]
 [-11.628593]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  3.  1.  1.  6.  0.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [22. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6] -> size -> 48 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 17. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  8. 11.  1.  0.] 
adversary cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1] -> size -> 27 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1
Learning step: -2.6546413898468018
desired expected reward: -14.283233642578125



buy possibilites: [-1] 
expected returns: [[-16.51852]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  3.  1.  1.  6.  0.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [22. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 16. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  8. 11.  1.  0.] 
adversary cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1] -> size -> 27 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5.    0.   -4.  -90.    0.    0.   40.    0.    0.    0.    0.  -14.
   0.    0.    4.5   0. ] 
sum of rewards: -68.5 

action type: buy - action 1.0
Learning step: -3.183922529220581
desired expected reward: -15.438807487487793






Player: 1 
cards in hand: [ 8.  8. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11.  1.  0.] 
cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 16. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [11.  0.  3. 25. 22.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1] -> size -> 49 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 11.  1.  0.] 
cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 16. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [11.  0.  3. 25. 22.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1] -> size -> 49 
adversary victory points: -4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 11.  1.  0.] 
cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [11.  0.  3. 25. 22.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1] -> size -> 49 
adversary victory points: -4
player victory points: 5 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [11.  0.  3. 25. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 22.] 
expected returns: [[24.152061]
 [22.858427]
 [23.669075]
 [16.012125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 25. 22.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 3.  0. 10. 10.  0.] 
adversary cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.  1.  8.  8. 11.  1.  0.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1] -> size -> 28 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: buy - action -1
Learning step: -3.6247193813323975
desired expected reward: -20.143239974975586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.058596]
 [14.761654]
 [24.152061]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 25. 22.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 15. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 3.  0. 10. 10.  0.] 
adversary cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.  1.  8.  8. 11.  1.  0.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1] -> size -> 28 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: take_action - action -1.0
Learning step: -5.699998378753662
desired expected reward: 18.452062606811523



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 10.  0.] 
cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.  1.  8.  8. 11.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 1.  6. 14. 11. 16.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0. 11.  0.
  3. 25. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1] -> size -> 49 
adversary victory points: -4
player victory points: 5 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  3.] 
cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.  1.  8.  8. 11.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 1.  6. 14. 11. 16.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0. 11.  0.
  3. 25. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1] -> size -> 49 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  3.] 
cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.  1.  8.  8. 11.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 15. 30. 22. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 1.  6. 14. 11. 16.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0. 11.  0.
  3. 25. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1] -> size -> 49 
adversary victory points: -4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  3.] 
cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.  1.  8.  8. 11.  1.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 21. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 1.  6. 14. 11. 16.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0. 11.  0.
  3. 25. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1] -> size -> 49 
adversary victory points: -4
player victory points: 6 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 1.  6. 14. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 16.] 
expected returns: [[ 1.3667736]
 [-4.193532 ]
 [-1.6469247]
 [-5.651387 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 14. 11. 16.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0. 11.  0.
  3. 25. 22.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 21. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  0.] 
adversary cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.  1.  8.  8. 11.  1.  0.  3.
 10.  3.  0. 10.  0.  3.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1  3] -> size -> 29 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: buy - action -1.0
Learning step: -6.561972141265869
desired expected reward: 14.906757354736328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-6.082609 ]
 [-2.8793325]
 [-6.8584175]
 [-6.9338894]
 [ 1.3667736]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 14. 11. 16.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0. 11.  0.
  3. 25. 22.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 15. 30. 21. 29.  8.  1.  6.  3.  4.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  0.] 
adversary cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.  1.  8.  8. 11.  1.  0.  3.
 10.  3.  0. 10.  0.  3.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1  3] -> size -> 29 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: take_action - action -1.0
Learning step: -5.587913990020752
desired expected reward: -4.221126556396484



buy possibilites: [-1] 
expected returns: [[12.54254]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 14. 11. 16.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0. 11.  0.
  3. 25. 22.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 21. 29.  8.  1.  6.  3.  3.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  0.] 
adversary cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.  1.  8.  8. 11.  1.  0.  3.
 10.  3.  0. 10.  0.  3.] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1  3] -> size -> 29 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0  -15    0    0
    8    0] 
sum of rewards: -116 

action type: buy - action 8.0
Learning step: -5.1710991859436035
desired expected reward: -12.104972839355469






Player: 1 
cards in hand: [ 0.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  0.] 
cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.  1.  8.  8. 11.  1.  0.  3.
 10.  3.  0. 10.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 21. 29.  8.  1.  6.  3.  3.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 11.  1.  0.  3.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0. 11.  0.
  3. 25. 22.  8.  1.  6. 14. 11. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8] -> size -> 50 
adversary victory points: -4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  0.] 
cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.  1.  8.  8. 11.  1.  0.  3.
 10.  3.  0. 10.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 15. 30. 21. 29.  8.  1.  6.  3.  3.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 11.  1.  0.  3.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0. 11.  0.
  3. 25. 22.  8.  1.  6. 14. 11. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8] -> size -> 50 
adversary victory points: -4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  0.] 
cards in discard: [15.  0. 11. 16.  4.  0. 29.  1.  0.  1. 16.  1.  8.  8. 11.  1.  0.  3.
 10.  3.  0. 10.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1  3  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 15. 30. 20. 29.  8.  1.  6.  3.  3.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [ 0. 11.  1.  0.  3.] 
adversary cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0. 11.  0.
  3. 25. 22.  8.  1.  6. 14. 11. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8] -> size -> 50 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[15.063471]
 [13.993771]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  1.  0.  3.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0. 11.  0.
  3. 25. 22.  8.  1.  6. 14. 11. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 20. 29.  8.  1.  6.  3.  3.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [16. 10. 15.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1  3  3] -> size -> 30 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: buy - action -1
Learning step: -6.247705936431885
desired expected reward: 6.294833660125732





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[10.599947 ]
 [12.751249 ]
 [12.097647 ]
 [ 6.7682242]
 [11.561827 ]
 [13.993771 ]
 [11.779287 ]
 [11.911404 ]
 [ 8.477976 ]
 [11.63389  ]
 [10.632946 ]
 [15.063471 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  1.  0.  3.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0. 11.  0.
  3. 25. 22.  8.  1.  6. 14. 11. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8] -> size -> 50 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 15. 30. 20. 29.  8.  1.  6.  3.  3.  8.  9.  5. 10.  5.  8.  8.] 
adversary cards in hand: [16. 10. 15.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1  3  3] -> size -> 30 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: take_action - action -1.0
Learning step: -6.4286651611328125
desired expected reward: 8.634809494018555



buy possibilites: [-1] 
expected returns: [[4.7495737]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  1.  0.  3.] 
cards in discard: [10.  8.  0.  0.  0. 14.  8.  6. 11.  0.  6.  3.  6.  6.  0.  6.  1. 10.
 25. 14.  3.  0.  6.  0.  1. 22. 16. 11.  6.  3.  1.  1.  6.  0. 11.  0.
  3. 25. 22.  8.  1.  6. 14. 11. 16. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8 14] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 20. 29.  8.  1.  6.  3.  3.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [16. 10. 15.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1  3  3] -> size -> 30 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0  -16    0    0
   32    0] 
sum of rewards: -103 

action type: buy - action 14.0
Learning step: -5.467033386230469
desired expected reward: 3.0109424591064453






Player: 1 
cards in hand: [16. 10. 15.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 15.  8. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10. 15.  8. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1  3  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 20. 29.  8.  1.  6.  3.  3.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 1. 14.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8 14] -> size -> 51 
adversary victory points: -4
player victory points: 7 


action possibilites: [-1. 16. 15.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 15.  8. 15.  1.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 15  8  0  0  4 11 10  0  0  3  3  0 16 16 11 15  0  0  0  1  0 10  1
  0  8  1  1  3  3] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 20. 29.  8.  1.  6.  3.  3.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 1. 14.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8 14] -> size -> 51 
adversary victory points: -4
player victory points: 7 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 20. 29.  8.  1.  6.  3.  3.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 1. 14.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8 14] -> size -> 51 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 15. 30. 20. 29.  8.  1.  6.  3.  3.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 1. 14.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8 14] -> size -> 51 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 1. 14.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
expected returns: [[45.360664]
 [31.61117 ]
 [31.61117 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8 14] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 20. 29.  8.  1.  6.  3.  3.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [4. 0. 0. 0. 0.] 
adversary cards in discard: [10.  8. 15.  1.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3] -> size -> 28 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: buy - action -1
Learning step: -5.3297953605651855
desired expected reward: -0.5802216529846191



action possibilites: [-1] 
expected returns: [[74.70959]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8 14] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 15. 30. 20. 29.  8.  1.  6.  3.  3.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [4. 0. 0.] 
adversary cards in discard: [10.  8. 15.  1.  0.  0.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3] -> size -> 28 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -99 

action type: take_action - action 14.0
Learning step: -4.849593639373779
desired expected reward: 26.76158332824707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[60.26604 ]
 [65.594345]
 [58.9374  ]
 [64.89805 ]
 [54.883198]
 [52.380405]
 [62.71218 ]
 [69.773544]
 [62.749382]
 [71.96513 ]
 [63.33844 ]
 [56.839523]
 [59.81622 ]
 [63.746773]
 [54.95037 ]
 [61.305504]
 [72.11119 ]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8 14] -> size -> 51 
action values: 0 
buys: 1 
player value: 6 
card supply: [15. 15. 30. 20. 29.  8.  1.  6.  3.  3.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [4. 0. 0.] 
adversary cards in discard: [10.  8. 15.  1.  0.  0.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3] -> size -> 28 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -99 

action type: take_action - action -1
Learning step: -7.240332126617432
desired expected reward: 67.46925354003906



buy possibilites: [-1] 
expected returns: [[47.648968]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 14.  0.] 
cards in discard: [4.] 
cards in deck: 46 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8 14  4] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 15. 30. 20. 28.  8.  1.  6.  3.  3.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [4. 0. 0.] 
adversary cards in discard: [10.  8. 15.  1.  0.  0.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3] -> size -> 28 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5.    0.   -1.  -80.    0.    0.   20.    0.    0.    0.    0.  -17.
   0.    0.   12.5   0. ] 
sum of rewards: -70.5 

action type: buy - action 4.0
Learning step: -5.19705867767334
desired expected reward: 49.6861457824707






Player: 1 
cards in hand: [4. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0.] 
cards in discard: [10.  8. 15.  1.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 20. 28.  8.  1.  6.  3.  3.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  3. 11.  6.  0.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8 14  4] -> size -> 52 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0.] 
cards in discard: [10.  8. 15.  1.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 15. 30. 20. 28.  8.  1.  6.  3.  3.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  3. 11.  6.  0.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8 14  4] -> size -> 52 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0.] 
cards in discard: [10.  8. 15.  1.  0.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 20. 28.  8.  1.  6.  3.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  3. 11.  6.  0.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8 14  4] -> size -> 52 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 8.  3. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[9.77696  ]
 [5.1518693]
 [9.086168 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.  6.  0.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  3  0  1  6 16  1  1  0 11 25 10  1
  6  0 22 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6
  1  8 14  4] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 20. 28.  8.  1.  6.  3.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  3. 29. 10.  1.] 
adversary cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8] -> size -> 29 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -6.493963718414307
desired expected reward: 41.15500259399414



action possibilites: [-1] 
expected returns: [[63.82022]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 20. 28.  8.  1.  6.  3.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  3. 29. 10.  1.] 
adversary cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8] -> size -> 29 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: trash_cards_n_from_hand - action 12
Learning step: -1.7625846862792969
desired expected reward: -3.7917885780334473





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[52.590996]
 [36.35412 ]
 [63.065536]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4] -> size -> 49 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 15. 30. 20. 28.  8.  1.  6.  3.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 8.  3. 29. 10.  1.] 
adversary cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8] -> size -> 29 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -5.292363166809082
desired expected reward: 58.52785873413086






Player: 1 
cards in hand: [ 8.  3. 29. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29. 10.  1.] 
cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 20. 28.  8.  1.  6.  3.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [22.  6.  6.  1.  1.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4] -> size -> 49 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 29. 10.  1.] 
cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 15. 30. 20. 28.  8.  1.  6.  3.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [22.  6.  6.  1.  1.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4] -> size -> 49 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 29. 10.  1.] 
cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 15. 30. 20. 28.  8.  1.  6.  3.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [22.  6.  6.  1.  1.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4] -> size -> 49 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [22.  6.  6.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[ -0.8873496]
 [-13.648373 ]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  6.  6.  1.  1.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 15. 30. 20. 28.  8.  1.  6.  3.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [11. 16.  0.  0.  1.] 
adversary cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.  0.  8.  3. 29. 10.  1.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0] -> size -> 30 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -7.5866546630859375
desired expected reward: 55.47887420654297



action possibilites: [-1] 
expected returns: [[-10.496136]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  1.  1.  3.  3. 25.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 15. 30. 20. 28.  8.  1.  6.  3.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [11. 16.  0.  0.  1.] 
adversary cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.  0.  8.  3. 29. 10.  1.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0] -> size -> 30 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: LIBRARY: skip_action_card - action 1
Learning step: -2.5172650814056396
desired expected reward: -2.895220994949341





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-9.013929]
 [-9.679005]
 [-8.441788]
 [-6.973704]
 [-9.360327]
 [-9.347277]
 [-9.730675]
 [-9.884252]
 [-7.541304]
 [-8.613131]
 [-8.373331]
 [-9.779482]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  1.  1.  3.  3. 25.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4] -> size -> 49 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 15. 30. 20. 28.  8.  1.  6.  3.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [11. 16.  0.  0.  1.] 
adversary cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.  0.  8.  3. 29. 10.  1.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0] -> size -> 30 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -1.9662498235702515
desired expected reward: -12.462385177612305



buy possibilites: [-1] 
expected returns: [[6.8682513]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  1.  1.  3.  3. 25.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 15. 30. 20. 28.  8.  1.  6.  2.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [11. 16.  0.  0.  1.] 
adversary cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.  0.  8.  3. 29. 10.  1.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0] -> size -> 30 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5.    0.   -1.  -80.    0.    0.   40.    0.    0.    0.    0.  -15.
   0.    0.    4.5   0. ] 
sum of rewards: -56.5 

action type: buy - action 11.0
Learning step: -2.2031006813049316
desired expected reward: -11.550374984741211






Player: 1 
cards in hand: [11. 16.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  0.  0.  1.] 
cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.  0.  8.  3. 29. 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 15. 30. 20. 28.  8.  1.  6.  2.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 8. 22.  0. 10.  6.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11] -> size -> 50 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  0.  0.  1.] 
cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.  0.  8.  3. 29. 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 15. 30. 20. 28.  8.  1.  6.  2.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 8. 22.  0. 10.  6.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11] -> size -> 50 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  0.  0.  1.] 
cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.  0.  8.  3. 29. 10.  1.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 14. 30. 20. 28.  8.  1.  6.  2.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 8. 22.  0. 10.  6.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11] -> size -> 50 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 8. 22.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 10.] 
expected returns: [[-12.400379 ]
 [-10.328207 ]
 [ -5.9937553]
 [ -9.112169 ]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22.  0. 10.  6.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 14. 30. 20. 28.  8.  1.  6.  2.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.  0.  8.  3. 29. 10.  1.  1. 11.
 16.  0.  0.  1.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1] -> size -> 31 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -4.839859962463379
desired expected reward: 2.0283913612365723



action possibilites: [-1] 
expected returns: [[16.913464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  6.  0.  0.  6.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 14. 30. 20. 28.  8.  1.  6.  2.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.  0.  8.  3. 29. 10.  1.  1. 11.
 16.  0.  0.  1.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1] -> size -> 31 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: LIBRARY: skip_action_card - action 0
Learning step: -1.4829283952713013
desired expected reward: -10.213303565979004





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[13.898411]
 [16.151531]
 [14.979404]
 [ 9.303476]
 [16.836828]
 [15.311941]
 [14.455095]
 [16.91346 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  6.  0.  0.  6.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 14. 30. 20. 28.  8.  1.  6.  2.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.  0.  8.  3. 29. 10.  1.  1. 11.
 16.  0.  0.  1.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1] -> size -> 31 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -2.8039088249206543
desired expected reward: 14.109554290771484



buy possibilites: [-1] 
expected returns: [[-8.902082]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  6.  0.  0.  6.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 14. 30. 20. 28.  8.  1.  6.  2.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.  0.  8.  3. 29. 10.  1.  1. 11.
 16.  0.  0.  1.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1] -> size -> 31 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -80.   0.   0.  40. -30.   0.   0.   0. -16.   0.   0.
   0.   0.] 
sum of rewards: -92.0 

action type: buy - action 0.0
Learning step: -5.495217800140381
desired expected reward: 8.403194427490234






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.  0.  8.  3. 29. 10.  1.  1. 11.
 16.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 20. 28.  8.  1.  6.  2.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [14.  3. 11.  0.  0.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11  0] -> size -> 51 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.  0.  8.  3. 29. 10.  1.  1. 11.
 16.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 14. 30. 20. 28.  8.  1.  6.  2.  2.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [14.  3. 11.  0.  0.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11  0] -> size -> 51 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10.  8. 15.  1.  0.  0.  8.  4.  0.  0.  0.  8.  3. 29. 10.  1.  1. 11.
 16.  0.  0.  1.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 14. 30. 20. 28.  8.  1.  6.  2.  1.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [14.  3. 11.  0.  0.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11  0] -> size -> 51 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [14.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[-8.277774 ]
 [-6.7046022]
 [-8.183383 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 11.  0.  0.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 20. 28.  8.  1.  6.  2.  1.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [10.  1.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8] -> size -> 32 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -4.023831844329834
desired expected reward: -12.925914764404297



action possibilites: [-1] 
expected returns: [[-30.783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 14. 30. 20. 28.  8.  1.  6.  2.  1.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [10.  0. 11.] 
adversary cards in discard: [1. 3.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8] -> size -> 32 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action 14.0
Learning step: -3.6573872566223145
desired expected reward: -10.361989974975586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-27.516056]
 [-29.834208]
 [-28.128876]
 [-22.39557 ]
 [-28.569311]
 [-30.392488]
 [-29.072746]
 [-29.111027]
 [-24.293299]
 [-27.62639 ]
 [-26.53273 ]
 [-30.783009]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11  0] -> size -> 51 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 14. 30. 20. 28.  8.  1.  6.  2.  1.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [10.  0. 11.] 
adversary cards in discard: [1. 3.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8] -> size -> 32 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -2.3617849349975586
desired expected reward: -33.1447868347168



buy possibilites: [-1] 
expected returns: [[-21.5316]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11  0  3] -> size -> 52 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 14. 30. 19. 28.  8.  1.  6.  2.  1.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [10.  0. 11.] 
adversary cards in discard: [1. 3.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8] -> size -> 32 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -70.   0.   0.  20.   0.   0.   0.   0. -17.   0.   0.
   2.   0.] 
sum of rewards: -70.0 

action type: buy - action 3.0
Learning step: -2.578017473220825
desired expected reward: -30.706892013549805






Player: 1 
cards in hand: [10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.] 
cards in discard: [1. 3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  1.  6.  2.  1.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [1. 6. 6. 0. 8.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11  0  3] -> size -> 52 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [ 1.  3. 16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  1.  5.  2.  1.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [1. 6. 6. 0. 8.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11  0  3] -> size -> 52 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 1.  3. 16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 14. 30. 19. 28.  8.  1.  5.  2.  1.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [1. 6. 6. 0. 8.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11  0  3] -> size -> 52 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [1. 6. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-5.986749]
 [-8.107003]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 6. 0. 8.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22
 14 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14
  4 11  0  3] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  1.  5.  2.  1.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 1.  3.  3.  0. 29.] 
adversary cards in discard: [ 1.  3. 16. 11. 10.  0.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16] -> size -> 33 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -2.82696533203125
desired expected reward: -24.358566284179688



action possibilites: [-1] 
expected returns: [[-7.0601006]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 6.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  1.  5.  2.  1.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 1.  3.  3.  0. 29.] 
adversary cards in discard: [ 1.  3. 16. 11. 10.  0.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16] -> size -> 33 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: trash_cards_n_from_hand - action 2
Learning step: -2.560727596282959
desired expected reward: -9.376572608947754





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-6.994299 ]
 [-6.480789 ]
 [-5.14707  ]
 [-7.7373676]
 [-7.0600996]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 14. 30. 19. 28.  8.  1.  5.  2.  1.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 1.  3.  3.  0. 29.] 
adversary cards in discard: [ 1.  3. 16. 11. 10.  0.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16] -> size -> 33 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: -2.5401217937469482
desired expected reward: -9.60022258758545



buy possibilites: [-1] 
expected returns: [[-12.898836]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6] -> size -> 52 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 14. 30. 19. 28.  8.  0.  5.  2.  1.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 1.  3.  3.  0. 29.] 
adversary cards in discard: [ 1.  3. 16. 11. 10.  0.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16] -> size -> 33 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -80.    0.    0.   20.    0.    0.    0.    0.  -17.
    0. -300.    0.    0.] 
sum of rewards: -383.0 

action type: buy - action 6.0
Learning step: -19.182870864868164
desired expected reward: -24.329940795898438






Player: 1 
cards in hand: [ 1.  3.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3.  0. 29.] 
cards in discard: [ 1.  3. 16. 11. 10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  0.  5.  2.  1.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [25. 10.  6. 16. 11.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.  6.  8.
  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6] -> size -> 52 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  3.  0. 29.] 
cards in discard: [ 1.  3. 16. 11. 10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 14. 30. 19. 28.  8.  0.  5.  2.  1.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [25. 10.  6. 16. 11.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.  6.  8.
  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6] -> size -> 52 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  3.  0. 29.] 
cards in discard: [ 1.  3. 16. 11. 10.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 14. 30. 19. 28.  8.  0.  5.  2.  0.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [25. 10.  6. 16. 11.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.  6.  8.
  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6] -> size -> 52 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [25. 10.  6. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 16. 11.] 
expected returns: [[-10.593983]
 [-12.216769]
 [-10.82255 ]
 [-11.647161]
 [-10.967142]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  6. 16. 11.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.  6.  8.
  1.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  0.  5.  2.  0.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 1.  0. 10. 15.  0.] 
adversary cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8] -> size -> 34 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -3.9050750732421875
desired expected reward: -16.803911209106445





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-11.542404]
 [-10.593983]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 10.  6. 16. 11.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.  6.  8.
  1.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6] -> size -> 52 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  0.  5.  2.  0.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [ 1.  0. 10. 15.  0.] 
adversary cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8] -> size -> 34 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -4.017094612121582
desired expected reward: -14.611078262329102



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0. 10. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10. 15.  0.] 
cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  0.  5.  2.  0.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [16.  0.  3. 14.  1.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.  6.  8.
  1.  6.  6. 25. 10.  6. 16. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6] -> size -> 52 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15.  0.  0.] 
cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  0.  5.  2.  0.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [16.  0.  3. 14.  1.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.  6.  8.
  1.  6.  6. 25. 10.  6. 16. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6] -> size -> 52 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 15.  0.  0.] 
cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 14. 30. 19. 28.  8.  0.  5.  2.  0.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [16.  0.  3. 14.  1.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.  6.  8.
  1.  6.  6. 25. 10.  6. 16. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6] -> size -> 52 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 15.  0.  0.] 
cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 14. 30. 19. 28.  8.  0.  4.  2.  0.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [16.  0.  3. 14.  1.] 
adversary cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.  6.  8.
  1.  6.  6. 25. 10.  6. 16. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6] -> size -> 52 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [16.  0.  3. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
expected returns: [[-9.272069]
 [-9.263279]
 [-7.762933]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3. 14.  1.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.  6.  8.
  1.  6.  6. 25. 10.  6. 16. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  0.  4.  2.  0.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8 16] -> size -> 35 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -3.9627978801727295
desired expected reward: -14.556781768798828



action possibilites: [-1] 
expected returns: [[-14.759834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  1.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.  6.  8.
  1.  6.  6. 25. 10.  6. 16. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6] -> size -> 52 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 14. 30. 19. 28.  8.  0.  4.  2.  0.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8 16] -> size -> 35 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action 14.0
Learning step: -3.2439496517181396
desired expected reward: -11.006881713867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-12.38193  ]
 [-13.7976265]
 [-13.109833 ]
 [-10.917072 ]
 [-13.065493 ]
 [-14.27214  ]
 [-15.456711 ]
 [-13.263674 ]
 [-10.818515 ]
 [-11.579137 ]
 [-12.7209635]
 [-10.4231415]
 [-11.982623 ]
 [-14.759836 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  1.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.  6.  8.
  1.  6.  6. 25. 10.  6. 16. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6] -> size -> 52 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 14. 30. 19. 28.  8.  0.  4.  2.  0.  8.  9.  4. 10.  5.  8.  8.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8 16] -> size -> 35 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -2.8379504680633545
desired expected reward: -17.5977840423584



buy possibilites: [-1] 
expected returns: [[-13.174928]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  1.] 
cards in discard: [ 4. 14.  1.  0. 14.  0.  8. 11. 11. 22. 11.  6.  6.  1.  1.  3.  3. 25.
  0. 22. 11.  8.  0. 10.  6.  0.  0.  6.  3. 14.  3. 11.  0.  0.  6.  8.
  1.  6.  6. 25. 10.  6. 16. 11. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10] -> size -> 53 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 14. 30. 19. 28.  8.  0.  4.  2.  0.  8.  9.  4. 10.  4.  8.  8.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8 16] -> size -> 35 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5.    0.   -1.  -80.    0.    0.   20.    0.    0.    0.    0.  -18.
   0.    0.    4.5   0. ] 
sum of rewards: -79.5 

action type: buy - action 10.0
Learning step: -3.635387897491455
desired expected reward: -16.356348037719727






Player: 1 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  0.  4.  2.  0.  8.  9.  4. 10.  4.  8.  8.] 
adversary cards in hand: [0. 6. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10] -> size -> 53 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 14. 30. 19. 28.  8.  0.  4.  2.  0.  8.  9.  4. 10.  4.  8.  8.] 
adversary cards in hand: [0. 6. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10] -> size -> 53 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8 16 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  0.  4.  1.  0.  8.  9.  4. 10.  4.  8.  8.] 
adversary cards in hand: [0. 6. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10] -> size -> 53 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [0. 6. 6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-11.814037]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 1.] 
cards in discard: [] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  0.  4.  1.  0.  8.  9.  4. 10.  4.  8.  8.] 
adversary cards in hand: [ 4.  8.  3.  0. 11.] 
adversary cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8. 11.  0.  0.  0.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8 16 11] -> size -> 36 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -3.907069444656372
desired expected reward: -17.08199691772461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-10.107601 ]
 [-11.736473 ]
 [-10.37543  ]
 [-10.838568 ]
 [-11.772444 ]
 [-11.30741  ]
 [ -7.7108593]
 [-10.085232 ]
 [ -9.31016  ]
 [-11.758839 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 1.] 
cards in discard: [] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10] -> size -> 53 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 14. 30. 19. 28.  8.  0.  4.  1.  0.  8.  9.  4. 10.  4.  8.  8.] 
adversary cards in hand: [ 4.  8.  3.  0. 11.] 
adversary cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8. 11.  0.  0.  0.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8 16 11] -> size -> 36 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -3.9323747158050537
desired expected reward: -15.74641227722168



buy possibilites: [-1] 
expected returns: [[18.363314]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 1.] 
cards in discard: [14.] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  0.  4.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 4.  8.  3.  0. 11.] 
adversary cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8. 11.  0.  0.  0.] 
adversary owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8 16 11] -> size -> 36 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0 -19   0   0  32   0] 
sum of rewards: -73 

action type: buy - action 14.0
Learning step: -2.851282835006714
desired expected reward: -10.562141418457031






Player: 1 
cards in hand: [ 4.  8.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  8.  3.  0. 11.] 
cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8. 11.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0  4 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8
  1  1  3  3  8  0  1  8 16  8 16 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  0.  4.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [11. 25.  6.  0. 10.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14] -> size -> 54 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.] 
cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8. 11.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  0  0 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8  1
  1  3  3  8  0  1  8 16  8 16 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  0.  4.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [11. 25.  6.  0. 10.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14] -> size -> 54 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.] 
cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8. 11.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  0  0 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8  1
  1  3  3  8  0  1  8 16  8 16 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 14. 30. 19. 28.  8.  0.  4.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [11. 25.  6.  0. 10.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14] -> size -> 54 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [11. 25.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10.] 
expected returns: [[-15.77993 ]
 [-15.935011]
 [-18.424723]
 [-15.406797]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  6.  0. 10.] 
cards in discard: [14.  0.  6.  6.  0.  1.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  0.  4.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 0.  8.  1. 16.  1.] 
adversary cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8. 11.  0.  0.  0.  8.  3.  0. 11.] 
adversary owned cards: [29  8  0  0 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8  1
  1  3  3  8  0  1  8 16  8 16 11] -> size -> 35 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -4.082234859466553
desired expected reward: 14.281078338623047



action possibilites: [-1] 
expected returns: [[-24.949875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0. 10.  6.  0.] 
cards in discard: [14.  0.  6.  6.  0.  1.] 
cards in deck: 41 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 19. 28.  8.  0.  4.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 0.  8.  1. 16.  1.] 
adversary cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8. 11.  0.  0.  0.  8.  3.  0. 11.] 
adversary owned cards: [29  8  0  0 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8  1
  1  3  3  8  0  1  8 16  8 16 11] -> size -> 35 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -35 

action type: take_action - action 25.0
Learning step: -1.390136480331421
desired expected reward: -19.814851760864258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-27.571825]
 [-25.87986 ]
 [-24.368773]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0. 10.  6.  0.] 
cards in discard: [14.  0.  6.  6.  0.  1.] 
cards in deck: 41 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14] -> size -> 54 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 14. 30. 19. 28.  8.  0.  4.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 0.  8.  1. 16.  1.] 
adversary cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8. 11.  0.  0.  0.  8.  3.  0. 11.] 
adversary owned cards: [29  8  0  0 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8  1
  1  3  3  8  0  1  8 16  8 16 11] -> size -> 35 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -1.128734827041626
desired expected reward: -26.078609466552734



buy possibilites: [-1] 
expected returns: [[-15.129116]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0. 10.  6.  0.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3.] 
cards in deck: 41 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 18. 28.  8.  0.  4.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 0.  8.  1. 16.  1.] 
adversary cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8. 11.  0.  0.  0.  8.  3.  0. 11.] 
adversary owned cards: [29  8  0  0 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8  1
  1  3  3  8  0  1  8 16  8 16 11] -> size -> 35 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0 -20   0   0   8   0] 
sum of rewards: -37 

action type: buy - action 3.0
Learning step: -0.8964115977287292
desired expected reward: -26.776281356811523






Player: 1 
cards in hand: [ 0.  8.  1. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1. 16.  1.] 
cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8. 11.  0.  0.  0.  8.  3.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0 11 10  0  0  3  3  0 16 11 15  0  0  0  1  0 10  1  0  8  1
  1  3  3  8  0  1  8 16  8 16 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 18. 28.  8.  0.  4.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 0. 16.  1.  0.  0.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3] -> size -> 55 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8. 11.  0.  0.  0.  8.  3.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 18. 28.  8.  0.  4.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 0. 16.  1.  0.  0.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3] -> size -> 55 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8. 11.  0.  0.  0.  8.  3.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 14. 30. 18. 28.  8.  0.  4.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 0. 16.  1.  0.  0.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3] -> size -> 55 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  3. 16. 11. 10.  0.  8.  1.  3.  3.  0. 29. 16. 10.  1.  0. 15.  0.
  0.  0.  8. 11.  0.  0.  0.  8.  3.  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 14. 30. 18. 28.  8.  0.  4.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 0. 16.  1.  0.  0.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3] -> size -> 55 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[-22.325855]
 [-22.451593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  1.  0.  0.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 14. 30. 18. 28.  8.  0.  4.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 0. 15.  3.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -1.9969934225082397
desired expected reward: -17.126110076904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-23.250856]
 [-24.101582]
 [-23.058441]
 [-23.488214]
 [-23.645014]
 [-23.472467]
 [-24.27571 ]
 [-23.991571]
 [-21.540874]
 [-22.169127]
 [-22.784996]
 [-22.542969]
 [-22.410555]
 [-23.042711]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1.  0.  0.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3] -> size -> 55 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 14. 30. 18. 28.  8.  0.  4.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 0. 15.  3.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -1.6107234954833984
desired expected reward: -24.653438568115234



buy possibilites: [-1] 
expected returns: [[13.691369]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1.  0.  0.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16] -> size -> 56 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 14. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 0. 15.  3.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.   0.   0.   0.   0.   0. -21.   0.   0.
   8.   0.] 
sum of rewards: -58.0 

action type: buy - action 16.0
Learning step: -1.4096932411193848
desired expected reward: -25.054710388183594






Player: 1 
cards in hand: [ 0. 15.  3.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  8.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 14. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 3. 22. 11.  1.  0.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16] -> size -> 56 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  8.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 14. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 3. 22. 11.  1.  0.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16] -> size -> 56 
adversary victory points: 0
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 3. 22. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11.] 
expected returns: [[-6.934493 ]
 [-9.205389 ]
 [-7.1426115]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 22. 11.  1.  0.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 14. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [10. 11.  0. 11. 10.] 
adversary cards in discard: [ 0. 15.  3.  8.  8.] 
adversary owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -3.1052825450897217
desired expected reward: 10.58608627319336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-8.009776 ]
 [-7.580838 ]
 [-7.525199 ]
 [-7.1426105]
 [-7.403226 ]
 [-6.934493 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22. 11.  1.  0.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16] -> size -> 56 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 14. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [10. 11.  0. 11. 10.] 
adversary cards in discard: [ 0. 15.  3.  8.  8.] 
adversary owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -2.0681569576263428
desired expected reward: -9.002652168273926



buy possibilites: [-1] 
expected returns: [[-9.181868]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22. 11.  1.  0.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [10. 11.  0. 11. 10.] 
adversary cards in discard: [ 0. 15.  3.  8.  8.] 
adversary owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0 -22   0   0  18   0] 
sum of rewards: -49 

action type: buy - action 1.0
Learning step: -2.2775495052337646
desired expected reward: -9.8583984375






Player: 1 
cards in hand: [10. 11.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 11. 10.] 
cards in discard: [ 0. 15.  3.  8.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 3.  1. 25. 14.  3.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1] -> size -> 57 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0. 11. 10.] 
cards in discard: [ 0. 15.  3.  8.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 3.  1. 25. 14.  3.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1] -> size -> 57 
adversary victory points: 0
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 3.  1. 25. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.] 
expected returns: [[-15.329579]
 [-16.640934]
 [-16.087133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 25. 14.  3.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [3. 0. 0. 1. 1.] 
adversary cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10.] 
adversary owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -2.148080587387085
desired expected reward: -11.329948425292969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-15.122268]
 [-15.158009]
 [-15.329579]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 25. 14.  3.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1] -> size -> 57 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [3. 0. 0. 1. 1.] 
adversary cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10.] 
adversary owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -1.8252121210098267
desired expected reward: -17.154788970947266



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 1.] 
cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 6. 11.  6.  6. 11.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1] -> size -> 57 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 1.] 
cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 6 
card supply: [12. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3. 10.  4.  8.  8.] 
adversary cards in hand: [ 6. 11.  6.  6. 11.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1] -> size -> 57 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 1.] 
cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0 23] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3.  9.  4.  8.  8.] 
adversary cards in hand: [ 6. 11.  6.  6. 11.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1] -> size -> 57 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  6.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[-14.116341]
 [-13.588956]
 [-13.588956]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  6.  6. 11.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3.  9.  4.  8.  8.] 
adversary cards in hand: [ 0. 11.  8.  0.  0.] 
adversary cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.  3.  0.  0.  1.  1.] 
adversary owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0 23] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -1.792397379875183
desired expected reward: -17.12197494506836



action possibilites: [-1] 
expected returns: [[-21.500185]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  6. 11.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1 10] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3.  9.  3.  8.  8.] 
adversary cards in hand: [ 0. 11.  8.  0.  0.] 
adversary cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.  3.  0.  0.  1.  1.] 
adversary owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0 23] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0 -23   0   0   9   0] 
sum of rewards: -39 

action type: gain_card_n - action 7
Learning step: -1.976826548576355
desired expected reward: -11.115379333496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-18.511518]
 [-21.500185]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  6. 11.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1 10] -> size -> 58 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3.  9.  3.  8.  8.] 
adversary cards in hand: [ 0. 11.  8.  0.  0.] 
adversary cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.  3.  0.  0.  1.  1.] 
adversary owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0 23] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -0.6180617213249207
desired expected reward: -22.11824607849121






Player: 1 
cards in hand: [ 0. 11.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  0.  0.] 
cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.  3.  0.  0.  1.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  0 11 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3
  8  0  1  8 16  8 16 11  0 23] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3.  9.  3.  8.  8.] 
adversary cards in hand: [ 8.  1. 14.  4. 10.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3. 10. 11.  6.  6.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1 10] -> size -> 58 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.  3.  0.  0.  1.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3  8  0  1
  8 16  8 16 11  0 23] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3.  9.  3.  8.  8.] 
adversary cards in hand: [ 8.  1. 14.  4. 10.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3. 10. 11.  6.  6.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1 10] -> size -> 58 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.  3.  0.  0.  1.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3  8  0  1
  8 16  8 16 11  0 23] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3.  9.  3.  8.  8.] 
adversary cards in hand: [ 8.  1. 14.  4. 10.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3. 10. 11.  6.  6.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1 10] -> size -> 58 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.  3.  0.  0.  1.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3  8  0  1
  8 16  8 16 11  0 23  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3.  9.  3.  8.  8.] 
adversary cards in hand: [ 8.  1. 14.  4. 10.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3. 10. 11.  6.  6.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1 10] -> size -> 58 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 8.  1. 14.  4. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 10.] 
expected returns: [[-10.164529 ]
 [ -9.439914 ]
 [ -5.5422134]
 [ -8.031066 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 14.  4. 10.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3. 10. 11.  6.  6.  6.
 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1 10] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3.  9.  3.  8.  8.] 
adversary cards in hand: [16.  0.  0.  0. 16.] 
adversary cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.  3.  0.  0.  1.  1.  0.  8.
  0.] 
adversary owned cards: [29  8 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3  8  0  1
  8 16  8 16 11  0 23  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -1.3486112356185913
desired expected reward: -22.848796844482422



action possibilites: [-1] 
expected returns: [[-23.550474]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  4. 10.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3. 10. 11.  6.  6.  6.
 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1 10] -> size -> 58 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3.  9.  3.  8.  8.] 
adversary cards in hand: [ 0.  0. 16.] 
adversary cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.  3.  0.  0.  1.  1.  0.  8.
  0.  0. 16.] 
adversary owned cards: [29  8 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3  8  0  1
  8 16  8 16 11  0 23  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 14.0
Learning step: -1.5027750730514526
desired expected reward: -7.044988632202148





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-20.441883]
 [-22.392878]
 [-20.921745]
 [-21.197828]
 [-22.867552]
 [-21.698296]
 [-18.088474]
 [-20.478611]
 [-19.431345]
 [-23.550474]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  4. 10.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3. 10. 11.  6.  6.  6.
 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1 10] -> size -> 58 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 13. 30. 18. 28.  8.  0.  3.  1.  0.  8.  9.  3.  9.  3.  8.  8.] 
adversary cards in hand: [ 0.  0. 16.] 
adversary cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.  3.  0.  0.  1.  1.  0.  8.
  0.  0. 16.] 
adversary owned cards: [29  8 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3  8  0  1
  8 16  8 16 11  0 23  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -0.5331194996833801
desired expected reward: -24.083593368530273



buy possibilites: [-1] 
expected returns: [[-7.813778]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  4. 10.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3. 10. 11.  6.  6.  6.
 11. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1 10 16] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 13. 30. 18. 28.  8.  0.  2.  1.  0.  8.  9.  3.  9.  3.  8.  8.] 
adversary cards in hand: [ 0.  0. 16.] 
adversary cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.  3.  0.  0.  1.  1.  0.  8.
  0.  0. 16.] 
adversary owned cards: [29  8 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3  8  0  1
  8 16  8 16 11  0 23  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0 -24   0   0  32   0] 
sum of rewards: -17 

action type: buy - action 16.0
Learning step: 0.03408107906579971
desired expected reward: -21.163742065429688






Player: 1 
cards in hand: [ 0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.] 
cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.  3.  0.  0.  1.  1.  0.  8.
  0.  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3  8  0  1
  8 16  8 16 11  0 23  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 13. 30. 18. 28.  8.  0.  2.  1.  0.  8.  9.  3.  9.  3.  8.  8.] 
adversary cards in hand: [ 8.  1. 11.  0. 22.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3. 10. 11.  6.  6.  6.
 11. 16. 14.  8.  1.  4. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1 10 16] -> size -> 59 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.  3.  0.  0.  1.  1.  0.  8.
  0.  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3  8  0  1
  8 16  8 16 11  0 23  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 13. 30. 18. 28.  8.  0.  2.  1.  0.  8.  9.  3.  9.  3.  8.  8.] 
adversary cards in hand: [ 8.  1. 11.  0. 22.] 
adversary cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3. 10. 11.  6.  6.  6.
 11. 16. 14.  8.  1.  4. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1 10 16] -> size -> 59 
adversary victory points: 0
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [ 8.  1. 11.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 22.] 
expected returns: [[-9.848585 ]
 [-9.415884 ]
 [-9.57727  ]
 [-4.7937922]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 11.  0. 22.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3. 10. 11.  6.  6.  6.
 11. 16. 14.  8.  1.  4. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1 10 16] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 13. 30. 18. 28.  8.  0.  2.  1.  0.  8.  9.  3.  9.  3.  8.  8.] 
adversary cards in hand: [ 8.  1.  3.  0. 29.] 
adversary cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.  3.  0.  0.  1.  1.  0.  8.
  0.  0. 16.  0.  0. 16.] 
adversary owned cards: [29  8 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3  8  0  1
  8 16  8 16 11  0 23  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -2.0314295291900635
desired expected reward: -9.845207214355469



action possibilites: [-1] 
expected returns: [[-15.370177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 11.  0.  6.  0.  8.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3. 10. 11.  6.  6.  6.
 11. 16. 14.  8.  1.  4. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1 10 16] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 13. 30. 18. 28.  8.  0.  2.  1.  0.  8.  9.  3.  9.  3.  8.  8.] 
adversary cards in hand: [ 8.  1.  3.  0. 29.] 
adversary cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.  3.  0.  0.  1.  1.  0.  8.
  0.  0. 16.  0.  0. 16.] 
adversary owned cards: [29  8 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3  8  0  1
  8 16  8 16 11  0 23  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: LIBRARY: skip_action_card - action 1
Learning step: -1.0825865268707275
desired expected reward: -11.347436904907227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-14.632129]
 [-16.622185]
 [-13.479592]
 [-14.947698]
 [-16.260658]
 [-15.728249]
 [-12.435802]
 [-13.311379]
 [-12.322564]
 [-15.37017 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 11.  0.  6.  0.  8.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3. 10. 11.  6.  6.  6.
 11. 16. 14.  8.  1.  4. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1 10 16] -> size -> 59 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 13. 30. 18. 28.  8.  0.  2.  1.  0.  8.  9.  3.  9.  3.  8.  8.] 
adversary cards in hand: [ 8.  1.  3.  0. 29.] 
adversary cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.  3.  0.  0.  1.  1.  0.  8.
  0.  0. 16.  0.  0. 16.] 
adversary owned cards: [29  8 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3  8  0  1
  8 16  8 16 11  0 23  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -0.7976489663124084
desired expected reward: -16.16782569885254



Player 1 won the game! 



Player 0 bought cards:
Copper: 5 
Silver: 7 
Gold: 0 
Estate: 4 
Duchy: 1 
Province: 0 
Curse: 10 

Remodel: 4 
Workshop: 6 
Chapel: 2 
Witch: 2 
Poacher: 0 
Militia: 5 
Market: 0 
Village: 2 
Library: 2 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 8.  1. 11.  0.  6.  0.  8.] 
cards in discard: [14.  0.  6.  6.  0.  1.  3. 25. 11.  6.  0. 10.  6.  0. 16.  0. 16.  1.
  0.  0.  1.  3. 22. 11.  1.  0.  3.  1. 25. 14.  3. 10. 11.  6.  6.  6.
 11. 16. 14.  8.  1.  4. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  1  3  0  1  6 16  1  1  0 11 25 10  1  6  0 22 14
 14 11  6 11 11 14 11  0  3 16 25  6 22  6  6  8 10  8  6  6  1  8 14  4
 11  0  3  6 10 14  3 16  1 10 16 11] -> size -> 60 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 13. 30. 18. 28.  8.  0.  2.  0.  0.  8.  9.  3.  9.  3.  8.  8.] 
adversary cards in hand: [ 8.  1.  3.  0. 29.] 
adversary cards in discard: [ 0. 15.  3.  8.  8. 10. 11.  0. 11. 10. 23.  3.  0.  0.  1.  1.  0.  8.
  0.  0. 16.  0.  0. 16.] 
adversary owned cards: [29  8 10  0  0  3  3  0 11 15  0  0  0  0 10  0  8  1  1  3  3  8  0  1
  8 16  8 16 11  0 23  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5 -500    0  -40    0    0   20    0    0    0    0  -25    0    0
    9    0] 
sum of rewards: -541 

action type: buy - action 11.0
Learning step: -26.236967086791992
desired expected reward: -42.49763488769531



